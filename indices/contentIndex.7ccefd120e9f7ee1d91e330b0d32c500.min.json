{"/":{"title":"CarlosGG's Knowledge Garden ü™¥","content":"Welcome to my personal digital knowledge garden, a collection of notes and resources that I started to compile a couple of years ago as my best attempt to become a somewhat functional _information junkie_. Here I curate, organize and catalog the stuff I ~~read~~ [skim over](https://learningcenter.unc.edu/tips-and-tools/skimming/) everyday. \n\n## About digital knowledge gardens\n\nThe concept of a digital knowledge garden, a.k.a. \"second brain\", has been around for quite [some time](https://maggieappleton.com/garden-history) and is related to that of [personal knowledge management](https://en.wikipedia.org/wiki/Personal_knowledge_management). Digital gardens build upon note-taking methodologies such as [Zettelkasten](https://en.wikipedia.org/wiki/Zettelkasten) or [Evergreen](https://notes.andymatuschak.org/Evergreen_notes). In short, a digital garden is something in between a blog and a wiki; a way to accumulate personal knowledge over time in an explorable space and in a non-linear fashion, while benefiting from fancy features such as (bidirectional) links between different topics, and visual graphs or [mind maps](https://en.wikipedia.org/wiki/Mind_map). This GitHub [repository](https://github.com/MaggieAppleton/digital-gardeners) offers a complete list of tools and workflows for aspiring gardeners wishing to grow a knowledge garden. \n\nThroughout my journey with personal knowledge management, I have used a combination of different tools and practices with varying levels of success: curating lists of links as bookmarks or [Pocket](https://getpocket.com/) collections, compiling notes with [Evernote](https://evernote.com/) or [OneNote](https://www.microsoft.com/es-es/microsoft-365/onenote/digital-note-taking-app), organizing ideas in mind maps with [XMind](https://www.xmind.net/), and collecting bibliographic data in [Zotero](https://www.zotero.org/). Nowadays, I use [Obsidian](https://obsidian.md/) for growing my digital knowledge garden and managing my markdown notes locally. Although Obsidian cannot fully replace all one of the aforementioned tools, it comes really close to it by providing flexible workflows for personal knowledge management. Apart from Obsidian, I use [Quartz](https://quartz.jzhao.xyz/) for publishing and sharing the content of my vault using [GitHub pages](https://carlos-gg.github.io/digitalgarden/). \n\n## Main motivation for creating this knowledge garden\n\nKeeping up with the literature related to Artificial Intelligence (AI) and Machine Learning (ML) is ~~impossible~~ very difficult and, although tools like the [Deep Learning Monitor](https://deeplearn.org/) might be of help, the \"Fear Of Missing Out\" [(FOMO)](https://en.wikipedia.org/wiki/Fear_of_missing_out) information is hardly avoidable, especially if you are an _information junkie_ like me. While my personal knowledge garden is mainly focused on AI, it is [not meant to be a complete](https://nick.groenen.me/notes/digital-garden-notes-may-be-incomplete/) or exhaustive mapping of all there is to know about AI or ML. It is also not aimed at teaching anyone or to be pedagogical, though it can certainly point you to a multitude of educational resources. The content of this knowledge garden is based merely on my personal research notes, the topics that I have been interested in or that I have come across in my work as a researcher in AI/ML applied to Earth Sciences. \n\n## What to find in here\n\nMost notes in this knowledge garden are focused on specific topics (e.g., [GFlowNets](AI/Deep%20learning/GFlowNets.md)) but others are broader [_maps of content_](https://jing.io/garden/MOC/) (e.g., [Deep Learning](AI/Deep%20learning/DL.md)). The notes are composed of common subsections:\n\n- **Resources**: definitions, wikipedia entries, blog posts and other useful stuff.\n- **Books**: well... books, mostly free or open source.\n- **Courses**: online and free/open courses mostly by recognized universities and institutions.\n- **References**: peer-reviewed publications and papers.\n- **Code**: open source code and relevant libraries.\n- **Talks**: talks, video summaries and video podcasts.\n\nMost of the entries (bullet points) in a note carry a specific tag, depending on the subsections they belong to, for example: _#PAPER_,  _#COURSE_, _#BOOK_ or _#CODE_. The following are some _maps of content_ or important pages you may want to start from:\n\n- [AI](AI/AI.md)\n- [Deep Learning](AI/Deep%20learning/DL.md)\n- [Machine Learning](AI/Machine%20Learning.md) \n- [Data Science](AI/DS%20and%20DataEng/Data%20Science.md)\n- [AI for good](AI4G/AI4good.md)\n\nFeel free to look around, either by exploring the _maps of content_ above, checking out the main index of [notes related to AI](https://carlos-gg.github.io/digitalgarden/ai/), using the search box, or by interacting with the mind map on top of the page. Expect some broken links and all sort of bugs and errors. I hope you find something useful in this knowledge garden. Enjoy!","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/AI":{"title":"Artificial Intelligence","content":"## Resources\n- The expression _artificial intelligence_ is an umbrella term encompassing a suite of technologies that can perform complex tasks when acting in conditions of uncertainty, including visual perception, speech recognition, natural language processing, reasoning, learning from data, and a range of optimisation problems.\n- https://en.wikipedia.org/wiki/Artificial_intelligence\n- [AtHomeWithAI | Deepmind](https://storage.googleapis.com/deepmind-media/research/New_AtHomeWithAI%20resources.pdf)\n- https://github.com/owainlewis/awesome-artificial-intelligence\n- https://github.com/amusi/awesome-ai-awesomeness\n- https://github.com/JosPolfliet/awesome-ai-usecases\n- [Stop Calling Everything AI, Machine-Learning Pioneer](https://spectrum.ieee.org/stop-calling-everything-ai-machinelearning-pioneer-says)\n- [Artificial Intelligence‚ÄîThe Revolution Hasn‚Äôt Happened Yet](https://hdsr.mitpress.mit.edu/pub/wot7mkc1/release/9)\n- [Making sense of artificial intelligence (Google)](https://atozofai.withgoogle.com/)\n- [People + AI guidebook (Google)](https://pair.withgoogle.com/guidebook/patterns )\n- [General AI Challenge](https://www.general-ai-challenge.org/)\n- [AI Index (Stanford)](https://aiindex.stanford.edu/report/ )\n- [AI Playbook](http://aiplaybook.a16z.com/)\n- [What‚Äôs the Difference Between AI, ML, and Deep Learning?](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)\n- [The AI takeover is coming. Let's embrace it](https://www.wired.com/2016/12/the-ai-takeover-is-coming-lets-embrace-it/)\n- [What worries me about AI](https://medium.com/@francois.chollet/what-worries-me-about-ai-ed9df072b704)\n- [Machine Learning Confronts the Elephant in the Room](https://www.quantamagazine.org/machine-learning-confronts-the-elephant-in-the-room-20180920/)\n- [AI Experiments](https://aiexperiments.withgoogle.com/ )\n- [Where will AGI come from? (Karpathy)](https://ivenzor.com/wp-content/uploads/2018/07/yconftalk-170902200916.pdf)\n- [AlphaGo Zero](https://deepmind.com/blog/alphago-zero-learning-scratch/)\n\t- [AlphaGo Zero Explained In One Diagram](https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0)\n\n### AI in Science and research\n- [The AI revolution in science: applications and new research directions](https://blogs.royalsociety.org/in-verba/2019/08/07/the-ai-revolution-in-science-applications-and-new-research-directions/)\n- [The AI revolution in scientific research (The Royal Society, The Alan Turing Institute)](https://royalsociety.org/-/media/policy/projects/ai-and-society/AI-revolution-in-science.pdf)\n- [The AI revolution in science](https://www.sciencemag.org/news/2017/07/ai-revolution-science)\n- [Artificial intelligence in research (Musib 2017)](https://science.sciencemag.org/content/357/6346/28)\n\n### AI for good\n- See [AI4good](AI4G/AI4good.md)\n\n## Events\n- [Neural Information Processing Systems Conference (NeurIPS)](https://nips.cc/)\n\t- [Proceedings](http://papers.nips.cc/)\n\t- [Videos](https://nips.cc/Conferences/2018/Videos)\n- [International Conference on Machine Learning (ICML)](https://icml.cc/)\n- [International Conference for Learning Representations (ICLR)](https://iclr.cc/)\n- [AI \u0026 Deep Learning Conference (NVIDIA)](https://www.nvidia.com/en-us/gtc/)\n- [AAAI Conference on Artificial Intelligence](http://www.aaai.org/Conferences/conferences.php)\n- [World summit AI](https://worldsummit.ai/)\n\n## References\n- #PAPER [The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence (Marcus 2020)](https://arxiv.org/abs/2002.06177v3)\n\t- https://www.zdnet.com/article/rebooting-ai-deep-learning-meet-knowledge-graphs/\n\t- #TALK [AI debate: Yoshua Bengio | Gary Marcus](https://www.youtube.com/watch?v=EeqwFjqFvJA)\n\n## Books\n- #BOOK [AI Transformation Playbook (Andrew Ng, 2018)](https://landing.ai/ai-transformation-playbook/)\n- #BOOK [Artificial Intelligence - Foundations of Computational Agents (Poole 2017, Cambridge)](http://artint.info/2e/index.html)\n- #BOOK [The Future of Machine Intelligence (Beyer 2016, O'REILLY)](https://www.oreilly.com/library/view/the-future-of/9781492042334/)\n- #BOOK [Artificial Intelligence - A Modern Approach (Russell \u0026 Norvig, 2010)](http://aima.cs.berkeley.edu/)\n\t- https://github.com/aimacode\n\t- [Javascript visualization (and implementation) of algorithms](http://aimacode.github.io/aima-javascript/)\n- #BOOK [The quest for AI - A history of ideas and achievements (Nilson 2010, Cambridge)](http://ai.stanford.edu/~nilsson/QAI/qai.pdf)\n## Courses\n- #COURSE [Introduction to Artificial Intelligence (CS 188, Berkeley)](https://inst.eecs.berkeley.edu/~cs188/fa18/)\n- #COURSE [Intro to AI (CS188 , UC Berkeley)](http://ai.berkeley.edu/home.html, )\n\t- http://ai.berkeley.edu/lecture_videos.html\n- #COURSE [Introduction to Artificial Intelligence with Python (CS50, Harvard U)](https://pll.harvard.edu/course/cs50s-introduction-artificial-intelligence-python?delta=0)\n- #COURSE [Introduction to Artificial Intelligence (ULiege)](https://github.com/glouppe/info8006-introduction-to-ai)\n- #COURSE [Artificial General Intelligence (MIT 6.S099)](https://agi.mit.edu/)\n- #COURSE [Artificial General (MINES Saint-Etienne)](https://www.emse.fr/~picard/cours/ai/)\n- #COURSE [Elements of AI (Reaktor and the U of Helsinki)](https://www.elementsofai.com/)\n- #COURSE [Introduction to Artificial Intelligence (Coursera - UVA Darden )](https://www.coursera.org/learn/introduction-to-ai#reviews)\n- #COURSE [Artificial Intelligence (edX - Columbia U)](https://www.edx.org/course/artificial-intelligence-ai-columbiax-csmm-101x-0)\n- #COURSE [Artificial Intelligence Nanodegree (Udacity)](https://www.udacity.com/course/artificial-intelligence-nanodegree--nd889)\n- #COURSE [Self-Driving Car Engineer (Udacity)](https://www.udacity.com/drive)\n\t- https://github.com/udacity/self-driving-car\n\t- https://github.com/udacity/self-driving-car-sim\n\t- https://github.com/jessicayung/self-driving-car-nd\n\t- https://github.com/Everhusk/Self-Driving-Car-Engineering\n\n## Talks\n- #TALK [Lex Fridman Podcast](https://lexfridman.com/podcast/)\n- #TALK [Building machines that see, learn, and think like people (Tenenbaum)](https://www.youtube.com/watch?v=7ROelYvo8f0)\n- #TALK [The Rise of Artificial Intelligence through Deep Learning (Bengio)](https://www.youtube.com/watch?v=uawLjkSI7Mo)\n- #TALK [Creating human-level AI (Bengio)](https://www.youtube.com/watch?v=ZHYXp3gJCaI)\n- #TALK [A DARPA Perspective on Artificial Intelligence](https://www.youtube.com/watch?time_continue=2\u0026v=-O01G3tSYpU)\n- #TALK [AI, Deep Learning, and Machine Learning: A Primer](https://a16z.com/2016/06/10/ai-deep-learning-machines/ )\n- #TALK [Symbolic, Statistical and Causal Artificial Intelligence, MLSS 2020](https://www.youtube.com/watch?v=8staJlMbAig)\n- #TALK [Francois Chollet - Intelligence and Generalisation (Interview/podcast)](https://www.youtube.com/watch?v=J0p_thJJnoo)\n\n\n## Related fields and concepts\n\n### Math and Statistics\nSee [Math and Statistics](AI/Math%20and%20Statistics/Math%20and%20Statistics.md)\n\n### Data engineering and computer science\nSee [Data engineering and computer science](AI/DS%20and%20DataEng/Data%20engineering%20and%20computer%20science.md)\n\n### Data Science\nSee [Data Science](AI/DS%20and%20DataEng/Data%20Science.md)\n\n### Machine Learning\nSee [Machine Learning](AI/Machine%20Learning.md)\n\n### Computer vision\nSee [Computer vision](AI/Computer%20Vision/Computer%20vision.md)\n\n### NLP\nSee [NLP](AI/NLP.md)\n\n### Deep Learning\nSee [DL](AI/Deep%20learning/DL.md)\n\n### Causality\nSee [Causality](AI/Causality.md)\n\n### Problem Solving and Search\nSee [Problem Solving and Search](AI/Problem%20Solving%20and%20Search.md)\n\n### Automated planning\nSee [Automated planning](AI/Automated%20planning.md)\n\n### Fair AI\nSee [FairAI](AI/FairAI.md)\n\n### Explainable AI\nSee [XAI](AI/XAI.md)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Active-learning":{"title":"Active learning","content":"## Resources\n* https://en.wikipedia.org/wiki/Active_learning_(machine_learning)\n* Active learning refers to algorithms that take an active role in the selection of which ex-amples are labeled. Active learning assumes that there is an ‚Äòoracle‚Äô, such as a human expert, that can be queried to get ground-truth labels for selected unlabeled instances. \n* There are situations in which unlabeled data is abundant but manually labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning. With this approach, there is a risk that the algorithm be overwhelmed by uninformative examples.\n- [Overview of Active Learning for Deep Learning](https://jacobgil.github.io/deeplearning/activelearning)\n- #PAPER [An open source machine learning framework for efficient and transparent systematic reviews (van de Schoot 2021)](https://www.nature.com/articles/s42256-020-00287-7)\n\t- #CODE https://github.com/asreview/asreview\n\n## References\n- #PAPER [Active learning literature survey (Settles 2010)](http://burrsettles.com/pub/settles.activelearning.pdf)\n- #PAPER [Active Learning for Convolutional Neural Networks: A Core-Set Approach (2018)](https://openreview.net/forum?id=H1aIuk-RW)\n- #PAPER [Rethinking deep active learning: Using unlabeled data at model training (Simeoni 2019)](https://arxiv.org/abs/1911.08177)\n- #PAPER [Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds (2020)](https://openreview.net/forum?id=ryghZJBKPS )\n\n\n### Active learning for anomaly discovery\n- #PAPER [Incorporating Expert Feedback into Active Anomaly Discovery (Das 2016)](https://ieeexplore.ieee.org/document/7837915)\n\t- http://web.engr.oregonstate.edu/~tgd/publications/das-wong-dietterich-fern-emmott-incorporating-expert-feedback-into-active-anomaly-discovery-icdm2016.pdf\n- #PAPER [Deep Active Learning for Anomaly Detection (Pimentel 2018)](https://arxiv.org/abs/1805.09411)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Anomaly-and-Outlier-Detection":{"title":"Anomaly and Outlier Detection","content":"See \"Active learning for anomaly discovery\" section in [Active learning](AI/Active%20learning.md)\n\n## Resources\n- Most of the outlier detection approaches belong to [Unsupervised learning](AI/Unsupervised%20learning/Unsupervised%20learning.md) although it might be framed as a [Semi-supervised learning](AI/Semi-supervised%20learning.md) problem. In data mining, anomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data. Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.\n- https://towardsdatascience.com/density-based-algorithm-for-outlier-detection-8f278d2f7983 \n- https://towardsdatascience.com/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561 \n- [Novelty and Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)\n- [Comparing anomaly detection algorithms for outlier detection on toy datasets](https://scikit-learn.org/stable/auto_examples/plot_anomaly_comparison.html)\n- #TALK [Anomaly detection with TensorFlow (VAEs)](https://www.youtube.com/watch?v=2K3ScZp1dXQ)\n- [Local outlier factor](https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py)\n- One-class SVM\n\t- https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/one-class-support-vector-machine\n\t- https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py\n  - Z-score\n\t- The z-score or standard score of an observation is a metric that indicates how many standard deviations a data point is from the sample‚Äôs mean, assuming a gaussian distribution. This makes z-score a parametric method. \n\t- Z-score is a simple, yet powerful method to get rid of outliers in data if you are dealing with parametric distributions in a low dimensional feature space. For nonparametric problems Dbscan and Isolation Forests can be good solutions.\n- Dbscan\n\t- Density Based Spatial Clustering of Applications with Noise\n\t- Dbscan is a density based clustering algorithm, it is focused on finding neighbors by density (MinPts) on an ‚Äòn-dimensional sphere‚Äô with radius …õ. A cluster can be defined as the maximal set of 'density connected points' in the feature space.\n\t- Dbscan then defines different classes of points: core, border and outlier points.\n\n  \n## Code\n- #CODE [Pyod](https://github.com/yzhao062/pyod)\n\t- https://pyod.readthedocs.io/en/latest/\n\t- PyOD is a comprehensive and scalable Python toolkit for detecting outlying objects in multivariate data. This exciting yet challenging field is commonly referred as Outlier Detection or Anomaly Detection.\n - #CODE [Anomaly detection (Twitter, for R)](https://github.com/twitter/AnomalyDetection)\n  \n  \n## References\n- #PAPER [Isolation forest (Liu 2008)](https://ieeexplore.ieee.org/document/4781136 )\n\t- #TALK [Unsupervised Anomaly Detection with Isolation Forest - Pydata 2018](https://www.youtube.com/watch?v=5p8B2Ikcw-k)\n\t- https://quantdare.com/isolation-forest-algorithm/\n\t- https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py\n\t- https://towardsdatascience.com/outlier-detection-with-isolation-forest-3d190448d45e\n\t- Isolation forest‚Äôs basic principle is that outliers are few and far from the rest of the observations. To build a tree (training), the algorithm randomly picks a feature from the feature space and a random split value ranging between the maximums and minimums. This is made for all the observations in the training set. To build the forest a tree ensemble is made averaging all the trees in the forest.\n    - Then for prediction, it compares an observation against that splitting value in a ‚Äúnode‚Äù, that node will have two node children on which another random comparisons will be made. The number of ‚Äúsplittings‚Äù made by the algorithm for an instance is named: ‚Äúpath length‚Äù. As expected, outliers will have shorter path lengths than the rest of the observations.\n- #PAPER [Modeling Extreme Events in Time Series Prediction (Ding 2019)](http://staff.ustc.edu.cn/~hexn/papers/kdd19-timeseries.pdf)\n- #PAPER [Bayesian Anomaly Detection and Classification (2019)](https://arxiv.org/abs/1902.08627  )\n\n\n### DL-based\nSee \"GANs for anomaly detection\" section in [GANs](AI/Deep%20learning/GANs.md)\n\n- #PAPER [Learning Deep Features for One-Class Classification (Perera 2018)](https://arxiv.org/abs/1801.05365)\n- #PAPER [Deep One-Class Classification (Ruff 2018)](http://proceedings.mlr.press/v80/ruff18a.html)\n- #PAPER [Learning and Evaluating Representations for Deep One-Class Classification (Sohn 2021)](https://openreview.net/forum?id=HCSgyPUfeDj)\n\t- #CODE https://github.com/google-research/deep_representation_one_class\n\t- https://ai.googleblog.com/2021/09/discovering-anomalous-data-with-self.html\n- #PAPER [VOS: Learning What You Don't Know by Virtual Outlier Synthesis (Du 2022)](https://arxiv.org/pdf/2202.01197)\n\t- #CODE https://github.com/deeplearning-wisc/vos\n\t- [Paper explained](https://www.youtube.com/watch?v=i-J4T3uLC9M\u0026list=WL\u0026index=59\u0026t=4s)\n\n#### Code\n- #CODE [Anomalib](https://github.com/openvinotoolkit/anomalib)\n\t- An anomaly detection library comprising state-of-the-art algorithms and features such as experiment management, hyper-parameter optimization, and edge inference\n\t- https://openvinotoolkit.github.io/anomalib/\n\t- Anomalib is a deep learning library that aims to collect state-of-the-art anomaly detection algorithms for benchmarking on both public and private datasets\n- #CODE [Orion - A machine learning library for detecting anomalies in signals](https://github.com/signals-dev/Orion) ^oriontfanomalies\n\t- https://sintel.dev/Orion/\n\t- Orion is a machine learning library built for unsupervised time series anomaly detection","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/AutoML":{"title":"AutoML","content":"See [Model selection and tuning](AI/Supervised%20Learning/Model%20selection%20and%20tuning.md)\n\n## Resources\n- https://en.wikipedia.org/wiki/Automated_machine_learning\n- Automated machine learning (AutoML) is the process of automating the process of applying machine learning to real-world problems. AutoML covers the complete pipeline from the raw dataset to the deployable machine learning model. AutoML was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine learning.\n- Automated machine learning can target various stages of the machine learning process. Steps to automate are:\n\t- Data preparation and ingestion (from raw data and miscellaneous formats)\n\t\t- Column type detection; e.g., boolean, discrete numerical, continuous numerical, or text\n\t\t- Column intent detection; e.g., target/label, stratification field, numerical feature, categorical text feature, or free text feature\n\t\t- Task detection; e.g., binary classification, regression, clustering, or ranking\n\t- Feature engineering\n\t\t- Feature selection\n\t\t- Feature extraction\n\t\t- Meta learning and transfer learning\n\t\t- Detection and handling of skewed data and/or missing values\n\t- Model selection. See [Model selection and tuning](AI/Supervised%20Learning/Model%20selection%20and%20tuning.md)\n\t- Hyperparameter optimization of the learning algorithm and featurization\n\t- Pipeline selection under time, memory, and complexity constraints\n\t- Selection of evaluation metrics and validation procedures\n\t- Problem checking\n\t\t- Leakage detection\n\t\t- Misconfiguration detection\n\t- Analysis of results obtained\n\t- User interfaces and visualizations for automated machine learning\n- https://www.automl.org/\n- http://www.kdnuggets.com/2017/01/current-state-automated-machine-learning.html\n- https://medium.com/airbnb-engineering/automated-machine-learning-a-paradigm-shift-that-accelerates-data-scientist-productivity-airbnb-f1f8a10d61f8\n\n\n## Books\n-  #BOOK [AutoML: Methods, systems, challenges](https://www.automl.org/book/)\n\n\n## Code\n- #CODE [FLAML - Fast and Lightweight AutoML](https://github.com/microsoft/FLAML)\n\t- FLAML is powered by a new, cost-effective hyperparameter optimization and learner selection method invented by Microsoft Research\n- #CODE [EvalML - AutoML library written in python](https://github.com/alteryx/evalml)\n\t- https://innovation.alteryx.com/introducing-evalml/\n- #CODE [Model Search](https://github.com/google/model_search)\n\t- https://ai.googleblog.com/2021/02/introducing-model-search-open-source.html\n- #CODE [Auto-sklearn](https://github.com/automl/auto-sklearn)\n\t- http://automl.github.io/auto-sklearn/stable/\n\t- [Efficient and Robust Automated Machine Learning (Feurer 2015)](https://ml.informatik.uni-freiburg.de/papers/15-NIPS-auto-sklearn-preprint.pdf)\n\t- http://www.kdnuggets.com/2016/08/winning-automl-challenge-auto-sklearn.html\n- #CODE [TPOT](https://github.com/rhiever/tpot)\n\t- http://rhiever.github.io/tpot/\n\t- Consider TPOT yourData Science Assistant. TPOT is a Python tool that automatically creates and optimizes ML pipelines using genetic programming\n\t- https://blog.alookanalytics.com/2017/05/25/automate-your-machine-learning/\n- #CODE [AutoKeras](https://github.com/keras-team/autokeras)\n- #CODE [H2O autoML](https://blog.h2o.ai/2017/06/automatic-machine-learning/)\n- #CODE [Adanet - Fast and flexible AutoML with learning guarantees](https://github.com/tensorflow/adanet )\n\t- https://adanet.readthedocs.io\n\t- AdaNet is a lightweight TensorFlow-based framework for automatically learning high-quality models with minimal expert intervention\n- #CODE [FEDOT](https://github.com/nccr-itmo/FEDOT)\n\t- Automated modeling and machine learning framework\n\t- https://fedot.readthedocs.io/en/latest/\n\n\n## Neural architecture search (NAS)\n- NAS is closely related to hyperparameter optimization and is a subfield of automated machine learning (AutoML).\n- https://en.wikipedia.org/wiki/Neural_architecture_search\n\t- Neural architecture search (NAS) is a technique for automating the design of artificial neural networks (ANN), a widely used model in the field of machine learning. NAS has been used to design networks that are on par or outperform hand-designed architectures. Methods for NAS can be categorized according to the search space, search strategy and performance estimation strategy used:\n\t- The search space defines the type(s) of ANN that can be designed and optimized.\n\t- The search strategy defines the approach used to explore the search space.\n\t- The performance estimation strategy evaluates the performance of a possible ANN from its design (without constructing and training it).\n\n- [Literature on NAS](https://www.automl.org/automl/literature-on-neural-architecture-search/)\n- #PAPER [AdaNet: Adaptive Structural Learning of Artificial Neural Networks (Cortes 2017)](http://proceedings.mlr.press/v70/cortes17a.html)\n\t- https://ai.googleblog.com/2018/10/introducing-adanet-fast-and-flexible.html?m=1\n- #PAPER [Improving Neural Architecture Search Image Classifiers via Ensemble Learning, AdaNas (Macko 2019)](https://arxiv.org/abs/1903.06236)\n- #PAPER [Up to two billion times acceleration of scientific simulations with deep neural architecture search (Kasim 2020)](https://arxiv.org/abs/2001.08055)\n- #PAPER [Neural Architecture Search without Training (Mellor 2020)](https://arxiv.org/abs/2006.04647)\n\t- [Paper explained](https://www.youtube.com/watch?v=a6v92P0EbJc)\n- #PAPER [Automated Evolutionary Approach for the Design of Composite Machine Learning Pipelines (Nikitin 2021)](https://arxiv.org/abs/2106.15397)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Automated-planning":{"title":"Automated planning","content":"## Resources\n- AI Planning is a branch of artificial intelligence that concerns the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles. Unlike classical control and classification problems, the solutions are complex and must be discovered and optimized in multidimensional space.\n- [A brief overview of AI planning](https://users.aalto.fi/~rintanj1/jussi/planning.html)\n- Planning: \n\t- https://www.emse.fr/~picard/cours/ai/chapter-planning-intro.pdf\n\t- https://www.emse.fr/~picard/cours/ai/chapter-planning-space.pdf","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Bayesian-modelling":{"title":"Bayesian modelling","content":"See [Monte Carlo methods](AI/Math%20and%20Statistics/Monte%20Carlo%20methods.md) and [Probabilistic deep learning](AI/Deep%20learning/Probabilistic%20deep%20learning.md)\n\n\n## Resources\n- https://en.wikipedia.org/wiki/Bayesian_statistics\n- https://en.wikipedia.org/wiki/Bayesian_inference\n- http://brohrer.github.io/how_bayesian_inference_works.html\n- http://willwolf.io/en/2017/02/07/bayesian-inference-via-simulated-annealing/\n- #TALK Bayesian Inference, Shakir Mohamed, MLSS 2020:\n\t- [Part I](https://www.youtube.com/watch?v=x4Y90zPjbq0)\n\t- [Part II](https://www.youtube.com/watch?v=x4Y90zPjbq0\u0026feature=youtu.be)\n\n### Bayesian vs frequentist discussion\n- http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/\n- http://www.fharrell.com/2017/02/my-journey-from-frequentist-to-bayesian.html\n- https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/\n- https://aeon.co/essays/it-s-time-for-science-to-abandon-the-term-statistically-significant\n- http://www.fharrell.com/2017/02/a-litany-of-problems-with-p-values.html?m=1\n\n### Bayes theorem\n- http://blogs.scientificamerican.com/cross-check/bayes-s-theorem-what-s-the-big-deal/\n- http://www.analyticsvidhya.com/blog/2016/06/bayesian-statistics-beginners-simple-english/\n\n### MAP\n- https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation\n- In Bayesian statistics, a maximum a posteriori probability(MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data.It is closely related toFisher's method of maximum likelihood(ML) estimation, but employs an augmented optimization objective which incorporates a prior distribution(that quantifies the additional information available through prior knowledge of a related event) over the quantity one wants to estimate. MAP estimation can therefore be seen as a regularization of ML estimation.\n\n### MLE\n- https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\n- Maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters. MLE can be seen as a special case of the maximum a posteriori estimation (MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized.\n\n### Bayesian network\n- https://en.wikipedia.org/wiki/Bayesian_network\n\n### Variational Bayesian methods\n- See [Normalizing flows](AI/Deep%20learning/Normalizing%20flows.md)\n- [Variational Bayesian inference with normalizing flows: a simple example](https://towardsdatascience.com/variational-bayesian-inference-with-normalizing-flows-a-simple-example-1db109d91062)\n\t- #CODE https://github.com/fraseriainlewis/towardsdatascience\n\n### MCMC\nSee MCMC section in [Monte Carlo methods](AI/Math%20and%20Statistics/Monte%20Carlo%20methods.md)\n\n\n## Code\n- #CODE [Stan](https://github.com/stan-dev/stan)\n\t- http://mc-stan.org\n- #CODE [Pymc3 - Probabilistic Programming in Python](http://pymc-devs.github.io/pymc3/)\n- #CODE [Arviz - Exploratory analysis of Bayesian models with Python](https://arviz-devs.github.io/arviz/)\n- #CODE [BayesicFitting - A package for model fitting and bayesian evidence calculation](https://github.com/dokester/BayesicFitting)\n\n\n## Books\n- #BOOK [Think Bayes - Bayesian Statistics Made Simple (Downey 2012)](http://greenteapress.com/wp/think-bayes/)\n\t- Think Bayes is an introduction to Bayesian statistics using computational methods\n- #BOOK [Probabilistic programming and bayesian methods for hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)\n\t- https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers\n- #BOOK [Bayesian Modeling and Computation in Python (Martin 2021, CRC)](https://bayesiancomputationbook.com/welcome.html)\n\n\n## References\n- #PAPER [Bayesian model selection for complex dynamic systems (Mark 2018)](https://www.nature.com/articles/s41467-018-04241-5) ^1ef748","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Causality":{"title":"Causality","content":"## Resources\n- [To Build Truly Intelligent Machines, Teach Them Cause and Effect](https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/)\n- [Representing uncertain knowledge](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture5.md)\n- [Reasoning over time](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture7.md)\n- [Making decisions](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture8.md)\n- [Causal Analysis Introduction - Examples in Python and PyMC](https://engl.is/causal-analysis-introduction-examples-in-python-and-pymc.html)\n- [Granger causality](https://en.wikipedia.org/wiki/Granger_causality)\n\t- The Granger causality test is a statistical hypothesis test for determining whether one time series is useful in forecasting another, first proposed in 1969\n\t- Granger causality is a fundamental technique for causal inference in time series data, commonly used in the social and biological sciences\n- PCMCI:\n\t- https://jakobrunge.github.io/tigramite/#tigramite-pcmci-pcmci\n\t- PCMCI causal discovery for time series datasets. It is a 2-step causal discovery method for large-scale time series datasets. The first step is a condition-selection followed by the MCI conditional independence test.\n\n\n## Talks\n- #TALK [Interview - Causal Reasoning, Counterfactuals, and the Path to AGI (Judea Pearl)](https://www.youtube.com/watch?v=pEBI0vF45ic)\n- #TALK Causality, Bernhard Sch√∂lkopf and Stefan Bauer, MLSS 2020: \n\t- [Part I](https://www.youtube.com/watch?v=btmJtThWmhA\u0026feature=youtu.be)\n\t\t- https://drive.google.com/file/d/1qlUYuU7wfoD6C8Qo0x4Eyz5aT2k0B_jC/view\n\t- [Part II](https://www.youtube.com/watch?v=9DJWJpn0DmU\u0026feature=youtu.be)\n\t\t- https://drive.google.com/file/d/1_-bUoyY-Thfqu1ac4EwBSv6cCoS-qtnn/view\n- #TALK [Yoshua Bengio Guest Talk - Towards Causal Representation Learning](https://www.youtube.com/watch?v=rKZJ0TJWvTk)\n\n\n## Code\n- #CODE [Causalml](https://github.com/uber/causalml)\n- #CODE [Causality - Tools for causal analysis](https://github.com/akelleh/causality)\n\t- https://medium.com/@akelleh/causal-inference-with-pandas-dataframes-fc3e64fce5d\n- #CODE [CausalImpact (for R)](https://google.github.io/CausalImpact/)\n- #CODE [tfcausalimpact - Google's Causal Impact Algorithm Implemented on Top of TensorFlow Probability](https://github.com/WillianFuks/tfcausalimpact)\n\t- https://towardsdatascience.com/implementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126\n\n  \n## References\n- #PAPER [Causal inference with multiple time series: principles and problems (2013)](https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0613)\n- #PAPER [Towards a Learning Theory of Cause-Effect Inference (Lopez-Paz 2015)](https://arxiv.org/abs/1502.02398)\n- #PAPER [Unsupervised Discovery of El Nino Using Causal Feature Learning on Microlevel Climate Data (Chalupka 2016)](https://arxiv.org/abs/1605.09370)\n- #PAPER [Comparative Benchmarking of Causal Discovery Techniques (Singh 2017)](https://arxiv.org/abs/1708.06246)\n- #PAPER [A Physics-Based Approach to Unsupervised Discovery of Coherent Structures in Spatiotemporal Systems (Rupe 2017)](https://arxiv.org/abs/1709.03184) ^rupe17\n- #PAPER [A Primer on Causal Analysis (2018)](https://arxiv.org/abs/1806.01488)\n- #PAPER [DAGs with NO TEARS: Continuous Optimization for Structure Learning (Zheng 2018)](https://arxiv.org/abs/1803.01422)\n\t- #CODE https://github.com/xunzheng/notears\n- #PAPER [Local causal states and discrete coherent structures (Rupe 2018)](https://aip.scitation.org/doi/10.1063/1.5021130) ^f00b92\n- #PAPER [Learning Functional Causal Models with Generative Neural Networks (Goudet 2018)](https://arxiv.org/abs/1709.05321)\n- #PAPER [Variable-lag Granger Causality for Time Series Analysis (2019)](https://arxiv.org/abs/1912.10829)\n- #PAPER [Learning Sparse Nonparametric DAGs (Zheng 2020)](https://arxiv.org/abs/1909.13189)\n\t- #CODE https://github.com/xunzheng/notears\n\t- #CODE https://github.com/jmoss20/notears\n- #PAPER [When causal inference meets deep learning (Luo 2020)](https://www.nature.com/articles/s42256-020-0218-x)\n\t- Learning causal relations, rather than correlations, is a fundamental problem in both statistical Machine Learning and computer sciences\n\t- Bayesian networks (BNs) can capture causal relations, but learning such a network from data is NP-hard\n\t- Recent work has made it possible to approximate this problem as a continuous optimization task that can be solved efficiently with well-established numerical techniques\n\t- BNs encode the conditional independencies between variables using directed acyclic graphs (DAGs)\n- #PAPER [Spacetime Autoencoders Using Local Causal States (Rupe 2020)](https://arxiv.org/abs/2010.05451)\n\t- #CODE https://github.com/adamrupe/spacetime_autoencoders\n\t- Local causal states are latent representations that capture organized pattern and structure in complex spatiotemporal systems\n\t- We expand their functionality, framing them as space-time autoencoders\n- #PAPER [Algorithms for Causal Reasoning in Probability Trees (Genewein 2020)](https://arxiv.org/abs/2010.12237)\n\t- #CODE https://github.com/deepmind/deepmind-research/tree/master/causal_reasoning\n\t- https://syncedreview.com/2020/10/29/deepmind-introduces-algorithms-for-causal-reasoning-in-probability-trees/\n- #PAPER [Off-the-shelf deep learning is not enough, and requires parsimony, Bayesianity, and causality (Vasudevan 2021)](https://www.nature.com/articles/s41524-020-00487-0)\n- #PAPER [Towards Causal Representation Learning (Sch√∂lkopf 2021)](https://arxiv.org/abs/2102.11107)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Background-subtraction":{"title":"Background subtraction","content":"---\n\n## Resources\n- https://en.wikipedia.org/wiki/Foreground_detection\n- https://github.com/murari023/awesome-background-subtraction\n- Foreground detection is one of the major tasks in the field of computer vision and image processing whose aim is to detect changes in image sequences. \n- Background subtraction is any technique which allows an image's foreground to be extracted for further processing (object recognition etc.).\n- [Background Subtraction Website (T. Bouwmans)](https://sites.google.com/site/thierrybouwmans/background-subtraction","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Computer-vision":{"title":"Computer Vision","content":"See \n- [CNNs](AI/Deep%20learning/CNNs.md)\n- \"MLPs for vision and language\" section in [MLPs](AI/Deep%20learning/MLPs.md)\n- \"For Computer Vision\" section in [Transformers](AI/Deep%20learning/Transformers.md)\n- \"Generative models for Image data\" section in [Generative modelling](AI/Deep%20learning/Generative%20modelling.md)\n- [GANs](AI/Deep%20learning/GANs.md)\n\n\n## Resources\n- https://github.com/jbhuang0604/awesome-computer-vision\n- [Papers with code - computer vision](https://paperswithcode.com/area/computer-vision)\n\n## Books\n- #BOOK [Image Processing and Acquisition using Python (Chityala 2014)](https://www.crcpress.com/Image-Processing-and-Acquisition-using-Python/Chityala-Pudipeddi/p/book/9781466583757)\n- #BOOK [Computer Vision: A Modern Approach (Forsyth, 2011 PEARSON)](https://www.pearson.com/us/higher-education/program/Forsyth-Computer-Vision-A-Modern-Approach-2nd-Edition/PGM111082.html)\n\t- https://github.com/yihui-he/computer-vision-tutorial/blob/master/Computer%20Vision%20A%20Modern%20Approach%202nd%20Edition.pdf\n- #BOOK [Computer Vision: Models, Learning, and Inference (Prince, 2012 CAMBRIDGE)](http://www.computervisionmodels.com/)\n- #BOOK [Computer vision (chapter)](https://d2l.ai/chapter_computer-vision/index.html)\n\n## Courses\n- #COURSE [Computer vision (CS543/ECE549, UIUC)](https://courses.engr.illinois.edu/cs543/sp2015/)\n- #COURSE [Advances in Computer vision (MIT)](http://6.869.csail.mit.edu/fa18/)\n- #COURSE [Introduction to computer vision (Udacity, Georgia Tech)](https://www.udacity.com/course/introduction-to-computer-vision--ud810)\n- #COURSE [Deep Learning for Computer Vision (UPC TelecomBCN 2016)](http://imatge-upc.github.io/telecombcn-2016-dlcv/)\n- #COURSE [Convolutional Neural Networks for Visual Recognition (CS231n, Stanford)](http://cs231n.github.io/)\n\t- [Pre-version of the course](http://karpathy.github.io/neuralnets/)\n\t- [Notes (Karpathy)](http://cs231n.github.io/)\n\t- [Videos for each lecture](https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC)\n- #COURSE [Computer vision (NYU)](https://cs.nyu.edu/~fergus/teaching/vision/)\n- #COURSE [Digital image processing (U Tartu)](https://sisu.ut.ee/dev/imageprocessing/avaleht)\n- #COURSE Convolutional Neural Networks for Image Recognition (DeepMind x UCL | Deep Learning Lectures)\n\t- https://www.youtube.com/watch?v=shVKhOmT0HE\u0026list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\u0026index=3\u0026t=1s\n\t- https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L3%20-%20UUCLxDeepMind%20DL2020.pdf\n- #COURSE Advanced Models for Computer Vision (DeepMind x UCL | Deep Learning Lectures)\n\t- https://www.youtube.com/watch?v=_aUq7lmMfxo\u0026list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\u0026index=4\n\t- https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L4%20-%20UCLxDeepMind%20DL2020.pdf\n\n\n## Code\n- #CODE [Scikit-image. Image processing in Python](https://github.com/scikit-image/scikit-image)\n\t- http://scikit-image.org\n- #CODE [OpenCV (Open Source Computer Vision Library)](https://opencv.org/)\n\t- OpenCV is released under a BSD license and hence it‚Äôs free for both academic and commercial use. It has C++, Python and Java interfaces and supports Windows, Linux, Mac OS, iOS and Android. OpenCV was designed for computational efficiency and with a strong focus on real-time applications. Written in optimized C/C++, the library can take advantage of multi-core processing. Enabled with OpenCL, it can take advantage of the hardware acceleration of the underlying heterogeneous compute platform.\n\t- https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV\n\t- #PAPER [Real-time computer vision with OpenCV (Pulli 2012)](https://dl.acm.org/doi/10.1145/2184319.2184337)\n- #CODE [SimpleCV](https://github.com/sightmachine/SimpleCV)\n\t- http://simplecv.org/\n\t- SimpleCV is an open source framework for building computer vision applications. With it, you get access to several high-powered computer vision libraries such as OpenCV ‚Äì without having to first learn about bit depths, file formats, color spaces, buffer management, eigenvalues, or matrix versus bitmap storage. This is computer vision made easy.\n- #CODE [Imgaug. Image augmentation for machine learning experiments](https://github.com/aleju/imgaug)\n\t- http://imgaug.readthedocs.io\n- #CODE [ChainerCV: a Library for Computer Vision in Deep Learning](https://github.com/chainer/chainercv)\n\t\t- http://chainercv.readthedocs.io/en/stable/\n\t\t- ChainerCV is a collection of tools to train and run neural networks for computer vision tasks using Chainer\n- #CODE [Openface. Free and open source face recognition with deep neural networks](https://cmusatyalab.github.io/openface/)\n- #CODE Vision - The torchvision package consists of popular datasets, model architectures, and common image transformations fo CV. \n\t- https://github.com/pytorch/vision\n- #CODE [Scenic](https://github.com/google-research/scenic)\n\t- https://www.marktechpost.com/2021/10/30/google-research-introduces-scenic-an-open-source-jax-library-for-computer-vision-research/\n\t- A Jax Library for Computer Vision Research and Beyond\n\t- codebase with a focus on research around attention-based models for computer vision\n\t- #PAPER [SCENIC: A JAX Library for Computer Vision Research and Beyond (2021)](https://arxiv.org/abs/2110.11403)\n\n\n## References\n### Deep learning-based CV\nSee: \n- [CNNs](AI/Deep%20learning/CNNs.md)\n- [GANs](AI/Deep%20learning/GANs.md)\n- [Normalizing flows](AI/Deep%20learning/Normalizing%20flows.md)\n- \"For Computer Vision\" section in [Transformers](AI/Deep%20learning/Transformers.md)\n\n- Deep Learning is used in the domain of digital image processing to solve difficult problems (e.g.image colourization, classification, segmentation and  detection). DL methods such as CNNs mostly improve  prediction performance using big  data and plentiful computing resources and have pushed the boundaries of what was possible. Problems which were assumed to be unsolvable are now being solved with super-human accuracy. Image classification is a prime example of this. Since being reignited by Krizhevsky, Sutskever and Hinton in 2012, DL has dominated the domain ever since due to a substantially better performance compared to traditional methods.\n- https://github.com/kjw0612/awesome-deep-vision\n- https://github.com/timzhang642/3D-Machine-Learning\n- https://medium.com/@taposhdr/medical-image-analysis-with-deep-learning-i-23d518abf531\n- http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/\n\n- #PAPER [Deep Learning for Computer Vision: A Brief Review (Voulodimos 2017)](https://www.hindawi.com/journals/cin/2018/7068349/)\n- #PAPER [Deep Learning vs. Traditional Computer Vision (O'Mahony 2019)](https://arxiv.org/abs/1910.13796)\n- #PAPER [Deep learning encodes robust discriminative neuroimaging representations to outperform standard machine learning (Abrol 2021)](https://www.nature.com/articles/s41467-020-20655-6)\n- #PAPER [Deep learning-enabled medical computer vision (Esteva 2021)](https://www.nature.com/articles/s41746-020-00376-2)\n- #PAPER [Involution: Inverting the Inherence of Convolution for Visual Recognition, a brand new neural operator (Li 2021)](https://arxiv.org/abs/2103.06255)\n\t- #CODE https://github.com/d-li14/involution\n\t- [Paper explained](https://www.youtube.com/watch?v=pH2jZun8MoY\u0026list=WL\u0026index=27\u0026t=641s)\n\t- involution is a general-purpose neural primitive that is versatile for a spectrum of deep learning models on different vision tasks\n\t- involution bridges convolution and self-attention in design, while being more efficient and effective than convolution, simpler than self-attention in form\n\t- the proposed involution operator could be leveraged as fundamental bricks to build the new generation of neural networks for visual recognition, powering different deep learning models on several prevalent benchmarks\n- #PAPER [Unifying Nonlocal Blocks for Neural Networks (Zhu 2021)](https://arxiv.org/abs/2108.02451v3)\n\t- #CODE https://github.com/zh460045050/SNL_ICCV2021\n\n\n### Traditional CV techniques\n\n#### Background subtraction\nSee [Background subtraction](AI/Computer%20Vision/Background%20subtraction.md)\n\n#### Geometric transformations\n- https://en.wikipedia.org/wiki/Geometric_transformation\n- https://www.graphicsmill.com/docs/gm/affine-and-projective-transformations.htm\n- https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html\n- http://eeweb.poly.edu/~yao/EL5123/lecture12_ImageWarping.pdf\n\n##### Affine transformations \n- https://en.wikipedia.org/wiki/Affine_transformation\n- Affine transformations are combinations of linear transformations and translations. Properties of affine transformations:\n- Lines map to lines\n- Parallel lines remain parallel\n- Ratios are preserved\n- Closed under composition\n\n##### Projective transformations \n- https://en.wikipedia.org/wiki/Projective_transformation\n- Projective transformations are combos of Affine transformations, and projective warps. Properties of projective transformations:\n- Lines map to lines\n- Parallel lines do not necessarily remain parallel\n- Ratios are not preserved\n- Closed under composition\n- Models change of basis\n- Projective matrix is defined up to a scale (8 DOF)\n\n\n#### Filtering\n- For each pixel we compute a function of local neighborhood and output a new value. Use cases:\n- Enhance images: Denoise, smooth, increase contrast, etc.\n- Extract information from images: Texture, edges, distinctive points, etc.\n- Detect patterns: Template matching\n\nhttps://dsp.stackexchange.com/questions/12684/difference-between-correlation-and-convolution-on-an-image\n\n##### Spatial domain\n- Linear filtering: function is a weighted sum/difference of pixel values (dot products at each position).\n- [Convolution and kernels](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n- [Kernels visualization](http://setosa.io/ev/image-kernels/)\n- http://scikit-image.org/docs/dev/api/skimage.filters.html\n- Examples:\n\t- [Box filter. Replaces each pixel with an average of its neighborhood (smoothing effect)](https://en.wikipedia.org/wiki/Box_blur)\n\t- Sharpening filter. Accentuates differences with local average. \n\t\t- http://northstar-www.dartmouth.edu/doc/idl/html_6.2/Sharpening_an_Image.html\n\t\t- https://en.wikipedia.org/wiki/Box_blur\n\t- Sobel filter. This filter is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. \n\t\t- http://aishack.in/tutorials/sobel-laplacian-edge-detectors/\n\t\t- https://en.wikipedia.org/wiki/Sobel_operator\n\t- [Gaussian filter. Smoothing. Remove ‚Äúhigh-frequency‚Äù components from the image (low-pass filter)](https://en.wikipedia.org/wiki/Gaussian_filter)\n\t- [Median filter. Non linear filter for image smoothing. Robustness to outliers](https://en.wikipedia.org/wiki/Median_filter)\n\t- [Bilateral filter. A bilateral filter is a non-linear, edge-preserving, and noise-reducing smoothing filter for images. It replaces the intensity of each pixel with a weighted average of intensity values from nearby pixels](https://en.wikipedia.org/wiki/Bilateral_filter)\n\t- Laplacian filter. Filtering with a Laplacian operator: \n\t\t- http://aishack.in/tutorials/sobel-laplacian-edge-detectors/\n\t\t- https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.html\n```\n0\t 1\t  0\n1 \t-4\t  1\n0 \t 1\t  0\n```\n  \n##### Frequency domain\n- Fourier transform stores the magnitude and phase at each frequency. The magnitude encodes how much signal there is at a particular frequency whiel the phase encodes spatial information (indirectly). \n- The Convolution Theorem:\n\t- The Fourier transform of the convolution of two functions is the product of their Fourier transforms\n\t- The inverse Fourier transform of the product of two Fourier transforms is the convolution of the two inverse Fourier transforms\n\t- Convolution in spatial domain is equivalent to multiplication in frequency domain\n\n\n#### Template matching\n- https://en.wikipedia.org/wiki/Template_matching\n\n##### Template based\n- http://aishack.in/tutorials/template-matching/\n- For templates without strong features, or for when the bulk of the template image constitutes the matching image, a template-based approach may be effective.\n- Cross-correlation. Linear filtering: function is a weighted sum/difference of pixel values (dot products at each position)\n\t- https://en.wikipedia.org/wiki/Cross-correlation\n\t- [Convolution and kernels](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n\t- [Kernels visualization](http://setosa.io/ev/image-kernels/)\n- [Using image pyramids](https://en.wikipedia.org/wiki/Pyramid_(image_processing))\n\n\n##### Feature based\n- Feature-based approach relies on the extraction of image features such, i.e. shapes, textures , colors, to match in the target image or frame. This approach is currently achieved by using Neural Networks and Deep Learning classifiers such as VGG, AlexNet, ResNet. Deep Convolutional Neural Networks process the image by passing it through different hidden layers and at each layer produce a vector with classification information about the image. These vectors are extracted from the network and are used as the features of the image. Feature extraction by using Deep Neural Networks is extremely effective and thus is the standard in state of the art template matching algorithms.\n- This method is considered more robust and is state of the art as it can match templates with non-rigid and out of plane transformation, it can match with high background clutter and illumination changes.\n\n#### Feature extraction\n- The Computer Vision Pipeline, Part 4: feature extraction. https://freecontent.manning.com/the-computer-vision-pipeline-part-4-feature-extraction/\n\t- Feature extraction is a core component of the computer vision pipeline. In fact, the entire deep learning model works around the idea of extracting useful features which clearly define the objects in the image. We‚Äôre going to spend a little more time here because it‚Äôs important that you understand what a feature is, what a vector of features is, and why we extract features.\n\t- A feature in Machine Learning is an individual measurable property or characteristic of a phenomenon being observed. Features are the input that you feed to your machine learning model to output a prediction or classification. Suppose you want to predict the price of a house, your input features (properties) might include: square_foot, number_of_rooms, bathrooms, etc. and the model will output the predicted price based on the values of your features. Selecting good features that clearly distinguish your objects increases the predictive power of machine learning algorithms.\n- In image processing, algorithms are used to detect and isolate various desired portions or shapes (features) of a digitized image or video stream. It is particularly important in the area of optical character recognition. \n\t- Low-level: Edge detection, Corner detection, Blob detection, Ridge detection, Scale-invariant feature transform,\n\t- Curvature: Edge direction, changing intensity, autocorrelation\n\t- Image motion: Motion detection. Area based, differential approach, Optical flow (https://en.wikipedia.org/wiki/Optical_flow)\n\t- Shape based: Thresholding, Blob extraction, Template matching, Hough transform\n\t\t- Lines: Circles/ellipses, Arbitrary shapes (generalized Hough transform). Works with any parameterizable feature (class variables, cluster detection, etc..)\n\t- Flexible methods: Deformable, parameterized shapesActive contours (snakes)\n\n##### Blob detection\n- https://en.wikipedia.org/wiki/Blob_detection\n- In computer vision, blob detection methods are aimed at detecting regions in a digital image that differ in properties, such as brightness or color, compared to surrounding regions. Informally, a blob is a region of an image in which some properties are constant or approximately constant; all the points in a blob can be considered in some sense to be similar to each other.\n- [The Laplacian of Gaussian](https://en.wikipedia.org/wiki/Blob_detection#The_Laplacian_of_Gaussian)\n- [The difference of Gaussians](https://en.wikipedia.org/wiki/Difference_of_Gaussians)\n- [The determinant of the Hessian](https://en.wikipedia.org/wiki/Blob_detection#The_determinant_of_the_Hessian)\n- [The hybrid Laplacian and determinant of the Hessian operator (Hessian-Laplace)](https://en.wikipedia.org/wiki/Blob_detection#The_hybrid_Laplacian_and_determinant_of_the_Hessian_operator_(Hessian-Laplace))\n- [Maximally stable extremal regions (MSER)](https://en.wikipedia.org/wiki/Maximally_stable_extremal_regions)\n\n##### Edge detection\n- https://en.wikipedia.org/wiki/Template_matching\n- [Canny edge detector](https://en.wikipedia.org/wiki/Canny_edge_detector)\n\t- The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images.\n\t- The Process of Canny edge detection algorithm can be broken down to 5 different steps:\n\t\t1. Apply Gaussian filter to smooth the image in order to remove the noise\n\t\t2. Find the intensity gradients of the image\n\t\t3. Apply non-maximum suppression to get rid of spurious response to edge detection\n\t\t4. Apply double threshold to determine potential edges\n\t\t5. Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n\t- http://aishack.in/tutorials/canny-edge-detector/\n- Robert cross\n\t- https://en.wikipedia.org/wiki/Roberts_cross\n\t- The Roberts cross operator is used in image processing and computer vision for edge detection. \n\t- As a differential operator, the idea behind the Roberts cross operator is to approximate the gradient of an image through discrete differentiation which is achieved by computing the sum of the squares of the differences between diagonally adjacent pixels.\n- Prewitt operator\n\t- https://en.wikipedia.org/wiki/Prewitt_operator\n\t- The Prewitt operator is used in image processing, particularly within edge detection algorithms. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Prewitt operator is either the corresponding gradient vector or the norm of this vector. The Prewitt operator is based on convolving the image with a small, separable, and integer valued filter in horizontal and vertical directions and is therefore relatively inexpensive in terms of computations like Sobel and Kayyali operators. On the other hand, the gradient approximation which it produces is relatively crude, in particular for high frequency variations in the image.\n- Deriche edge detector\n\t- https://en.wikipedia.org/wiki/Deriche_edge_detector\n\t- The Prewitt operator is used in image processing, particularly within edge detection algorithms. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Prewitt operator is either the corresponding gradient vector or the norm of this vector. The Prewitt operator is based on convolving the image with a small, separable, and integer valued filter in horizontal and vertical directions and is therefore relatively inexpensive in terms of computations like Sobel and Kayyali operators. On the other hand, the gradient approximation which it produces is relatively crude, in particular for high frequency variations in the image.\n\n##### Corner detection\n- https://en.wikipedia.org/wiki/Corner_detection\n- http://aishack.in/tutorials/corner-detection-opencv/\n- Corner detection is an approach used within computer vision systems to extract certain kinds of features and infer the contents of an image.\n- [Harris operator: detects corners (patches that have strong gradients in two orthogonal directions)](https://en.wikipedia.org/wiki/Harris_Corner_Detector)\n- [F√∂rstner corner detector](https://en.wikipedia.org/wiki/Corner_detection#The_F%C3%B6rstner_corner_detector)\n- [The Wang and Brady corner detection algorithm](https://en.wikipedia.org/wiki/Corner_detection#The_Wang_and_Brady_corner_detection_algorithm)\n- [The SUSAN corner detector](https://en.wikipedia.org/wiki/Corner_detection#The_SUSAN_corner_detector)\n- [The Trajkovic and Hedley corner detector](https://en.wikipedia.org/wiki/Corner_detection#The_Trajkovic_and_Hedley_corner_detector)\n\n##### Feature descriptors\n- Scale-invariant feature transform (SIFT)\n\t- http://aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/\n\t- SIFT keypoints of objects are first extracted from a set of reference images and stored in a database. An object is recognized in a new image by individually comparing each feature from the new image to this database and finding candidate matching features based on Euclidean distance of their feature vectors. From the full set of matches, subsets of keypoints that agree on the object and its location, scale, and orientation in the new image are identified to filter out good matches. The determination of consistent clusters is performed rapidly by using an efficient hash table implementation of the generalised Hough transform. Each cluster of 3 or more features that agree on an object and its pose is then subject to further detailed model verification and subsequently outliers are discarded. Finally the probability that a particular set of features indicates the presence of an object is computed, given the accuracy of fit and number of probable false matches. Object matches that pass all these tests can be identified as correct with high confidence.\n\t- https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html\n\t- There are mainly five steps involved in SIFT algorithm.\n\t\t1. Scale-space Extrema Detection (using DoG)\n\t\t2. Keypoint Localization\n\t\t3. Orientation Assignment\n\t\t4. Keypoint Descriptor\n\t\t5. Keypoint Matching\n- [Histogram of oriented gradients (HOG)](https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients)\n- Speeded up robust features (SURF)\n\t- https://en.wikipedia.org/wiki/Speeded_up_robust_features\n\t- In computer vision, speeded up robust features (SURF) is a patented local feature detector and descriptor. It can be used for tasks such as object recognition, image registration, classification or 3D reconstruction. It is partly inspired by the scale-invariant feature transform (SIFT) descriptor. The standard version of SURF is several times faster than SIFT and claimed by its authors to be more robust against different image transformations than SIFT.\n\n##### Kanade‚ÄìLucas‚ÄìTomasi (KLT) feature tracker\n- https://en.wikipedia.org/wiki/Kanade%E2%80%93Lucas%E2%80%93Tomasi_feature_tracker\n- In computer vision, the Kanade‚ÄìLucas‚ÄìTomasi (KLT) feature tracker is an approach to feature extraction. It is proposed mainly for the purpose of dealing with the problem that traditional image registration techniques are generally costly. KLT makes use of spatial intensity information to direct the search for the position that yields the best match. It is faster than traditional techniques for examining far fewer potential matches between the images.\n- Summary of KLT tracking:\n\t- Find a good point to track (harriscorner)\n\t- Use intensity second moment matrix and difference across frames to find displacement\n\t- Iterate and use coarse-to-fine search to deal with larger movements \n\t- When creating long tracks, check appearance of registered patch against appearance of initial patch to find points that have drifted\n\n##### Optical flow\n- https://en.wikipedia.org/wiki/Optical_flow\n- Vector field function of the spatio-temporal image brightness variations \n- #PAPER [Large Displacement Optical Flow](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/brox_cvpr09.pdf)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Image-and-video-captioning":{"title":"Image and video captioning","content":"## References\nReview papers: \n- #PAPER [A Systematic Literature Review on Image Captioning (Staniute 2019)](https://www.mdpi.com/2076-3417/9/10/2024/htm)\n- #PAPER [Survey of convolutional neural networks for image captioning (Kalra 2020)](https://www.tandfonline.com/doi/abs/10.1080/02522667.2020.1715602)\n\n- #PAPER [Show and Tell: A Neural Image Caption Generator (Vinyals 2015)](https://arxiv.org/abs/1411.4555)\n- #PAPER [Deep Visual-Semantic Alignments for Generating Image Description](http://cs.stanford.edu/people/karpathy/cvpr2015.pdf)\n\t- http://cs.stanford.edu/people/karpathy/deepimagesent/\n- #PAPER [Mind‚Äôs Eye: A Recurrent Visual Representation for Image Caption Generation](http://www.cs.cmu.edu/~xinleic/papers/cvpr15_rnn.pdf)\n- #PAPER [Sequence to Sequence--Video to Text](http://arxiv.org/abs/1505.00487)\n- #PAPER [Describing Videos by Exploiting Temporal Structure (Yao 2015)](http://arxiv.org/abs/1502.08029)\n- #PAPER [3G structure for image caption generation (Yuan 2018)](https://arxiv.org/abs/1904.09544)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Image-to-image-translation":{"title":"Image-to-image translation","content":"## Resources\n- The task of Image-to-image translation is to learn the mapping from a given image (X) to a specific target image (Y), e.g., mapping grayscale images to RGB images.\n- Learning the mapping from one visual representation to another requires an understanding of underlying features that are shared between these representations, such features are either domain-independent or domain-specific.\n- https://paperswithcode.com/task/image-to-image-translation\n- https://github.com/weihaox/awesome-image-translation\n- [Deep Domain Adaptation In Computer Vision](https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f)\n\n## References\nReview papers:\n- #PAPER [Image-to-Image Translation: Methods and Applications (Pang 2021)](https://arxiv.org/abs/2101.08629)\n\n\n### CNN-based\nSee [Encoder-decoder networks](AI/Deep%20learning/Encoder-decoder%20networks.md)\n- Related to the task of supervised semantic segmentation but changing the Y and the loss (MAE, MSE or other reconstruction loss)\n\n\n### GAN-based\nSee \"GANs for representation learning and image synthesis\" section in [GANs](AI/Deep%20learning/GANs.md)\n- #PAPER [Deep Generative Adversarial Networks for Image-to-Image Translation: A Review (Alotaibi 2020)](https://www.mdpi.com/2073-8994/12/10/1705/htm#) ^I2IGANs20\n\t- The powerful ability of deep feature learning to automatically utilize complex and high-level feature representations has significantly advanced the performance of state-of-the-art methods across computer applications\n\t- The underlying structure and distinctive (complex) features are both discovered via deep learning-based methods that can be classified further into discriminative feature-learning algorithms and generative feature-learning algorithms\n\t- Discriminative models focus on the classification-learning process by learning the conditional probability p (x|y) to map input x to class label y. One of the most popular methods used for image feature learning utilizes convolutional neural networks (CNN) for feature extraction and image classification (LeNet, AlexNet, VGGNet, ResNet and other supervised learning algorithms)\n\t- Generative models focus on the data distribution to discover the underlying features from large amounts of data in an unsupervised setting. Such models are able to generate new samples by learning the estimation of the joint probability distribution p (x,y) and predicting y\n\t- The most dominant and efficient deep generative models of recent years have been VAE and GAN. A variational autoencoder learns the underlying probability distribution and generates a new sample that is based on Bayesian inference by maximizing the lower bound of the data‚Äôs log-likelihood. In contrast, generative adversarial networks learn data distributions through the adversarial training process based on game theory instead of maximizing the likelihood.\n\t- I2I methods:\n\t\t- Supervised\n\t\t\t- Directional translation (Pix2Pix, StarGAN)\n\t\t\t- Bidirectional translation (BicycleGAN, CEGAN)\n\t\t- Unsupervised\n\t\t\t- Cyclic consistency (CycleGAN, DiscoGAN, DualGAN, QGAN, XGAN)\n\t\t\t- Autoencoder-based (UNIT, BranchGAN)\n\t\t\t- Disentangler representation (MUNIT, DIRT, DosGAN)\n\n#### Paired (supervised) translation \n- #PAPER [Image-to-Image Translation with Conditional Adversarial Networks, pix2pix (Isola 2016)](https://arxiv.org/abs/1611.07004) ^pix2pix\n\t- Loss function learned by the network itself instead of L2, L1 norms\n\t- UNET generator, CNN discriminator\n\t- Euclidean distance is minimized by averaging all plausible outputs, which causes blurring.  Coming up with loss functions that force the CNN to do what we really want‚Äì e.g., output sharp, realistic images ‚Äì is an open problem and generally requires expert knowledge \n\t- Evaluating the quality of synthesized images is an open and difficult problem. Traditional metrics such as per-pixel mean-squared error do not assess joint statistics of the result, and therefore do not measure the very structure that structured losses aim to capture\n\t- #CODE https://github.com/phillipi/pix2pix\n\t- #CODE https://www.tensorflow.org/tutorials/generative/pix2pix \n\t- #CODE https://github.com/He-Jian/pix2pix-keras\n\t- https://affinelayer.com/pixsrv/\n\t- https://medium.com/deep-math-machine-learning-ai/ch-14-2-pix2pix-gan-and-cycle-gan-55cd84318fb8 \n\t- https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/\n\t- https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n\t- [Image-to-Image Translation in Tensorflow](https://affinelayer.com/pix2pix/)\n\t- [Two minutes papers](https://www.youtube.com/watch?v=u7kQ5lNfUfg)\n\t- [Paper walkthrough](https://www.youtube.com/watch?v=9SGs4Nm0VR4)\n\t- Stochastic inference: \n\t\t- https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/152\n\t\t\t- tried a few ways of adding z to the nets, e.g., adding z to a latent state, concatenating with a latent state, applying dropout, etc. The output tended not to vary much as a function of z\n\t\t\t- see follow up paper by Zhu et al 2017 (BicycleGAN). Shows one way of getting z to actually have a substantial effect\n\t\t- https://machinelearningmastery.com/how-to-implement-pix2pix-gan-models-from-scratch-with-keras/ \n\t\t\t- unlike traditional generator models in the GAN architecture, the U-Net generator does not take a point from the latent space as input. Instead, dropout layers are used as a source of randomness both during training and when the model is used to make a prediction, e.g. generate an image at inference time\n\t\t\t- similarly, batch normalization is used in the same way during training and inference, meaning that statistics are calculated for each batch and not fixed at the end of the training process. This is referred to as instance normalization, specifically when the batch size is set to 1 as it is with the Pix2Pix model\n\t\t\t- \"At inference time, we run the generator net in exactly the same manner as during the training phase. This differs from the usual protocol in that we apply dropout at test time, and we apply batch normalization using the statistics of the test batch, rather than aggregated statistics of the training batch.\"\n\t\t\t- in Keras, layers like Dropout and BatchNormalization operate differently during training and in inference model. We can set the ‚Äútraining‚Äù argument when calling these layers to ‚ÄúTrue‚Äù to ensure that they always operate in training-model, even when used during inference\n- #PAPER [Toward Multimodal Image-to-Image Translation, BicycleGAN (Zhu 2017)](https://arxiv.org/abs/1711.11586) ^bicyclegan\n\t- #CODE https://github.com/junyanz/BicycleGAN\n\t- #CODE https://github.com/clvrai/BicycleGAN-Tensorflow\n\t- #CODE https://github.com/prakashpandey9/BicycleGAN\n\t- Aimed to model a distribution of possible outputs in a conditional generative modeling setting\n\t-  The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. \n\t- Encouraged the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results\n- #PAPER [Bayesian Conditional Generative Adverserial Networks (Ehsan Abbasnejad 2017)](https://arxiv.org/abs/1706.05477)\n- #PAPER [Image-to-image translation with conditional GAN (Hu 2018)](https://cs230.stanford.edu/projects_spring_2018/reports/8289557.pdf)\n- #PAPER [High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs (Wang 2018)](https://tcwang0509.github.io/pix2pixHD/)\n\t- #CODE https://github.com/NVIDIA/pix2pixHD\n\t- https://youtu.be/3AIpPlzM_qs\n- #PAPER [StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation (Choi 2018)](https://arxiv.org/abs/1711.09020)\n\t- #CODE https://github.com/yunjey/stargan\n- #PAPER [Reversible GANs for Memory-efficient Image-to-Image Translation (van der Ouderaa 2019)](https://arxiv.org/abs/1902.02729)\n- #PAPER [StarGAN v2: Diverse Image Synthesis for Multiple Domains (Choi 2020)](https://arxiv.org/abs/1912.01865)\n\t- #CODE https://github.com/clovaai/stargan-v2\n\n\n#### Unpaired (unsupervised) translation\n- #PAPER [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, CycleGAN (Zhu, 2017)](https://arxiv.org/abs/1703.10593 )\n\t- #TALK https://www.youtube.com/watch?v=Fea4kZq0oFQ \n\t- #CODE https://github.com/clvrai/CycleGAN-Tensorflow\n\t- https://junyanz.github.io/CycleGAN/\n\t- CycleGAN is an approach to training deep convolutional networks for Image-to-Image translation tasks. Unlike other GANs models for image translation tasks, CycleGAN learns a mapping between one image domain and another using an unsupervised approach. This is done by training Generator Networks to learn a mapping from domain X into an image that looks like it came from domain Y (and vice-versa)\n\t- for the generator, residual functions (residual block) are used\n\t- https://medium.com/deep-math-machine-learning-ai/ch-14-2-pix2pix-gan-and-cycle-gan-55cd84318fb8 \n\t- https://towardsdatascience.com/image-to-image-translation-using-cyclegan-model-d58cfff04755\n\t- https://www.tensorflow.org/tutorials/generative/cyclegan \n\t- https://machinelearningmastery.com/cyclegan-tutorial-with-keras/\n\t- https://yanjia.li/gender-swap-and-cyclegan-in-tensorflow-2-0/\n- #PAPER [Learning to Discover Cross-Domain Relations with Generative Adversarial Networks (Kim 2017)](https://arxiv.org/abs/1703.05192)\n\t- #CODE https://github.com/SKTBrain/DiscoGAN\n\t- #CODE https://github.com/clvrai/DiscoGAN-Tensorflow\n\t- This paper introduced an awesome framework for finding one-to-one mapping between two domains in an unsupervised way. The high-level idea is the joint training of two GAN model G1 and G2 in parallel (one for A-\u003eB and the other one for B-\u003eA)\n\t- Besides the adversarial loss, there is also reconstruction loss to ensure the consistency. Specifically, we restrict that G2(G1(A)) = A and G1(G2(B)) = B\n- #PAPER [Unsupervised Image-to-Image Translation Networks (Liu 2018)](https://arxiv.org/abs/1703.00848)\n\t- #CODE https://github.com/mingyuliutw/UNIT/\n\t- https://www.youtube.com/watch?v=dqxqbvyOnMY\u0026feature=youtu.be\n\t- https://medium.com/@theehiproject/unet-unit-for-fast-unsupervised-image2image-translation-using-fastai-e366408eddb4\n- #PAPER [MUNIT: Multimodal UNsupervised Image-to-image Translation (Huang 2018)](https://arxiv.org/abs/1804.04732)\n\t- #CODE https://github.com/NVlabs/MUNIT\n- #PAPER [Fixed-point GAN - Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization (Siddiquee 2019)](https://arxiv.org/abs/1908.06965) ^fixedpointGAN\n\t- #CODE https://github.com/mahfuzmohammad/Fixed-Point-GAN\n- #PAPER [Contrastive Learning for Unpaired Image-to-Image Translation (Park 2020)](https://arxiv.org/abs/2007.15651)\n\t- https://taesung.me/ContrastiveUnpairedTranslation/\n\t- #CODE https://github.com/taesungp/contrastive-unpaired-translation\n\t- #TALK https://www.youtube.com/watch?v=jSGOzjmN8q0\n- #PAPER [Rethinking the Truly Unsupervised Image-to-Image Translation, TUNIT (Baek 2020)](https://arxiv.org/abs/2006.06500)\n\t- #CODE https://github.com/clovaai/tunit\n\t- [Paper explained](https://www.youtube.com/watch?v=sEG8hD64c_Q)\n- #PAPER [Implicit Pairs for Boosting Unpaired Image-to-Image Translation (Ginger 2020)](https://arxiv.org/abs/1904.06913v4)\n- #PAPER [TuiGAN: Learning Versatile Image-to-Image Translation with Two Unpaired Images (Lin 2020)](https://arxiv.org/pdf/2004.04634)            \n\t- #CODE https://github.com/linjx-ustc1106/TuiGAN-PyTorch\n\n### Flow-based\n- #CODE [Image-to-image translation with flow-based generative model](https://github.com/yenchenlin/pix2pix-flow)\n\n- #PAPER [Flow-based Image-to-Image Translation with Feature Disentanglement (Kondo 2019)](https://papers.nips.cc/paper/2019/file/ffedf5be3a86e2ee281d54cdc97bc1cf-Paper.pdf)\n- #PAPER [AlignFlow: Cycle Consistent Learning from Multiple Domains via Normalizing Flows (Grover, 2019)](https://arxiv.org/abs/1905.12892)\n\t-  A generative modeling framework that models each domain via a normalizing flow\n\t-  The use of normalizing flows allows for\n\t\t- flexibility in specifying learning objectives via adversarial training, maximum likelihood estimation, or a hybrid of the two methods\n\t\t- learning and exact inference of a shared representation in the latent space of the generative model. \n- #PAPER [Flow-based Deformation Guidance for Unpaired Multi-Contrast MRI Image-to-Image Translation (Duc Bui 2020)](https://arxiv.org/abs/2012.01777v1)\n\t- Normalizing flows for unpaired image-to-image translation\n\t- Utilized the temporal information between consecutive slices to provide more constraints to the optimization for transforming one domain to another in un-paired volumetric medical image","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Inpainting":{"title":"Inpainting","content":"## Resources\n- https://en.wikipedia.org/wiki/Inpainting\n- Inpainting is a conservation process where damaged, deteriorating, or missing parts of an artwork are filled in to present a complete image\n- https://www.nvidia.com/research/inpainting/\n- [An Introduction to Image Inpainting using Deep Learning](https://wandb.ai/ayush-thakur/image-impainting/reports/An-Introduction-to-Image-Inpainting-using-Deep-Learning--Vmlldzo3NDU0Nw)\n\n\n## References\nReview papers:\n- #PAPER [Image inpainting: A review (Elharrouss 2019)](https://arxiv.org/abs/1909.06399)\n\n### CNN-based\n- #PAPER [Feature Learning by Inpainting (Pathak 2016)](https://arxiv.org/abs/1604.07379v1)\n\t- #CODE https://github.com/pathak22/context-encoder\n- #PAPER [Image Inpainting for Irregular Holes Using Partial Convolutions (Liu 2018)](https://arxiv.org/abs/1804.07723)\n\t- https://nv-adlr.github.io/publication/partialconv-inpainting\n\t- #CODE https://github.com/NVIDIA/partialconv\n\t- #CODE https://github.com/naoto0804/pytorch-inpainting-with-partial-conv\n\t- #CODE https://github.com/MathiasGruber/PConv-Keras\n\t- #CODE [Various Keras Layers that can be used with TensorFlow 2.x](https://github.com/mvoelk/keras_layers)\n- #PAPER [Partial Convolution based Padding (Liu 2018)](https://arxiv.org/pdf/1811.11718)\n- #PAPER [Probabilistic Semantic Inpainting with Pixel Constrained CNNs (Dupont 2019)](https://arxiv.org/abs/1810.03728)\n\t- #CODE https://github.com/Schlumberger/pixel-constrained-cnn-tf\n- #PAPER [A Flexible Deep CNNs Framework for Image Restoration (2020)](https://ieeexplore.ieee.org/document/8820082)\n\t- https://www.researchgate.net/profile/Zhi_Jin6/publication/335500109_A_Flexible_Deep_CNN_Framework_for_Image_Restoration/links/5da7c1a9299bf1c1e4c837c3/A-Flexible-Deep-CNN-Framework-for-Image-Restoration.pdf\n- #PAPER [Deep learning-Based 3D inpainting of brain MR images (Kwan Kang 2021)](https://www.nature.com/articles/s41598-020-80930-w )\n\n\n### GAN-based\n- [GANs and Missing Data Imputation](https://towardsdatascience.com/gans-and-missing-data-imputation-815a0cbc4ece)\n\n- #PAPER [VIGAN: Missing View Imputation with Generative Adversarial Networks (Shang 2017)](https://arxiv.org/abs/1708.06724)\n\t- #CODE https://github.com/chaoshangcs/VIGAN\n- #PAPER [Patch-Based Image Inpainting with GANs (Demir 2018)](https://arxiv.org/abs/1803.07422)\n- #PAPER [GAIN: Missing Data Imputation using GANs (Yoon 2018)](https://arxiv.org/abs/1806.02920)\n\t- #CODE https://github.com/jsyoon0823/GAIN\n- #PAPER [MisGAN: Learning from Incomplete Data with Generative Adversarial Networks (Li 2019)](https://arxiv.org/abs/1902.09599)\n- #PAPER [CollaGAN : Collaborative GAN for Missing Image Data Imputation (Li 2019)](https://arxiv.org/abs/1901.09764)\n- #PAPER [DeepGIN: Deep Generative Inpainting Network for Extreme Image Inpainting (Li 2020)](https://arxiv.org/abs/2008.07173)\n\t- #CODE https://github.com/rlct1/DeepGIN\n\t- https://medium.com/analytics-vidhya/review-of-deepgin-deep-generative-inpainting-network-for-extreme-image-inpainting-de5b191562b0\n- #PAPER [The image inpainting algorithm used on multi-scale generative adversarial networks and neighbourhood (Mo 2020)](https://www.tandfonline.com/doi/full/10.1080/00051144.2020.1821535)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Object-classification-image-recognition":{"title":"Object classification, image recognition","content":"See:\n- [CNNs](AI/Deep%20learning/CNNs.md)\n- [Object detection](AI/Computer%20Vision/Object%20detection.md)\n- [Semantic segmentation](AI/Computer%20Vision/Semantic%20segmentation.md)\n- [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n\n## Resources\n- https://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception/\n- https://blog.paralleldots.com/data-science/must-read-path-breaking-papers-about-image-classification/\n\n## References\n- #PAPER [AlexNet: ImageNet Classification with Deep Convolutional Neural Networks (2012)](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)\n\t- This architecture was one of the first deep networks to push ImageNet Classification accuracy by a significant stride in comparison to traditional methodologies. It is composed of 5 convolutional layers followed by 3 fully connected layers.\n\t- AlexNet, proposed by Alex Krizhevsky, uses ReLu(Rectified Linear Unit) for the non-linear part, instead of a Tanh or Sigmoid function which was the earlier standard for traditional neural networks. Another problem that this architecture solved was reducing the over-fitting by using a Dropout layer after every FC layer.\n- #PAPER [Visualizing and Understanding Convolutional Networks (Zeiler and Fergus 2013)](https://arxiv.org/abs/1311.2901)\n- #PAPER [Very Deep Convolutional Networks for Large-Scale Image Recognition, VGG16 (Symonian 2014)](https://arxiv.org/abs/1409.1556)\n\t- This architecture is from VGG group, Oxford. It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3X3 kernel-sized filters one after another.\n- #PAPER [Going Deeper with Convolutions (Szegedy 2015)](https://ai.google/research/pubs/pub43022)\n\t- GoogLeNet (Inception-V1, 2015)\n\t- http://nicolovaligi.com/history-inception-deep-learning-architecture.html\n\t- GoogLeNet devised a module called inception module that approximates a sparse CNN with a normal dense construction(shown in the figure). Since only a small number of neurons are effective as mentioned earlier, the width/number of the convolutional filters of a particular kernel size is kept small. Also, it uses convolutions of different sizes to capture details at varied scales(5X5, 3X3, 1X1). Another salient point about the module is that it has a so-called bottleneck layer(1X1 convolutions in the figure). It helps in the massive reduction of the computation requirement. Another change that GoogLeNet made, was to replace the fully-connected layers at the end with a simple global average pooling which averages out the channel values across the 2D feature map, after the last convolutional layer. \n- #PAPER See Resnet in [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n- #PAPER See Resnext in [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n- #PAPER See Densenet in [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n- #PAPER [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and \u003c0.5MB model size (Iandola 2016)](https://arxiv.org/abs/1602.07360)\n\t- [Paper explained](https://www.youtube.com/watch?v=ge_RT5wvHvY )\n\t- https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7\n- #PAPER See SENets in [CNNs](AI/Deep%20learning/CNNs.md)\n- #PAPER [Aggregated Residual Transformations for Deep Neural Networks (Xie 2017)](https://arxiv.org/abs/1611.05431)\n\t- #CODE https://github.com/taki0112/SENet-Tensorflow\n- #PAPER [Designing Network Design Spaces (Radosavovic 2020)](https://arxiv.org/abs/2003.13678v1)\n- #PAPER [NFNets. High-Performance Large-Scale Image Recognition Without Normalization (Brock 2021)](https://arxiv.org/abs/2102.06171)\n\t- #CODE https://github.com/deepmind/deepmind-research/tree/master/nfnets\n\t- https://towardsdatascience.com/deepmind-releases-a-new-state-of-the-art-image-classification-model-nfnets-75c0b3f37312\n- #PAPER [Patches Are All You Need? (2021)](https://openreview.net/forum?id=TVHS5Y4dNvM)\n\t- #CODE https://github.com/tmp-iclr/convmixer\n\t- https://syncedreview.com/2021/10/12/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-121/\n- #PAPER [CoAtNet: Marrying Convolution and Attention for All Data Sizes (Dai 2021)](https://arxiv.org/abs/2106.04803)\n\t- https://ai.googleblog.com/2021/09/toward-fast-and-accurate-neural.html","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Object-detection":{"title":"Object detection","content":"See [Semantic segmentation](AI/Computer%20Vision/Semantic%20segmentation.md)\n \n## Code\n- https://github.com/microsoft/computervision-recipes/tree/master/scenarios/detection\n- #CODE [MMdetection](https://github.com/open-mmlab/mmdetection)\n\t- OpenMMLab Detection Toolbox and Benchmark (pytorch)\n\t- https://mmdetection.readthedocs.io/\n- #CODE TensorFlow object detection API\n\t- [Repository](https://github.com/tensorflow/models/tree/master/research/object_detection)\n\t- [Model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)\n\t- https://medium.com/swlh/train-your-custom-object-detector-with-tensorflow-object-detector-api-65d38dcdf08c\n\t- https://modelzoo.co/model/objectdetection\n- #CODE [Detectron2](https://github.com/facebookresearch/detectron2)\n\t- Detectron2 is FAIR's next-generation platform for object detection and segmentation\n- #CODE https://github.com/jinwchoi/awesome-action-recognition#object-detection\n- #CODE [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/)\n\n## References\nReview papers:\n- #PAPER [Recent Advances in Object Detection in the Age of Deep [CNNs](AI/Deep%20learning/CNNs.md) (Agarwal 2019)](https://arxiv.org/abs/1809.03193)\n- #PAPER [Deep learning for Generic Object Detection: A Survey (Liu 2019)](https://arxiv.org/abs/1809.02165v4)\n\n\n- #PAPER [Multiple Object Recognition with Visual Attention (Ba 2015)](http://arxiv.org/abs/1412.7755)\n- #PAPER Is object localization for free? ‚Äì Weakly Supervised Object Recognition with Convolutional Neural Networks (Oquab 2015): \n\t- http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Oquab_Is_Object_Localization_2015_CVPR_paper.pdf\n\t- https://www.di.ens.fr/willow/research/weakcnn/\n- #PAPER [DeepLab - Weakly-and semi-supervised learning of a DCNN for semantic image segmentation (Papandreou 2015)](http://arxiv.org/abs/1502.02734)\n- #PAPER [SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation (Badrinarayanan 2016)](http://arxiv.org/abs/1511.00561)\n- #PAPER [SSD. Single Shot MultiBox Detector (Liu 2016)](https://arxiv.org/abs/1512.02325)\n\t- #BOOK https://d2l.ai/chapter_computer-vision/ssd.html\n- #PAPER [YOLO. You Only Look Once: Unified, Real-Time Object Detection (Redmon 2016)](https://arxiv.org/abs/1506.02640)\n\t- YOLO or You Only Look Once is an object detection algorithm much different from the region based algorithms. In YOLO a single convolutional network predicts the bounding boxes and the class probabilities for these boxes.\n\t- How YOLO works is that we take an image and split it into an SxS grid, within each of the grid we take m bounding boxes. For each of the bounding box, the network outputs a class probability and offset values for the bounding box. The bounding boxes having the class probability above a threshold value is selected and used to locate the object within the image.\n- #PAPER [RetinaNet. Focal Loss for Dense Object Detection (Lin 2018)](https://arxiv.org/abs/1708.02002)\n\t- #CODE https://github.com/fizyr/keras-retinanet\n\t- https://keras.io/examples/vision/retinanet/\n\t- https://towardsdatascience.com/object-detection-on-aerial-imagery-using-retinanet-626130ba2203\n- #PAPER [CornerNet: Detecting Objects as Paired Keypoints (Law 2018)](https://arxiv.org/abs/1808.01244)\n\t- #CODE https://github.com/makalo/CornerNet\n- #PAPER [ExtremeNet. Bottom-up Object Detection by Grouping Extreme and Center Points (Zhou 2019)](https://arxiv.org/abs/1901.08043)\n\t- #CODE https://github.com/xingyizhou/ExtremeNet\n- #PAPER [EfficientDet: Scalable and Efficient Object Detection (Tan 2020)](https://arxiv.org/pdf/1911.09070.pdf)\n\t- #CODE https://github.com/xuannianz/EfficientDet\n\t- Included in the TF object detection API\n- #CODE [YOLOX: Exceeding YOLO Series in 2021 (Ge 2021)](https://arxiv.org/abs/2107.08430v1)\n\t- #CODE https://paperswithcode.com/paper/yolox-exceeding-yolo-series-in-2021\n\nRegion-based CNNs (R-CNNs):\n- https://www.pyimagesearch.com/2020/07/06/region-proposal-object-detection-with-opencv-keras-and-tensorflow/\n- #BOOK [Region-based RCNNs](https://d2l.ai/chapter_computer-vision/rcnn.html)\n- #PAPER [Regional CNN (R-CNN)](https://arxiv.org/abs/1311.2524)\n\t- The goal of R-CNN is to take in an image, and correctly identify where the main objects (via a bounding box) in the image.\n\t- R-CNN creates these bounding boxes, or region proposals, using a process called Selective Search. \n\t- Once the proposals are created, R-CNN warps the region to a standard square size and passes it through to a modified version of AlexNet (the winning submission to ImageNet 2012 that inspired R-CNN).\n\t- On the final layer of the CNN, R-CNN adds a Support Vector Machine (SVM) that simply classifies whether this is an object, and if so what object. \n- #PAPER [Fast R-CNN](https://arxiv.org/abs/1504.08083)\n\t- RoI (Region of Interest) Pooling. At its core, RoIPool shares the forward pass of a CNN for an image across its subregions. \n\t- The second insight of Fast R-CNN is to jointly train the CNN, classifier, and bounding box regressor in a single model. \n- #PAPER [Faster R-CNN](https://arxiv.org/abs/1506.01497)\n\t- The insight of Faster R-CNN was that region proposals depended on features of the image that were already calculated with the forward pass of the CNN (first step of classification).\n\t- So why not reuse those same CNN results for region proposals instead of running a separate selective search algorithm?\n\t- A single CNN is used to both carry out region proposals and classification. This way, only one CNN needs to be trained and we get region proposals almost for free. Faster R-CNN adds a Fully Convolutional Network on top of the features of the CNN creating what‚Äôs known as the Region Proposal Network.\n- #PAPER [Mask R-CNN (He 2018)](https://arxiv.org/abs/1703.06870)\n\t- Extending Faster R-CNN for Pixel Level Segmentation\n\t- Mask R-CNN does this by adding a branch to Faster R-CNN that outputs a binary mask that says whether or not a given pixel is part of an object. The branch, as before, is just a Fully Convolutional Network on top of a CNN based feature map. \n\t- But the Mask R-CNN authors had to make one small adjustment to make this pipeline work as expected: Realigning RoIPool to be More Accurate.\n\t- https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46\n\t- https://modelzoo.co/model/mask-r-cnn-keras\n\t- https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Semantic-segmentation":{"title":"Semantic segmentation","content":"See:\n- [Encoder-decoder networks](AI/Deep%20learning/Encoder-decoder%20networks.md) for image segmentation\n- [Object detection](AI/Computer%20Vision/Object%20detection.md)\n\n## Resources\n- https://en.wikipedia.org/wiki/Image_segmentation\n- https://github.com/mrgloom/awesome-semantic-segmentation\n- https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4\n- [Overview of semantic image segmentation](https://www.jeremyjordan.me/semantic-segmentation/)\n\n## Code\n- #CODE [DeepLab2](https://github.com/google-research/deeplab2)\n\t- DeepLab2 is a TensorFlow library for deep labeling, aiming to provide a unified and state-of-the-art TensorFlow codebase for dense pixel labeling tasks.\n- #CODE [Segmentation models with pretrained backbones (PyTorch)](https://github.com/qubvel/segmentation_models)\n- #CODE https://github.com/qubvel/segmentation_models\n- #CODE https://www.tensorflow.org/tutorials/images/segmentation\n- #CODE https://github.com/yassouali/pytorch-segmentation\n\n## References\nReview papers:\n- #PAPER [Deep learning for cardiac image segmentation: A review (2019)](https://arxiv.org/abs/1911.03723)\n- #PAPER [Evolution of Image Segmentation using Deep Convolutional Neural Network: A Survey (Sultana, 2020)](https://arxiv.org/abs/2001.0407430)\n\n- #PAPER [Fully Convolutional Networks for Semantic Segmentation (Long 2015)](https://arxiv.org/abs/1411.4038)\n- #PAPER [CGNet: A Light-weight Context Guided Network for Semantic Segmentation (Wu 2018)](https://arxiv.org/abs/1811.08201) ^cgnet\n\t- Context Guided (CG) block learns the joint feature of both local feature and surrounding context, and further improves the joint feature with the global context\n\t- CGNet captures contextual information in all stages of the network and is specially tailored for increasing segmentation accuracy \n\t- CGNet is also elaborately designed to reduce the number of parameters and save memory footprint\n- #PAPER [Panoptic-DeepLab: A Simple, Strong, and Fast Baseline for Bottom-Up Panoptic Segmentation (Cheng 2020)](https://arxiv.org/abs/1911.10194)\n\t- #CODE https://github.com/bowenc0221/panoptic-deeplab\n- #PAPER [Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation (Wang 2020)](https://arxiv.org/abs/2003.07853)\n\t- #CODE https://github.com/csrhddlam/axial-deeplab\n\t- [Paper explained](https://www.youtube.com/watch?v=hv3UO3G0Ofo)\n- #PAPER [Towards infield, live plant phenotyping using a reduced-parameter CNN (Atanbori 2020)](https://link.springer.com/article/10.1007%2Fs00138-019-01051-7)\n- #PAPER [Learning What Not to Segment: A New Perspective on Few-Shot Segmentation (Lang 2022)](https://arxiv.org/pdf/2203.07615v2)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Super-resolution":{"title":"Super-resolution","content":"See [Image-to-image translation](AI/Computer%20Vision/Image-to-image%20translation.md)\n\n## Resources\n- [Papers and related resources, mainly state-of-the-art and novel works in ICCV, ECCV and CVPR about image super-resolution and video super-resolution](https://github.com/HymEric/latest-development-of-ISR-VSR)\n- https://github.com/ptkin/Awesome-Super-Resolution\n- https://github.com/ChaofWang/Awesome-Super-Resolution\n- https://keras.io/examples/vision/super_resolution_sub_pixel/\n- [Image Super-Resolution: A Comprehensive Review (2020)](https://blog.paperspace.com/image-super-resolution/ )\n\n\n## Talks\n- #TALK [How Super Resolution Works (2019)](https://www.youtube.com/watch?v=KULkSwLk62I)\n- #TALK [Can you enhance that? Single Image Super Resolution (Pydata 2019)](https://www.youtube.com/watch?v=lmUxbRY7H2I)\n\n## Code\n- #CODE [BasicSR: Open Source Image and Video Restoration Toolbox for Super-resolution, Denoise, Deblurring (Pytorch)](https://github.com/xinntao/BasicSR)\n\t- It includes EDSR, RCAN, SRResNet, SRGAN, ESRGAN, EDVR, etc\n- #CODE [Single Image Super Resolution benchmark (Keras)](https://github.com/hieubkset/Keras-Image-Super-Resolution)\n\t- EDSR, SRGAN, SRFeat, RCAN, ESRGAN and ERCA (not published)\n- #CODE [Single Image Super-Resolution with EDSR, WDSR and SRGAN (Keras)](https://github.com/krasserm/super-resolution)\n\t- http://krasserm.github.io/2019/09/04/super-resolution/\n\n\n## References\n### Review Papers\n- #PAPER [Deep Learning for Single Image Super-Resolution: A Brief Review (2018)](https://arxiv.org/abs/1808.03344)\n- #PAPER [A Deep Journey into Super-resolution: A survey (Anwar 2020)](https://arxiv.org/abs/1904.07523)\n\t- https://github.com/saeed-anwar/SRsurvey\n- #PAPER [Deep Learning for Image Super-resolution: A Survey (Wang 2020)](https://arxiv.org/abs/1902.06068 )\n- #PAPER [NTIRE 2020 Challenge on Perceptual Extreme Super-Resolution: Methods and Results (Zhang 2020)](https://arxiv.org/abs/2005.01056)\n\t- https://data.vision.ee.ethz.ch/cvl/ntire20/\n\t- Jointly with NTIRE 2020 workshop we have an NTIRE challenge on perceptual extreme super-resolution, that is,the task of super-resolving an LR image to a perceptually pleasant HR image with a magnification factor x16\n- #PAPER [A Comprehensive Review of Deep Learning-based Single Image Super-resolution (Bashir 2021)](https://arxiv.org/abs/2102.09351)\n\n\n### CNN-based\n- #PAPER [Image Super-Resolution Using Deep Convolutional Networks, SRCNN (Dong 2015)](https://arxiv.org/abs/1501.00092)\n\t- #CODE https://github.com/MarkPrecursor/SRCNN-keras\n\t- #CODE https://github.com/yukia18/srcnn-keras\n- #PAPER [Accurate Image Super-Resolution Using Very Deep Convolutional Networks (2015)](http://arxiv.org/abs/1511.04587)\n- #PAPER [Deep Networks for Image Super-Resolution with Sparse Prior (Wang 2015)](http://www.ifp.illinois.edu/~dingliu2/iccv15/)\n\t- http://www.ifp.illinois.edu/~dingliu2/iccv15/iccv15.pdf\n- #PAPER [FSRCNN - Accelerating the Super-Resolution Convolutional Neural Network (Dong 2016)](https://arxiv.org/abs/1608.00367)\n\t- http://mmlab.ie.cuhk.edu.hk/projects/FSRCNN.html\n\t- Uses deconvolution layers (transposed convolution)\n\t- #CODE https://github.com/GeorgeSeif/FSRCNN-Keras\n- #PAPER [Deconvolution and Checkerboard Artifacts (Odena 2016)](https://distill.pub/2016/deconv-checkerboard/)\n\t- Identifies the learned upsample operation (often called deconvolutions) in generative networks as a source of noise\n\t- Overall lesson here is that if you use transposed convolutions, be careful that your kernel size is a multiple of your stride\n\t- However if you use a nearest neighbor or bilinear upsample approach followed by a convolution (termed the ‚Äòresize convolution‚Äô) checkerboard artifacts should not appear\n\t- They have more succes with nearest neighbor than with bilinear, possibly because bilinear upsampling smooths away important high frequency signals\n- #PAPER [Perceptual Losses for Real-Time Style Transfer and Super-Resolution (Johnson 2016)](http://arxiv.org/abs/1603.08155)\n\t- http://cs.stanford.edu/people/jcjohns/papers/fast-style/fast-style-supp.pdf\n- #PAPER [ESPCN - Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network (Shi 2016)](https://arxiv.org/abs/1609.05158)\n\t- https://medium.datadriveninvestor.com/review-espcn-real-time-sr-super-resolution-8dceca249350\n\t- #CODE https://keras.io/examples/vision/super_resolution_sub_pixel/\n\t- [SubPixelUpscaling implementation here](https://github.com/pavitrakumar78/Anime-Face-GAN-Keras/blob/master/misc_layers.py)\n\t- [Subpixel convolution is the same as pixel-shuffle](https://nico-curti.github.io/NumPyNet/NumPyNet/layers/pixelshuffle_layer.html)\n\t- A drawback of the interpolation upsampling is that upsampling errors are introduced that can be hard to correct sub-sequently\n\t- The idea of pixel shuffling is to rearrange the pixels of multiple low-resolution images, or in this case feature activations, to one high-resolution out-put image by periodic shuffling of the image points. It thus represents a learnable upsampling operation\n\t- Through the constant periodicity, the previous operations of the neural network can learn to distribute content across the feature dimension which is then shuffled to yield the high-resolution output\n\t- This allows to process the image entirely in low-resolution space\n- #PAPER [Checkerboard artifact free sub-pixel convolution: A note on sub-pixel convolution, resize convolution and convolution resize (Aitken 2017)](https://arxiv.org/abs/1707.02937)\n\t- #CODE https://github.com/Golbstein/EDSR-Keras/blob/master/subpixel.py\n- #PAPER [EDSR - Enhanced Deep Residual Networks for Single Image Super-Resolution (Lim 2017)](https://arxiv.org/abs/1707.02921)\n\t- #CODE https://github.com/Golbstein/EDSR-Keras\n\t- #CODE https://github.com/hieubkset/Keras-Image-Super-Resolution\n- #PAPER [Pixel Deconvolutional Networks (Gao 2017)](https://arxiv.org/abs/1705.06820)\n- #PAPER [RDN - Residual Dense Network for Image Super-Resolution (Zhang 2018)](https://arxiv.org/abs/1802.08797)\n\t- #CODE https://github.com/idealo/image-super-resolution\n\t- #CODE https://github.com/hengchuan/RDN-TensorFlow\n- #PAPER [WDSR - Wide Activation for Efficient and Accurate ImageSuper-Resolution (Yu 2018)](https://arxiv.org/abs/1808.08718)\n- #PAPER [RecResNet: A Recurrent Residual CNN Architecture for Disparity Map Enhancement (Batsos 2018)](https://ieeexplore.ieee.org/document/8490974)\n\t- https://mordohai.github.io/public/Batsos_RecResNet18.pdf\n\t- #CODE https://github.com/kbatsos/RecResNet\n- #PAPER [RCAN - Image Super-Resolution Using Very Deep Residual Channel Attention Networks (Zhang 2018)](https://arxiv.org/abs/1807.02758)\n\t- #CODE https://github.com/yulunzhang/RCAN\n- #PAPER [Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks (Lai 2018)](http://vllab.ucmerced.edu/wlai24/LapSRN/)\n- #PAPER [Super-Resolution using Convolutional Neural Networks without Any Checkerboard Artifacts (Sugawara 2018)](https://arxiv.org/abs/1806.02658v1)\n- #PAPER [Supervised Deep Kriging for Single-Image Super-Resolution (Franchis 2018)](https://arxiv.org/abs/1812.04042)\n- #PAPER [Single Image Super Resolution based on a Modified U-net with Mixed Gradient Loss (Lu, 2019)](https://arxiv.org/abs/1911.09428)\n- #PAPER [Densely Residual Laplacian Super-Resolution (Anwar 2019)](https://arxiv.org/abs/1906.12021)\n\t- #CODE https://github.com/saeed-anwar/DRLN\n- #PAPER [Hyperspectral Image Super-Resolution with 1D‚Äì2D Attentional Convolutional Neural Network (Li 2019)](https://www.mdpi.com/2072-4292/11/23/2859/htm)\n- #PAPER [Deep Learning for Multiple-Image Super-Resolution (Kawulok 2019)](https://arxiv.org/abs/1903.00440)\n- #PAPER [RUNet: A Robust UNet Architecture for Image Super-Resolution (Hu 2019)](https://openaccess.thecvf.com/content_CVPRW_2019/papers/WiCV/Hu_RUNet_A_Robust_UNet_Architecture_for_Image_Super-Resolution_CVPRW_2019_paper.pdf)\n- #PAPER [Learned Image Downscaling for Upscaling using Content Adaptive Resampler (Sun 2019)](https://arxiv.org/abs/1907.12904)\n\t- #CODE https://github.com/sunwj/CAR\n\t- https://paperswithcode.com/paper/learned-image-downscaling-for-upscaling-using\n\t- The proposed resampler network generates content adaptive image resampling kernels that are applied to the original HR input to generate pixels on the downscaled image\n\t- Moreover, a differentiable upscaling (SR) module is employed to upscale the LR result into its underlying HR counterpart\n\t- By back-propagating the reconstruction error down to the original HR input across the entire framework to adjust model parameters, the proposed framework achieves a new state-of-the-art SR performance through upscaling guided image resamplers which adaptively preserve detailed information that is essential to the upscaling\n- #PAPER [Image Super-Resolution Using Attention Based DenseNet with Residual Deconvolution (Li 2019)](https://arxiv.org/abs/1907.05282)\n- #PAPER [Meta-SR: A Magnification-Arbitrary Network for Super-Resolution (Hu 2019)](https://arxiv.org/abs/1903.00875)\n\t- #CODE https://github.com/XuecaiHu/Meta-SR-Pytorch\n\t- #CODE https://github.com/smallsunsun1/Meta-SR/\n\t- #CODE https://github.com/jason71995/meta_sr/\n\t- Continuous, arbitrary scaling\n- #PAPER [Pixel Transposed Convolutional Networks (Gao 2019)](https://ieeexplore.ieee.org/document/8618415)\n\t- The pixel transposed convolutional layer (PixelTCL) is proposed to establish direct relationships among adjacent pixels on the up-sampled feature map\n\t- PixelTCL can largely overcome the checkerboard problem suffered by regular transposed convolutional operations\n- #PAPER [A Very Deep Spatial Transformer Towards Robust Single Image Super-Resolution (Jiang 2019)](https://ieeexplore.ieee.org/abstract/document/8679959)\n- #PAPER [ASDN: A Deep Convolutional Network for Arbitrary Scale Image Super-Resolution (Shen 2020)](https://arxiv.org/abs/2010.02414v1)\n- #PAPER [LIIF - Learning Continuous Image Representation with Local Implicit Image Function (Chen 2020)](https://arxiv.org/abs/2012.09161)\n\t- https://yinboc.github.io/liif/\n\t- #CODE https://github.com/yinboc/liif\n\t- Continuous, arbitrary scaling\n- #PAPER [Fixed smooth convolutional layer for avoiding checkerboard artifacts in CNNs (Kinoshita 2020)](https://arxiv.org/abs/2002.02117v1)\n- #PAPER [Efficient Image Super-Resolution Using Pixel Attention (Zhao 2020)](https://arxiv.org/abs/2010.01073) ^srwithpixelattention\n\t-  #CODE See code in [CNNs](AI/Deep%20learning/CNNs.md)\n\t-  #CODE https://github.com/zhaohengyuan1/PAN\n- #PAPER [Dense U-net for super-resolution with shuffle pooling layer (Lu 2021)](https://arxiv.org/abs/2011.05490)\n- #PAPER [OverNet: Lightweight Multi-Scale Super-Resolution with Overscaling Network (Behjati 2021)](https://arxiv.org/abs/2008.02382)\n\t- https://www.youtube.com/watch?v=_YAn5TaIJfM\n\n\n### GAN-based\n- #PAPER [SRGAN: Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (Ledig 2016)](https://arxiv.org/abs/1609.04802)\n\t- #CODE https://github.com/idealo/image-super-resolution\n\t- #CODE https://github.com/tensorlayer/srgan\n\t- #CODE https://github.com/leftthomas/SRGAN\n\t- #TALK https://www.youtube.com/watch?v=BXIR_SVCrsE\n\t- First proposed the perceptual loss: content loss + adversarial loss\n\t\t- content loss ensures high-level content is preserved by computing the MSE in the VGG feature-space (instead of pixel image space)\n\t\t- adversarial loss ensures the reconstructed images look real (textures detail)\n\t- Model based on VGG architecture and DCGAN\n- #PAPER [Class-Conditional Superresolution with GANs (Chen 2017)](http://cs231n.stanford.edu/reports/2017/pdfs/314.pdf )\n\t- #CODE https://github.com/vincentschen/cgan-superres\n- #PAPER [ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks (Wang 2018)](https://arxiv.org/abs/1809.00219)\n\t\t- #CODE https://github.com/xinntao/ESRGAN\n- #PAPER [tempoGAN: A temporally coherent, volumetric GAN for super-resolution fluid flow (Xie 2018)](https://arxiv.org/abs/1801.09710)\n- #PAPER [Unsupervised Single-Image Super-Resolution with Multi-Gram Loss (Shi 2019)](https://www.mdpi.com/2079-9292/8/8/833/htm)\n- #PAPER [TecoGAN: Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation (Chu 2020)](https://ge.in.tum.de/publications/2019-tecogan-chu/)\n\t- #CODE https://github.com/thunil/TecoGAN\n\t- [Paper explained](https://www.youtube.com/watch?v=MwCgvYtOLS0)\n- #PAPER [TSRGAN: Generative Adversarial Network for Image Super-Resolution Combining Texture Loss (Jiang 2020)](https://www.mdpi.com/2076-3417/10/5/1729/htm)\n- #PAPER [Residual Channel Attention Generative Adversarial Network for Image Super-Resolution and Noise Reduction (Cai 2020)](https://arxiv.org/abs/2004.13674)\n- #PAPER [Meta-SRGAN - Arbitrary Scale Super-Resolution for Brain MRI Images (Tan 2020)](https://arxiv.org/abs/2004.02086)\n\t- #CODE https://github.com/pancakewaffles/metasrgan-tutorial/\n- #PAPER [MSG-GAN: Multi-Scale Gradients for Generative Adversarial Networks (Karnewar 2020)](https://arxiv.org/abs/1903.06048)\n- #PAPER [MRI Super-Resolution with GAN and 3D Multi-Level DenseNet: Smaller, Faster, and Better (Chen 2020)](https://arxiv.org/abs/2003.01217)\n- #PAPER [Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data (Wnag 2021)](https://arxiv.org/abs/2107.10833v1) ^real-esrgan\n\t- #CODE https://github.com/xinntao/Real-ESRGAN\n\t- Super-resolution with a hint of image restoration\n\t- Proposed a high-order degradation modeling process to better simulate complex real-world degradations (blur, downsampling, noise, etc and combinations)\n\n\n### Transformer-based\n- #PAPER [Learning Texture Transformer Network for Image Super-Resolution (Yang 2020)](https://arxiv.org/abs/2006.04139) ^ttsr\n\t- #CODE https://github.com/researchmm/TTSR\n\t- Texture Transformer Network for Image Super-Resolution (TTSR)\n\t- LR and Ref images are formulated as queries and keys in a transformer, respectively\n\t- The proposed texture transformer consists of a learnable texture extractor which learns a jointly feature embedding for further attention computation and two attention based modules which transfer HR textures from the Ref image. \n\t- Furthermore, the proposed texture transformer can be stacked in a cross-scale way with the proposed CSFI module to learn a more powerful feature representation\n\n\n### Diffusion models-based\n- #PAPER [Image Super-Resolution via Iterative Refinement (Saharia 2021)](https://arxiv.org/abs/2104.07636)\n\t- https://iterative-refinement.github.io/\n\t- Related to [Diffusion models](AI/Deep%20learning/Diffusion%20models.md)\n\t- SR3 is inspired by recent work on Denoising Diffusion Probabilistic Models (DDPM) and denoising score matching\n\t- SR3 adapts denoising diffusion probabilistic models to conditional image generation and performs super-resolution through a stochastic denoising process\n\t- Inference starts with pure Gaussian noise and iteratively refines the noisy output using a U-Net model trained on denoising at various noise levels\n\t- #CODE https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement\n\t- #CODE https://paperswithcode.com/paper/image-super-resolution-via-iterative\n\t- https://beebom.com/google-new-ai-models-turn-low-resolution-images-into-high-quality/","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Video-Frame-Interpolation":{"title":"Video Frame Interpolation","content":"## Resources\n- The goal of **Video Frame Interpolation** is to synthesize several frames in the middle of two adjacent frames of the original video. Video Frame Interpolation can be applied to generate slow motion video, increase video frame rate, and frame recovery in video streaming.\n\n## References\n- #PAPER [Asymmetric Bilateral Motion Estimation for Video Frame Interpolation (Park 2021)](https://arxiv.org/abs/2108.06815)\n\t- https://github.com/JunHeum/ABME\n- #PAPER [Enhanced Correlation Matching based Video Frame Interpolation (Lee 2021)](https://arxiv.org/abs/2111.08869v1)\n- #PAPER [FILM: Frame Interpolation for Large Motion (Reda 2022)](https://arxiv.org/abs/2202.04901v2)\n\t- #CODE https://github.com/google-research/frame-interpolation\n\t- https://www.youtube.com/watch?v=OAD-BieIjH4\n\t- present a single unified network, distinguished by a multi-scale feature extractor that shares weights at all scales, and is trainable from frames alone\n\t- to synthesize crisp and pleasing frames, proposed to optimize the network with the Gram matrix loss that measures the correlation difference between feature maps","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Computer-Vision/Video-segmentation-and-prediction":{"title":"Video segmentation and prediction","content":"See: \n- [Encoder-decoder networks](AI/Deep%20learning/Encoder-decoder%20networks.md)\n- \"Deep learning for multi-dimensional data\" section in [DL](AI/Deep%20learning/DL.md)\n- [RNNs](AI/Deep%20learning/RNNs.md)\n\n## Resources\n- Spatiotemporal classification and regression\n- Hybrid convolutional and recurrent networks, 3dconv and related approaches\n- https://github.com/jinwchoi/awesome-action-recognition\n- http://blog.qure.ai/notes/deep-learning-for-videos-action-recognition-review\n- https://stackoverflow.com/questions/55926841/convolving-across-channels-in-keras-cnn-conv1d-depthwise-separable-conv-cccp\n- https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\n\n\n## Courses\n- #COURSE [Advanced Models for Computer Vision (DeepMind x UCL | Deep Learning Lectures)](https://www.youtube.com/watch?v=_aUq7lmMfxo\u0026list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\u0026index=4)\n\t- https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L4%20-%20UCLxDeepMind%20DL2020.pdf\n\n\n## References\n- #PAPER [Learning Spatiotemporal Features with 3D Convolutional Networks. C3D, 3D CNNs (Tran 2015)](https://arxiv.org/abs/1412.0767)\n- #PAPER [Unsupervised Learning of Video Representations using LSTMs (Srivastava 2016)](https://arxiv.org/abs/1502.04681)\n- #PAPER [Convolutional Gated Recurrent Networks for Video Segmentation (Siam 2016)](https://arxiv.org/abs/1611.05435)\n\t- Hybrid convolutional and recurrent networks\n- #PAPER [LRCN: Long-term Recurrent Convolutional Networks for Visual Recognition and Description (Donahue 2016)](https://arxiv.org/abs/1411.4389)\n\t- Hybrid convolutional and recurrent networks\n- #PAPER [Convolutional Two-Stream Network Fusion for Video Action Recognition (Feichtenhofer 2016)](https://arxiv.org/abs/1604.06573)\n- #PAPER [Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning (Lotter 2016)](https://arxiv.org/abs/1605.08104)\n\t- https://coxlab.github.io/prednet/\n- #PAPER [ContextVP: Fully Context-Aware Video Prediction (Byeon 2018)](https://arxiv.org/abs/1710.08518)\n\t- http://on-demand.gputechconf.com/gtc/2018/presentation/s8713-fully-context-aware-video-prediction.pdf \n- #PAPER [Machine Learning for Spatiotemporal Sequence Forecasting: A Survey (Shi, 2018)](https://arxiv.org/abs/1808.06865)\n- #PAPER [Residual Convolutional LSTM for Tweet Count Prediction (Wei 2018)](https://dl.acm.org/doi/fullHtml/10.1145/3184558.3191571)\n- #PAPER [A Closer Look at Spatiotemporal Convolutions for Action Recognition (Tran 2018)](https://arxiv.org/abs/1711.11248)\n\t- #CODE https://github.com/facebookresearch/VMZ\n\t- #CODE See Ghadiyaram 2019 below\n\t- #CODE https://github.com/juenkhaw/action_recognition_project\n\t- demonstrate that 3D ResNets significantly outperform 2D ResNets for the same depth when trained and evaluated on large-scale,challenging action recognition benchmarks\n\t- introduce two new forms of spatio temporal convolution that can be viewed as middle grounds between the extremes of 2D (spatial convolution) and full 3D: mixed convolution (MC) and consists in employing 3D convolutions only in the early layers of the network, with 2D convolutions in the top layers, and the R(2+1)D spatiotemporal conv block which explicitly factorizes 3D convolution into two separate and successive operations, a 2D spatial convolution and a 1D temporal convolution\n\t- the first advantage is an additional nonlinear rectification between these two operations. This effectively doubles the number of non-linearities compared to a network using full 3D convolutions for the same number of parameters, thus rendering the model capable of representing more complex functions.The second potential benefit is that the decomposition facilitates the optimization, yielding in practice both a lower training loss and a lower testing loss\n- #PAPER [Video Classification with Channel-Separated Convolutional Networks (Tran 2019)](https://arxiv.org/abs/1904.02811)\n\t- #CODE https://github.com/facebookresearch/VMZ\n- #PAPER [Dilated 3D Convolutional Neural Networks for Brain MRI Data Classification (Wang 2019)](https://ieeexplore.ieee.org/abstract/document/8840843)\n- #PAPER [Deep Learning for Spatio-Temporal Data Mining: A Survey (Wang 2019)](https://arxiv.org/abs/1906.04928)\n- #PAPER [Large-scale weakly-supervised pre-training for video action recognition (Ghadiyaram 2019)](https://arxiv.org/abs/1905.00561)\n\t- #CODE https://github.com/microsoft/computervision-recipes/tree/master/scenarios/action_recognition\n- #PAPER [Eidetic 3D LSTM A Model for Video Prediction and Beyond, E3D-LSTM (Wang 2019)](https://openreview.net/forum?id=B1lKS2AqtX)\n\t- #CODE https://github.com/google/e3d_lstm\n- #PAPER [Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition (Esat Kalfaoglu 2020)](https://arxiv.org/abs/2008.01232)\n- #PAPER [An Image is Worth 16x16 Words, What is a Video Worth? (Sharir 2021)](https://arxiv.org/abs/2103.13915)\n- #PAPER [UNETR: Transformers for 3D Medical Image Segmentation (Hatamizadeh 2021)](https://arxiv.org/abs/2103.10504)\n\t- https://theaisummer.com/medical-segmentation-transformers/\n\t- UNETR is the first successful transformer architecture for 3D medical image segmentation\n- #PAPER [Dense Unsupervised Learning for Video Segmentation (Araslanov 2021)](https://arxiv.org/abs/2111.06265)\n\t- https://github.com/visinf/dense-ulearn-vos\n\t- methods that learns spatio-temporal correspondences without any supervision ([Unsupervised learning](AI/Unsupervised%20learning/Unsupervised%20learning.md)), and achieves state-of-the-art accuracy of video object segmentation\n\t- #TALK https://www.youtube.com/watch?v=tSBWZ6nYld0\n- #PAPER [Mask2Former for Video Instance Segmentation (Cheng 2021)](https://arxiv.org/abs/2112.10764v1)\n\t- #CODE https://github.com/facebookresearch/Mask2Former","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Dask":{"title":"Dask","content":"## Resources\n- [Parallel computing with Dask](https://xarray.pydata.org/en/v0.10.1/dask.html)\n- http://jcrist.github.io/introducing-dask-searchcv.html\n\n## Talks\n- #TALK [Dask for ad hoc distributed computing (Pydata)](https://www.youtube.com/watch?v=EEfI-11itn0)\n- #TALK [Using Dask for Parallel Computing in Python](https://www.youtube.com/watch?v=s4ChP7tc3tA)\n- #TALK [Parallelizing Scientific Python with Dask | SciPy 2017 Tutorial | James Crist](https://www.youtube.com/watch?v=mbfsog3e5DA)\n\n\n## Code\n- #CODE [Dask](https://github.com/dask/dask)\n\t- flexible parallel computing library for analytics\n\t- http://docs.dask.org/en/latest/cheatsheet.html\n- #CODE [Dask-Jobqueue](https://github.com/dask/dask-jobqueue)\n\t- https://jobqueue.dask.org/en/latest/\n\t- Easily deploy Dask on job queuing systems like PBS, Slurm, MOAB, SGE, LSF, and HTCondor\n\t- [Scalable interactive analysis workflows using dask on HPC Systems](https://medium.com/pangeo/dask-jobqueue-d7754e42ca53)\n- #code [Dask-ml - [Machine Learning](AI/Machine%20Learning.md) with Dask](https://github.com/dask/dask-ml)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Data-Science":{"title":"Data Science","content":"## Resources\n- https://en.wikipedia.org/wiki/Data_science\n- https://github.com/bulutyazilim/awesome-datascience\n- [Reproducible Data Analysis in Jupyter (Vanderplas)](https://jakevdp.github.io/blog/2017/03/03/reproducible-data-analysis-in-jupyter/)\n- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)\n- [An Executive's Guide To Understanding Cloud-based ML Services](https://www.forbes.com/sites/janakirammsv/2019/01/01/an-executives-guide-to-understanding-cloud-based-machine-learning-services/)\n- [Why data-driven science is more than just a buzzword](https://sydney.edu.au/news-opinion/news/2017/05/11/Why-data-driven-science-is-more-than-just-a-buzzword.html)\n- [A Complete Data Science Curriculum for Beginners](https://towardsdatascience.com/a-complete-data-science-curriculum-for-beginners-825a39915b54)\n\n### Cheatsheets\n- https://github.com/ml874/Data-Science-Cheatsheet\n- https://github.com/aaronwangy/Data-Science-Cheatsheet\n- https://github.com/FavioVazquez/ds-cheatsheets\n\n### Infographics\n- [Data Never Sleeps 3.0](https://www.domo.com/blog/data-never-sleeps-3-0/)\n- [The Data Science Industry - who does what](https://www.datacamp.com/community/tutorials/data-science-industry-infographic)\n- [Learn data science infographic](https://www.datacamp.com/community/tutorials/learn-data-science-infographic)\n- [DS Infographic](http://online.rutgers.edu/resources/infographics/what-can-you-do-with-a-career-in-data-science/)\n- [Data Science Venn Diagram v2.0](http://www.anlytcs.com/2014/01/data-science-venn-diagram-v20.html)\n- [Updated DS Venn diagram](http://www.kdnuggets.com/2016/09/new-data-science-venn-diagram.html)\n- [DS vs STATS vs DATA-ENG](https://www.analyticsvidhya.com/blog/2015/10/job-comparison-data-scientist-data-engineer-statistician/)\n\n### Data Science for good\n- See [AI4good](AI4G/AI4good.md)\n\n## References\n- #PAPER [Science and data science (Blei 2017)](https://www.pnas.org/content/114/33/8689)\n- #PAPER [50 Years of Data Science (Donoho 2017)](https://www.tandfonline.com/doi/full/10.1080/10618600.2017.1384734)\n\t- #TALK 50 Years of Data Science (Donoho)\n\t\t- https://www.youtube.com/watch?v=GUFL-Mf0EWY\n\t\t- https://www.youtube.com/watch?v=E7w-gfFKPf8\n\t\t- https://www.youtube.com/watch?v=QTzNXYcZLbU\n\t\t- https://www.youtube.com/watch?v=BnRRwmeGBgU\n\t- Comments: \n\t\t- https://matloff.wordpress.com/2016/01/23/some-comments-on-donahos-50-years-of-data-science/\n\t\t- https://medium.com/@srowen/what-50-years-of-data-science-leaves-out-2366c9b61d3d\n\t\t- https://www.youtube.com/watch?v=zamQgXDytUA\n\t\t- #TALK [Big Data LDN 2016: What ‚Äú50 Years of Data Science‚Äù Leaves Out](https://www.youtube.com/watch?v=zamQgXDytUA)\n- #PAPER [Theory-guided data science: a new paradigm for scientific discovery from data (Karpatne 2017)](https://ieeexplore.ieee.org/document/7959606)\n\n\n## Books\n- #BOOK [The field guide to DS (Booz Allen Hamilton Inc 2015)](https://www.boozallen.com/s/insight/publication/field-guide-to-data-science.html)\n\t- https://www.boozallen.com/content/dam/boozallen_site/sig/pdf/publications/2015-field-guide-to-data-science.pdf\n\t- https://github.com/booz-allen-hamilton/The-Field-Guide-to-Data-Science\n- #BOOK [Going pro in data science (Overton 2016, O'REILLY)](https://www.oreilly.com/library/view/going-pro-in/9781492048534/)\n\t- http://ds4100.weebly.com/uploads/8/6/5/9/8659576/going-pro-in-data-science.pdf\n- #BOOK [Weapons of Math Destruction - How big data increases inequality and threatens democracy (O'Neil, 2016)](https://weaponsofmathdestructionbook.com/)\n\t- https://we.riseup.net/assets/404114/Weapons+of+Math+Destruction+Cathy+O%27Neil.pdf\n- #BOOK [Introducing Data Science - Big Data, ML and more, using Python tools (Cielen 2016, MANNING)](https://www.manning.com/books/introducing-data-science)\n\t- http://bedford-computing.co.uk/learning/wp-content/uploads/2016/09/introducing-data-science-machine-learning-python.pdf\n- #BOOK [Mastering Python for Data Science (Madhavan 2015, PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/mastering-python-data-science)\n\t- http://nuovolabs.fauser.edu/~valeria/materiale-didattico/python/Packt.Mastering.Aug.2015.ISBN.1784390151.pdf\n- #BOOK [Python Data Science Handbook (VanderPlas, 2016 OREILLY)](https://jakevdp.github.io/PythonDataScienceHandbook/)\n\t-  http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb\n- #BOOK [Python for Data Analysis 2nd ed (McKinney, 2017 O'REILLY)](http://wesmckinney.com/pages/book.html)\n\t-  https://github.com/wesm/pydata-book\n- #BOOK [Scala for Data Science (Bugnion, 2016 PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/scala-data-science)\n- #BOOK [Scala: Guide for Data Science Professionals (Nicolas, 2017 PACKT)](http://shop.oreilly.com/product/9781787282858.do)\n- #BOOK [R for Data Science (Grolemund 2017 O'REILLY)](http://r4ds.had.co.nz/)\n- #BOOK [Data Science Live Book (in R)](https://livebook.datascienceheroes.com/)\n- #BOOK [R Programming for Data Science (Peng, 2020)](https://bookdown.org/rdpeng/rprogdatascience/)\n- #BOOK [Statistical Inference via Data Science (Ismay 2020)](https://moderndive.com/)\n- #BOOK [Data Science Live Book (Casas 2020)](https://livebook.datascienceheroes.com/)\n- #BOOK [Geographic Data Science with Python](https://geographicdata.science/book/intro.html)\n- #BOOK [Network Data Science](https://bdpedigo.github.io/networks-course/landing.html)\n- #BOOK [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html)\n- #BOOK [The Data Science Interview Book](https://dipranjan.github.io/dsinterviewqns/intro.html)\n- #BOOK [Statistics and Data Science](http://theoryandpractice.org/stats-ds-book/intro.html)\n\n\n## Courses\n- #COURSE [Mathematical Tools for Data Science (NYU Center for Data Science)](https://cds.nyu.edu/math-tools/)\n- - #COURSE [Python for Data Science workshop (Paris-Saclay Center for Data Science)](https://github.com/paris-saclay-cds/python-workshop)\n- #COURSE [Data Science (Harvard CS109)](http://cs109.github.io/2015/)\n- #COURSE [Data 8: The Foundations of Data Science (UC Berkeley)](http://data8.org/fa16/)\n\t-  https://www.inferentialthinking.com/index.html\n- #COURSE [Intro to Data Science (Udacity)](https://www.udacity.com/course/intro-to-data-science--ud359)\n- #COURSE [Introduction to Data Science in Python (Coursera, U Michigan)](https://www.coursera.org/learn/python-data-analysis)\n- #COURSE [Data Science in Stratified Healthcare and Precision Medicine (Coursera, U Edinburgh)](https://www.coursera.org/learn/datascimed)\n- #COURSE [Big Data Analytics in Healthcare (Udacity, Georgia Tech)](https://eu.udacity.com/course/big-data-analytics-in-healthcare--ud758)\n- #TALK [Building a Data Science Team with Open Source Tools](https://www.youtube.com/watch?v=mzTlqNTHTmc)\n- #TALK [Introduction to Python for Data Science (Seabold, PyCon 2018)](https://www.youtube.com/watch?v=W4WQi2OIy7o)\n\n\n## Code\n### Interactive Computing Environments\n- #CODE [Jupyter](AI/DS%20and%20DataEng/Jupyter.md)\n- #CODE [Zepelin](https://zeppelin.apache.org/)\n- #CODE [Rstudio](https://www.rstudio.com/products/rstudio/)\n- #CODE [Cauldron](https://github.com/sernst/cauldron)\n\t- http://www.unnotebook.com/\n- #CODE [Polynote](https://github.com/polynote/polynote)\n\t- https://polynote.org/\n- #CODE [Google Colaboratory](https://colab.research.google.com/)\n\n\n## Related fields\n\n### Math and Statistics\nSee [Math and Statistics](AI/Math%20and%20Statistics/Math%20and%20Statistics.md)\n\n### Machine Learning\nSee [Machine Learning](AI/Machine%20Learning.md)\n\n### Data engineering and Computer Science\nSee [Data engineering and computer science](AI/DS%20and%20DataEng/Data%20engineering%20and%20computer%20science.md)\n\n### Visualization\nSee [Visualization](AI/DS%20and%20DataEng/Visualization.md)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Data-engineering-and-computer-science":{"title":"Data Engineering and Computer Science","content":"## Resources\n- Data engineering role is ensuring uninterrupted flow of data between servers and applications\n- https://github.com/ossu/computer-science\n- [What is Data Engineering and Why Is It So Important?](https://quanthub.com/what-is-data-engineering/)\n- [ETL (extract, transform, load)](https://en.wikipedia.org/wiki/Extract,_transform,_load)\n- [Have we bridged the gap between Data Science and DevOps?](https://jaxenter.com/bridge-gap-data-science-devops-134712.html)\n\n### Python\n- #COURSE [Python in High Performance Computing](https://www.futurelearn.com/courses/python-in-hpc)\n- #COURSE [Scientific Computing with Python](https://www.freecodecamp.org/learn/scientific-computing-with-python/)\n- #COURSE [SoloLearn Python 3 Tutorial](https://www.sololearn.com/Course/Python/)\n- #COURSE https://www.learneroo.com/modules/65/nodes/366\n- https://github.com/FavioVazquez/ds-cheatsheets/tree/master/Python\n- https://github.com/ujjwalkarn/DataSciencePython\n- [Numpy](http://www.labri.fr/perso/nrougier/from-python-to-numpy/)\n- [Optimizing Python code performance with cProfile](https://blog.alookanalytics.com/2017/03/21/python-profiling-basics/)\n- [Consistent Python code with Black](https://www.mattlayman.com/blog/2018/python-code-black/)\n- [Writing proper classes](https://aboucaud.github.io/slides/2016/python-classes)\n- [Documenting Python code](https://aboucaud.github.io/slides/2016/python-docstrings)\n- [Compiled C or Fortran to Python](http://people.duke.edu/~ccc14/sta-663/FromCompiledToPython.html)\n- [Using Python as glue](https://docs.scipy.org/doc/numpy-1.13.0/user/c-info.python-as-glue.html)\n- [Extending Python with Compiled Code](https://github.com/AstroHackWeek/AstroHackWeek2014/blob/master/day4/ExtendingPython.ipynb)\n- [Wrapping C/C++ for Python](https://intermediate-and-advanced-software-carpentry.readthedocs.io/en/latest/c++-wrapping.html)\n\n### R\n- #BOOK [R para profesionales de los datos: una introducci√≥n](https://www.datanalytics.com/libro_r/)\n- #BOOK [Geocomputation with R](https://geocompr.robinlovelace.net/)\n- #BOOK [Efficient R programming](https://csgillespie.github.io/efficientR/)\n- #BOOK [Engineering Production-Grade Shiny Apps](https://engineering-shiny.org/)\n- #BOOK [Advanced R](https://adv-r.hadley.nz/)\n- #BOOK [Hands-On Programming with R](https://rstudio-education.github.io/hopr/)\n- #BOOK [R Packages (Wickham 2020)](https://r-pkgs.org/)\n\n### Julia \n- #TALK https://www.youtube.com/watch?v=AyvyVS6u8AM\n- https://julialang.org/learning/\n\n### Javascript\n- https://www.w3schools.com/js/\n- https://codesandbox.io\n- https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/JavaScript_basics\n- https://dtabio.gitbooks.io/data-science-with-javascript/content/links_and_resources.html\n- http://www.kdnuggets.com/2016/06/top-machine-learning-libraries-javascript.html\n\n### Bash\n- [free GNU/Linux Online Terminal and Programming IDE](http://www.webminal.org/)\n\n\n### CUDA\n- https://developer.nvidia.com/cuda-education\n- https://dragan.rocks/articles/18/Interactive-GPU-Programming-1-Hello-CUDA\n\n\n## Books\n- #BOOK [Problem Solving with Algorithms and Data Structures using Python (Interactive book)](https://runestone.academy/runestone/books/published/pythonds/index.html)\n- #BOOK [Large Scale Machine Learning with Python (Sjandin 2016, PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/large-scale-machine-learning-python)\n- #BOOK [Mining of Massive Datasets (Leskovec, 2014 CAMBRIDGE)](http://www.mmds.org/)\n- #BOOK [Advanced Analytics with Spark (Ryza, 2017 OREILLY)](http://shop.oreilly.com/product/0636920056591.do)\n\t- [Advanced Analytics with Spark, 2nd Edition.pdf](https://github.com/analystfreakabhi/btb_spark/blob/master/Advanced%20Analytics%20with%20Spark%2C%202nd%20Edition.pdf)\n- #BOOK [Pandas cookbook (Petrou, 2017 PACKT)](https://packtpub.com/big-data-and-business-intelligence/pandas-cookbook)\n- #BOOK [The Big Book of Data Engineering (Databricks)](https://databricks.com/p/ebook/the-big-book-of-data-engineering)\n\n\n## Courses\n- #COURSE [Data Structures \u0026 Algorithms - Python](https://pythonschool.net/category/data-structures-algorithms.html)\n- #COURSE [Intro to Hadoop and MapReduce](https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617)\n- #COURSE [Mining Massive Data Sets (CS246 Stanford)](http://web.stanford.edu/class/cs246/)\n\t- https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about\n- #COURSE [Getting and Cleaning Data (Coursera)](https://www.coursera.org/learn/data-cleaning)\n- SQL:\n\t- [Tutorial and exercises](http://sqlzoo.net)\n\t- SQL (basic, intermediate, advanced / pet problems): \n\t\t- https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/\n\t\t- https://github.com/FavioVazquez/ds-cheatsheets/tree/master/SQL\n\n## Code\n- #CODE [ABSL.flags](https://abseil.io/docs/python/guides/flags)\n\t- Defines a distributed command line system and manual argument parsing\n- #CODE [StreamAlert](https://github.com/airbnb/streamalert)\n\t- StreamAlert is a serverless, realtime data analysis framework which empowers you to ingest, analyze, and alert on data from any environment, using datasources and alerting logic you define\n- #CODE [Pandas](https://github.com/pandas-dev/pandas)\n\t- https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n\t- https://www.youtube.com/watch?v=9d5-Ti6onew\n\t- https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n\t- [Merge, Join and concatenate](http://pandas.pydata.org/pandas-docs/stable/merging.html)\n\t- [SQL for pandas](http://blog.yhat.com/posts/pandasql-intro.html)\n\t- [Plotting in pandas](http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n\t- http://jakevdp.github.io/blog/2017/03/22/group-by-from-scratch/\n\t- [Essential Descriptive Statistics in Pandas](https://simplyml.com/essential-descriptive-statistics-in-pandas/)\n\t- Selecting Subsets of Data in Pandas:\n\t\t- https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c\n\t\t- https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-39e811c81a0c\n- #CODE [Modin - Scale your pandas workflows by changing one line of code](https://github.com/modin-project/modin)\n- #CODE [Xarray](AI/DS%20and%20DataEng/Xarray.md)\n- #CODE [Dedupe - A python library for accurate and scaleable fuzzy matching, record deduplication and entity-resolution](https://github.com/dedupeio/dedupe)\n\t- http://blog.districtdatalabs.com/basics-of-entity-resolution\n- #CODE [PyTables](https://github.com/PyTables/PyTables)\n\t- http://www.pytables.org/\n- #CODE [H5py](https://github.com/h5py/h5py)\n- #CODE [Singer - Simple, Composable Open Source ETL](https://www.singer.io/)\n- #CODE [Docker](https://www.docker.com/)\n\t- https://towardsdatascience.com/docker-for-data-science-4901f35d7cf9\n- #CODE Kubernetes - K8s is an open-source system for automating deployment, scaling, and management of containerized applications.\n\t- https://kubernetes.io/\n\t- https://opensource.com/article/19/1/why-data-scientists-love-kubernetes\n\t- https://github.com/Langhalsdino/Kubernetes-GPU-Guide\n\t- https://blog.alexellis.io/kubernetes-in-10-minutes/\n\n ### Business Intelligence\n - #CODE [kuwala](https://github.com/kuwala-io/kuwala)\n\t - https://kuwala.io/\n \n ### Big data, distributed computing\n- #CODE [Dask](AI/DS%20and%20DataEng/Dask.md)\n- #CODE [Ray](https://github.com/ray-project/ray)\n\t- A system for parallel and distributed Python that unifies the ML ecosystem\n\t- https://ray.readthedocs.io/en/latest/\n\t- https://ray-project.github.io/\n\t- #TALK [Ray: A Distributed Execution Framework for AI | SciPy 2018 | Robert Nishihara](https://www.youtube.com/watch?v=D_oz7E4v-U0)\n\t- #TALK [Ray: A System for Scalable Python and ML |SciPy 2020| Robert Nishihara](https://www.youtube.com/watch?v=XIu8ZF7RSkw)\n- #CODE [PyGDF - GPU Data Frame](https://github.com/gpuopenanalytics/pygdf)\n\t- https://devblogs.nvidia.com/parallelforall/goai-open-gpu-accelerated-data-analytics/\n- #CODE [Apache Hadoop](http://hadoop.apache.org/)\n\t- The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models.\n\t- https://www.quora.com/What-is-the-difference-between-Apache-Spark-and-Apache-Hadoop-Map-Reduce\n\t- [Intro to Hadoop and MapReduce (Udacity)](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkXJ6LAV96gH8yxIfGaN3H-)\n\t- https://datawanderings.com/2017/01/15/your-first-diy-hadoop-cluster/\n\t- http://ruhanixedu.com/blog/interview-question-and-answers/big-data/\n- #CODE [Apache Spark](https://en.wikipedia.org/wiki/Apache_Spark)\n\t- http://cacm.acm.org/magazines/2016/11/209116-apache-spark/fulltext\n\t- http://www.kdnuggets.com/2015/11/introduction-spark-python.html\n\t- https://databricks.com/blog/2018/05/03/benchmarking-apache-spark-on-a-single-node-machine.html\n\t- #TALK [A brief introduction to Distributed Computing with PySpark (Pydata)](https://www.youtube.com/watch?v=bJouNc1REno)\n\t- #TALK [Connecting Python To The Spark Ecosystem](https://www.youtube.com/watch?v=niTAJYCEAUM)\n\t- http://tech.marksblogg.com/billion-nyc-taxi-rides-spark-2-1-0-emr.html\n\t- http://ruhanixedu.com/blog/interview-question-and-answers/apache-spark-interview-questions-answers/\n\t- [Text Normalization with Spark](http://www.treselle.com/blog/text-normalization-with-spark-part-1/)\n\t- [Spark ML](http://spark.apache.org/docs/latest/ml-guide.html)\n\t\t- https://www.infoq.com/articles/apache-sparkml-data-pipelines\n\t\t- https://commitlogs.com/2017/02/18/serve-spark-ml-model-using-play-framework-and-s3/\n\t\t- https://pages.databricks.com/definitive-guide-spark.html\n\t- [MLlib](http://spark.apache.org/mllib/, https://spark.apache.org/docs/latest/ml-guide.html)\n\t- [PySpark](https://spark.apache.org/docs/latest/api/python/index.html)\n\t- [Optimus](https://github.com/hi-primus/optimus)\n- #CODE [Apache Storm](https://storm.apache.org/)\n\t- http://zdatainc.com/2014/09/apache-storm-apache-spark/\n\t- http://www.collaberatact.com/understanding-hadoop-vs-spark-vs-storm/\n- #CODE [Apache Arrow](https://arrow.apache.org/)\n\t- http://wesmckinney.com/blog/apache-arrow-pandas-internals/\n- #CODE [Blaze](http://blaze.pydata.org/)\n\t- http://blaze.readthedocs.io/en/latest/index.html\n\n### Databases\n- SQL:\n\t- #CODE [SQLAlchemy](https://www.sqlalchemy.org/)\n\t\t- https://github.com/zzzeek/sqlalchemy\n\t- #CODE [Pyodbc](https://github.com/mkleehammer/pyodbc)\n\t- #CODE [ClickHouse](https://clickhouse.yandex/)\n- NoSQL:\n\t- [Neo4j](https://neo4j.com/product/)\n\t- [MongoDB](https://en.wikipedia.org/wiki/MongoDB)\n\t- [PyMongo](https://api.mongodb.com/python/current/)\n\t- [CouchDB](https://en.wikipedia.org/wiki/CouchDB)\n\n\n## Subtopics\n\n### Open datasets (for ML, DL and DS)\nSee [Open ML data](AI/DS%20and%20DataEng/Open%20ML%20data.md)\n\n### MLOps\nSee [ML Ops](AI/DS%20and%20DataEng/ML%20Ops.md)\n\n### Feature engineering\n- https://en.wikipedia.org/wiki/Feature_engineering\n- Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. It is fundamental to the application of ML, and is both difficult and expensive. The need for manual feature engineering can be obviated by automated feature learning\n- http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/\n- https://tech.zalando.com/blog/feature-extraction-science-or-engineering/\n\n#### Feature extraction\nSee [Feature learning](AI/Feature%20learning.md) techniques in [Computer vision](AI/Computer%20Vision/Computer%20vision.md)\n\n\n### Data mining\n- http://nbviewer.jupyter.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/tree/master/ipynb/\n- https://www.dataquest.io/course/apis-and-scraping\n\n#### Web scraping\n- https://www.dataquest.io/blog/web-scraping-tutorial-python/\n- http://thiagomarzagao.com/2013/11/12/webscraping-with-selenium-part-1/\n- https://medium.com/@hoppy/how-to-test-or-scrape-javascript-rendered-websites-with-python-selenium-a-beginner-step-by-c137892216aa#.hrjljvffd\n- https://antonio-maiolo.com/2016/12/01/web-crawler-scrapy-crawl-spider-tutorial/\n- http://stackoverflow.com/questions/19021541/scrapy-scrapping-data-inside-a-javascript\n\n#### API\n- [A categorized public list of APIs from round the web](https://github.com/abhishekbanthia/Public-APIs)\n- [A collective list of public JSON APIs for use in web development](https://github.com/toddmotto/public-apis)\n- [Public APIs](https://public-apis.io/)\n\n\n### Databases\n- https://en.wikipedia.org/wiki/Distributed_database\n- [ACID (Atomicity, Consistency, Isolation, Durability) ](https://en.wikipedia.org/wiki/ACID)\n- [SQL vs NoSQL](http://dataconomy.com/2014/07/sql-vs-nosql-need-know/)\n\n#### SQL\n- https://en.wikipedia.org/wiki/SQL\n- https://en.wikipedia.org/wiki/Relational_database\n- A relational database is a digital database whose organization is based on the relational model of data. \n- https://www.analyticsvidhya.com/blog/2017/01/46-questions-on-sql-to-test-a-data-science-professional-skilltest-solution/\n- [Tutorial and exercises](http://sqlzoo.net)\n- [SQL (basic, intermediate, advanced / pet problems)](https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/)\n- [List of SQL Commands](https://www.codecademy.com/articles/sql-commands)\n- [JOIN](https://en.wikipedia.org/wiki/Join_(SQL))\n\t- A SQL join clause combines columns from one or more tables in a relational database. It creates a set that can be saved as a table or used as it is. A JOIN is a means for combining columns from one (self-table) or more tables by using values common to each. ANSI-standard SQL specifies five types ofJOIN:INNER,LEFT OUTER,RIGHT OUTER,FULL OUTER and CROSS.\n\t- https://periscopedata.com/blog//how-joins-work.html\n- https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems\n- Python interface\n\t- https://www.tutorialspoint.com/python/python_database_access.htm\n\t- http://www.python-course.eu/sql_python.php\n\t- https://wiki.python.org/moin/DatabaseInterfaces\n\n#### NoSQL\n- https://en.wikipedia.org/wiki/NoSQL\n- Not only SQL: A NoSQL database provides a mechanism for storage and retrieval of data which is modeled in means other than the tabular relations used in relational databases. NoSQL databases are increasingly used in big data and real-time web applications. Many NoSQL stores compromise consistency (in the sense of theCAP theorem) in favor of availability, partition tolerance, and speed. \n- Column: Accumulo, Cassandra, Druid, HBase, Vertica, SAP HANA \n- #TALK [GOTO 2012 - Introduction to NoSQL - Martin Fowler](https://www.youtube.com/watch?v=qI_g07C_Q5I)\n- Graph: \n\t- A graph database is a database that uses graph structures for semantic queries with nodes, edges and properties to represent and store data. A key concept of the system is the graph (or edge or relationship), which directly relates data items in the store. The relationships allow data in the store to be linked together directly, and in many cases retrieved with a single operation.\n\t- Graph databases employ nodes, edges and properties.\n\t\t- Nodes represent entities/items you might want to keep track of (people, businesses, accounts).\n\t\t- Edges, also known as graphs or relationships, are the lines that connect nodes to other nodes; they represent the relationship between them.\n\t\t- Properties are pertinent information that relate to nodes (sort of keywords).\n\t\t- AllegroGraph, ArangoDB, InfiniteGraph, Apache Giraph, MarkLogic, Neo4J, OrientDB, Virtuoso, Stardog\n\t\t- https://neo4j.com/developer/graph-database/\n- Key-value\n\t- https://en.wikipedia.org/wiki/Key-value_database\n\t- A key-value store, or key-value database, is a data storage paradigm designed for storing, retrieving, and managing associative arrays, a data structure more commonly known today as a dictionary or hash.\n\t- Dictionaries contain a collection of objects, or records, which in turn have many different fields within them, each containing data. These records are stored and retrieved using a key that uniquely identifies the record, and is used to quickly find the data within the database.\n- [Document-oriented database](https://en.wikipedia.org/wiki/Document-oriented_database)\n\n### Data munging\n- https://www.coursera.org/learn/data-cleaning\n\n#### Data preparation\n- Data cleansing: Missing data\n\t- https://scikit-learn.org/stable/modules/impute.html\n\t- https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#two\n\t- https://www.quora.com/How-can-I-deal-with-missing-values-in-a-predictive-model\n- [Variables encoding](http://pbpython.com/categorical-encoding.html)\n- [Normalisation, scaling](http://scikit-learn.org/stable/modules/preprocessing.html)\n- [Outlier detection](https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#three)\n\n#### Exploratory data analysis\n- https://www.codementor.io/jadianes/data-science-python-r-exploratory-data-analysis-visualization-du107jjms\n- http://blog.districtdatalabs.com/data-exploration-with-python-2\n- https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/\n\n\n### Big data\n- http://www.datasciencecentral.com/profiles/blogs/25-big-data-terms-you-must-know-to-impress-your-date-or-whoever\n- [Architecture of Giants: Data Stacks at Facebook, Netflix, Airbnb, and Pinterest](https://blog.keen.io/architecture-of-giants-data-stacks-at-facebook-netflix-airbnb-and-pinterest-9b7cd881af54)\n\n#### MapReduce\n- https://en.wikipedia.org/wiki/MapReduce\n- MapReduce is a programming model and an associated implementation for processing and generating large data sets with a parallel, distributed algorithm on a cluster\n- A MapReduce program is composed of aMap() procedure (method) that performs filtering and sorting (such as sorting students by first name into queues, one queue for each name) and aReduce() method that performs a summary operation (such as counting the number of students in each queue, yielding name frequencies)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Distributed-DL":{"title":"Distributed Deep learning","content":"## Resources\n- https://d2l.ai/chapter_computational-performance/multiple-gpus.html \n- https://jhui.github.io/2017/03/07/TensorFlow-GPU/ \n- https://www.logicalclocks.com/blog/goodbye-horovod-hello-collectiveallreduce \n- [Twelve ways to fool the masses when reporting performance of deep learning workloads](https://htor.inf.ethz.ch/blog/index.php/2018/11/08/twelve-ways-to-fool-the-masses-when-reporting-performance-of-deep-learning-workloads/)\n- [Distributed Deep Learning 101: Introduction](https://towardsdatascience.com/distributed-deep-learning-101-introduction-ebfc1bcd59d9)\n\n## Talks\n- #TALK [ALCF Datascience frameworks: Tensorflow, PyTorch, Keras, and Horovod](https://www.alcf.anl.gov/files/Zheng_SDL_ML_Frameworks_1.pdf)\n- #TALK [Scaling Deep Learning for Scientific Workloads on the #1 Summit Supercomputer](https://insidehpc.com/2019/04/scaling-deep-learning-for-scientific-workloads-on-the-1-summit-supercomputer/)\n- #TALK [Scaling Neural Networks Training - Thorsten Kurth](https://www.youtube.com/watch?v=cRjiwIi_kuc)\n\n## Code\nSee [Tensorflow, keras](AI/DS%20and%20DataEng/Tensorflow,%20keras.md), Distributed training section\n\n- #CODE [Analytics Zoo](https://github.com/intel-analytics/analytics-zoo)\n\t- Distributed Tensorflow, Keras and PyTorch on Apache Spark/Flink \u0026 Ray\n\t- https://analytics-zoo.readthedocs.io/en/latest/index.html\n- #CODE [Horovod](AI/DS%20and%20DataEng/Horovod.md)\n- #CODE [Colossal-AI: A Unified Deep Learning System for Large-Scale Parallel Training](https://github.com/hpcaitech/colossalai)\n\t- See [[#^colossalai]]\n\t-  https://www.marktechpost.com/2021/10/31/researchers-introduce-colossal-ai-a-pytorch-based-deep-learning-system-for-large-scale-parallel-training/\n\n## References\n- #PAPER [Evaluation of Deep Learning Frameworks over Different HPC Architectures (Shams 2017)](https://www.ibm.com/university/power/images/EvaluationofDeepLearningFrameworksoverDifferentHPCArchitectures.pdf)\n- #PAPER [Deep Learning at 15PF: Supervised and Semi-Supervised Classification for Scientific Data (Kurth 2017)](https://arxiv.org/abs/1708.05256)\n- #PAPER [Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis (Tal Ben-Nun and Torsten Hoefler 2018)](http://arxiv.org/abs/1802.09941) ^bennun18\n\t- #TALK [Hoefler 2018](https://www.youtube.com/watch?v=xtxxLWZznBI)\n\t- #TALK [Hoefler 2020](https://www.youtube.com/watch?v=uNzQ1vvJ82c)\n\t- #TALK [Ben-Nun 2020](https://www.youtube.com/watch?v=N5uIFSVR7jE)\n- #PAPER [Mesh-TensorFlow: Deep Learning for Supercomputers (Shazeer 2018)](https://arxiv.org/abs/1811.02084v1) ^f86598\n\t- #TALK https://www.youtube.com/watch?v=HgGyWS40g-g\n\t- #CODE [Mesh-TensorFlow](https://github.com/tensorflow/mesh)\n\t\t- Go beyond data-parallel training\n\t\t- More sophisticated parallel computations (big models that do not fit on one device)\n- #PAPER [GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism (Huang 2019)](http://arxiv.org/abs/1811.06965)\n- #PAPER [A Quantitative Study of Deep Learning Training on Heterogeneous Supercomputers (Han 2019)](https://ieeexplore.ieee.org/document/8890993)\n\t- http://people.cs.vt.edu/~butta/docs/cluster2019-DL.pdf\n- #PAPER [Channel and filter parallelism for large-scale CNN training (Dryden 2019)](https://dl.acm.org/doi/10.1145/3295500.3356207)\n\t- https://ndryden.com/data/papers/sc2019-chanfilt.pdf\n- #PAPER [Improving Strong-Scaling of CNN Training by Exploiting Finer-Grained Parallelism (Dryden 2019)](http://arxiv.org/abs/1903.06681)\n- #PAPER [Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training (Li 2019)](http://arxiv.org/abs/1811.03619)\n- #PAPER [Scalable Deep Learning on Distributed Infrastructures: Challenges, Techniques and Tools (Mayer 2019)](http://arxiv.org/abs/1903.11314)\n- #PAPER [Performance Analysis of Deep Learning Workloads on Leading-edge Systems (Ren 2019)](https://www.osti.gov/biblio/1571428-performance-analysis-deep-learning-workloads-leading-edge-systems)\n- #PAPER [TensorFlow on State-of-the-Art HPC Clusters: A Machine Learning use Case (Ramirez-Gargallo 2019)](https://ieeexplore.ieee.org/document/8752892) ^ramirez19\n\t- https://core.ac.uk/download/pdf/196280993.pdf \n\t- Compared MN4, Power9 and Dibona HPC clusters. Only CPUs compared (Power9 GPUs are not evaluated)\n- #PAPER [Exascale Deep Learning for Scientific Inverse Problems (Laanait 2019)](http://arxiv.org/abs/1909.11150)\n- #PAPER [TensorFlow Doing HPC (Chien 2019)](https://arxiv.org/abs/1903.04364)\n- #PAPER [ZeRO: memory optimizations toward training trillion parameter models (Rajbhandari 2019)](https://arxiv.org/abs/1910.02054)\n\t- #CODE [DeepSpeed](https://github.com/microsoft/DeepSpeed)\n\t\t- DeepSpeed is a deep learning optimization library that makes distributed training easy, efficient, and effective. For pytorch\n\t\t- www.deepspeed.ai/\n\t- https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/\n- #PAPER [Towards a Scalable and Distributed Infrastructure for Deep Learning Applications (Hasheminezhad 2020)](https://arxiv.org/abs/2010.03012)\n\t- Phylanx Deep Learning Framework\n\t- Good comparison with respect to SOTA\n\t- [Phylanx provides a high-productivity debugable Python-based interactive interface, JetLag](https://github.com/STEllAR-GROUP/JetLag)\n\t- Tests only on CPU. Does it support GPUs?\n- #PAPER [Distributed Training of Deep Learning Models: A Taxonomic Perspective (Langer 2020)](https://arxiv.org/abs/2007.03970)\n- #PAPER [Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training (Bian 2021)](https://arxiv.org/abs/2110.14883) ^colossalai","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Horovod":{"title":"Horovod","content":"## References\n- #PAPER [Horovod: fast and easy distributed deep learning in TensorFlow (Sergeev 2018)](http://arxiv.org/abs/1802.05799 )\n\t- #CODE https://github.com/horovod/horovod \n\t- https://horovod.readthedocs.io/en/latest/keras.html \n\t- https://horovod.readthedocs.io/en/stable/tensorflow.html\n\t- https://eng.uber.com/horovod/\n\t- Horovod is a distributed training framework for TensorFlow, Keras, PyTorch, and MXNet. The goal of Horovod is to make distributed Deep Learning fast and easy to use. Horovod is hosted by the‚ÄØLF AI Foundation‚ÄØ(Linux Foundation AI). Horovod implements all-reduce operations into the back-propagation computation to average the computed gradients and allow the distributed scaling among multiple GPUs. Based on Baidu ring allreduce (http://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/)\n\t- [Not straightforward from Jupyterlab](https://github.com/horovod/horovod/issues/622. Possible solution - Ipyparallel:)\n\t\t- [Interactive Distributed Deep Learning with Jupyter Notebooks](https://sc18.supercomputing.org/proceedings/tech_poster/poster_files/post206s2-file3.pdf)\n\t\t- https://github.com/sparticlesteve/cori-intml-examples \n\n## Examples\n- https://github.com/horovod/horovod/tree/master/examples\n- https://horovod.readthedocs.io/en/stable/running_include.html\n- https://github.com/horovod/tutorials/blob/master/fashion_mnist/README.md \n- [Distributed Deep Learning with Horovod (Jordi Torres)](https://towardsdatascience.com/distributed-deep-learning-with-horovod-2d1eea004cb2)\n- https://towardsdatascience.com/a-quick-guide-to-distributed-training-with-tensorflow-and-horovod-on-amazon-sagemaker-dae18371ef6e \n- [with SLURM on the BSC-P9 cluster](https://towardsdatascience.com/distributed-deep-learning-with-horovod-2d1eea004cb2)\n- With SLURM workload manager. See paper Ramirez-Gargallo 2019 in [Distributed DL](AI/DS%20and%20DataEng/Distributed%20DL.md)\n- [Example with SLURM](http://www.idris.fr/eng/jean-zay/gpu/jean-zay-gpu-hvd-tf-multi-eng.html)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Jupyter":{"title":"Jupyter","content":"## Resources\n- #CODE [Jupyter](https://github.com/jupyter)\n\t- #CODE [Jupyterlab](https://github.com/jupyterlab/jupyterlab )\n\t- #CODE [Jupyter(hub)](https://jupyter.org/hub )\n\t- #CODE [Jupyterlite](https://github.com/jupyterlite)\n\t\t- https://blog.jupyter.org/jupyterlite-jupyter-%EF%B8%8F-webassembly-%EF%B8%8F-python-f6e2e41ab3fa\n\t- #CODE [Stickyland](https://github.com/xiaohk/stickyland)\n\t\t- Break the linear presentation of Jupyter Notebooks with sticky cells\n\t- #CODE [Nbterm](https://github.com/davidbrochart/nbterm) - Jupyter Notebooks in the terminal\n- #CODE [Papermill - Parameterize, execute, and analyze notebooks](https://github.com/nteract/papermill)\n- #CODE [Beaker kernels and extensions](http://beakerx.com/)\n- [Juypterbook - Books with Jupyter](https://jupyterbook.org/intro.html)\n- [Jupyter everywhere](https://blog.jupyter.org/jupyter-everywhere-f8151c2cc6e8)\n- [Executing notebooks from the command line](https://nbconvert.readthedocs.io/en/latest/execute_api.html#executing-notebooks-from-the-command-line \"Permalink to this headline\")\n\t- `$ jupyter nbconvert --to notebook --inplace --ExecutePreprocessor.timeout=None --execute mynotebook.ipynb`\n\n## Jupyter in HPC\n- High-level scripting languages such as Python, R and Julia, have become the go-to choices in the world of Data Science and ML/AI. Project Jupyter exists to develop open-source software, open-standards, and services for interactive computing across dozens of programming languages. For instance, the Jupyter Notebook is an open-source web-app that allows users to write portable documents containing executable code, narrative text, and equations, and to visualize the results of running the code directly in the web browser. The name comes from a combination of the three core programming languages of Jupyter (Julia, Python and R) though Jupyter is not limited to these languages.  \n- Tools in the Jupyter ecosystem are designed in a modular fashion, and behave similarly on a researcher's laptop, a high-performance computing center, or the cloud. As a result, Jupyter technologies have been widely adopted across a spectrum of scientific disciplines, including Earth Sciences (Perez et al. 2019).  \n- JupyterHub brings the power of notebooks to groups of users. It gives users access to computational environments and resources without burdening the users with installation and maintenance tasks. These are a few examples of JupyterHub systems running on supercomputing systems: \n\t- University Corporation for Atmospheric Research (UCAR, https://jupyterhub.ucar.edu/)  \n\t- CSCS, ETH Zurich (https://jupyter.cscs.ch/hub/login) \n\t- CHPC, University of Utah (https://www.chpc.utah.edu/documentation/software/jupyterhub.php#hub, http://notebook.chpc.utah.edu/) \n\t- Minesota supercomputing institute (https://www.msi.umn.edu/content/msi-beta) \n- A common denominator of these computing platforms is that they allow the interactive execution of Jupyter tools on HPC systems over multiple nodes. The user is offered to choose the job configuration options in order to allocate the resources to be used to run Jupyter: account, number of nodes, access to GPUs, wall-clock time, etc.  \n- [Interactive supercomputing with Jupyter lab](https://www.cscs.ch/publications/news/2019/interactive-supercomputing-with-jupyterlab/)\n\n- #PAPER [Jupyter as common technology platform for interactive HPC services (Milligan 2018)](https://arxiv.org/abs/1807.09929)\n- #PAPER [Jupyter meets the Earth: Enabling discovery in geoscience through interactive computing at scale (Perez 2019)](https://zenodo.org/record/3369939 )\n- #PAPER [Interactive Supercomputing with Jupyter (Thomas 2021)](https://authorea.com/doi/full/10.22541/au.161230518.84458221) ^thomas21hpcjupyter\n\n\n## Ipython\n- Save interactive ipython session: `%history -f /tmp/history.py`","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/ML-Ops":{"title":"Machine Learning Operations (MLOps)","content":"## Resources\n- Set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently. The word is a compound of \"machine learning\" and the continuous development practice of DevOps in the software field\n- https://en.wikipedia.org/wiki/MLOps\n- https://github.com/GokuMohandas/MadeWithML\n- https://github.com/visenger/awesome-mlops\n- https://github.com/EthicalML/awesome-production-machine-learning\n\n## Code\n### Experiment tracking\n- https://neptune.ai/blog/best-ml-experiment-tracking-tools\n- #CODE [Weights \u0026 Biases](https://docs.wandb.com/)\n\t- Library that -helps you keep track of your machine learning projects. Use our tool to log hyperparameters and output metrics from your runs, then visualize and compare results and quickly share findings with your colleagues.\n- #CODE [Aim](https://github.com/aimhubio/aim)\n\t- The open-source tool for ML experiment comparison\n\t- https://aimstack.io/\n- #CODE [ClearML](https://github.com/allegroai/clearml)\n\t- https://clear.ml/\n\n### Workflow managers\n- #CODE [Kedro](https://github.com/kedro-org/kedro)\n\t- A Python framework for creating reproducible, maintainable and modular data science code\n\t- https://kedro.readthedocs.io/\n\t- #CODE [kedro-viz](https://github.com/kedro-org/kedro-viz)\n- #CODE [MLrun](https://github.com/mlrun/mlrun)\n\t- The Open-Source MLOps Orchestration Framework\n\t- https://docs.mlrun.org/en/stable/\n- #CODE [Metaflow](https://github.com/Netflix/metaflow)\n\t- Metaflow is a human-friendly Python/R library that helps scientists and engineers build and manage real-life data science projects\n\t- Originally developed at Netflix to boost productivity of data scientists who work on a wide variety of projects from classical statistics to state-of-the-art deep learning\n\t- https://metaflow.org/\n\t- #CODE [metaflow-ui](https://github.com/Netflix/metaflow-ui)\n\t\t- https://netflixtechblog.com/open-sourcing-a-monitoring-gui-for-metaflow-75ff465f0d60\n- #CODE [Flyte](https://github.com/flyteorg/flyte)\n\t- Kubernetes-native workflow automation platform for complex, mission-critical data and ML processes at scale. It has been battle-tested at Lyft, Spotify, Freenome, and others and is truly open-source\n\t- https://flyte.org/\n- #CODE [MLFlow](https://github.com/mlflow/mlflow/ )\n\t- [An open source platform for the machine learning lifecycle](https://mlflow.org)\n- #CODE [Airflow: Apache Airflow - A platform to programmatically author, schedule, and monitor workflows](https://github.com/apache/airflow)\n\t- http://nerds.airbnb.com/airflow/\n\t- https://medium.com/datasd/why-data-automation-matters-4391d59e1952\n- #CODE [Luigi (Spotify)](https://github.com/spotify/luigi)\n\t- https://luigi.readthedocs.io/en/latest/\n- #CODE [Kale](https://github.com/kubeflow-kale/kale)\n- #CODE [Azkaban](https://github.com/azkaban/azkaban)\n- #CODE [PredictionIO (Apache)](https://predictionio.apache.org)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Open-ML-data":{"title":"Open ML data","content":"## Resources\n- https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research\n- https://paperswithcode.com/datasets\n- [OpenML (open-source datasets)](http://www.openml.org/)\n\t- [API](https://docs.openml.org/APIs/)\n- [Awesome Public Datasets (high quality datasets from communities such as academia, education etc)](https://github.com/awesomedata/awesome-public-datasets)\n- [Registry of Open Data on AWS](https://registry.opendata.aws/)\n- [Gym (OpenAI) - For reinforcement learning algorithms](https://gym.openai.com/)\n- [Data Is Plural - newsfeed](http://tinyletter.com/data-is-plural/archive)\n- [Datasets for data mining (ML)](http://www.inf.ed.ac.uk/teaching/courses/dme/html/datasets0405.html)\n- [Greatest Public Datasets for AI/ML](https://medium.com/startup-grind/fueling-the-ai-gold-rush-7ae438505bc2)\n- [Open knowledge foundation repository (varied formats and sources)](https://datahub.io/dataset)\n- [Stanford Large Network Dataset Collection](http://snap.stanford.edu/data/#!)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Pytorch":{"title":"Pytorch","content":"## References\n- #PAPER [PyTorch: An Imperative Style, High-Performance Deep Learning Library (Paszke 2019)](https://arxiv.org/abs/1912.01703)\n\t- Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs\n\n\n## Code\n- #CODE [PyTorch (Facebook)](https://github.com/pytorch/pytorch)\n\t- http://pytorch.org\n\t- [Ecosystem tools](https://pytorch.org/ecosystem/)\n\t- Tensors and Dynamic neural networks in Python with strong GPU acceleration\n\t- https://sagivtech.com/2017/09/19/optimizing-pytorch-training-code/\n- #CODE [Pytorch-lightning](https://pytorchlightning.ai/)\n\t- https://medium.com/pytorch/introducing-lightning-flash-the-fastest-way-to-get-started-with-deep-learning-202f196b3b98\n- #CODE [Fastai](https://github.com/fastai/fastai)\n\t- fastai simplifies training fast and accurate neural nets using modern best practices\n\t- https://docs.fast.ai/\n\t- #PAPER [Fastai: A Layered API for Deep Learning (Howard 2020)](https://www.mdpi.com/2078-2489/11/2/108/htm)\n- #CODE [kornia](https://github.com/kornia/kornia)\n\t- Open Source Differentiable Computer Vision Library\n\t- https://kornia.github.io/\n- #CODE [NMF](https://github.com/facebookresearch/mmf)\n\t- A modular framework for vision \u0026 language multimodal research from Facebook AI Research (FAIR)\n\t- https://mmf.sh/\n- #CODE [Pytext (Facebook) - A natural language modeling framework based on PyTorch](https://github.com/facebookresearch/pytext )\n\t- https://fb.me/pytextdocs\n\t- PyText is a deep-learning based NLP modeling framework built on PyTorch\n- #CODE [Pytorch tabular](https://github.com/manujosephv/pytorch_tabular) ^pytorchtab\n\t- https://deep-and-shallow.com/2021/01/27/pytorch-tabular-a-framework-for-deep-learning-for-tabular-data/\n- #CODE [Clearml](https://github.com/allegroai/clearml)\n\t- ClearML - Auto-Magical CI/CD to streamline your ML workflow. Experiment Manager, [ML Ops](AI/DS%20and%20DataEng/ML%20Ops.md) and Data-Management\n\t- https://clear.ml/docs\n- #CODE [Composer](https://github.com/mosaicml/composer)\n\t- A PyTorch Library for Efficient Neural Network Training\n- #CODE [ColossalAI](https://github.com/hpcaitech/ColossalAI)\n\t- Colossal-AI: A Unified Deep Learning System for Large-Scale Parallel Training\n\t- https://analyticsindiamag.com/a-guide-to-parallel-deep-learning-with-colossal-ai/","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Tensorflow-keras":{"title":"Tensorflow, Keras","content":"## Code\n- #CODE [Tensorflow (Google)](https://github.com/tensorflow/tensorflow)\n\t- http://playground.tensorflow.org/\n\t- https://cloud.google.com/blog/big-data/2016/07/understanding-neural-networks-with-tensorflow-playground\n\t- https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc#.dg41ldof5\n\t- https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0\n\t- [Tensorflow 2.0: models migration and new design](https://pgaleone.eu/tensorflow/gan/2018/11/04/tensorflow-2-models-migration-and-new-design/)\n\t- http://planspace.org/20170404-how_not_to_program_the_tensorflow_graph/\n- #CODE [TF Compression](https://github.com/tensorflow/compression)\n\t- TensorFlow Compression (TFC) contains data compression tools for TensorFlow\n- #CODE [TF Similarity](https://github.com/tensorflow/similarity)\n\t- https://blog.tensorflow.org/2021/09/introducing-tensorflow-similarity.html\n\t- Metric learning is different from traditional classification as it's objective is different. The model learns to minimize the distance between similar examples and maximize the distance between dissimilar examples, in a supervised or self-supervised fashion\n- #CODE [TF Probability](https://github.com/tensorflow/probability)\n\t- Probabilistic reasoning and statistical analysis in TensorFlow\n\t- https://www.tensorflow.org/probability\n- #CODE [TF Decision Forests](https://github.com/tensorflow/decision-forests)\n\t- A collection of state-of-the-art algorithms for the training, serving and interpretation of Decision Forest models in Keras\n\t- https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html\n\t- https://towardsdatascience.com/tensorflow-decision-forests-train-your-favorite-tree-based-models-using-keras-875d05a441f\n\t- [Decision forests in TF](https://www.youtube.com/watch?v=5qgk9QJ4rdQ)\n- #CODE [TF Datasets](https://github.com/tensorflow/datasets)\n- #CODE [TF Agents](https://github.com/tensorflow/agents)\n\t- A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning\n- #CODE [TF Recommenders](https://github.com/tensorflow/recommenders )\n\t- Library for building recommender system models using TensorFlow.\n- #CODE [TF Graphics](https://github.com/tensorflow/graphics)\n\t- Differentiable Graphics Layers for TensorFlow\n- #CODE [TF Ranking](https://github.com/tensorflow/ranking)\n\t- Learning to Rank in TensorFlow\n- #CODE [Tensorboard](https://github.com/tensorflow/tensorboard)\n\t- https://tensorboard.dev/\n\t- https://www.tensorflow.org/tensorboard/get_started (use as a jupyterlab magic)\n- #CODE [Tensorflow.js](https://www.tensorflow.org/js/)\n- #CODE [TF On Spark](https://github.com/yahoo/TensorFlowOnSpark)\n- #CODE [Sonnet](https://github.com/deepmind/sonnet)\n\t- https://deepmind.com/blog/open-sourcing-sonnet/\n- #CODE [seq2seq](https://github.com/google/seq2seq)\n- #CODE [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor)\n\t- https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html\n- #CODE [Graph Nets - Build Graph Nets in Tensorflow](https://github.com/deepmind/graph_nets)\n\t- https://arxiv.org/abs/1806.01261\n- [TF Graph Visualizer](http://idl.cs.washington.edu/papers/tfgraph/)\n- #CODE [Tensorpack - It's Yet Another TF high-level API, with speed, and flexibility built together](https://github.com/tensorpack/tensorpack)\n- #CODE [Cleverhans - A library for benchmarking vulnerability to adversarial examples](https://github.com/tensorflow/cleverhans)\n\t- http://karpathy.github.io/2015/03/30/breaking-convnets/\n\t- https://blog.openai.com/adversarial-example-research/\n\n\n## Keras\n- #CODE [Keras](https://github.com/keras-team/keras )\n\t- Keras is a deep learning API written in Python, running on top of the machine learning platform Tensorflow\n\t- http://keras.io/\n\t- https://keras.io/getting_started/intro_to_keras_for_researchers/\n\t- [Modern Keras design patterns](https://www.youtube.com/watch?v=FCz9m4T0DI0)\n- #CODE [AutoKeras - Auto-Keras is an open source software library for automated machine learning (AutoML)](https://github.com/keras-team/autokeras)\n\t- http://autokeras.com/\n\t- #PAPER [Auto-Keras: An Efficient Neural Architecture Search System (Jin 2019)](https://arxiv.org/abs/1806.10282)\n\t- https://towardsdatascience.com/autokeras-the-killer-of-googles-automl-9e84c552a319\n- #CODE [Ktrain](https://github.com/amaiya/ktrain)\n\t- https://analyticsindiamag.com/a-complete-guide-to-ktrain-a-wrapper-for-tensorflow-keras/\n\n\n## Distributed training\n- https://missinglink.ai/guides/tensorflow/tensorflow-distributed-training-introduction-tutorials/ \n- TF.Distribute\n\t- https://www.tensorflow.org/guide/distributed_training \n\t- https://www.tensorflow.org/guide/gpu\n\t- https://keras.io/guides/distributed_training/\n\t- #TALK [Inside TensorFlow: tf.data + tf.distribute](https://www.youtube.com/watch?v=ZnukSLKEw34)\n- [Numpy to tf.record](https://gist.github.com/swyoon/8185b3dcf08ec728fb22b99016dd533f)\n- https://www.tensorflow.org/tutorials/distribute/keras \n- https://www.tensorflow.org/tutorials/distribute/custom_training \n- https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#scrollTo=9iagoTBfijUz \n- [Train a Neural Network on multi-GPU with TensorFlow (Jordi Torres)](https://towardsdatascience.com/train-a-neural-network-on-multi-gpu-with-tensorflow-42fa5f51b8af)\n- [Multinode example](https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md)\n- MultiWorkerMirroredStrategy:\n\t- https://www.tensorflow.org/api_docs/python/tf/distribute/MultiWorkerMirroredStrategy (after TF v2)\n\t- https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy\n\t- https://blog.tensorflow.org/2020/12/whats-new-in-tensorflow-24.html (TF v2.4)\n\t- https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras \n\t- https://github.com/tensorflow/tensorflow/issues/36094\n- https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/SlurmClusterResolver \n- https://lambdalabs.com/blog/tensorflow-2-0-tutorial-05-distributed-training-multi-node/ \n\nData lazy loading: \n- Tf.data:\n\t- https://www.tensorflow.org/api_docs/python/tf/data/Dataset \n\t- https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator\n\t- https://www.tensorflow.org/tutorials/distribute/input\n- Tensorflow data netcdf, MATEX tensorflow (seems to be abandoned) :https://github.com/matex-org/matex/wiki/DataSet-Reader","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Visualization":{"title":"Visualization","content":"## Resources\n- https://github.com/fasouto/awesome-dataviz\n- http://keshif.me/demo/VisTools\n- [The visualization universe](http://visualizationuniverse.com/)\n\t- http://visualizationuniverse.com/charts/\n- [Dataviz project](https://datavizproject.com/)\n- [UW Interactive Data Lab](http://idl.cs.washington.edu/)\n- [Flowing Data Tutorials](https://flowingdata.com/category/tutorials/)\n- http://www.coolinfographics.com/blog/2017/1/10/digital-marketing-tools-landscape.html\n- https://www.analyticsvidhya.com/blog/2015/09/infographic-tools-data-visualization/\n- https://visme.co/blog/examples-data-visualizations/\n- https://towardsdatascience.com/3rd-wave-data-visualization-824c5dc84967\n- [What's so hard about histograms?](https://tinlizzie.org/histograms/)\n- [Dataviz tools](http://visualizationuniverse.com/tools/)\n- [Data visualization tools and books](https://keshif.me/demo/VisTools)\n- [Python data viz tools](http://blog.yhat.com/posts/python-data-viz-landscape.html)\n- [Dataviz.tools: A curated guide to the best tools, resources and technologies for data viz](http://dataviz.tools/)\n- [Dashboard design (how-to)](http://www.designyourway.net/blog/inspiration/showcase-of-beautiful-dashboard-ui-designs/    )\n- Python Data Visualization 2018 (Anaconda)\n\t1. Why So Many Libraries?: https://www.anaconda.com/blog/developer-blog/python-data-visualization-2018-why-so-many-libraries/\n\t2. Moving Toward Convergence: https://www.anaconda.com/blog/developer-blog/python-data-visualization-moving-toward-convergence/\n\t3. Where Do We Go From Here?: https://www.anaconda.com/blog/developer-blog/python-data-visualization-2018-where-do-we-go-from-here/\n\n## Books\n- [Dataviz books](http://visualizationuniverse.com/books/?sortBy=volume\u0026sortDir=desc)\n- #BOOK [Fundamentals of Data Visualization (Wilke 2020)](https://clauswilke.com/dataviz/)\n- #BOOK [Data Visualization (Healy 2020)](https://socviz.co/)\n- #BOOK [R Graphics Cookbook, 2nd edition](https://r-graphics.org/)\n\n## Courses\n- #COURSE [Information Visualization (CS 465, Middlebury)](http://www.cs.middlebury.edu/~candrews/archive/infovis_s14/)\n- #COURSE [Data Visualization (CSE512, U Washington)](http://courses.cs.washington.edu/courses/cse512/14wi/)\n\t- https://github.com/uwdata/d3-tutorials\n- #COURSE [Data Science: Visualization (Harvard-edX)](https://www.edx.org/course/data-science-visualization-harvardx-ph125-2x)\n- #COURSE [Reading and interpreting data (Khan academy)](https://www.khanacademy.org/math/pre-algebra/pre-algebra-math-reasoning)\n- #TALK [23 Visualizations and When to Use Them in 30 Minutes](https://www.youtube.com/watch?v=RG_BKQRbJZw)\n- #TALK The Python Visualization Landscape (Vanderplas, Pycon 2017): \n\t- https://www.youtube.com/watch?v=FytuB8nFHPQ\n\t- https://us.pycon.org/2017/schedule/presentation/616/\n- #TALK [Everything we know about how humans interpret graphics (Elliot 2016)](https://www.youtube.com/watch?v=s0J6EDvlN30)\n- #TALK [Constructive Code Review (Rose, PyCon 2017)](https://www.youtube.com/watch?v=iNG1a--SIlk)\n\n## Code\n- #CODE [Matplotlib](https://matplotlib.org/)\n\t- http://nbviewer.jupyter.org/github/cs109/content/blob/master/lec_03_statistical_graphs.ipynb\n- #CODE [Seaborn](http://seaborn.pydata.org/)\n- #CODE [Bokeh](https://github.com/bokeh/bokeh)\n- #CODE [Plotly](https://github.com/plotly)\n\t- https://github.com/plotly/plotly.js\n\t- http://blog.yhat.com/posts/visualize-nba-pipelines.html\n- #CODE [Lightning](http://lightning-viz.org/)\n\t- Lightning is a data-visualization server providing API-based access to reproducible, web-based, interactive visualizations\n\t- https://github.com/lightning-viz/lightning-python\n- #CODE [Perspective](https://jpmorganchase.github.io/perspective/)\n- #CODE [D3.js](https://d3js.org/)\n\t- http://chimera.labs.oreilly.com/books/1230000000345/index.html\n\t- https://github.com/d3/d3/wiki/Tutorials\n\t- https://blog.datazar.com/the-best-resources-when-learning-d3-js-7da4ba0a783e#.oyw1gyxzz\n\t- https://learningd3.com/\n\t- https://learningd3.com/blog/generative-art/\n\t- http://blog.thedataincubator.com/2015/08/embedding-d3-in-an-ipython-notebook/\n\t- https://datawanderings.com/2017/01/29/data-visualisation-from-scratch-with-d3-js-part-1-canvas-setup/\n\t- [D3 Tips and Tricks](https://leanpub.com/D3-Tips-and-Tricks)\n\t- [Blocks - database of examples](https://bl.ocks.org/)\n\t- [Building a storytelling scroller with D3](http://vallandingham.me/scroller.html)\n\t- [Interactive Data Visualization for the Web](http://chimera.labs.oreilly.com/books/1230000000345/index.html)\n\t- https://www.analyticsvidhya.com/blog/2017/08/visualizations-with-d3-js/\n\t- [PykCharts.js](https://github.com/pykih/PykCharts.js)\n\t- [dc.js](https://dc-js.github.io/dc.js/)\n- #CODE [deck.gl (Uber) - deck.gl is a WebGL-powered framework for visual exploratory data analysis of large datasets](https://eng.uber.com/deck-gl-framework/)\n- #CODE [Visdom (Facebook) - A flexible tool for creating, organizing, and sharing visualizations of live, rich data. Supports Torch and Numpy](https://github.com/facebookresearch/visdom)\n- #CODE [Vega](https://github.com/vega/vega)\n\t- https://github.com/vega/vega-lite\n\t- https://github.com/vega/voyager\n\t- https://github.com/vega/lyra\n- #CODE [Altair](https://altair-viz.github.io/)\n\t- #TALK [Jake VanderPlas - Exploratory Data Visualization with Vega, Vega-Lite, and Altair - PyCon 2018](https://www.youtube.com/watch?v=ms29ZPUKxbU)\n- #CODE [Bqplot (Bloomberg) - Plotting library for IPython/Jupyter Notebooks](https://github.com/bloomberg/bqplot)\n\t- #TALK [PyData Ann Arbor: Dhruv Madeka | Interactive Data Visualization in Jupyter Notebook Using bqplot](https://www.youtube.com/watch?v=wJS4S0WB4Jw)\n- #CODE [Chartify (Spotify)](https://github.com/spotify/chartify/)\n\t- https://labs.spotify.com/2018/11/15/introducing-chartify-easier-chart-creation-in-python-for-data-scientists/\n\t- Chartify is a Python library that makes it easy for data scientists to create charts.\n- #CODE [ggplot2 (for R)](http://ggplot2.org/)\n- Graphs, networks:\n\t- #CODE [NetworkX](https://networkx.github.io/)\n\t- #CODE [Gephi](https://gephi.org/)\n\t- #CODE [Graph-tool](https://graph-tool.skewed.de/)\n\t- #CODE [igraph](http://igraph.org/)\n\t- #CODE [Graphviz](http://www.graphviz.org/)\n- Dashboards (webapps):\n\t- #CODE [Dash - Interactive, reactive web apps in pure python](https://plot.ly/products/dash)\n\t\t- https://medium.com/@plotlygraphs/introducing-dash-5ecf7191b503\n\t\t- #TALK [Dash - A New Framework for Building User Interfaces for Technical Computing | SciPy 2017 | Chris Par](https://www.youtube.com/watch?v=sea2K4AuPOk)\n\t- #CODE [Redash](https://redash.io/)\n\t- #CODE Superset:  http://airbnb.io/projects/superset/\n\t\t- https://medium.com/airbnb-engineering/caravel-airbnb-s-data-exploration-platform-15a72aa610e5\n\t\t- https://indatalabs.com/blog/data-strategy/open-source-data-visualization-tool-superset\n\t- #CODE Shiny (for R)\n\t\t- https://shiny.rstudio.com/\n\t\t- http://www.htmlwidgets.org/\n\t- #CODE Pyxley - Python helpers for building dashboards using Flask and React: \n\t\t- https://github.com/stitchfix/pyxley\n\t\t- http://multithreaded.stitchfix.com/blog/2015/07/16/pyxley/\n\t- #CODE [Spyre](https://github.com/adamhajari/spyre)\n\t- #CODE [Bowtie](http://bowtie-py.readthedocs.io/en/latest/)\n\t- #CODE [Stackimpact-python](https://stackimpact.com)\n- #CODE [PyViz](https://github.com/pyviz)\n\t- [HoloViews](https://holoviews.org/)\n\t- [Panel](https://panel.pyviz.org/)\n\t- [Datashader](http://datashader.org)\n\t - [GeoViews](http://geoviews.org/ )\n\t - [Hvplot](https://hvplot.pyviz.org/)\n- #CODE [Ipyvolume](https://ipyvolume.readthedocs.io/en/latest/)\n- #CODE [Vaex](https://vaex.io/)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/DS-and-DataEng/Xarray":{"title":"Xarray","content":"## Code\n- #CODE [Xarray - N-D labeled arrays and datasets in Python](https://github.com/pydata/xarray)\n\t- #PAPER [Xarray - N-D labeled Arrays and Datasets in Python (Hoyer 2017)](https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/)\n\t- http://xarray.pydata.org/en/stable/why-xarray.html\n\t- [Breaking up arrays up into chunks for fun and science with Xarray and Dask](https://www.youtube.com/watch?v=0dO-iC16xUo)\n- #CODE [Dask](AI/DS%20and%20DataEng/Dask.md)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Deep-learning/Autoencoders":{"title":"Autoencoders","content":"## Resources\n- https://en.wikipedia.org/wiki/Autoencoder\n- [Dimensionality Reduction](https://www.cs.toronto.edu/~hinton/science.pdf)\n- The classical approach for unsupervised learning using neural networks. The basic version consists of a Multilayer Perceptron (MLP) where the input and output layer have the same size and a smaller hidden layer is trained to recover the input. Once trained, the output from the hidden layer corresponds to data representation that can be useful for clustering, dimensionality reduction, improving supervised classification and even for data compression.\n- https://blog.keras.io/building-autoencoders-in-keras.html\n- https://blog.insightdatascience.com/isee-removing-eyeglasses-from-faces-using-deep-learning-d4e7d935376f\n- https://github.com/nanopony/keras-convautoencoder\n\n### VAEs\n- Variational autoencoders are generative models. Traditional autoencoders that just do reconstruction don‚Äôt have an obvious generative interpretation. There are some cases in between, like denoising autoencoders, where it is possible to construct a Markov chain that uses the autoencoder to sample from the data distribution, but the autoencoder doesn‚Äôt give direct explicit access to an estimate of the density or the ability to sample directly.\n- VAE is a type of autoencoder with added constraints on the encoded representations being learned. More precisely, it is an autoencoder that learns a latent variable model for its input data. So instead of letting your neural network learn an arbitrary function, you are learning the parameters of a probability distribution modeling your data. If you sample points from this distribution, you can generate new input data samples: a VAE is a \"generative model\".\n- [Introduction to deep generative modeling: Variational Auto-Encoders](https://jmtomczak.github.io/blog/4/4_VAE.html)\n- [Introduction to deep generative modeling: Priors in VAEs](https://jmtomczak.github.io/blog/7/7_priors.html)\n- [Introduction to deep generative modeling: Hierarchical VAEs](https://jmtomczak.github.io/blog/9/9_hierarchical_lvm_p1.html)\n- [Variational Autoencoders Explained](http://kvfrans.com/variational-autoencoders-explained/)\n- [Intuitively understanding VAEs](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)\n- [An Intuitive Comparison of Autoencoders with Variational Autoencoders](https://thilospinner.com/towards-an-interpretable-latent-space/)\n- http://blog.fastforwardlabs.com/post/148842796218/introducing-variational-autoencoders-in-prose-and\n- [Arxiv insights. Variational Autoencoders](https://www.youtube.com/watch?v=9zKuYvjFFS8)\n- [From Autoencoder to Beta-VAE](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)\n\n\n## References\n- #PAPER [Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion (Vincent 2010)](https://www.jmlr.org/papers/v11/vincent10a.html)\n- #PAPER [Adversarial Autoencoders with Constant-Curvature Latent Manifolds (Grattarola 2018)](https://arxiv.org/abs/1812.04314)\n- #PAPER [Image-To-Image Translation Using a Cross-Domain Auto-Encoder and Decoder (Yoo 2019)](https://www.mdpi.com/2076-3417/9/22/4780/htm )\n\t- Early image-to-image translation methods used convolutional neural networks (CNN), which learn to minimize the loss of a pixel value between the source domain image and the target domain image but had the limitation of failing to produce more photorealistic images \n\t- Unlike other approaches‚Ä¶ our method is not limited to a specific task, nor do we rely on predefined relationships between the source and target domains. Our method can be applied to make a general-domain solution for many image-to-image translation tasks. \n- #PAPER [Masked Autoencoders Are Scalable Vision Learners (He 2021)](https://arxiv.org/abs/2111.06377)\n\t- #CODE https://github.com/facebookresearch/mae\n\t- #CODE https://github.com/ariG23498/mae-scalable-vision-learners\n\t- https://keras.io/examples/vision/masked_image_modeling/\n\t- Masked autoencoder (MAE) is a simple autoencoding approach that reconstructs the original signal given its partial observation\n\n### VAEs\n- #PAPER [Auto-Encoding Variational Bayes (Kingma 2014)](https://arxiv.org/abs/1312.6114)\n- #PAPER [An Introduction to Variational Autoencoders (Kingma 2019)](https://arxiv.org/abs/1906.02691)\n- #PAPER [NVAE: A Deep Hierarchical Variational Autoencoder (Vahdat 2020)](https://arxiv.org/abs/2007.03898)\n\t- [Paper explained](https://www.youtube.com/watch?v=x6T1zMSE4Ts)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Deep-learning/CNNs":{"title":"Convolutional Neural Networks (CNNs)","content":"## Resources\n- A convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks, based on their shared-weights architecture and translation invariance characteristics. \n- https://github.com/kjw0612/awesome-deep-vision\n- https://en.wikipedia.org/wiki/Convolutional_neural_network\n- [CNNs chapter in d2l.ai](https://d2l.ai/chapter_convolutional-neural-networks/index.html)\n- [Convolutional Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)\n- http://cs231n.github.io/convolutional-networks/\n- http://cs231n.github.io/understanding-cnn/\n- https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/\n* [Best deep CNN architectures and their principles: from AlexNet to EfficientNet](https://theaisummer.com/cnn-architectures/)\n\n### Convolutions\n- [Understanding convolutions](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)\n- [An Introduction to different Types of Convolutions in DL](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d)\n- https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215\n- https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d\n- [Depthwise separable convolution](https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728)\n- https://stackoverflow.com/questions/42883547/intuitive-understanding-of-1d-2d-and-3d-convolutions-in-convolutional-neural-n \n- https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807\n- [Convolutions Over Volumes (channels)](https://www.youtube.com/watch?v=KTB_OFoAQcc )\n\n### 1x1 convolutions\n- 1x1 convolutions: https://d2l.ai/chapter_convolutional-neural-networks/channels.html#times-1-convolutional-layer\n- [1x1 convolutions](https://www.youtube.com/watch?v=qVP574skyuM)\n- [Networks in Networks and 1x1 Convolutions](https://www.youtube.com/watch?v=vcp0XvDAX68)\n- https://iamaaditya.github.io/2016/03/one-by-one-convolution/\n- https://towardsdatascience.com/1x1-convolution-5219bbc09027\n- https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578\n- https://machinelearningmastery.com/introduction-to-1x1-convolutions-to-reduce-the-complexity-of-convolutional-neural-networks/\n\t- A convolutional layer with a 1√ó1 filter is used at any point in a CNN to control the number of feature maps. It's often referred to as a projection operation or projection layer, or even a feature map or channel pooling layer\n\n\n## Code \n- #CODE [Modern Convolutional Neural Network Architectures](https://github.com/Nyandwi/ModernConvNets)\n- #CODE [Keras Layers (for TensorFlow 2.x)](https://github.com/mvoelk/keras_layers)\n- #CODE [Model Zoo - Discover open source deep learning code and pretrained models](https://modelzoo.co/)\n- #CODE https://github.com/microsoft/computervision-recipes\n\n\n### Channel/visual attention\n- #CODE [Visual-attention-tf](https://github.com/vinayak19th/Visual_attention_tf) ^tfvisualattention\n\t- Pixel Attention\n\t- Channel Attention (CBAM)\n\t- Efficient Channel Attention\n- #CODE [Convolution Variants](https://github.com/JinLi711/Convolution_Variants) ^kerasconvvariants\n\t- Attention Augmented (AA) Convolution Layer\n\t- Mixed Depthwise Convolution Layer\n\t- Drop Block\n\t- Efficient Channel Attention (ECA) Layer\n\t- Convolutional Block Attention Module (CBAM) Layer\n\n\n## References\n- #PAPER [A guide to convolution arithmetic for deep learning (Dumoulin, 2016)](https://arxiv.org/abs/1603.07285)\n\t- #CODE https://github.com/vdumoulin/conv_arithmetic\n- #PAPER [Xception: Deep Learning with Depthwise Separable Convolutions (Chollet 2017)](https://arxiv.org/abs/1610.02357)\n- #PAPER [3D Depthwise Convolution: Reducing Model Parameters in 3D Vision Tasks (Ye 2018)](https://arxiv.org/abs/1808.01556)\n- #PAPER [Making Convolutional Networks Shift-Invariant Again (Zhang 2019)](https://arxiv.org/pdf/1904.11486v2)\n- #PAPER [A Survey of the Recent Architectures of Deep Convolutional Neural Networks (Khan 2020)](https://arxiv.org/abs/1901.06032v7)\n- #PAPER [Revisiting Spatial Invariance with Low-Rank Local Connectivity (Elsayed 2020)](https://arxiv.org/abs/2002.02959)\n\t- #CODE https://github.com/google-research/google-research/tree/master/low_rank_local_connectivity\n- #THESIS/PHD [Multi-modal Medical Image Processing with Applications in HybridX-ray/Magnetic Resonance Imaging (Stimpel 2021)](https://opus4.kobv.de/opus4-fau/frontdoor/deliver/index/docId/15697/file/Dissertation_Bernhard_Stimpel.pdf)\n- #PAPER [Involution: Inverting the Inherence of Convolution for Visual Recognition (Li 2021)](https://arxiv.org/abs/2103.06255)\n\t- #CODE https://github.com/d-li14/involution\n\t- #CODE https://github.com/PrivateMaRyan/keras-involution2Ds\n\t- [Paper explained](https://www.youtube.com/watch?v=pH2jZun8MoY)\n- #PAPER [Convolutional Conditional Neural Processes (Gordon 2020)](https://arxiv.org/abs/1910.13556) ^convcondneuralproc\n\t- #CODE https://github.com/cambridge-mlg/convcnp\n\t- https://yanndubs.github.io/Neural-Process-Family/reproducibility/ConvCNP.html\n- #PAPER [Non-deep Networks (Goyal 2021)](https://arxiv.org/abs/2110.07641)\n\t- #CODE https://paperswithcode.com/paper/non-deep-networks-1?from=n19\n\t- use parallel subnetworks instead of stacking one layer after another. This helps effectively reduce depth while maintaining high performance\n* #PAPER [ConvNext: A ConvNet for the 2020s (Liu 2022)](https://arxiv.org/abs/2201.03545) ^convnext\n\t* #CODE https://github.com/facebookresearch/ConvNeXt\n\t* #CODE https://github.com/bamps53/convnext-tf/\n\t* #CODE https://github.com/sayakpaul/ConvNeXt-TF\n\t* Paper explained: \n\t\t* https://www.youtube.com/watch?v=WvKsMI4Iemk\u0026t=330s\n\t\t* https://www.youtube.com/watch?v=idiIllIQOfU\u0026list=WL\u0026index=55\n\t\t* https://www.youtube.com/watch?v=QqejV0LNDHA\n\t* https://twitter.com/papers_daily/status/1481937771732566021\n\t* ConvNeXt essentially takes a ResNet and gradually \"modernizes\" it to discover components that contribute to performance gains. ConvNeXt applies several tricks like larger kernels, layer norm, fewer activation functions, separate downsampling layers to name a few. \n\t* These results show that hybrid models are promising and that different components can still be optimized further and composed more effectively to improve the overall model on a wide range of vision tasks.\n- #PAPER [Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs (Ding 2022)](https://arxiv.org/pdf/2203.06717v3)            \n\t- #CODE https://paperswithcode.com/paper/scaling-up-your-kernels-to-31x31-revisiting\n\n## Subtopics and applications\n### Sequence (time series) modelling\n- #PAPER [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling (Bai 2018)](https://arxiv.org/abs/1803.01271)\n  - Temporal convolutional networks (TCN)\n  - #CODE https://github.com/philipperemy/keras-tcn\n  - [Implementing Temporal Convolutional Networks](https://medium.com/the-artificial-impostor/notes-understanding-tensorflow-part-3-7f6633fcc7c7)\n\t  - The most important component of TCNs is dilated causal convolution. ‚ÄúCausal‚Äù simply means a filter at time step t can only see inputs that are no later than t. The point of using dilated convolution is to achieve larger receptive field with fewer parameters and fewer layers. \n\t  - A residual block stacks two dilated causal convolution layers together, and the results from the final convolution are added back to the inputs to obtain the outputs of the block. \n  - [Temporal convolutional networks for sequence modeling](https://dida.do/blog/temporal-convolutional-networks-for-sequence-modeling)\n- #PAPER [Convolutions Are All You Need (For Classifying Character Sequences) (Wood-doughty 2018)](https://www.aclweb.org/anthology/W18-6127/)\n- #PAPER [InceptionTime: Finding AlexNet for time series classification (Fawaz 2021)](https://link.springer.com/article/10.1007/s10618-020-00710-y)\n\t- #CODE https://github.com/hfawaz/InceptionTime\n\t- https://arxiv.org/abs/1909.04939\n\n\n### Object classification, image recognition\nSee [Object classification, image recognition](AI/Computer%20Vision/Object%20classification,%20image%20recognition.md)\n\n### Semantic segmentation\nSee [Semantic segmentation](AI/Computer%20Vision/Semantic%20segmentation.md)\n\n### Object detection\nSee [Object detection](AI/Computer%20Vision/Object%20detection.md)\n\n### Video segmentation and prediction\nSee [Video segmentation and prediction](AI/Computer%20Vision/Video%20segmentation%20and%20prediction.md)\n\n### Image and video captioning\nSee [Image and video captioning](AI/Computer%20Vision/Image%20and%20video%20captioning.md)\n\n### Image-to-image translation\nSee [Image-to-image translation](AI/Computer%20Vision/Image-to-image%20translation.md)\n\n### Super-resolution \nSee \"CNN-based\" section in [Super-resolution](AI/Computer%20Vision/Super-resolution.md)\n\n### Inpainting\nSee \"CNN-based\" section in [Inpainting](AI/Computer%20Vision/Inpainting.md)\n\n### Background subtraction, foreground detection\nSee \"CNN-based\" section in [Background subtraction](AI/Computer%20Vision/Background%20subtraction.md)\n\n### Edge detection\n- #PAPER [DeepEdge: A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection](http://arxiv.org/pdf/1412.1123)\n- #PAPER [DeepContour: A Deep Convolutional Feature Learned by Positive-Sharing Loss for Contour Detection](http://mc.eistar.net/UpLoadFiles/Papers/DeepContour_cvpr15.pdf)\n\n\n### Human pose estimation and activity recognition\n- https://en.wikipedia.org/wiki/Activity_recognition\n- https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/\n- https://github.com/cbsudux/awesome-human-pose-estimation\n- https://github.com/topics/human-pose-estimation\n- https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/\n\n- #PAPER [Human activity recognition with smartphone sensors using deep learning neural networks (Ann Ronao 2016)](https://www.sciencedirect.com/science/article/abs/pii/S0957417416302056)\n- #PAPER [Convolutional pose machines (Wei 2016)](https://arxiv.org/abs/1602.00134)\n- #PAPER [Fast Human Pose Estimation (Zhang 2019)](https://arxiv.org/abs/1811.05419)\n\n\n### Motion detection, tracking\n- #PAPER [FlowNet: Learning Optical Flow with Convolutional Networks (Fischer 2015)](https://arxiv.org/abs/1504.06852)\n\n\n### Deconvolution\n- #PAPER [Deep Convolutional Neural Network for Image Deconvolution (Xu 2014)](http://lxu.me/projects/dcnn/)\n\n\n### Visual/Channel attention and Saliency\nSee \"Neural Networks explainability\" section in [XAI](AI/XAI.md)\n\n - #PAPER [Squeeze-and-Excitation Networks, SENets (Hu 2017)](https://arxiv.org/abs/1709.01507) ^senets\n\t- Features can incorporate global context\n\t- Since SENet only revolves around providing channel attention by using dedicated global feature descriptors, which in this case is Global Average Pooling (GAP), there is a loss of information and the attention provided is point-wise. This means that all pixels are mapped in the spatial domain of a feature map uniformly, and thus not discriminating between important or class-deterministic pixels versus those which are part of the background or not containing useful information.\n\t- Thus, the importance/need for spatial attention is justified to be coupled with channel attention. One of the prime examples of the same is CBAM (published at ECCV 2018) \n\t- #CODE https://github.com/hujie-frank/SENet\n\t- #CODE https://github.com/yoheikikuta/senet-keras\n\t- https://blog.paperspace.com/channel-attention-squeeze-and-excitation-networks/\n\t- https://programmerclick.com/article/4934219785/\n - #PAPER [CBAM: Convolutional Block Attention Module (Woo 2018)](https://arxiv.org/abs/1807.06521) ^cbam\n\t -  #CODE https://kobiso.github.io//research/research-CBAM/\n\t -  https://medium.com/visionwizard/understanding-attention-modules-cbam-and-bam-a-quick-read-ca8678d1c671\n- #PAPER [ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks (Wang 2020)](https://arxiv.org/abs/1910.03151)\n\t- this paper proposes an Efficient Channel Attention (ECA) module, which only involves a handful of parameters while bringing clear performance gain\n\t- proposed a local cross-channel interaction strategy without dimensionality reduction, which can be efficiently implemented via 1D convolution\n- #PAPER See ^srwithpixelattention in [Super-resolution](AI/Computer%20Vision/Super-resolution.md)\n- #PAPER [Attention Mechanisms in Computer Vision: A Survey (Guo 2021)](https://arxiv.org/abs/2111.07624v1)\n\t- https://github.com/MenghaoGuo/Awesome-Vision-Attentions\n- #PAPER [Visual Attention Network (Guo 2022)](https://arxiv.org/abs/2202.09741)\n\t- #CODE https://paperswithcode.com/paper/visual-attention-network?from=n26\n\t- This work presents an approach that decomposes a large kernel convolution operation to capture long-range relationship. After obtaining long-range relationship, it estimates the importance of a point and generates attention map","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Deep-learning/CapsNets":{"title":"Capsule Neural networks (CapsNets)","content":"## Resources\n- https://en.wikipedia.org/wiki/Capsule_neural_network\n- A Capsule Neural Network (CapsNet) is a machine learning system that is a type of artificial neural network (ANN) that can be used to better model hierarchical relationships. The approach is an attempt to more closely mimic biological neural organization.\n- The main failure of CNNs is that they do not carry any information about the relative relationships between features (CNNs since they are based on the convolution operation applied to scalar values).\n- Capsules introduce a new building block that can be used in deep learning to better model relationships inside the network. The key to this richer feature representation is the use of vectors rather than scalars.\n- A capsule is an abstract idea of having a group of neurons with an activity vector that contains more information about the object. There are many ways to implement this. Hinton et al chose one particular way to implement this, which allows using ‚Äúdynamic routing‚Äù. \n- https://towardsdatascience.com/a-simple-and-intuitive-explanation-of-hintons-capsule-networks-b59792ad46b1\n- https://towardsdatascience.com/capsule-neural-networks-are-here-to-finally-recognize-spatial-relationships-693b7c99b12\n- https://towardsdatascience.com/capsule-neural-networks-part-2-what-is-a-capsule-846d5418929f\n- https://www.freecodecamp.org/news/understanding-capsule-networks-ais-alluring-new-architecture-bdb228173ddc/\n\n## References\n- #PAPER [Dynamic Routing Between Capsules (Sabour 2017)](https://arxiv.org/abs/1710.09829)\n\t- #CODE https://github.com/XifengGuo/CapsNet-Keras\n- #PAPER [Capsule Networks ‚Äì A survey (Mensah 2019)](https://www.sciencedirect.com/science/article/pii/S1319157819309322)","lastmodified":"2022-03-31T08:22:26.954977114Z","tags":null},"/AI/Deep-learning/DL":{"title":"Deep Learning (DL)","content":"See:\n- [Multimodal learning](AI/Deep%20learning/Multimodal%20learning.md)\n- [Geometric deep learning](AI/Deep%20learning/Geometric%20deep%20learning.md)\n- [Probabilistic deep learning](AI/Deep%20learning/Probabilistic%20deep%20learning.md)\n- [Time Series analysis](AI/Time%20Series%20analysis.md) and [Forecasting](AI/Forecasting.md)\n\n\n## Resources\n- DL is a branch of [Machine Learning](AI/Machine%20Learning.md) and [AI](AI/AI.md) based on a set of algorithms that attempt to model high level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear transformations.\n- DL uses huge neural networks with many layers of processing units, taking advantage of advances in computing power and improved training techniques to learn complex patterns in large amounts of data. \n- https://github.com/ChristosChristofidis/awesome-deep-learning\n- https://github.com/endymecy/awesome-deeplearning-resources\n- https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/\n- [A Quick Introduction to Neural¬†Networks](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)\n- [Deep Neural Nets: 33 years ago and 33 years from now (Andrej Karpathy)](http://karpathy.github.io/2022/03/14/lecun1989/)\n- [Deep learning's diminish returns (Thompson)](https://spectrum.ieee.org/deep-learning-computational-cost)\n\t- https://towardsdatascience.com/the-future-of-deep-learning-7e8574ad6ae3\n- [Deep Learning Is Hitting a Wall](https://nautil.us/deep-learning-is-hitting-a-wall-14467/)\n- [A Brief History of Neural Nets and Deep Learning (2020)](http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/)\n- [Time Benchmark of models](https://dawn.cs.stanford.edu/benchmark/)\n- [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)\n- [Computer Scientists Prove Why Bigger Neural Networks Do Better](https://www.quantamagazine.org/computer-scientists-prove-why-bigger-neural-networks-do-better-20220210/)\n- [SurvNet: A backward elimination procedure to enhance variable selection for deep neural networks](https://techxplore.com/news/2021-05-survnet-procedure-variable-deep-neural.html)\n\n### DL news aggregators\n- [DeepAI](https://deepai.org/)\n- [Papers with code](https://paperswithcode.com/)\n- [Deep learning monitor](https://deeplearn.org/)\n\n### Cheatsheets\n- https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/super-cheatsheet-deep-learning.pdf\n\n### When to use and not to use deep learning\n- [When and When Not to Use Deep Learning](https://blog.dataiku.com/when-and-when-not-to-use-deep-learning)\n- [You can probably use deep learning even if your data isn't that big](http://beamandrew.github.io/deeplearning/2017/06/04/deep_learning_works.html)\n- [When not to use deep learning](http://hyperparameter.space/blog/when-not-to-use-deep-learning/)\n- [Using ANNs on small data ‚Äì Deep Learning vs. Xgboost](http://maxberggren.se/2017/06/18/deep-learning-vs-xgboost/)\n- [The limitations of deep learning](https://blog.keras.io/the-limitations-of-deep-learning.html)\n\n\n## Books\n- #BOOK [Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI (Kashani 2022)](https://arxiv.org/abs/2201.00650)\n- #BOOK [Physics-based Deep Learning Book (Thuerey 2021)](https://physicsbaseddeeplearning.org/intro.html) ^PBDL\n- #BOOK [The Principles of DL Theory: An Effective Theory Approach to Understanding Neural Networks (Roberts 2022)](https://deeplearningtheory.com/PDLT.pdf)\n\t- https://ai.facebook.com/blog/advancing-ai-theory-with-a-first-principles-understanding-of-deep-neural-networks/\n- #BOOK [Deep Learning Book (Goodfellow, 2016 MIT)](https://www.deeplearningbook.org/)\n\t- The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular\n- #BOOK [DL tutorial (LISA Lab, U Montreal)](http://deeplearning.net/tutorial/)\n- #BOOK [Deep Learning with Python (Chollet, 2021 MANNING)](https://www.manning.com/books/deep-learning-with-python-second-edition)\n\t- [1st edition](http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf)\n- #BOOK [Machine learning yearning (Andrew Ng, 2018)](https://freecomputerbooks.com/Machine-Learning-Yearning.html)\n\t- https://github.com/ajaymache/machine-learning-yearning\n- #BOOK [Dive into Deep Learning (Zhang)](https://d2l.ai/index.html)\n\t- An interactive deep learning book for students, engineers, and researchers. Uses MXNet/Gluon, Pytorch and Tensorflow\n\t- [Jupyter notebooks for each section](https://en.d2l.ai/d2l-en.zip)\n- #BOOK [Introduccion practica con Keras (Torres 2018)](https://torres.ai/deep-learning-inteligencia-artificial-keras/)\n- #BOOK [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html)\n\n\n## Talks\n- #TALK [The Future of Sparsity in Deep Learning (Trevor Gale, Phd student Stanford, 2021)](https://events.rainfocus.com/widget/nvidia/nvidiagtc/sessioncatalog/session/1631029840983001jvzq)\n- #TALK Deep Learning (Yoshua Bengio, MLSS 2020): \n\t- [Part I](https://www.youtube.com/watch?v=c_U4THknoHE)\n\t- [Part II](https://www.youtube.com/watch?v=PDPdIDihPvc)\n- #TALK [Deep Learning Hardware: Past, Present, and Future (Yann LeCun, ISSCC 2019)](https://www.youtube.com/watch?v=YzD7Z2yRL7Y)\n- #TALK [Keras, Deep Learning, and the Progress of AI (Fran√ßois Chollet, Lex Fridman Podcast, 2019)](https://www.youtube.com/watch?v=Bo8MY4JpiXE)\n- #TALK [Deep Learning and the Future of Artificial Intelligence (Yann LeCun, 2018)](https://www.youtube.com/watch?v=RM-Jtc2ryfM\u0026t=5s)\n- #TALK [AI Breakthroughs \u0026 Obstacles to Progress, Mathematical and Otherwise (Yann LeCun, 2018)](https://www.youtube.com/watch?v=1_KhJv0Em5Y)\n- #TALK [Fran√ßois Chollet at France is AI 2017: Deep Learning: current limits and future perspectives (Chollet 2017)](https://www.youtube.com/watch?v=MUF32XHqM34 )\n- #TALK [Power \u0026 Limits of Deep Learning (Yann Lecun, 2017)](https://www.youtube.com/watch?v=0tEhw5t6rhc)\n- #TALK [The Deep End of Deep Learning (Hugo Larochelle, TEDxBoston 2016)](https://www.youtube.com/watch?v=dz_jeuWx3j0)\n- #TALK [How deep neural networks work (Brandon Rohrer)](https://www.youtube.com/watch?v=ILsA4nyG7I0)\n\t- Simple explanations of DL basics and nice graphics\n\n\n## Courses\n- #COURSE [Introduction to Deep Learning (COMP0090, UCL)](https://github.com/YipengHu/COMP0090 )\n- #COURSE [Full Stack Deep Learning](https://fullstackdeeplearning.com/)\n\t- [Full Stack Deep Learning - Spring 2021](https://fullstackdeeplearning.com/spring2021/)\n\t\t- [Lecture 13: ML Teams and Startups](https://fullstackdeeplearning.com/spring2021/lecture-13/)\n\t- https://fall2019.fullstackdeeplearning.com/\n\t\t- https://github.com/full-stack-deep-learning/course-gitbook\n- #COURSE [Deep Learning (NYU)](https://atcold.github.io/pytorch-Deep-Learning/)\n\t- https://github.com/Atcold/pytorch-Deep-Learning (pytorch)\n- #COURSE [Deep Learning (CS230, Stanford)](http://cs230.stanford.edu/)\n\t- [Cheatsheets](https://github.com/afshinea/stanford-cs-230-deep-learning)\n- #COURSE [Tensorflow for Deep Learning Research (CS20SI, Stanford)](http://web.stanford.edu/class/cs20si/syllabus.html)\n- #COURSE [DeepMind x UCL | Deep Learning Lecture Series 2020](https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF)\n- #COURSE [Introduction to Deep Learning (6.S191, MIT)](http://introtodeeplearning.com/)\n\t- [MIT Introduction to Deep Learning | 6.S191 | 2022](https://www.youtube.com/watch?v=7sB052Pz0sQ)\n- #COURSE [MIT Deep Learning and Artificial Intelligence Lectures](https://deeplearning.mit.edu/)\n\t- [Youtube playlist](https://www.youtube.com/watch?v=0VH1Lim8gL8\u0026list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)\n\t- [Deep Learning State of the Art (2020)](https://www.youtube.com/watch?v=0VH1Lim8gL8)\n- #COURSE [Introduction to Deep Learning (MIT 6.S191)](http://introtodeeplearning.com/)\n- #COURSE [Intro to Neural Networks and Machine Learning (CSC 321, UToronto)](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/)\n- #COURSE [Deep Learning nanodegree (Udacity)](https://www.udacity.com/course/deep-learning-nanodegree--nd101)\n\t- https://github.com/udacity/deep-learning-v2-pytorch\n\t- https://www.udacity.com/course/deep-learning-pytorch--ud188\n- #COURSE [Deep Learning with PyTorch: Zero to GANs (Jovian)](https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans)\n- #COURSE [Fast AI - Practical Deep Learning For Coders](http://course.fast.ai/)\n\t- Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD - the book and the course\n\t- https://github.com/fastai/fastbook\n- #COURSE [Deep Learning course (U Paris-Saclay)](https://m2dsupsdlclass.github.io/lectures-labs/)\n- #COURSE [Introduction to Machine Learning and Neural Networks (Uniandes)](https://albahnsen.com/courses/applied-deep-learning/)\n\t- https://github.com/albahnsen/AppliedDeepLearningClass\n- #COURSE [Deep learning specialization (deeplearning.ai, Coursera, Andrew Ng)](https://www.coursera.org/specializations/deep-learning)\n\t- https://www.deeplearning.ai/deep-learning-specialization/\n- #COURSE [Neural Networks (U Sherbrooke)](http://info.usherbrooke.ca/hlarochelle/neural_networks/description.html)\n- #COURSE [The Neural Aesthetic (ITP-NYU)](http://ml4a.github.io/classes/itp-F18/)\n\n\n## Code\nState of ML frameworks: \n- https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/\n- https://towardsdatascience.com/tensorflow-or-pytorch-146f5397278a\n\n- #CODE [Tensorflow, keras](AI/DS%20and%20DataEng/Tensorflow,%20keras.md)\n- #CODE [Pytorch](AI/DS%20and%20DataEng/Pytorch.md)\n- #CODE [Ivy](https://github.com/unifyai/ivy)\n\t- The unified machine learning framework, enabling framework-agnostic functions, layers and libraries\n\t- [lets-unify.ai](https://lets-unify.ai/ \"https://lets-unify.ai\")\n\t- #PAPER [Ivy: Templated Deep Learning for Inter-Framework Portability (Lenton 2021)](https://arxiv.org/abs/2102.02886)\n- #CODE [Huggingface](https://huggingface.co/)\n\t- Build, train and deploy state of the art models powered by the reference open source in ML\n\t- [Datasets](https://github.com/huggingface/datasets)\n\t- [Datasets-viewer](https://github.com/huggingface/datasets-viewer)\n\t\t- https://huggingface.co/datasets/viewer/\n\t- [Transformers](https://github.com/huggingface/transformers)\n- #CODE [Triton](https://github.com/openai/triton)\n\t- language and compiler for writing highly efficient custom Deep-Learning primitives\n\t- https://openai.com/blog/triton/\n\t- https://www.infoq.com/news/2021/08/openAI-triton/\n\t- Triton uses Python as its base. The developer writes code in Python using Triton‚Äôs libraries, which are then JIT-compiled to run on the GPU. This allows integration with the rest of the Python ecosystem, currently the biggest destination for developing machine-learning solutions\n- #CODE [Oneflow](https://github.com/Oneflow-Inc/oneflow)\n\t- OneFlow is a performance-centered and open-source deep learning framework\n\t- http://www.oneflow.org/\n- #CODE [MindSpore (Huawei)](https://github.com/mindspore-ai/mindspore) ^huaweimindpore\n\t- https://towardsdatascience.com/program-your-first-neural-network-with-huawei-mindspore-1fc50023e90d\n\t- https://towardsdatascience.com/huaweis-mindspore-a-new-competitor-for-tensorflow-and-pytorch-d319deff2aec\n\t- https://www.mindspore.cn/en\n- #CODE [Tensorlayer - Deep Learning and Reinforcement Learning Library for Scientists and Engineers](https://github.com/tensorlayer/tensorlayer)\n\t- http://tensorlayer.org/\n- #CODE [Elegy - Neural Networks framework based on Jax and inspired by Keras](https://github.com/poets-ai/elegy)\n\t- https://poets-ai.github.io/elegy/\n\t- See [Mathematical Optimization](AI/Math%20and%20Statistics/Mathematical%20Optimization.md) JAX\n- #CODE [Paddle (Baidu)](https://github.com/PaddlePaddle/Paddle)\n\t- http://www.paddlepaddle.org/\n\t- PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice\n- #CODE [Mxnet (Apache)](https://github.com/apache/incubator-mxnet)\n\t- http://mxnet.io/\n\t- [Towards Next Generation Deep Learning Framework](https://mli.github.io/cvpr17/)\n- #CODE [Microsoft Cognitive Toolkit (CNTK)](https://github.com/Microsoft/CNTK)\n\t- https://www.microsoft.com/en-us/research/product/cognitive-toolkit/\n\t- Microsoft Cognitive Toolkit: A free, easy-to-use, open-source, commercial-grade toolkit that trains deep learning algorithms to learn like the human brain.\n\t- #TALK https://www.youtube.com/watch?v=9gDDO5ldT-4\u0026feature=youtu.be\n- #CODE [Neupy - NeuPy is a Tensorflow based python library for prototyping and building neural networks](https://github.com/itdxer/neupy)\n\t- http://neupy.com/pages/home.html\n- #CODE Chainer - Chainer is a Python-based deep learning framework aiming at flexibility\n\t- https://github.com/chainer/chainer\n- #CODE [Neural Network Console (Sony)](https://dl.sony.com/)\n- #CODE [PySyft](https://github.com/OpenMined/PySyft)\n\t- PySyft is a Python library for secure and private Deep Learning. \n\t- PySyft decouples private data from model training, using Federated Learning, Differential Privacy, and Encrypted Computation (like Multi-Party Computation (MPC) and Homomorphic Encryption (HE)) within the main Deep Learning frameworks like PyTorch and TensorFlow.\n\t- #PAPER [A generic framework for privacy preserving deep learning](https://arxiv.org/abs/1811.04017)\n- #CODE [Deep cognition](https://deepcognition.ai/)\n\n\n## References\n- #PAPER [Deep learning in NNs: An overview (Schmidhuber 2015)](https://www.sciencedirect.com/science/article/pii/S0893608014002135)\n- #PAPER [Deep learning (LeCun 2015)](https://www.nature.com/articles/nature14539) ^dllecun15\n\t- https://www.researchgate.net/profile/Y_Bengio/publication/277411157_Deep_Learning/links/55e0cdf908ae2fac471ccf0f/Deep-Learning.pdf\n- #PAPER [Deep Neural Decision Forests (Kontschieder 2016)](https://www.ijcai.org/Proceedings/16/Papers/628.pdf)\n\t- #CODE https://keras.io/examples/structured_data/deep_neural_decision_forests/\n- #PAPER [On the Origin of Deep Learning (Wang 2017)](https://arxiv.org/abs/1702.07800v4 )\n- #PAPER [Representation Learning on Large and Small Data (Chou 2017)](https://arxiv.org/abs/1707.09873v1)\n- #PAPER [Deep Learning in Neural Networks: An Overview (Schmidhuber, 2018)](https://arxiv.org/abs/1404.7828)\n- #PAPER [Deep Learning as a Mixed Convex-Combinatorial Optimization Problem (Friesen 2018)](https://arxiv.org/abs/1710.11573)\n- #PAPER [Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods (Lucas, 2018)](https://ieeexplore.ieee.org/document/8253590)\n\t- http://decsai.ugr.es/vip/files/journals/08253590.pdf\n- #PAPER [Neural Tangent Kernel: Convergence and Generalization in Neural Networks (Jacot 2018)](https://arxiv.org/abs/1806.07572#)\n\t- https://www.quantamagazine.org/a-new-link-to-an-old-model-could-crack-the-mystery-of-deep-learning-20211011/\n- #PAPER [Neural circuit policies enabling auditable autonomy (Lechner 2020)](https://www.nature.com/articles/s42256-020-00237-3)\n\t- #CODE https://github.com/mlech26l/keras-ncp\n\t- https://www.csail.mit.edu/news/new-deep-learning-models-require-fewer-neurons\n\t- https://www.marktechpost.com/2021/10/19/mit-csail-tu-wien-and-ist-researchers-introduce-deep-learning-models-that-require-fewer-neurons/\n- #PAPER [Implicitly Defined Layers in Neural Networks (Zhang 2020)](https://arxiv.org/abs/2003.01822)\n- #PAPER [A Mathematical Principle of Deep Learning: Learn the Geodesic Curve in the Wasserstein Space (Gai 2021)](https://arxiv.org/abs/2102.09235)\n- #PAPER [Why is AI hard and Physics simple? (Roberts 2021)](https://arxiv.org/abs/2104.00008)\n- #PAPER [Deep Learning for AI (By Yoshua Bengio, Yann Lecun, Geoffrey Hinton, Turing lecture, 2021)](https://dl.acm.org/doi/10.1145/3448250)\n\t- https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltex\n- #PAPER [Self-Tuning for Data-Efficient Deep Learning (Wang 2021)](https://arxiv.org/abs/2102.12903)\n\t- #CODE https://github.com/thuml/Self-Tuning\n\t- #TALK https://recorder-v3.slideslive.com/#/share?share=40334\u0026s=f7988e61-bece-4a7a-a6ba-3e1a2b49b37b\n- #PAPER [Neural circuit policies enabling auditable autonomy (Lechner 2021)](https://www.nature.com/articles/s42256-020-00237-3)\n\t- #CODE https://github.com/mlech26l/keras-ncp\n- #PAPER [Controlling Neural Networks with Rule Representations (Seo 2021)](https://arxiv.org/abs/2106.07804)\n\t- https://ai.googleblog.com/2022/01/controlling-neural-networks-with-rule.html\n- #PAPER [Deep physical neural networks trained with backpropagation (Wrigth 2022)](https://www.nature.com/articles/s41586-021-04223-6)\n- #PAPER [Ensemble deep learning: A review (Ganaie 2022)](https://arxiv.org/pdf/2104.02395)            \n\n\n### Generalization\nSee \"Interpretability of deep learning models\" section in [XAI](AI/XAI.md)\n- http://www.inference.vc/everything-that-works-works-because-its-bayesian-2/\n\n- #PAPER [Understanding deep learning requires re-thinking generalization (Zhang 2016)](https://arxiv.org/abs/1611.03530)\n\t- https://blog.acolyer.org/2017/05/11/understanding-deep-learning-requires-re-thinking-generalization/\n\t- https://www.quora.com/Why-is-the-paper-%E2%80%9CUnderstanding-Deep-Learning-Requires-Rethinking-Generalization%E2%80%9D-important\n- #PAPER [A Closer Look at Memorization in Deep Networks (Arpit 2017)](https://arxiv.org/abs/1706.05394)\n- #PAPER [Deep nets don‚Äôt learn via memorization (Krueger 2017)](https://openreview.net/pdf?id=rJv6ZgHYg)\n- #PAPER [Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior (Martin 2017)](https://arxiv.org/abs/1710.09553)\n- #PAPER [Ablation Studies in Artificial Neural Networks (Meyes 2019)](https://arxiv.org/abs/1901.08644)\n- #PAPER [Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning (Allen-Zhu 2020)](https://arxiv.org/abs/2012.09816)\n\t- https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/\n- #PAPER [The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers (Nakkiran 2021)](https://arxiv.org/abs/2010.08127)\n\t- https://ai.googleblog.com/2021/03/a-new-lens-on-understanding.html\n- #PAPER [Predicting trends in the quality of state-of-the-art neural networks without access to training or testing data (Martin 2021)](https://www.nature.com/articles/s41467-021-24025-8)\n- #PAPER [Stochastic Training is Not Necessary for Generalization (Geiping 2021)](https://arxiv.org/abs/2109.14119)\n- #PAPER [Underspecification Presents Challenges for Credibility in Modern Machine Learning (D'Amour 2021)](https://arxiv.org/abs/2011.03395)\n\t- https://ai.googleblog.com/2021/10/how-underspecification-presents.html\n- #PAPER [Learning in High Dimension Always Amounts to Extrapolation (Balestriero 2021)](https://arxiv.org/abs/2110.09485)\n\t- In order for NNs to succeed at solving a task, they have to operate in the ‚Äúextrapolation‚Äù regime! But not all of them generalise as well as others. So this opens up new questions about the relationship between this specific notion of extrapolation and generalisation more generally.\n- #PAPER [Incorporating Symmetry into Deep Dynamics Models for Improved Generalization (Wang 2021)](https://arxiv.org/abs/2002.03061)\n\t- #CODE https://github.com/Rose-STL-Lab/Equivariant-Net\n- #PAPER [Grokking - Generatlization beyond overfitting on small algorithmic datasets (Power 2022)](https://arxiv.org/abs/2201.02177v1)\n\t- [Paper explained](https://www.youtube.com/watch?v=dND-7llwrpw)\n\n\n### Regularization\n- In general, techniques aimed at reducing overfitting and improve generalization\n- [Overfit and underfit](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit)\n- [Regularization techniques for training deep neural networks](https://theaisummer.com/regularization/)\n- https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036\n- https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/\n- https://medium.com/intelligentmachines/convolutional-neural-network-and-regularization-techniques-with-tensorflow-and-keras-5a09e6e65dc7\n\n#### Data augmentation\n- https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n- https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n- #PAPER [A survey on Image Data Augmentation for Deep Learning (Shorten 2019)](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)\n\n#### Dropout\n- http://www.cs.toronto.edu/~hinton/absps/dropout.pdf\n- https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/\n- [12 Main Dropout Methods: Mathematical and Visual Explanation for DNNs, CNNs, and RNNs](https://towardsdatascience.com/12-main-dropout-methods-mathematical-and-visual-explanation-58cdc2112293)\n\n- #PAPER [Dropout: A Simple Way to Prevent Neural Networks from Overfitting (Srivastava 2014)](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n- #PAPER [Efficient Object Localization Using Convolutional Networks (Tompson 2015)](https://arxiv.org/abs/1411.4280v3)\n\t- Proposed spatial dropout\n- #PAPER [Analysis on the Dropout Effect in Convolutional Neural Networks (Park 2017)](https://link.springer.com/chapter/10.1007/978-3-319-54184-6_12)\n\t- http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf\n- #PAPER [Effective and Efficient Dropout for Deep Convolutional Neural Networks (Cai 2020)](https://arxiv.org/abs/1904.03392)\n\n\n#### Normalization\n- Normalization techniques also improve generalization error, providing some regularization\n- [Normalization Techniques in Deep Neural Networks](https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8)\n- [Different Types of Normalization in Tensorflow](https://towardsdatascience.com/different-types-of-normalization-in-tensorflow-dac60396efb0)\n- [Normalization in Deep Learning](https://arthurdouillard.com/post/normalization/)\n- https://sebastianraschka.com/faq/docs/scale-training-test.html \n- Data normalization/standardization can be used as an alternative (before training) to synch batchnorm (multi-gpu training)\n- [Spectral normalization](https://sthalles.github.io/advanced_gans/)\n\n- #PAPER [Normalization Techniques in Training DNNs: Methodology, Analysis and Application (Huang 2020)](https://arxiv.org/abs/2009.12836)\n\n##### BatchNorm\n- #PAPER [ Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (Ioffe 2015)](https://arxiv.org/abs/1502.03167)\n\t- #TALK https://www.youtube.com/watch?v=ZOabsYbmBRM\u0026feature=youtu.be\n\t- http://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras\n\t- Slower convergence w/o BN, BN can be applied on top of standardization \n\t- Synch BatchNorm appears in TF 2.2, for multi-gpu training \n\t\t- https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/SyncBatchNormalization \n- #PAPER [Rethinking the Usage of Batch Normalization and Dropout (Chen 2019)](https://arxiv.org/abs/1905.05928)\n\n### Activations\n- https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html\n- https://mlfromscratch.com/activation-functions-explained/\n- [RELU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))\n\t- https://www.quora.com/What-is-special-about-rectifier-neural-units-used-in-NN-learning\n- http://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-network\n- https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions\n\n### Loss/Cost functions\n- Cross entropy\n\t- http://neuralnetworksanddeeplearning.com/chap3.html\n\t- https://en.wikipedia.org/wiki/Cross_entropy\n\t- http://www.kdnuggets.com/2017/02/gentlest-introduction-tensorflow-part-4.html\n- Perceptual loss, image reconstruction\n\t- https://arxiv.org/pdf/1511.06409.pdf (Learning to Generate Images With Perceptual Similarity Metrics) \n\t- #PAPER [Loss Functions for Image Restoration with Neural Networks (Zhao 2018)](https://arxiv.org/abs/1511.08861)\n\t- https://medium.com/@sanari85/rediscovery-of-ssim-index-in-image-reconstruction-ssim-as-a-loss-function-a1ffef7d2be \n\t\t- We use three different metric for comparing each different methods such as DSSIM, MSE, and MAE. Structural dissimilarity(DSSIM) is an image distance metric, that corresponds better to the human perception than MAE or RMSE. Mean Squared Error (MSE) measures the average of the squares of the errors that is, the average squared difference between the estimated values and the actual value. Mean Absolute Error (MAE) is the average distance between each pixel point. https://arxiv.org/abs/2001.05372\n- [Deep learning image enhancement insights on loss function engineering](https://towardsdatascience.com/deep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7)\n- Mean squared logarithmic error \n\t- https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle) \n\t- https://medium.com/@olegrybkin_20684/the-reasonable-ineffectiveness-of-mse-pixel-loss-for-future-prediction-and-what-to-do-about-it-4dca8152355d \n\n### Optimizers and backpropagation\n- [How to use Learning Curves to Diagnose Machine Learning Model Performance](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)\n- https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent\n- [Keras optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/ )\n- [Adam](http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n- [An overview of gradient descent optimization algorithms (2016)](https://ruder.io/optimizing-gradient-descent/index.html#otherrecentoptimizers )\n- https://hackernoon.com/some-state-of-the-art-optimizers-in-neural-networks-a3c2ba5a5643 \n- https://www.jeremyjordan.me/neural-networks-training/\n- http://colah.github.io/posts/2015-08-Backprop/\n- [Back-propagation - Math Simplified](https://github.com/DebPanigrahi/Machine-Learning/blob/master/back_prop.ipynb)\n- https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n- https://venturebeat.com/2020/12/16/at-neurips-2020-researchers-proposed-faster-more-efficient-alternatives-to-backpropagation/amp/\n\n- #PAPER [On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima (Shirish Keshkar 2017)](https://arxiv.org/abs/1609.04836)\n- #PAPER [Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour (Goyal 2018)](https://arxiv.org/abs/1706.02677)\n- #PAPER [Decoupled Weight Decay Regularization (Loshchilov 2018)](https://arxiv.org/abs/1711.05101)\n\t- AdamW optimizer\n\t- #CODE https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/AdamW\n\t- https://www.fast.ai/2018/07/02/adam-weight-decay/\n- #PAPER [Deep Double Descent: Where Bigger Models and More Data Hurt (Nakkiran 2019)](https://arxiv.org/abs/1912.02292)\n\t- https://openai.com/blog/deep-double-descent/\n\t- https://medium.com/mlearning-ai/double-descent-8f92dfdc442f\n- #PAPER [Reconciling modern machine learning practice and the bias-variance trade-off (Belkin 2019)](https://arxiv.org/abs/1812.11118)\n\t- [Paper explained](https://www.youtube.com/watch?v=ZAW9EyNo2fw)\n- #PAPER [Deep Double Descent: Where Bigger Models and More Data Hurt (Nakkiran 2020)](https://arxiv.org/abs/1912.02292)\n\t- https://openai.com/blog/deep-double-descent/\n- #PAPER [Descending through a Crowded Valley -- Benchmarking Deep Learning Optimizers (Schmidt 2020)](https://arxiv.org/abs/2007.01547)\n\t- [Paper explained](https://www.youtube.com/watch?v=DiNzQP7kK-s)\n- #PAPER [Early Stopping in Deep Networks: Double Descent and How to Eliminate it (Heckel 2020)](https://arxiv.org/abs/2007.10099)\n\t- contrary to model-wise double descent, epoch-wise double descent is not a phenomena tied o over-parameterization\n\t- both under- and overparameterized models can have epoch-wise double descent \n\t- #CODE https://github.com/MLI-lab/early_stopping_double_descent\n\n\n### Efficiency and performance\n- #PAPER [Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better (Menghani 2021)](https://arxiv.org/abs/2106.08962)\n\t- https://analyticsindiamag.com/how-to-build-smaller-faster-better-deep-learning-models/\n\n### Attention\nSee: \n- \"For NLP\" section in [Transformers](AI/Deep%20learning/Transformers.md)\n- \"Channel/Visual attention\" section in [CNNs](/AI/Deep%20learning/CNNs.md)\n\n- #COURSE [Attention and Memory in Deep Learning (DeepMind x UCL | Deep Learning Lectures | 8/12)](https://www.youtube.com/watch?v=AIiwuClvH6k)\n\n### Deep learning for multi-dimensional data\nSee:\n- [Video segmentation and prediction](AI/Computer%20Vision/Video%20segmentation%20and%20prediction.md)\n- [Encoder-decoder networks](AI/Deep%20learning/Encoder-decoder%20networks.md)\n- [Transformers](AI/Deep%20learning/Transformers.md)\n- [Generative modelling](AI/Deep%20learning/Generative%20modelling.md)\n\n- #PAPER [Demystifying Deep Learning in Predictive Spatio-Temporal Analytics: An Information-Theoretic Framework (Tan 2020)](https://arxiv.org/abs/2009.06304)\n\n### Deep learning for tabular data\n- [An Introduction to Deep Learning for Tabular Data](https://www.fast.ai/2018/04/29/categorical-embeddings/)\n- [Applying Deep Learning on Tabular Data Using TensorFlow 2.0](https://pdf.co/blog/deep-learning-on-tabular-data-using-tensorflow-20)\n- #CODE See Pytorch tabular in [Pytorch](AI/DS%20and%20DataEng/Pytorch.md) \n- #PAPER [Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data (Popov 2019)](https://arxiv.org/abs/1909.06312)\n- #PAPER [TabNet: Attentive Interpretable Tabular Learning (Arik 2020)](https://arxiv.org/abs/1908.07442)\n- #PAPER [Converting tabular data into images for deep learning with convolutional neural networks (Zhu 2021)](https://www.nature.com/articles/s41598-021-90923-y)\n- #PAPER [Tabular Data: Deep Learning is Not All You Need (Shwartz-Ziv 2021)](https://arxiv.org/abs/2106.03253)\n- #PAPER [XBNet: An Extremely Boosted Neural Network (Sarkar 2021)](https://arxiv.org/abs/2106.05239)\n\t- #CODE [XBNet](https://github.com/tusharsarkar3/XBNet)\n\t- Boosted neural network for tabular data\n\t- https://analyticsindiamag.com/guide-to-xbnet-an-extremely-boosted-neural-network/\n- #PAPER [Revisiting Deep Learning Models for Tabular Data (Gorishniy 2021)](https://arxiv.org/abs/2106.11959)\n\t- #CODE [RDTL (Yandex)](https://github.com/yandex-research/rtdl)\n\t- https://yandex-research.github.io/rtdl/\n- #PAPER [TABBIE: Pretrained Representations of Tabular Data (Lida 2021)](https://arxiv.org/abs/2105.02584v1)\n\n### Deep learning for scientific discovery\nSee [Neural ODEs](AI/Deep%20learning/Neural%20ODEs.md)\n- #PAPER [A Survey of Deep Learning for Scientific Discovery (Raghu \u0026 Schmidt, 2020)](https://arxiv.org/abs/2003.11755) ^dlscience20\n- #PAPER [DeepXDE: A deep learning library for solving differential equations (Lu 2020)](https://arxiv.org/abs/1907.04502)\n\t- #CODE https://github.com/lululxvi/deepxde\n\t- https://deepxde.readthedocs.io/en/latest/\n- #PAPER [SciANN: A Keras/Tensorflow wrapper for scientific computations and physics-informed deep learning using artificial neural networks (Haghighat 2020)](https://arxiv.org/abs/2202.07575)\n\t - #CODE https://github.com/sciann/sciann\n- #PAPER [Learning an Accurate Physics Simulator via Adversarial Reinforcement Learning (Jiang 2021)](http://ai.googleblog.com/2021/06/learning-accurate-physics-simulator-via.html \"Learning an Accurate Physics Simulator via Adversarial Reinforcement Learning\")\n\n## Architectures and model types\n- [The neural network zoo](http://www.asimovinstitute.org/neural-network-zoo/)\n- [Deep Learning Tips and Tricks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks)\n- [A Visual and Interactive Guide to the Basics of NNs](https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/)\n- [A Visual And Interactive Look at Basic Neural Network Math](https://jalammar.github.io/feedforward-neural-networks-visual-interactive/)\n- #CODE [Model Zoo](https://modelzoo.co/)\n- #CODE [Deep Learning Models (Raschka)](https://github.com/rasbt/deeplearning-models)\n\n\n### MLPs\nSee [MLPs](AI/Deep%20learning/MLPs.md)\n\n### Deep belief network\nSee [Deep belief network](AI/Deep%20learning/Deep%20belief%20network.md)\n\n### Autoencoders\nSee [Autoencoders](AI/Deep%20learning/Autoencoders.md)\n\n### CNNs\nSee [CNNs](AI/Deep%20learning/CNNs.md)\n\n### RNNs\nSee [RNNs](AI/Deep%20learning/RNNs.md)\n\n### CapsNets\nSee [CapsNets](AI/Deep%20learning/CapsNets.md)\n\n### GANs\nSee [GANs](AI/Deep%20learning/GANs.md)\n\n### Diffusion models\nSee [Diffusion models](AI/Deep%20learning/Diffusion%20models.md)\n\n### GNNs\nSee [GNNs](AI/Deep%20learning/GNNs.md)\n\n### Residual and dense neural networks\nSee [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n\n### Neural ODEs\nSee [Neural ODEs](AI/Deep%20learning/Neural%20ODEs.md)\n\n### Fourier Neural Operators\nSee [Fourier Neural Operators](AI/Deep%20learning/Fourier%20Neural%20Operators.md)\n\n### Transformers\nSee [Transformers](AI/Deep%20learning/Transformers.md)\n\n### GFlowNets\nSee [GFlowNets](AI/Deep%20learning/GFlowNets.md)\n\n### Neural Cellular Automata\nSee [Neural Cellular Automata](AI/Deep%20learning/Neural%20Cellular%20Automata.md)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Deep-belief-network":{"title":"Deep belief network","content":"## Resources\n- In machine learning, a deep belief network (DBN) is a generative graphical model, or alternatively a type of deep neural network, composed of multiple layers of latent variables(\"hidden units\"), with connections between the layers but not between units within each layer. DBNs can be viewed as a composition of simple, unsupervised networks such as restricted Boltzmann machines (RBMs) or autoencoders, where each sub-network's hidden layer serves as the visible layer for the next.\n- #TALK [Deep Belief Nets (Hinton)](https://www.cs.toronto.edu/~hinton/nipstutorial/nipstut3.pdf)\n- [Deep-Belief Networks](https://wiki.pathmind.com/deep-belief-network)\n\t- A deep-belief network can be defined as a stack of restricted Boltzmann machines, in which each RBM layer communicates with both the previous and subsequent layers. The nodes of any single layer don‚Äôt communicate with each other laterally.\n\t- This stack of RBMs might end with a a Softmax layer to create a classifier, or it may simply help cluster unlabeled data in an unsupervised learning scenario.\n\t- With the exception of the first and final layers, each layer in a deep-belief network has a double role: it serves as the hidden layer to the nodes that come before it, and as the input (or ‚Äúvisible‚Äù) layer to the nodes that come after. It is a network built of single-layer networks.\n\t- Deep-belief networks are used to recognize, cluster and generate images, video sequences and motion-capture data. A continuous deep-belief network is simply an extension of a deep-belief network that accepts a continuum of decimals, rather than binary data. They were introduced by Geoff Hinton and his students in 2006.","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Diffusion-models":{"title":"Diffusion models","content":"## Resources\n- [Diffusion models are autoencoders (Dieleman | Deepmind)](https://benanne.github.io/2022/01/31/diffusion.html \"Diffusion models are autoencoders\")\n- [High Fidelity Image Generation Using Diffusion Models](http://ai.googleblog.com/2021/07/high-fidelity-image-generation-using.html \"High Fidelity Image Generation Using Diffusion Models\")\n- [Introduction to deep generative modeling: Diffusion-based Deep Generative Models](https://jmtomczak.github.io/blog/10/10_ddgms_lvm_p2.html)\n\n## References\n- #PAPER [Improved Denoising Diffusion Probabilistic Models (Nichol 2021)](https://arxiv.org/abs/2102.09672)\n- #PAPER [Cascaded Diffusion Models for High Fidelity Image Generation (Ho 2021)](https://cascaded-diffusion.github.io/)\n- #PAPER [Diffusion Models Beat GANs on Image Synthesis (Dhariwal 2021)](https://arxiv.org/abs/2105.05233v3)\n\t- #CODE https://github.com/openai/guided-diffusion\n\t- Diffusion models are a class of likelihood-based models that have shown to produce high-quality images with desired properties such as distribution coverage and easy scalability. These models generate samples by gradually removing noise from a signal. Previous research has shown that they improve reliably with increased compute. The proposed method brings improvements to diffusions models that have worked for GANs, such as improved model architecture and a scheme to trade off diversity for quality. The proposed diffusion model achieves several state-of-the-art results, surpassing GANs on several metrics and datasets\n\t- [Paper explained](https://www.youtube.com/watch?v=W-O7AZNzbzQ)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Encoder-decoder-networks":{"title":"Encoder-decoder networks","content":"## Resources\n- Very common models for semantic segmentation tasks\n- [DL](AI/Deep%20learning/DL.md) architectures composed of two paths, an encoding and a decoding one. [Autoencoders](AI/Deep%20learning/Autoencoders.md) are similar but unsupervised (reconstructions loss)\n- U-NETs are a type of encoder-decoder [CNNs](AI/Deep%20learning/CNNs.md) model with skipped connections trained in a [Supervised learning](AI/Supervised%20Learning/Supervised%20learning.md) context for image segmentation and related tasks\n- https://www.slideshare.net/PetteriTeikariPhD/multiphoton-vasculature-segmentation-5-unet\n\n\n## References\n- #PAPER [U-Net: Convolutional Networks for Biomedical Image Segmentation (Ronneberger 2015)](https://arxiv.org/abs/1505.04597 )\n\t- https://towardsdatascience.com/review-u-net-biomedical-image-segmentation-d02bf06ca760 \n\t- https://github.com/karolzak/keras-unet \n\t- https://tuatini.me/practical-image-segmentation-with-unet/ \n\t- https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/unet.py \n\t- [diagram example](https://www.researchgate.net/publication/323302730/figure/fig1/AS:596310398881793@1519182886358/U-Net-architecture-consisted-with-convolutional-encoding-and-decoding-units-that-take.png )\n- #PAPER [3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation (Cicek 2016)](https://arxiv.org/abs/1606.06650)\n\t- https://towardsdatascience.com/review-3d-u-net-volumetric-segmentation-medical-image-segmentation-8b592560fac1 \n- #PAPER [V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation (Milletari 2016)](https://arxiv.org/abs/1606.04797)\n\t- https://towardsdatascience.com/review-v-net-volumetric-convolution-biomedical-image-segmentation-aa15dbaea974 \n- #PAPER [Volumetric ConvNets with Mixed Residual Connections for Automated Prostate Segmentation from 3D MR Images, 3D UNET+Resnet (Yu 2017)](https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14719)\n\t- https://towardsdatascience.com/review-3d-u-net-resnet-volumetric-convolutions-long-short-residual-connections-biomedical-3a7da3f98dae\n- #PAPER [Automatic 3D Cardiovascular MR Segmentation with Densely-Connected Volumetric ConvNets, DenseVoxNet (Yu 2017)](https://arxiv.org/abs/1708.00573 )\n\t- https://medium.com/@sh.tsang/review-densevoxnet-volumetric-brain-segmentation-biomedical-image-segmentation-9136bb6128dd \n- #PAPER [Road Extraction by Deep Residual U-Net, ResUNET (Zhang 2017)](https://arxiv.org/abs/1711.10684)\n\t- https://github.com/nikhilroxtomar/Deep-Residual-Unet\n- #PAPER [Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation (Alom 2018)](https://www.researchgate.net/publication/323302730_Recurrent_Residual_Convolutional_Neural_Network_based_on_U-Net_R2U-Net_for_Medical_Image_Segmentation)\n- #PAPER [UNet++: A Nested U-Net Architecture for Medical Image Segmentation (Zhou 2018)](https://arxiv.org/abs/1807.10165)\n\t- https://medium.com/@sh.tsang/review-unet-a-nested-u-net-architecture-biomedical-image-segmentation-57be56859b20 \n- #PAPER [H-DenseUNet: Hybrid Densely Connected UNet for Liver and Tumor Segmentation from CT Volumes (Li 2018)](https://arxiv.org/abs/1709.07330  )\n\t- https://medium.com/@sh.tsang/review-h-denseunet-2d-3d-denseunet-for-intra-inter-slice-features-biomedical-image-f3e526e81fe7 \n\t- #CODE https://github.com/xmengli999/H-DenseUNet/\n- #PAPER [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation, DeepLabv3+ (Chen 2018)](https://arxiv.org/abs/1802.02611)\n\t- #CODE https://github.com/ChoiDM/pytorch-deeplabv3plus-3D \n- #PAPER [ResUNet-a: a deep learning framework for semantic segmentation of remotely sensed data (Diakogiannis 2019)](https://arxiv.org/abs/1904.00592)\n- #PAPER [ResUNet++: An Advanced Architecture for Medical Image Segmentation (Jha 2019)](https://arxiv.org/abs/1911.07067)\n- #PAPER [M-Net: U-Net with Multi-stream Feature Fusion and Multi-scale Dilated Convolutions (Fu 2019)](https://ieeexplore.ieee.org/document/8864993 )\n\t- https://www.researchgate.net/publication/336455527_M-Net_A_Novel_U-Net_with_Multi-stream_Feature_Fusion_and_Multi-scale_Dilated_Convolutions_for_Bile_Ducts_and_Hepatolith_Segmentation_September_2019 \n- #PAPER [Channel-Unet: A Spatial Channel-Wise Convolutional Neural Network for Liver and Tumors Segmentation (Chen 2019)](https://www.frontiersin.org/articles/10.3389/fgene.2019.01110/full)\n- #PAPER [Bi-Directional ConvLSTM U-Net with Densely Connected Convolutions (Azad 2019)](https://arxiv.org/abs/1909.00166)\n    - #CODE https://github.com/rezazad68/BCDU-Net/blob/master/Retina%20Blood%20Vessel%20Segmentation/models.py\n- #PAPER [LSTM-UNET - Microscopy Cell Segmentation via Convolutional LSTM Networks (Arbelle 2019)](https://arxiv.org/abs/1805.11247)\n\t#CODE https://github.com/arbellea/LSTM-UNet\n- #PAPER [USE-Net: incorporating Squeeze-and-Excitation blocks into U-Net for prostate zonal segmentation of multi-institutional MRI datasets (Rundo 2019)](https://arxiv.org/abs/1904.08254)\n- #PAPER [Evaluation of Multi-Slice Inputs to Convolutional Neural Networks for Medical Image Segmentation (Vu 2019)](https://arxiv.org/abs/1912.09287)\n- #PAPER [Making a Case for 3D Convolutions for Object Segmentation in Videos (Mahadevan 2020)](https://arxiv.org/abs/2008.11516)\n\t- proposed a simple and fast network architecture consisting entirely of 3D  convolutions that is capable of effectively learning spatio-temporal features\n\t- used a 3D ResNet pretrained for video action classification as an encoder, and a novel decoder architecture inspired by existing 2D convolutional networks\n- #PAPER [nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation (Isensee 2020)](https://www.nature.com/articles/s41592-020-01008-z)\n\t- https://www.sciencedaily.com/releases/2020/12/201207112253.htm\n\t- #CODE https://github.com/MIC-DKFZ/nnUNet\n- #PAPER [MCNN, Multi-resolution convolutional neural networks for inverse problems (Wang 2020)](https://www.nature.com/articles/s41598-020-62484-z)\n\t- #CODE https://github.com/fengwang/MCNN\n\t- #CODE https://github.com/fengwang/mcnn-demo/tree/master/demo","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Fourier-Neural-Operators":{"title":"Fourier Neural Operator","content":"## References\n- #PAPER [Fourier Neural Operator for Parametric Partial Differential Equations (Li 2020)](https://arxiv.org/abs/2010.08895)\n\t- #CODE https://github.com/zongyi-li/fourier_neural_operator\n\t- https://zongyi-li.github.io/blog/2020/fourier-pde/\n\t- https://www.technologyreview.com/2020/10/30/1011435/ai-fourier-neural-network-cracks-navier-stokes-and-partial-differential-equations/\n\t- Function approximation in Fourier space instead of a the Euclidian (with conventional convolutions)\n\t- [Paper explained](https://www.youtube.com/watch?v=IaS72aHrJKE)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/GANs":{"title":"Generative Adversarial Networks (GANs)","content":"See:\n- [Generative modelling](AI/Deep%20learning/Generative%20modelling.md)\n\n## Resources\n- A GAN consists of two networks; a generator (G) and a discriminator (D), given a set of training examples, G will generate outputs and D will classify them as either being from the same distribution as the training examples or not. In doing so D is optimized so as to be able to discriminate between examples from the training example and from the generator network which in turn is optimized to fool D into classifying its output as being drawn from the training examples. After such training G can now generate samples with properties very similar to those of the training examples. GANs tend to be devilishly hard to train. \n- [List of papers and other on Generative Adversarial Networks](https://github.com/pshams55/GAN-Case-Study)\n- [Generative Adversarial Networks](https://spectra.pub/ml/gans)\n- [Generative adversarial networks](https://deepgenerativemodels.github.io/notes/gan/ )\n- [Introduction to deep generative modeling: Generative Adversarial Networks (GANs)](https://jmtomczak.github.io/blog/12/12_gans.html)\n- [Generative adversarial networks for beginners](https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners)\n- [Intuitive explanation of GANs. Subtypes](https://tryolabs.com/blog/2016/12/06/major-advancements-deep-learning-2016/)\n- https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-1-Generative-Adversarial-Nets\n- http://www.openias.org/hybrid-generative-discriminative\n- http://edwardlib.org/tutorials/gan\n- [Play with GANs in your browser](https://poloclub.github.io/ganlab/)\n- [Do GANs actually do distribution learning?](http://www.offconvex.org/2017/07/06/GANs3/)\n- [The GAN Zoo - A list of all named GANs!](https://deephunt.in/the-gan-zoo-79597dc8c347)\n- [Advances in Generative Adversarial Networks](https://beyondminds.ai/advances-in-generative-adversarial-networks-gans/) ^advancesingans\n\t- Drawbacks of using GANs: Mode collapse, Convergence, Quality evaluation, Metrics\n\t- Techniques for Improving Performance:\n\t\t- Alternative Loss Functions: One of the most popular fixes to the shortcomings of GANs is the Wasserstein GAN. It essentially replaces the Jensen Shannon divergence of conventional GANs with the Earth Mover distance (Wasserstein-1 distance or EM distance)\n\t\t- Two Timescale Update Rule (TTUR): In this method, we use a different learning rate for the discriminator and the generator. Typically, a slower update rule is used for the generator and a faster update rule is used for the discriminator\n\t\t- Gradient Penalty: In the paper Wasserstein GAN GP, a simple gradient penalty was introduced which is added to the loss function to avoid exploding vanishing gradients and optimization issues (caused by weight clipping)\n\t\t- Spectral Normalization: weight normalization technique that is typically used on the Discriminator to enhance the training process\n\t\t- [Unrolling and Packing](http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/)\n\t\t- Stacking GANs: use multiple GANs placed consecutively, where each GAN solves an easier version of the problem.  For instance, FashionGAN used two GANs to perform localized image translation. Progressive GANs (ProGANs) can generate high quality images of excellent resolution.\n\t\t- Relativistic GANs: Conventional GANs measure the probability of the generated data being real. Relativistic GANs measure the probability of the generated data being ‚Äúmore realistic‚Äù than the real data. We can measure this ‚Äúrelative realism‚Äù using an appropriate distance measure, as mentioned in the RGAN paper\n\t\t- Self Attention Mechanism (SAGAN): The authors of Self Attention GANs claim that convolutions used for generating images look at information that are spread locally. That is, they miss out on relationships that span globally due to their restrictive receptive field. Self-Attention Generative Adversarial Network allows attention-driven, long-range dependency modeling for image generation tasks. \n\t\t- Miscellaneous Techniques: Feature Matching, Mini Batch Discrimination, Historical Averaging, One-sided Label Smoothing, Virtual Batch Normalization. \n\n## Courses\n- #COURSE [Generative Adversarial Networks ( DeepMind x UCL | Deep Learning Lectures | 9/12)](https://www.youtube.com/watch?v=wFsI2WqUfdA\u0026t=850s)\n\n\n## Talks\n- #TALK [GANs for Good - A Virtual Expert Panel by DeepLearning.AI](https://www.youtube.com/watch?v=9d4jmPmTWmc)\n- #TALK [A Friendly Introduction to Generative Adversarial Networks (GANs)](https://www.youtube.com/watch?v=8L11aMN5KY8)\n\n\n## Code\n- #CODE [Keras-GAN - Collection of Keras implementations of GANs](https://github.com/eriklindernoren/Keras-GAN)\n- #CODE [Pytorch-GAN - Collection of Pytorch implementations of GANs](https://github.com/eriklindernoren/PyTorch-GAN)\n- #CODE [Generative models in Tensorflow and Pytorch](https://github.com/wiseodd/generative-models)\n- #CODE [Tensorflow generative model collection](https://github.com/hwalsuklee/tensorflow-generative-model-collections)\n- #CODE [ydata-synthetic](https://github.com/ydataai/ydata-synthetic)\n\t- This repository contains material related with GANs for synthetic data generation, in particular regular tabular data and time-series\n\n\n## References\nReview papers:\n- #PAPER [A Survey on Generative Adversarial Networks: Variants, Applications,and Training (Jabbar 2020)](https://arxiv.org/abs/2006.05132)\n- #PAPER [A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications (Gui 2020)](https://arxiv.org/abs/2001.06937)\n\n- #PAPER [Generative Adversarial Networks (Goodfellow 2014)](http://arxiv.org/abs/1406.2661)\n\t- [Paper explained](https://www.youtube.com/watch?v=eyxmSmjmNS0)\n- #PAPER [GAN to convert text descriptions into images (Reed 2016)](https://arxiv.org/abs/1605.05396)\n- #PAPER [Unsupervised representation learning with GANs (Radford 2016)](https://arxiv.orga/abs/1511.06434v2)\n\t- Although GANs were already introduced in 2014 by Ian Goodfellow, it wasn't until the publication of this paper detailing a deep convolutional architecture (DCGAN) that GANs really took off \n\t- https://www.tensorflow.org/tutorials/generative/dcgan\n\t- https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8\n\t- #CODE https://github.com/tensorflow/models/blob/master/research/slim/nets/dcgan.py\n- #PAPER [Deconvolution and Checkerboard Artifacts (Odena 2016)](https://distill.pub/2016/deconv-checkerboard/)\n- #PAPER [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets (Chen 2016)](https://arxiv.org/abs/1606.03657)\n\t- https://wiseodd.github.io/techblog/2017/01/29/infogan/\n- #PAPER [Checkerboard artifact free sub-pixel convolution: A note on sub-pixel convolution, resize convolution and convolution resize (Aitken 2017)](https://arxiv.org/abs/1707.02937)\n- #PAPER [Wasserstein GAN (Arjovsky 2017)](https://arxiv.org/abs/1701.07875)\n\t- [From GAN to Wasserstein GAN](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html#wasserstein-gan-wgan )\n- #PAPER [Improved Training of Wasserstein GANs (Gulrajani 2017)](https://arxiv.org/abs/1704.00028) ^wgangp\n- #PAPER [Bayesian GAN (Saatchi 2017)](https://arxiv.org/abs/1705.09558)\n\t- #CODE https://github.com/andrewgordonwilson/bayesgan\n- #PAPER [WaterGAN: Unsupervised Generative Network to Enable Real-time Color Correction of Monocular Underwater Images (Li 2017)](https://arxiv.org/abs/1702.07392 )\n- #PAPER [A Style-Based Generator Architecture for Generative Adversarial Networks, StyleGAN (Karras 2018)](https://arxiv.org/abs/1812.04948 )\n\t- #TALK https://youtu.be/kSLJriaOumA \n\t- #CODE https://github.com/NVlabs/stylegan \n\t- [FFHQ](https://github.com/NVlabs/ffhq-dataset )\n- #PAPER [The relativistic discriminator: a key element missing from standard GAN (Jolicoeur-Martineau 2018)](https://arxiv.org/abs/1807.00734) ^190c58\n- #PAPER [From GAN to WGAN (Wenb 2019)](https://arxiv.org/abs/1904.08994)\n- #PAPER [Time Series Simulation by Conditional Generative Adversarial Net (Fu 2019)](https://arxiv.org/abs/1904.11419)\n- #PAPER [HoloGAN: Unsupervised learning of 3D representations from natural images (Nguyen-Phuoc 2019)](https://arxiv.org/abs/1904.01326 )\n\t- https://www.monkeyoverflow.com/#/hologan-unsupervised-learning-of-3d-representations-from-natural-images/ \n\t- #TALK https://www.youtube.com/watch?v=z2DnFOQNECM\n- #PAPER [Implicit competitive regularization in GANs (Schafer 2020)](https://arxiv.org/abs/1910.05852)\n- #PAPER [Training Generative Adversarial Networks with Limited Data (Karras 2020)](https://arxiv.org/abs/2006.06676)\n- #PAPER [Gradient-Guided Dynamic Efficient Adversarial Training (Waag 2021)](https://arxiv.org/abs/2103.03076)\n\t- #CODE https://github.com/locuslab/fast_adversarial\n\t- The goal of DEAT is to improve adversarial training while maintaining effectiveness. It begins by training one batch replay and gradually increases it during training\n\t- This method reduces large amount of computation when doing backpropagation and consequently achieves a more efficient training paradigm\n- #PAPER [ExGAN: Adversarial Generation of Extreme Samples (Bathia 2021)](https://arxiv.org/abs/2009.08454)\n\t- #CODE https://github.com/Stream-AD/ExGAN\n\t- Existing approaches based on GANs excel at generating realistic samples, but seek to generate typical samples, rather than extreme samples\n\t- ExGAN is a GAN-based approach to generate realistic and extreme samples. To model the extremes of the training distribution in a principled way, our work draws from Extreme Value Theory (EVT), a probabilistic approach for modelling the extreme tails of distributions\n\n\n## Subtopics\n\n### GANs for super-resolution\nSee \"GAN-based\" section in [Super-resolution](AI/Computer%20Vision/Super-resolution.md)\n\n\n### GANs for missing data, imputation and inpainting\nSee \"GAN-based\" section in [Inpainting](AI/Computer%20Vision/Inpainting.md)\n\n\n### Image-to-image translation. Conditional GANs\nSee \"GAN-based\" section in [Image-to-image translation](AI/Computer%20Vision/Image-to-image%20translation.md)\n\n\n### GANs for spatio-temporal data generation\n- #PAPER [COT-GAN: Generating Sequential Data via Causal Optimal Transport (Xu 2020)](https://arxiv.org/abs/2006.08571)\n- #PAPER [SPATE-GAN: Improved Generative Modeling of Dynamic Spatio-Temporal Patterns with an Autoregressive Embedding Loss (Klemmer 2021)](https://arxiv.org/abs/2109.15044#) ^spate-gan\n\t- #CODE https://github.com/konstantinklemmer/spate-gan\n\n\n### GANs for representation learning and image synthesis \n- #PAPER [Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks, Laplacian GAN (Denton 2015)](https://arxiv.org/abs/1506.05751)\n- #PAPER [Adversarial feature learning, BiGAN (Donahue 2017)](https://arxiv.org/abs/1605.09782)\n- #PAPER [Large Scale Adversarial Representation Learning, BigBiGAN (Donahue 2019)](https://arxiv.org/abs/1907.02544)\n- #PAPER [Large Scale GAN Training for High Fidelity Natural Image Synthesis, BigGAN (Brock 2019)](https://arxiv.org/abs/1809.11096)\n- #PAPER [Self-Attention GANs, SAGAN (Zhang 2019)](https://arxiv.org/abs/1805.08318) ^sagan\n\t- #CODE https://github.com/brain-research/self-attention-gan\n- #PAPER [In-domain GAN Inversion for Real Image Editing (Zhu 2020)](https://genforce.github.io/idinvert/)\n\t- [Paper explained](https://www.youtube.com/watch?v=2qMw8sOsNg0)\n- #PAPER [High-Fidelity Generative Image Compression (Mentzer 2020)](https://arxiv.org/abs/2006.09965)\n\t- https://hific.github.io/\n- #PAPER [Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications (Liu 2020)](https://arxiv.org/abs/2008.02793)\n- #PAPER [Image Synthesis with Adversarial Networks: a Comprehensive Survey and Case Studies (Shamsolmoali 2020)](https://arxiv.org/abs/2012.13736)\n- #PAPER [Cross-Modal Contrastive Learning for Text-to-Image Generation (Zhang 2021)](https://arxiv.org/abs/2101.04702)\n\t- https://ai.googleblog.com/2021/05/cross-modal-contrastive-learning-for.html\n\t- text-to-image generation by learning to maximize the mutual information between image and text using inter-modal (image-text) and intra-modal (image-image) contrastive losses\n- #PAPER [TriGAN: image-to-image translation for multi-source domain adaptation (Roy 2021)](https://link.springer.com/article/10.1007/s00138-020-01164-4)\n\t- approach for multi-source domain adaptation (MSDA) based on generative adversarial networks\n- #PAPER [Sketch Your Own GAN (Wang 2021)](https://arxiv.org/abs/2108.02774)\n- #PAPER [Instance-Conditioned GAN (Casanova 2021)](https://arxiv.org/abs/2109.05070)\n\t- #CODE https://paperswithcode.com/paper/instance-conditioned-gan?from=n17\n\n\n### Semi-supervised GANs\n- #PAPER [Improved Techniques for Training GANs (Saliman 2016)](https://arxiv.org/abs/1606.03498) ^improvedgans\n\t- https://towardsdatascience.com/semi-supervised-learning-with-gans-9f3cb128c5e\n\t- https://hjweide.github.io/semi-supervised-dcgan\n- #PAPER [Semi-Supervised Learning with Generative Adversarial Networks (Odena 2016)](https://arxiv.org/abs/1606.01583)\n\t- #CODE https://github.com/tryambak2019/SGAN\n- #PAPER [Semi and Weakly Supervised Semantic Segmentation Using Generative Adversarial Network (Suoly 2017)](https://arxiv.org/abs/1703.09695)\n- #PAPER [Semi-supervised Learning in Generative Adversarial Networks, review (2018)](https://farzadab.github.io/assets/projects/pdf/Review__SSL_in_GANs.pdf)\n    - The GAN framework can be integrated with almost any available neural network classifier in order to make use of unlabeled data\n\n\n### Few/one-shot learning GANs \nSee \"Few one-shot learning GANs\" section in [One, few-shot learning](AI/One,%20few-shot%20learning.md)\n\n\n### GANs for anomaly detection\n- #PAPER [A Survey on GANs for Anomaly Detection (Di Mattia 2019)](https://arxiv.org/abs/1906.11632 )\n- #PAPER [TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks (Geiger 2020)](https://arxiv.org/abs/2009.07769)\n\t- #CODE ^oriontfanomalies in [Anomaly and Outlier Detection](AI/Anomaly%20and%20Outlier%20Detection.md)\n\t- https://analyticsindiamag.com/hands-on-guide-to-tadgan-with-python-codes/","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/GFlowNets":{"title":"GFlowNets","content":"## Resources\n- [Generative Flow Networks (Bengio)](https://yoshuabengio.org/2022/03/05/generative-flow-networks/)\n\n## Talks\n- #TALK [GFlowNets for generative active learning | Amazon Science](https://www.youtube.com/watch?v=2s_GtmofbyU)\n- #TALK [Prof. YOSHUA BENGIO - GFlowNets, Consciousness \u0026 Causality (Podcast, discussion)](https://www.youtube.com/watch?v=M49TMqK5uCE)\n- #TALK [Confiance.ai Day 2021 - Yoshua Bengio, Director, Mila : GFlowNets for Generative Active Learning](https://www.youtube.com/watch?v=Ww9c9u_nTjQ)\n\n## References\n- #PAPER [Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation (Bengio 2021)](https://arxiv.org/abs/2106.04399)\n\t- #CODE https://github.com/GFNOrg/gflownet\n\t- http://folinoid.com/w/gflownet/\n- #PAPER [GFlowNet Foundations (Bengio 2021)](https://arxiv.org/abs/2111.09266)\n\t- Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function\n\t- https://syncedreview.com/2021/11/25/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-152/","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/GNNs":{"title":"Graph neural networks (GNNs)","content":"## Resources\n- Graph Neural networks (GNNs) are being widely adopted for diverse applications and domains. This is in part due to their effectiveness on complex data structures, improved performance and scalability, and availability of approaches\n- [A Gentle Introduction to Graph Neural Networks](https://distill.pub/2021/gnn-intro/)\n- [Must read papers on GNNs](https://github.com/thunlp/GNNPapers)\n- [Graph Neural Networks beyond Weisfeiler-Lehman and vanilla Message Passing](https://towardsdatascience.com/graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing-bc8605fa59a)\n- [Time Series Forecasting with Graph Convolutional Neural Network](https://towardsdatascience.com/time-series-forecasting-with-graph-convolutional-neural-network-7ffb3b70afcf)\n- https://medium.com/dair-ai/an-illustrated-guide-to-graph-neural-networks-d5564a551783\n\n## Talks\n- #TALK [Intro to graph neural networks (ML Tech Talks, Deepmind)](https://www.youtube.com/watch?v=8owQBFAHw7E)\n\n## Code\n- #CODE [TensorFlow GNN](https://github.com/tensorflow/gnn)\n\t- https://blog.tensorflow.org/2021/11/introducing-tensorflow-gnn.html\n\t- https://venturebeat.com/2021/11/18/google-releases-tf-gnn-for-creating-graph-neural-networks-in-tensorflow/\n- #CODE [DGL - Deep graph library](https://github.com/dmlc/dgl)\n\t- https://www.dgl.ai/\n- #CODE [Pytorch geometric](https://github.com/rusty1s/pytorch_geometric)\n- #CODE [Spektral - Graph Neural Networks with Keras and Tensorflow 2](https://github.com/danielegrattarola/spektral)\n- #CODE [Deep Graph Library (DGL)](https://github.com/dmlc/dgl) \n\t- http://dgl.ai\n\t- Python package built to ease deep learning on graph, on top of existing DL frameworks. \n\t- It makes implementing graph neural networks (including Graph Convolution Networks, TreeLSTM, and many others) easy while maintaining high computation efficiency.\n- #CODE [DIG: A Turnkey Library for Diving into Graph Deep Learning Research](https://github.com/divelab/DIG)\n- #CODE [PyTorch Geometric Temporal](https://github.com/benedekrozemberczki/pytorch_geometric_temporal)\n\t- A Temporal Extension Library for PyTorch Geometric\n- #CODE [PyNeuraLogic](https://github.com/LukasZahradnik/PyNeuraLogic)\n\t- https://pyneuralogic.readthedocs.io/\n\t- PyNeuraLogic lets you use Python to create Differentiable Logic Programs\n\t- https://towardsdatascience.com/beyond-graph-neural-networks-with-pyneuralogic-c1e6502c46f7\n\n## References\n- #PAPER [Structured Sequence Modeling with Graph Convolutional Recurrent Networks (Seo 2016)](https://arxiv.org/abs/1612.07659)\n\t- Graph Convolutional Recurrent Network (GCRN)\n- #PAPER [Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting (Yu 2018)](https://arxiv.org/abs/1709.04875 )\n- #PAPER [Dynamic Spatial-Temporal Graph Convolutional Neural Networks for Traffic Forecasting (Diao 2019)](https://www.aaai.org/ojs/index.php/AAAI/article/view/3877)\n- #PAPER [A Comprehensive Survey on Graph Neural Networks (Wu 2019)](https://arxiv.org/abs/1901.00596)\n- #PAPER [Graph Neural Networks: A Review of Methods and Applications (Zhou 2019)](https://arxiv.org/abs/1812.08434)\n- #PAPER [Graph Neural Networks for Decentralized Controllers (Gama 2020)](https://arxiv.org/abs/2003.10280 )\n- #PAPER [Learning to Simulate Complex Physics with Graph Networks (Sanchez-Gonzalez 2020)](https://arxiv.org/abs/2002.09405)\n\t- [Two minute papers](https://www.youtube.com/watch?v=2Bw5f4vYL98)\n- #PAPER [DeepSphere: a graph-based spherical CNN (Defferrard 2020)](https://arxiv.org/abs/2012.15000) ^deepsphere\n\t- #CODE https://github.com/deepsphere\n- #PAPER [VQ-GNN: A Universal Framework to Scale up Graph Neural Networks using Vector Quantization (Ding 2021)](https://arxiv.org/abs/2110.14363)\n- #PAPER [Nested Graph Neural Networks (Zhang 2021)](https://arxiv.org/abs/2110.13197)\n\t- #CODE https://paperswithcode.com/paper/nested-graph-neural-networks?from=n19\n- #PAPER [A Heterogeneous Graph Based Framework for Multimodal Neuroimaging Fusion Learning (Shi 2021)](https://arxiv.org/abs/2110.08465)\n\t- #CODE https://paperswithcode.com/paper/a-heterogeneous-graph-based-framework-for?from=n19","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/GRUs":{"title":"Gated Recurrent Units (GRUs)","content":"## Resources\n- GRUs are a gating mechanism in recurrent neural networks\n- https://en.wikipedia.org/wiki/Gated_recurrent_unit \n- https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be\n- GRU (Gated Recurrent Unit) aims to solve the vanishing gradient problem which comes with a standard recurrent neural network. GRU can also be considered as a variation on the LSTM. GRU‚Äôs got rid of the cell state and used the hidden state to transfer information. It also only has two gates, a reset gate and update gate. \n- The update gate acts similar to the forget and input gate of an LSTM. It decides what information to throw away and what new information to add.\n- The reset gate is another gate is used to decide how much past information to forget.\n\n## References\n- #PAPER [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation (Cho 2014)](https://arxiv.org/abs/1406.1078v3)\n- #PAPER [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches (Cho 2014)](https://arxiv.org/abs/1409.1259)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Generative-modelling":{"title":"Generative modeling","content":"## Resources\n- [Generative models](https://openai.com/blog/generative-models/ )\n- [Deep Generative Models](https://www.cs.toronto.edu/~slwang/generative_model.pdf)\n- [Taxonomy of Generative Models](https://christineai.blog/taxonomy/)\n- Jakub Tomczak [blog](https://jmtomczak.github.io/blog.html):\n\t- [Introduction to deep generative modeling: Why, Where and How](https://jmtomczak.github.io/blog/1/1_introduction.html)\n\t- [Introduction to deep generative modeling: Energy-based Models](https://jmtomczak.github.io/blog/11/11_energy_based_models.html)\n\n## Courses\n- #COURSE [Deep Generative Modeling: VAEs and GANs (MIT 6.S191)](https://www.youtube.com/watch?v=rZufA635dq4\u0026t=1062s)\n- #COURSE [Deep Generative Models (Stanford CS236 - Fall 2021)](https://deepgenerativemodels.github.io/)\n\n\n## Subtopics\n### Autoencoders\nSee \"VAEs\" section in [Autoencoders](AI/Deep%20learning/Autoencoders.md)\n\n### GANs\nSee [GANs](AI/Deep%20learning/GANs.md)\n\n### Normalizing flows\nSee [Normalizing flows](AI/Deep%20learning/Normalizing%20flows.md)\n\n### Diffusion models\nSee [Diffusion models](AI/Deep%20learning/Diffusion%20models.md)\n\n### Generative models for Image data\nSee:\n- [Image-to-image translation](AI/Computer%20Vision/Image-to-image%20translation.md)\n- \"GAN-based\" section in [Image-to-image translation](AI/Computer%20Vision/Image-to-image%20translation.md)\n- \"GANs for representation learning and image synthesis\" section in [GANs](AI/Deep%20learning/GANs.md)\n- \"For Computer Vision\" section in [Transformers](AI/Deep%20learning/Transformers.md)\n- [Diffusion models](AI/Deep%20learning/Diffusion%20models.md)\n\n- #PAPER [Video Pixel Networks (Kalchbrenner 2016)](https://arxiv.org/abs/1610.00527)\n- #PAPER [Pixel RNNs - Pixel Recurrent Neural Networks (van den Oord 2016)](https://arxiv.org/abs/1601.06759)\n\t- Pixel-RNN presents a novel architecture with recurrent layers and residual connections that predicts pixels across the vertical and horizontal axes. The architecture models the joint distribution of pixels as a product of conditional distributions of horizontal and diagonal pixels. The model achieves state-of-the-art in the generation of natural images.\n\t- https://medium.com/a-paper-a-day-will-have-you-screaming-hurray/day-4-pixel-recurrent-neural-networks-1b3201d8932d\n\t- https://christineai.blog/pixelcnn-and-pixelrnn/\n- #PAPER [Conditional Image Generation with PixelCNN Decoders (van den Oord 2016)](https://arxiv.org/abs/1606.05328)\n\t-  https://medium.com/a-paper-a-day-will-have-you-screaming-hurray/day-5-conditional-image-generation-with-pixelcnn-decoders-a8fc68b103a2\n\t-  #CODE https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/PixelCNN\n\t-  #CODE https://keras.io/examples/generative/pixelcnn/\n- #PAPER [PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications (Salimans 2017)](https://arxiv.org/abs/1701.05517)\n\t- #CODE https://github.com/openai/pixel-cnn\n\t- https://openreview.net/forum?id=BJrFC6ceg\u0026noteId=Bkc_sOZ4l\n- #PAPER [FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models (Grathwohl 2018)](https://arxiv.org/abs/1810.01367 )\n- #PAPER [Generating Realistic Geology Conditioned on Physical Measurements with Generative Adversarial Networks (Dupont 2018)](http://arxiv.org/abs/1802.03065) ^dupont18\n\t- Using G and D we want to generate realistic images conditioned on a set of known pixels\n\t- Total loss is a combination of a Prior loss (high score of generated images from D) and a Contexet loss (generated image should match the known pxs)\n\t- For the Context loss, a mask is used with smoothing\n- #PAPER [Parametric generation of conditional geological realizations using generative neural networks (Chan 2019)](https://link.springer.com/article/10.1007%2Fs10596-019-09850-7) ^chan19\n- #PAPER [Parametrization of Stochastic Inputs Using Generative Adversarial Networks With Application in Geology (Chan 2020)](https://www.frontiersin.org/articles/10.3389/frwa.2020.00005/full) ^chan20\n- #PAPER [Generative Models as Distributions of Functions (Dupont 2021)](https://arxiv.org/abs/2102.04776)\n\t- Generative models are typically trained on grid-like data such as images (tied to the underlying grid resolution)\n\t- Instead of discretized grids, they parametrized individual data points by continuous functions over which they learned distributions --\u003e generative models\n\t- Coordinate and feature pairs are treated as point clouds (sets with underlying notion of distance). Leveraged the PointConv framekwork \n\t- Their model can learn rich distributions of functions independently of data type and resolution. Application to [Super-resolution](AI/Computer%20Vision/Super-resolution.md)\n- #PAPER [Score-Based Generative Modeling through Stochastic Differential Equations (Song 2021)](https://arxiv.org/abs/2011.13456v2)\n\t- #CODE https://paperswithcode.com/paper/score-based-generative-modeling-through-1\n- #PAPER [Diverse Generation from a Single Video Made Possible (Haim 2021)](https://arxiv.org/abs/2109.08591)\n- #PAPER [Autoregressive Image Generation using Residual Quantization (Lee 2022)](https://arxiv.org/pdf/2203.01941v2)            \n\t- #CODE https://github.com/kakaobrain/rq-vae-transformer","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Geometric-deep-learning":{"title":"Geometric deep learning","content":"## Talks and courses\n- #TALK [Geometric Deep Learning: The Erlangen Programme of ML (M Bronstein, ICLR 2021 Keynote)](https://www.youtube.com/watch?v=w6Pw4MOzMuo)\n- #COURSE [Geometric Deep Learning](https://geometricdeeplearning.com/lectures/)\n\n## References\nReview papers:\n- #PAPER [Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges (Bronstein 2021)](https://arxiv.org/abs/2104.13478)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/LSTMs":{"title":"Long Short-Term Memory networks (LSTMs)","content":"## Resources\n- https://en.wikipedia.org/wiki/Long_short-term_memory\n- One of the most innovative works in the NLP space is LSTMs and their variations e.g. GRU \n- With a basic RNN cell, we see a massive drop in performance when it comes to long sequences and the network needs to remember patterns which have occurred way at the beginning to infer things correctly at a current time step. And this is because of exploding and vanishing gradients.\n- Then came Sepp Hochreiter and J√ºrgen Schmidhuber and invented LSTMs, which can remember information from the way past and also selectively forget stuff that is not required.\n- There are several architectures of LSTM units. A common architecture is composed of a cell (the memory part of the LSTM unit) and three \"regulators\", usually called gates, of the flow of information inside the LSTM unit: an input gate, an output gate and a forget gate. Some variations of the LSTM unit do not have one or more of these gates or maybe have other gates (for instance, GRUs do not have an output gate).\n- The Forget gate decides what is relevant to keep from prior steps. The input gate decides what information is relevant to add from the current step. The output gate determines what the next hidden state should be.\n- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n- http://machinelearningmastery.com/tune-lstm-hyperparameters-keras-time-series-forecasting/\n- http://machinelearningmastery.com/use-features-lstm-networks-time-series-forecasting/\n- http://blog.echen.me/2017/05/30/exploring-lstms/\n- https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4\n- https://rubikscode.net/2018/03/19/understanding-long-short-term-memory-networks-lstms/\n- https://eli.thegreenplace.net/2018/minimal-character-based-lstm-implementation/\n\n\n## References\n- #PAPER [Long Short-Term Memory (Hochreiter 1997)](https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735)\n- #PAPER [IndyLSTMs: Independently Recurrent LSTMs (Gonnet 2019)](https://arxiv.org/abs/1903.08023)\n\t- Independently Recurrent Long Short-term Memory cells (IndyLSTMs) differ from regular LSTM cells in that the recurrent weights are not modeled as a full matrix, but as a diagonal matrix, i.e.\\ the output and state of each LSTM cell depends on the inputs and its own output/state, as opposed to the input and the outputs/states of all the cells in the layer. The number of parameters per IndyLSTM layer, and thus the number of FLOPS per evaluation, is linear in the number of nodes in the layer, as opposed to quadratic for regular LSTM layers, resulting in potentially both smaller and faster models. IndyLSTMs, despite their smaller size, consistently outperform regular LSTMs both in terms of accuracy per parameter, and in best accuracy overall. We attribute this improved performance to the IndyLSTMs being less prone to overfitting.\n- #PAPER [Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks (Staudemeyer 2019)](https://arxiv.org/abs/1909.09586)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/MLPs":{"title":"Multilayer perceptrons (MLPs)","content":"## Resources\n- A multilayer perceptron (MLP) is a feed forward artificial neural network model that maps sets of input data onto a set of appropriate outputs. An MLP consists of multiple layers of nodes in a directed graph, with each layer fully connected to the next one. Except for the input nodes, each node is a neuron (or processing element) with a non linear activation function. \n- MLP utilizes a supervised learning technique called back propagation for training the network\n- MLP is a modification of the standard linear perceptron and can distinguish data that is not linearly separable\n- [Multilayer Perceptron (MLP) vs Convolutional Neural Network in Deep Learning](https://medium.com/data-science-bootcamp/multilayer-perceptron-mlp-vs-convolutional-neural-network-in-deep-learning-c890f487a8f1)\n\n## Code\n- #CODE [MLP for MNIST](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py)\n- #CODE Sklearn MLP implementation: \n\t- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n\t- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\n\n\n## Perceptron\n- [History of the Perceptron](https://medium.com/@Jaconda/a-concise-history-of-neural-networks-2070655d3fec)\n- https://www.neuraldesigner.com/blog/perceptron-the-main-component-of-neural-networks\n- https://fr.mathworks.com/help/nnet/ug/perceptron-neural-networks.html\n- http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/\n- http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html\n\n\n## MLPs for vision and language\n- #PAPER [MLP-Mixer: An all-MLP Architecture for Vision (Tolstikhin 2021)](https://arxiv.org/abs/2105.01601v2)\n\t- #CODE https://paperswithcode.com/paper/mlp-mixer-an-all-mlp-architecture-for-vision?from=n9\n\t- CNNs are widely regarded as the go-to model for dealing with computer vision tasks. Attention-based architectures have also emerged as promising approaches that produce good performance on a variety of vision tasks. Despite this trend and the successes of attention and CNN architectures, this paper proposes a simple alternative architecture, MLP-Mixer, based on multi-layer perceptions, that produces competitive results on image classification benchmarks\n\t- MLP-Mixer contains two types of layers. One layer of MLPs applied independently to image patches and another layer of MLPs applied across patches. These layers achieve the effect of mixing per-location features and mixing spatial information, respectively \n\t- MLP-Mixer achieves competitive results on the ImageNet benchmark\n- #PAPER [RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition (Ding 2021)](https://arxiv.org/abs/2105.01883v1)\n\t- #CODE https://github.com/DingXiaoH/RepMLP\n- #PAPER [ResMLP: Feedforward networks for image classification with data-efficient training (Touvron 2021)](https://arxiv.org/abs/2105.03404)\n- #PAPER [Pay Attention to MLPs (Liu 2021)](https://arxiv.org/abs/2105.08050v2)\n\t- #CODE https://paperswithcode.com/paper/pay-attention-to-mlps?from=n10\n\t- https://www.infoq.com/news/2021/10/google-mlp-vision-language/\n\t- Researchers at Google Brain have announced Gated Multi-Layer Perceptron (gMLP), a deep-learning model that contains only basic multi-layer perceptrons\n\t- gMLP aims to show that these simplified architectures can perform as well as Transformers on key vision and language applications. According to the authors, the results and comparisons show that attention is not critical for Vision Transformers\n\t- In fine-tuning tasks, gMLP can close the gap on Transformers by simply making the model substantially larger\n\t- gMLP can scale as well as Transformers over increased data and compute\n- #PAPER [MAXIM: Multi-Axis MLP for Image Processing (Tu 2022)](https://arxiv.org/abs/2201.02973v1)\n\t- #CODE https://paperswithcode.com/paper/maxim-multi-axis-mlp-for-image-processing?from=n23","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Multimodal-learning":{"title":"Multimodal learning","content":"## Resources\n- General-purpose neural networks capable of handling diverse inputs and output tasks\n- [Multimodal Deep Learning](https://multimodal-dl.mpi-inf.mpg.de/)\n- https://paperswithcode.com/methods/category/vision-and-language-pre-trained-models\n- [Vision Language models: towards multi-modal deep learning](https://theaisummer.com/vision-language-models/)\n\n## Code\n- #CODE [Pykale (in pytorch)](https://github.com/pykale/pykale)\n\n\n## References\nReview papers:\n- #PAPER [Recent Advances and Trends in Multimodal Deep Learning: A Review (Summaira 2021)](https://arxiv.org/abs/2105.11087)\n\n- #PAPER [Multi-modal Transformer for Video Retrieval (Gabeur 2020)](https://arxiv.org/abs/2007.10639)\n- #PAPER [Perceiver: General Perception with Iterative Attention (Jaegle 2021)](https://arxiv.org/abs/2103.03206)\n\t- https://www.zdnet.com/article/googles-supermodel-deepmind-perceiver-is-a-step-on-the-road-to-an-ai-machine-that-could-process-everything/\n\t- Multi-model with image, audio, video, 3d point clouds\n- #PAPER [PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python (Lu 2021)](https://arxiv.org/abs/2106.09756v1) ^pykale\n- #PAPER [Perceiver IO: A General Architecture for Structured Inputs \u0026 Outputs (Jaegle 2021)](https://arxiv.org/abs/2107.14795v2)\n\t- #CODE https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for\n- #PAPER [VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text (Akbari 2021)](https://arxiv.org/abs/2104.11178v2)\n\t- #CODE https://paperswithcode.com/paper/vatt-transformers-for-multimodal-self\n\t- VATT is trained to learn multimodal representations from unlabeled data using Transformer architectures\n- #PAPER [N√úWA: Visual Synthesis Pre-training for Neural visUal World creAtion (Wu 2021)](https://arxiv.org/abs/2111.12417v1)\n\t- #CODE https://paperswithcode.com/paper/nuwa-visual-synthesis-pre-training-for-neural\n\t- [Paper explained](https://www.youtube.com/watch?v=InhMx1h0N40\u0026list=WL\u0026index=50)\n\t- N√úWA¬†consists of an adaptive encoder that takes either text or visual input, and a pre-trained decoder shared by 8 visual tasks\n\t- 3D Nearby Attention mechanism (3DNA) is proposed to reduce computational complexity and improve visual quality of results, by considering the locality characteristics for both spatial and temporal axes to better deal with the nature of the visual data\n- #PAPER [data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language (Baevski 2022)](https://arxiv.org/abs/2202.03555)\n\t- #CODE https://github.com/pytorch/fairseq/tree/main/examples/data2vec\n\t- https://ai.facebook.com/blog/the-first-high-performance-self-supervised-algorithm-that-works-for-speech-vision-and-text/\n\n### Vision and language models\nReview papers:\n- #PAPER [A Survey of Vision-Language Pre-Trained Models (Du 2022)](https://arxiv.org/pdf/2202.10936)            \n\n- #PAPER [DALL-E - Creating Images from Text (Ramesh 2021)](https://openai.com/blog/dall-e/) ^dall-e\n\t- https://www.technologyreview.com/2021/01/05/1015754/avocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense/\n\t- [Blogpost explained](https://www.youtube.com/watch?v=j4xgkjWlfL4)\n\t- #CODE https://github.com/EleutherAI/DALLE-mtf\n\t- Multi-modal text and speech\n\t- [DALL-E mini](https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA)\n- #PAPER [Learning Transferable Visual Models From Natural Language Supervision (Radford 2021)](https://arxiv.org/pdf/2103.00020v1)            \n\t- #CODE https://paperswithcode.com/paper/learning-transferable-visual-models-from#code\n\t- #CODE https://github.com/openai/CLIP\n- #PAPER [SimVLM: Simple Visual Language Model Pretraining with Weak Supervision (Wang 2022)](https://arxiv.org/pdf/2108.10904v2)            \n- #PAPER [Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework (Wang 2022)](https://arxiv.org/pdf/2202.03052v1)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Neural-Cellular-Automata":{"title":"Neural Cellular Automata","content":"## References\n- #PAPER [Growing Neural Cellular Automata (Mordvintsev 2020)](https://distill.pub/2020/growing-ca/)\n\t- [Paper explained](https://www.youtube.com/watch?v=9Kec_7WFyp0)\n\t- #CODE https://github.com/chenmingxiang110/Growing-Neural-Cellular-Automata\n- #PAPER [Self-Organising Textures (Niklasson 2021)](https://distill.pub/selforg/2021/textures/)\n- #PAPER [Variational Neural Cellular Automata](https://arxiv.org/pdf/2201.12360)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Neural-ODEs":{"title":"Neural Ordinary Differential Equations","content":"## Resources\n- https://github.com/Zymrael/awesome-neural-ode\n- [Understanding Neural ODE's](https://jontysinai.github.io/jekyll/update/2019/01/18/understanding-neural-odes.html)\n- [Neural Ordinary Differential Equations and Dynamics Models](https://medium.com/@ml.at.berkeley/neural-ordinary-differential-equations-and-dynamics-models-1a4277fbb80)\n\t- ODEs are often used to describe the time derivatives of a physical situation, referred to as the dynamics. Knowing the dynamics allows us to model the change of an environment, like a physics simulation, unlocking the ability to take any starting condition and model how it will change. With Neural ODEs, we don‚Äôt define explicit ODEs to document the dynamics, but learn them via ML.\n\t- Strong connection with [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md). Why do residual layers help networks achieve higher accuracies and grow deeper? Firstly, skip connections help information flow through the network by sending the hidden state, h(t), along with the transformation by the layer, f(h(t)), to layer t+1, preventing important information from being discarded by f. Secondly, residual layers can be stacked, forming very deep networks.\n\t- However, ResNets still employ many layers of weights and biases requiring much time and data to train. On top of this, the backpropagation algorithm on such a deep network incurs a high memory cost to store intermediate values.\n\t- Continuous depth ODENets are evaluated using black box ODE solvers, but first the parameters of the model must be optimized via gradient descent. To do this, we need to know the gradient of the loss with respect to the parameters, or how the loss function depends on the parameters in the ODENet.\n\t- In deep learning, backpropagation is the workhorse for finding this gradient, but this algorithm incurs a high memory costs to store the intermediate values of the network. On top of this, the sheer number of chain rule applications produces numerical error. Since an ODENet models a differential equation, these issues can be circumvented using sensitivity analysis methods developed for calculating gradients of a loss function with respect to the parameters of the system producing its input.\n\n\n## References\n- #PAPER [Neural Ordinary Differential Equations (TQ Chen 2018)](https://arxiv.org/abs/1806.07366)\n\t- #CODE https://github.com/JSeam2/Neural-Ordinary-Differential-Equations\n\t- #CODE https://github.com/jason71995/Keras_ODENet\n\t- [Neural Ordinary Differential Equations - Best Paper Awards NeurIPS 2018](https://www.youtube.com/watch?v=V6nGT0Gakyg)\n\t- https://towardsdatascience.com/paper-summary-neural-ordinary-differential-equations-37c4e52df128\n\t- https://braindump.jethro.dev/posts/neural_ode/\n\t- https://msurtsukov.github.io/Neural-ODE/\n\t- https://github.com/msurtsukov/neural-ode/blob/master/Neural%20ODEs.ipynb\n\t- https://www.youtube.com/watch?v=jltgNGt8Lpg\n- #PAPER [Augmented Neural ODEs (Dupont 2019)](https://arxiv.org/abs/1904.01681)\n- #PAPER [Differential Bayesian Neural Nets (Look 2020)](https://arxiv.org/abs/1912.00796)\n\t- Neural Ordinary Differential Equations (N-ODEs) are a powerful building block for learning systems, which extend residual networks to a continuous-time dynamical system. Propose a Bayesian version of N-ODEs that enables well-calibrated quantification of prediction uncertainty, while maintaining the expressive power of their deterministic counterpart.\n- #THESIS/MSC [Generative Modeling with Neural Ordinary Differential Equations (2019)](https://uwspace.uwaterloo.ca/bitstream/handle/10012/15354/Dockhorn_Tim.pdf)\n- #PAPER [Universal Differential Equations for Scientific Machine Learning (Rackauckas 2020)](https://arxiv.org/abs/2001.04385)\n\t- https://www.stochasticlifestyle.com/how-to-train-interpretable-neural-networks-that-accurately-extrapolate-from-small-data/\n- #PAPER [Neural Differential Equations for Single Image Super-Resolution (Le Scao 2020)](https://arxiv.org/pdf/2005.00865)\n- #PAPER [Liquid Time-constant Networks (Hasani 2020)](https://arxiv.org/abs/2006.04439)\n\t- #TALK https://www.youtube.com/watch?v=IlliqYiRhMU\n\t- #CODE https://github.com/raminmh/liquid_time_constant_networks\n\t- https://news.mit.edu/2021/machine-learning-adapts-0128\n- #PAPER [On Neural Differential Equations (Kidger 2022)](https://arxiv.org/abs/2202.02435)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Normalizing-flows":{"title":"Normalizing flows","content":"## Resources\n- Normalizing flow models are generative models, i.e. they infer the underlying probability distribution of an observed dataset. With that distribution we can do a number of interesting things, namely sample new realistic points and query probability densities.\n- https://github.com/janosh/awesome-normalizing-flows\n- [Flow-based Deep Generative Models](https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html)\n- [Normalizing flow models](https://deepgenerativemodels.github.io/notes/flow/)\n- http://akosiorek.github.io/ml/2018/04/03/norm_flows.html \n\n\n## Talks\n- #TALK [Introduction to Normalizing Flows (ECCV2020 Tutorial)](https://www.youtube.com/watch?v=u3vVyFVU_lI)\n\n\n## Code\n- #CODE [Normalizing Flows in JAX](https://github.com/ChrisWaites/jax-flows)\n- #CODE [NuX - Normalizing Flows using JAX](https://github.com/Information-Fusion-Lab-Umass/NuX)\n\n\n## References\nReview papers:\n- #PAPER [Normalizing Flows: An Introduction and Review of Current Methods (Kobyzev 2020)](https://arxiv.org/abs/1908.09257)\n\n- #PAPER [NICE: Non-linear Independent Components Estimation (Dinh 2015)](https://arxiv.org/abs/1410.8516)\n- #PAPER [Glow: Generative Flow with Invertible 1x1 Convolutions (Kingma 2018)](https://arxiv.org/abs/1807.03039)\n\t- https://openai.com/blog/glow/\n\t- #CODE https://github.com/openai/glow\n\n\n### Image-to-image translation\nSee \"Flow-based\" section in [Image-to-image translation](AI/Computer%20Vision/Image-to-image%20translation.md)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Probabilistic-deep-learning":{"title":"Probabilistic deep learning","content":"See:\n- [Bayesian modelling](AI/Bayesian%20modelling.md)\n- [GFlowNets](AI/Deep%20learning/GFlowNets.md)\n\n\n## Resources\n- [A Comprehensive Introduction to Bayesian Deep Learning](https://jorisbaan.nl/2021/03/02/introduction-to-bayesian-deep-learning.html)\n- [Bayesian Neural Network tutorial](http://edwardlib.org/tutorials/bayesian-neural-network)\n- [Bayesian Deep Learning - NeurIPS Workshop](http://bayesiandeeplearning.org/ )\n- [Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe AI](https://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai/)\n- [Making Your Neural Network Say ‚ÄúI Don‚Äôt Know‚Äù‚Ää‚Äî‚ÄäBayesian NNs using Pyro and PyTorch](https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd)\n- [Building a Bayesian deep learning classifier](https://towardsdatascience.com/building-a-bayesian-deep-learning-classifier-ece1845bc09)\n- [Physics - a Gateway to Bayesian Deep Learning](https://github.com/henripal/sgld)\n- [Bayesian deep learning with Fastai : how not to be uncertain about your uncertainty!](https://towardsdatascience.com/bayesian-deep-learning-with-fastai-how-not-to-be-uncertain-about-your-uncertainty-6a99d1aa686e)\n\t- BNNs are a way to add uncertainty handling in our models. The idea is simple, instead of having deterministic weights that we learn, we instead learn the parameters of a random variable which we will use to sample our weights during forward propagation. Then, to learn the parameters, we will use backpropagation, sometimes with a little trick to make our parameters differentiable.\n\t- Dropout is a way to make your Neural Networks Bayesian almost for free, and to use it during inference you just have to keep the Dropout, and sample several models, this is called MC Dropout.\n\n ### Monte Carlo Dropout\n- [What is MC Dropout](https://datascience.stackexchange.com/questions/44065/what-is-monte-carlo-dropout)\n- normal dropout (only at training time) serves as a regularization to avoid overfitting. During test time, dropout is not applied; instead, all nodes/connections are present, but the weights are adjusted accordingly (e.g. multiplied by the keep ratio, which is 1 - dropout_ratio). Such a model during test time can be understood as a *average* of an ensemble of neural networks.\n- Notice that for normal dropout, at test time the prediction is *deterministic*. Without other source of randomness, given one test data point, the model will always predict the same label or value.\n- For *Monte Carlo dropout*, the dropout is applied at both training and test time. At test time, the prediction is no longer deterministic, but depending on which nodes/links you randomly choose to keep. Therefore, given a same datapoint, your model could predict different values each time.\n- The primary goal of MC dropout is to generate random predictions and interpret them as samples from a probabilistic distribution. \n- #TALK [Estimacion de la Incertidumbre en Redes Neuronales (Valdenegro)](https://mvaldenegro.github.io/files/DSRP-meetup-NeurIPS-2020-incertidumbre-redes-neuronales.pdf)\n\n\n## Code\n- #CODE [Pyro (Uber) - Deep universal probabilistic programming with Python and PyTorch](https://github.com/uber/pyro  )\n\t- http://pyro.ai\n\t- http://eng.uber.com/pyro\n- #CODE [Blitz - Bayesian Layers in Torch Zoo](https://github.com/piEsposito/blitz-bayesian-deep-learning)\n- #CODE [Bean machine (Meta/Facebook)](https://github.com/facebookresearch/beanmachine)\n\t- https://research.facebook.com/blog/2021/12/introducing-bean-machine-a-probabilistic-programming-platform-built-on-pytorch/\n- #CODE Edwardlib - Edward is a Python library for probabilistic modeling, inference, and criticism\n\t- https://theintelligenceofinformation.wordpress.com/2017/06/02/pydata-london-2017-bayesian-deep-learning-talk-by-andrew-rowan/\n\t- #TALK https://www.youtube.com/watch?v=I09QVNrUS3Q\n\t- http://willwolf.io/2017/06/15/random-effects-neural-networks/\n- #CODE [TensorFlow Probability](https://www.tensorflow.org/probability/)\n\t- https://towardsdatascience.com/bayesian-neural-networks-with-tensorflow-probability-fbce27d6ef6\n- #CODE [keras-uncertainty](https://github.com/mvaldenegro/keras-uncertainty)\n\t- Monte Carlo Dropout (MC-Dropout)\n\t- Deep Ensembles\n\n## Books\n- #BOOK [Probabilistic Graphical Models: Principles and Techniques (Koller, 2009 MIT)](http://pgm.stanford.edu/ )\n- #BOOK [Probabilistic Deep Learning - With Python, Keras and TensorFlow Probability (Durr, MANNING 2020)](https://www.manning.com/books/probabilistic-deep-learning)\n\t- https://tensorchiefs.github.io/dl_book/\n\n## Courses\n- #COURSE [Introductory course on probabilistic graphical models](https://ermongroup.github.io/cs228-notes/)\n\n## References\n- Review papers: \n\t- #PAPER [A Survey of Uncertainty in Deep Neural Networks (Gawlikowski 2022)](https://arxiv.org/abs/2107.03342)\n\n- #PAPER [Probabilistic machine learning and artificial intelligence (Ghahramani 2015)](https://www.nature.com/articles/nature14541)\n- #PAPER [Dropout as a Bayesian Approximation:Representing Model Uncertainty in Deep Learning (Gal 2016)](https://arxiv.org/abs/1506.02142)\n- #PAPER [Bayesian Neural Networks (Mullachery, 2018)](https://arxiv.org/abs/1801.07710)\n- #PAPER [Deep Sub-Ensembles for Fast Uncertainty Estimation in Image Classification (Valdenegro-Toro 2019)](https://arxiv.org/abs/1910.08168)\n- #PAPER [Bayesian Recurrent Neural Networks (Fortunato 2019)](https://arxiv.org/abs/1704.02798)\n- #PAPER [Bayesian Deep Learning and a Probabilistic Perspective of Generalization (Gordon Wilson, 2020)](https://arxiv.org/abs/2002.08791)\n\t- https://github.com/izmailovpavel/understandingbdl\n- #PAPER [Hands-on Bayesian Neural Networks - a Tutorial for Deep Learning Users (Jospin 2020)](https://arxiv.org/abs/2007.06823)\n- #PAPER [DropConnect is effective in modeling uncertainty of Bayesian deep networks (Mobiny 2021)](https://www.nature.com/articles/s41598-021-84854-x)\n\t- #CODE https://github.com/hula-ai/mc_dropconnect\n- #PAPER [Epistemic Neural Networks (Osband 2021)](https://arxiv.org/abs/2107.08924)\n\t- #CODE https://github.com/deepmind/enn\n\t- https://syncedreview.com/2021/07/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-69/\n- #PAPER [Uncertainty Baselines: Benchmarks for Uncertainty \u0026 Robustness in Deep Learning (Nado 2021)](https://arxiv.org/abs/2106.04015)\n\t- https://ai.googleblog.com/2021/10/baselines-for-uncertainty-and.html\n\t- #CODE https://github.com/google/uncertainty-baselines\n- #PAPER [Probabilistic Deep Learning with Probabilistic Neural Networks and Deep Probabilistic Models](https://arxiv.org/pdf/2106.00120)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/RNNs":{"title":"Recurrent Neural Networks (RNNs)","content":"See:\n[LSTMs](AI/Deep%20learning/LSTMs.md)\n[GRUs](AI/Deep%20learning/GRUs.md)\n[Reservoir computing](AI/Deep%20learning/Reservoir%20computing.md)\n[Transformers](AI/Deep%20learning/Transformers.md)\n\n## Resources\n- https://en.wikipedia.org/wiki/Recurrent_neural_network\n- https://github.com/kjw0612/awesome-rnn\n- [Recurrent Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)\n- [Tensorflow, DL and RNNs without a PhD](https://docs.google.com/presentation/d/e/2PACX-1vRouwj_3cYsmLrNNI3Uq5gv5-hYp_QFdeoan2GlxKgIZRSejozruAbVV0IMXBoPsINB7Jw92vJo2EAM/pub?slide=id.p)\n- http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html\n- http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n- https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0\n- https://www.kaggle.com/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru\n- https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n- [4 Sequence Encoding Blocks You Must Know Besides RNN/LSTM in Tensorflow](https://hanxiao.github.io/2018/06/24/4-Encoding-Blocks-You-Need-to-Know-Besides-LSTM-RNN-in-Tensorflow/)\n- [When Recurrent Models Don't Need to be Recurrent (recurrent vs feed-forward models)](http://www.offconvex.org/2018/07/27/approximating-recurrent/)\n- [Deep Learning: No, LSTMs Are Not Dead!](https://towardsdatascience.com/deep-learning-no-lstms-are-not-dead-20217553b87a)\n\n## References\n- #PAPER [Neural Turing Machines (Graves 2014)](http://arxiv.org/abs/1410.5401)\n- #PAPER [Attention and Augmented Recurrent Neural Networks (Olah 2016)](http://distill.pub/2016/augmented-rnns/)\n- #PAPER [Engineering Extreme Event Forecasting at Uber with Recurrent Neural Networks (Laptev 2017)](https://eng.uber.com/neural-networks/)\n- #PAPER [Deep and Confident Prediction for Time Series at Uber (Zhu 2017)](https://arxiv.org/abs/1709.01907)\n\t- https://eng.uber.com/neural-networks-uncertainty-estimation/ \n\t- introduced a new end-to-end Bayesian neural network (BNN) architecture that more accurately forecasts time series predictions and uncertainty estimations at scale\n- #PAPER [Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau 2016)](https://arxiv.org/abs/1409.0473)\n\t- https://medium.com/datadriveninvestor/attention-in-rnns-321fbcd64f05\n- #PAPER [DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks (Salinas 2019)](https://arxiv.org/abs/1704.04110)            \n\n### LSTMs\nSee [LSTMs](AI/Deep%20learning/LSTMs.md)\n\n### GRUs\nSee [GRUs](AI/Deep%20learning/GRUs.md)\n\n### Reservoir computing\nSee [Reservoir computing](AI/Deep%20learning/Reservoir%20computing.md)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Reservoir-computing":{"title":"Reservoir computing","content":"## Resources\n- Reservoir computing is a framework for computation derived from recurrent neural network theory that maps input signals into higher dimensional computational spaces through the dynamics of a fixed, non-linear system called a reservoir. After the input signal is fed into the reservoir, which is treated as a \"black box,\" a simple readout mechanism is trained to read the state of the reservoir and map it to the desired output.\n- https://en.wikipedia.org/wiki/Reservoir_computing\n\n#### Echo state networks (ESN)\n- https://en.wikipedia.org/wiki/Echo_state_network\n- The ESN is a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity)\n\n\n## References\n- #PAPER [Next generation reservoir computing (Gauthier 2021)](https://www.nature.com/articles/s41467-021-25801-2)\n\n#### Echo state networks (ESN)\n- https://en.wikipedia.org/wiki/Echo_state_network\n- The ESN is a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity)\n\n- #PAPER [Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication (Jaeger 2004)](https://pubmed.ncbi.nlm.nih.gov/15064413/)\n\t- #CODE https://github.com/cknd/pyESN\n- #PAPER [Design of deep echo state networks (Gallicchio 2018)](https://www.sciencedirect.com/science/article/pii/S0893608018302223)\n\t- #CODE https://github.com/lucapedrelli/DeepESN\n- #PAPER [Using Machine Learning to Replicate Chaotic Attractors and Calculate Lyapunov Exponents from Data (Pathak 2017)](https://arxiv.org/abs/1710.07313)\n- #PAPER [Model-Free Prediction of Large Spatiotemporally Chaotic Systems from Data: A Reservoir Computing Approach (Pathak 2018)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.024102)\n- #PAPER [Wind Power Forecasting Based on Echo State Networks and Long Short-Term Memory (Lopez 2018)](https://www.mdpi.com/1996-1073/11/3/526/htm)\n\t- ESN + LSTM\n- #PAPER [Comparison between DeepESNs and gatedRNNs on multivariate time-series prediction (Gallicchio 2019)](https://arxiv.org/abs/1812.11527)\n- #PAPER [Deep Echo State Network (DeepESN): A Brief Survey (Gallicchio 2020)](https://arxiv.org/abs/1812.11527\t)\n- #PAPER [Comparison of Recurrent Neural Networks for Wind Power Forecasting (Lopez 2020)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7297597/#CR12)\n\t- ESN + LSTM","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Residual-and-dense-neural-networks":{"title":"Residual and dense neural networks","content":"## Resources\n- https://en.wikipedia.org/wiki/Residual_neural_network\n- [Training and investigating Residual Nets](http://torch.ch/blog/2016/02/04/resnets.html)\n\n\n## References\n- #PAPER [Deep Residual Learning for Image Recognition, Resnet-50 (He 2015)](http://arxiv.org/abs/1512.03385) ^resnet\n\t- #CODE https://github.com/raghakot/keras-resnet\n\t- https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\n\t- [Explained paper](https://www.youtube.com/watch?v=GWt6Fu05voI)\n\t- Deep convolutional neural networks have led to a series of breakthroughs for image classification. Many other visual recognition tasks have also greatly benefited from very deep models. So, over the years there is a trend to go more deeper, to solve more complex tasks and to also increase /improve the classification/recognition accuracy. But, as we go deeper; the training of neural network becomes difficult and also the accuracy starts saturating and then degrades also. Residual Learning tries to solve both these problems.\n\t- What is Residual Learning?\n\t\t- In general, in a deep convolutional neural network, several layers are stacked and are trained to the task at hand. The network learns several low/mid/high level features at the end of its layers. In residual learning, instead of trying to learn some features, we try to learn some residual. Residual can be simply understood as subtraction of feature learned from input of that layer. ResNet does this using shortcut connections (directly connecting input of nth layer to some (n+x)th layer. It has proved that training this form of networks is easier than training simple deep convolutional neural networks and also the problem of degrading accuracy is resolved.\n\t\t- The architecture is similar to the VGGNet consisting mostly of 3X3 filters. From the VGGNet, shortcut connection as described above is inserted to form a residual network.\n- #PAPER [Aggregated Residual Transformations for Deep Neural Networks, ResNeXt (Xie 2016)](https://arxiv.org/abs/1611.05431) ^resnext\n- #PAPER [Densely Connected Convolutional Networks, DenseNet (Huang 2016)](https://arxiv.org/abs/1608.06993) ^densenet\n\t- #CODE https://github.com/liuzhuang13/DenseNet\n\t- #BOOK [DenseNet](https://d2l.ai/chapter_convolutional-modern/densenet.html)\n\t- For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages such as alleviating the vanishing-gradient problem, strengthening the feature propagation, encouraging feature reuse, and substantially reducing the number of parameters. DenseNets outperformed ResNets whilst requiring less memory and computation to achieve high performance.\n\t- https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803\n\t- In DenseNet, each layer obtains additional inputs from all preceding layers and passes on its own feature-maps to all subsequent layers. Concatenation is used (while element-wise addition for ResNets). Each layer is receiving a ‚Äúcollective knowledge‚Äù from all preceding layers. \n\t- https://arthurdouillard.com/post/densenet/\n- #PAPER [Wide Residual Networks (Zagoruyko 2016)](https://arxiv.org/abs/1605.07146)\n\t- #CODE https://github.com/szagoruyko/wide-residual-networks\n- #PAPER [Residual Attention Network for Image Classification (Wang 2017)](https://arxiv.org/abs/1704.06904)\n\t- Residual Attention Network, a convolutional neural network using attention mechanism which can incorporate with state-of-art feed forward network architecture in an end-to-end training fashion. The attention residual learning is used to train very deep Residual Attention Networks which can be easily scaled up to hundreds of layers.\n- #PAPER [ResNet strikes back: An improved training procedure in timm (Wightman 2021)](https://arxiv.org/abs/2110.00476)\n\t- [Paper explained](https://www.youtube.com/watch?v=Gl0s0GDqN3c)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Deep-learning/Transformers":{"title":"Transformers","content":"## Resources\n- https://github.com/IDEACVR/awesome-detection-transformer\n- https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/ (from RNNs with attention to Transformers)\n- https://analyticsindiamag.com/a-complete-learning-path-to-transformers/\n- https://analyticsindiamag.com/transformers-for-vision-7-works-that-indicate-fusion-is-the-future-of-ai/\n\n## Code\n- #CODE [Transformers](https://github.com/huggingface/transformers)\n\t- thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio\n- #CODE [Xformers](https://github.com/facebookresearch/xformers)\n- #CODE [Transformers: from NLP to CV](https://github.com/IbrahimSobh/Transformers)\n\n\n## For NLP\n- #PAPER [Attention is all you need (Vaswani 2017)](https://arxiv.org/abs/1706.03762)\n\t- https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\n\t- [Paper explained](https://www.youtube.com/watch?v=iDulhoQ2pro)\n\t- The Transformer is a novel neural network architecture based on a self-attention mechanism that is well suited for language understanding. \n\t- It outperforms both recurrent and convolutional models on academic English to German and English to French translation benchmarks. On top of higher translation quality, the Transformer requires less computation to train and is a much better fit for modern machine learning hardware, speeding up training by up to an order of magnitude.\n\t- Self-attention is the method the Transformer uses to bake the ‚Äúunderstanding‚Äù of other relevant words into the one we‚Äôre currently processing. If you‚Äôre familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it‚Äôs processing. \n\t- The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n\t- http://jalammar.github.io/illustrated-transformer/\n\t- [Attention is all you need, attentional neural network models (≈Åukasz Kaiser)](https://www.youtube.com/watch?v=rBCqOTEfxvg)\n\t- [LSTM is dead, long live Transformers](https://sea-adl.org/2019/12/03/lstm-is-dead-long-live-transformers/)\n- #PAPER [Tensor2tensor (Vaswani 2018)](https://arxiv.org/abs/1803.07416)\n\t- Tensor2Tensor, or T2T for short, is a library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research. T2T is actively used and maintained by researchers and engineers within the Google Brain team and a community of users. We're eager to collaborate with you too, so feel free to open an issue on GitHub or send along a pull request (see our contribution doc). You can chat with us on Gitter and join the T2T Google Group.\n\t- It includes the reference implementation of the state-of-the-art Transformer model.\n- #PAPER [Improving Language Understanding by Generative Pre-Training, GPT (Radford 2018)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n\t- https://openai.com/blog/language-unsupervised/\n- #PAPER [Language Models are Unsupervised Multitask Learners, GPT-2 (Radford 2018)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n\t- #CODE https://github.com/openai/gpt-2\n\t- https://openai.com/blog/better-language-models/\n\t- Paper explained\n\t\t- https://www.youtube.com/watch?v=u1_qMdb0kYU\n\t\t- https://www.youtube.com/watch?v=UULqu7LQoHs\n\t\t- https://www.youtube.com/watch?v=8ypnLjwpzK8\n- #PAPER [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin 2019)](https://arxiv.org/abs/1810.04805)\n\t- #CODE [TensorFlow code and pre-trained models for BERT](https://github.com/google-research/bert)\n\t- [Paper explained](https://www.youtube.com/watch?v=-9evrZnBorM)\n\t- [BERT as a service](https://github.com/hanxiao/bert-as-service)\n- #PAPER [Language Models are Few-Shot Learners, GPT-3 (Brown 2020)](https://arxiv.org/abs/2005.14165)\n\t- Paper explained: \n\t\t- https://www.youtube.com/watch?v=SY5PvZrJhLE\n\t\t-  https://www.youtube.com/watch?v=_x9AwxfjxvE\n- #PAPER [It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners (Schick 2020)](https://arxiv.org/abs/2009.07118)\n\t- #CODE https://github.com/timoschick/pet\n\t- https://www.infoq.com/news/2020/10/training-exceeds-gpt3/\n- #PAPER [Rethinking Attention with Performers (Choromanski 2020)](https://arxiv.org/abs/2009.14794)\n\t- https://syncedreview.com/2020/10/02/google-cambridge-deepmind-alan-turing-institutes-performer-transformer-slashes-compute-costs/\n\t- https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html\n\t- #CODE https://github.com/google-research/google-research/tree/master/performer/fast_self_attention\n\t- [Paper explained](https://www.youtube.com/watch?v=xJrKIPwVwGM)\n- #PAPER [SqueezeBERT: What can computer vision teach NLP about efficient neural networks? (Iandola 2020)](https://arxiv.org/abs/2006.11316)\n\t- #TALK [From SqueezeNet to SqueezeBERT: Developing Efficient Deep Neural Networks](https://www.youtube.com/watch?v=kPMaEYSywdI)\n\t- https://www.microsoft.com/en-us/research/video/from-squeezenet-to-squeezebert-developing-efficient-deep-neural-networks/\n- #PAPER [FNet: Mixing Tokens with Fourier Transforms (Lee-Thorp 2021)](https://arxiv.org/abs/2105.03824)\n\t- https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/\n\t- #CODE https://paperswithcode.com/paper/fnet-mixing-tokens-with-fourier-transforms?from=n10\n\t- Transformer architectures can be massively sped up, with limited accuracy costs, by replacing self-attention sublayers with linear transformations that \"mix\" input tokens\n- #PAPER [Optimizing Deeper Transformers on Small Datasets (Xu 2021)](https://arxiv.org/abs/2012.15355)\n- #PAPER [Infinity-former: Infinite Memory Transformer](https://arxiv.org/abs/2109.00301)\n\t- [Paper explained](https://www.youtube.com/watch?v=0JlB9gufTw8)\n\n\n## For Computer Vision\n- #PAPER [Spatial Transformer Networks (Jaderberg 2016)](https://arxiv.org/abs/1506.02025)\n\t-  the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, result-ing in state-of-the-art performance on several benchmarks, and for a number of classes of transformations\n\t-  https://www.youtube.com/watch?v=6NnearestOQC_fl1hQ\n\t-  #CODE https://github.com/oarriaga/paz/tree/master/examples/spatial_transfomer_networks\n- #PAPER [Image Transformer (Parmar 2018)](https://arxiv.org/abs/1802.05751)\n- #PAPER [Generative Pretraining from Pixels (Chen 2020)](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf) ^imagegpt\n\t- https://openai.com/blog/image-gpt/ \n\t- #CODE https://github.com/openai/image-gpt\n\t- [Paper explained](https://www.youtube.com/watch?v=YBlNQK0Ao6g)\n\t- https://www.youtube.com/watch?v=7rFLnQdl22c\n- #PAPER [DETR - End-to-End Object Detection with Transformers (Carion 2020)](https://arxiv.org/abs/2005.12872 )\n\t- #CODE https://paperswithcode.com/paper/end-to-end-object-detection-with-transformers\n- #PAPER [Taming Transformers for High-Resolution Image Synthesis (Esser 2020)](https://arxiv.org/abs/2012.09841v1) ^tamingtransformers\n\t- https://compvis.github.io/taming-transformers/\n\t- https://github.com/CompVis/taming-transformers\n\t- https://www.marktechpost.com/2020/12/28/a-new-method-to-code-inductive-image-biases-into-models-using-cnn-and-transformers/\n- #PAPER [ViT - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (2020)](https://openreview.net/forum?id=YicbFdNTTy)\n\t- While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer can perform very well on image classification tasks when applied directly to sequences of image patches\n\t- [Paper explained](https://www.youtube.com/watch?v=TrdevFK_am4)\n\t- #CODE https://github.com/google-research/vision_transformer\n\t- #CODE https://keras.io/examples/vision/image_classification_with_vision_transformer/\n\t- #CODE https://github.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples\n- #PAPER [Training data-efficient image transformers \u0026 distillation through attention (Touvron 2021)](https://arxiv.org/abs/2012.12877)\n\t- #CODE https://github.com/facebookresearch/deit\n\t- Propose a competitive convolution-free transformer by training on Imagenet only\n\t- Introduced a teacher-student strategy specific to transformers. It relies on a distillation token ensuring that the student learns from the teacher through attention\n\t- https://ai.facebook.com/blog/data-efficient-image-transformers-a-promising-new-technique-for-image-classification/\n- #PAPER [PVT - Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions (Wang 2021)](https://arxiv.org/abs/2102.12122) ^pvt\n\t- #CODE https://paperswithcode.com/paper/pyramid-vision-transformer-a-versatile\n\t- #CODE https://github.com/wangermeng2021/PVT-tensorflow2\n\t- PVT inherits the advantages from both CNN and Transformer, making it a unified backbone in various vision tasks without convolutions by simply replacing CNN backbones\n- #PAPER [Vision Transformers for Dense Prediction (Ranftl 2021)](https://arxiv.org/abs/2103.13413v1)\n\t- #CODE https://paperswithcode.com/paper/vision-transformers-for-dense-prediction\n\t- Model with an encoder-decoder design, leveraging the vision transformer (ViT) as the building block of the encoder\n\t- The representations produced by the transformer are reassembled into image-like feature representations at various resolutions and are progressively combined into the final dense prediction using a convolutional decoder \n\t- The transformer downsamples operations and keeps a representation with a constant dimensionality throughout the processing stages while keeping a global receptive field at every stage\n\t- These properties allows DPT to provide fine-grained and globally coherent predictions as compared to fully-convolutional networks\n- #PAPER [Understanding Robustness of Transformers for Image Classification (Bhojanapalli 2021)](https://arxiv.org/abs/2103.14586v1)\n- #PAPER [Medical Transformer: Gated Axial-Attention for Medical Image Segmentation (Valanarasu 2021)](https://arxiv.org/abs/2102.10662)\n\t- #CODE https://github.com/jeya-maria-jose/Medical-Transformer\n\t- https://analyticsindiamag.com/guide-to-medical-transformer-attention-for-medical-image-segmentation/\n\t- Trains with less data thanks to the Gated Axial-Attention model which extends the existing architectures by introducing an additional control mechanism in the self-attention module\n\t- To train the model effectively on medical images, we propose a Local-Global training strategy (LoGo) which further improves the performance. Specifically, we operate on the whole image and patches to learn global and local features, respectively\n- #PAPER [TransGAN: Two Transformers Can Make One Strong GAN (Jiang 2021)](https://arxiv.org/abs/2102.07074v2)\n\t- #CODE https://paperswithcode.com/paper/transgan-two-transformers-can-make-one-strong\n\t-  first pilot study in building a GAN completely free of convolutions, using only pure transformer-based architectures\n- #PAPER [Gansformer - Generative Adversarial Transformers (Hudson 2021)](https://arxiv.org/abs/2103.01209v2)\n\t- #CODE https://paperswithcode.com/paper/generative-adversarial-transformers\n- #PAPER [TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation (Chen 2021)](https://arxiv.org/abs/2102.04306v1)\n\t- #CODE https://paperswithcode.com/paper/transunet-transformers-make-strong-encoders\n\t- due to the intrinsic locality of convolution operations, U-Net generally demonstrates limitations in explicitly modeling long-range dependency\n\t- TransUNet merits both Transformers and U-Net, as a strong alternative for medical image segmentation\n\t- transformer encodes tokenized image patches from a convolution neural network (CNN) feature map as the input sequence for extracting global contexts\n\t- on the other hand, the decoder upsamples the encoded features which are then combined with the high-resolution CNN feature maps to enable precise localization\n- #PAPER [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Liu 2021)](https://arxiv.org/abs/2103.14030)\n\t- #CODE https://github.com/microsoft/Swin-Transformer\n\t- #CODE https://github.com/rishigami/Swin-Transformer-TF\n\t- #CODE https://github.com/yingkaisha/keras-vision-transformer\n\t- Swin Transformer serves as a general-purpose backbone for computer vision. Works for tasks such as image classification, object detection and semantic segmentation\n\t- involves a hierarchical Transformer whose representation is computed through a shifted windowing mechanism which limits the self-attention computation to non-overlapping local windows while still allowing for cross-window connection\n\t- the benefits of this hierarchical architecture are greater efficiency and flexibility to model at various scales. In addition, this model has linear computational complexity with respect to image size\n- #PAPER [How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers (Steiner 2021)](https://arxiv.org/abs/2106.10270v1)\n\t- Results show that models using a combination of AugReg (model regularization) and increased compute can attain similar performance as models trained on an order of magnitude more training data\n\t- ViT models of various sizes, trained on ImageNet-21k, match or outperform counterparts trained on a larger dataset (JFT-300M)\n\t- #CODE https://paperswithcode.com/paper/how-to-train-your-vit-data-augmentation-and\n- #PAPER [Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning (Kossen 2021)](https://arxiv.org/abs/2106.02584v1)\n\t- #CODE https://paperswithcode.com/paper/self-attention-between-datapoints-going?from=n11\n\t- Authors challenge a common assumption underlying most supervised deep learning: that a model makes a prediction depending only on its parameters and the features of a single input\n\t- Introduced a general-purpose deep learning architecture that takes as input the entire dataset instead of processing one datapoint at a time\n\t- The approach uses self-attention to reason about relationships between datapoints explicitly, which can be seen as realizing non-parametric models using parametric attention mechanisms\n- #PAPER [Segmenter: Transformer for Semantic Segmentation (Strudel 2021)](https://arxiv.org/abs/2105.05633)\n- #PAPER [Focal Self-attention for Local-Global Interactions in Vision Transformers (Yang 2021)](https://arxiv.org/abs/2107.00641)\n\t- https://www.marktechpost.com/2021/08/24/microsoft-ai-open-source-the-code-for-its-focal-transformer/\n- #PAPER [Do Vision Transformers See Like Convolutional Neural Networks (Raghu 2021)](https://arxiv.org/abs/2108.08810)\n\t- [Paper explained](https://www.youtube.com/watch?v=rk9bhIRInC0)\n- #PAPER [DECIMER 1.0: deep learning for chemical image recognition using transformers (Rajan 2021)](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-021-00538-8)\n- #PAPER [Multiscale Vision Transformers (Fan 2021)](https://arxiv.org/abs/2104.11227)\n\t- #CODE  https://github.com/facebookresearch/SlowFast\n\t- https://ai.facebook.com/blog/multiscale-vision-transformers-an-architecture-for-modeling-visual-data/\n- #PAPER [Swin Transformer V2: Scaling Up Capacity and Resolution (Liu 2021)](https://arxiv.org/abs/2111.09883v1)\n\t- #CODE https://paperswithcode.com/paper/swin-transformer-v2-scaling-up-capacity-and\n- #PAPER [Transformers in Medical Imaging: A Survey (Shamshad 2022)](https://arxiv.org/abs/2201.09873v1)\n\t- #CODE https://paperswithcode.com/paper/transformers-in-medical-imaging-a-survey?from=n24\n\t- https://github.com/fahadshamshad/awesome-transformers-in-medical-imaging\n- #PAPER [How Do Vision Transformers Work? (Park 2022)](https://arxiv.org/abs/2202.06709v2)\n\t- #CODE https://paperswithcode.com/paper/how-do-vision-transformers-work-1?from=n26\n\n\n### Self-supervised vision transformers\n- [Self-Supervised Learning in Vision Transformers](https://towardsdatascience.com/self-supervised-learning-in-vision-transformers-30ff9be928c)\n- #PAPER [SiT: Self-supervised vIsion Transformer (Atito 2021)](https://arxiv.org/abs/2104.03602)\n- #PAPER [DINO - Emerging Properties in Self-Supervised Vision Transformers (Caron 2021)](https://arxiv.org/abs/2104.14294)\n\t- https://towardsdatascience.com/on-dino-self-distillation-with-no-labels-c29e9365e382\n\n\n### Vision transformers with convolutions\n- #PAPER [CeiT - Incorporating Convolution Designs into Visual Transformers (Yan 2021)](https://arxiv.org/abs/2103.11816v1)\n\t- #CODE https://paperswithcode.com/paper/incorporating-convolution-designs-into-visual\n\t- CeiT combines the advantages of CNNs in extracting low-level features, strengthening locality, and the advantages of Transformers in establishing long-range dependencies\n- #PAPER [CvT: Introducing Convolutions to Vision Transformers (Wu 2021)](https://arxiv.org/abs/2103.16302v1)\n\t- #CODE https://paperswithcode.com/paper/cvt-introducing-convolutions-to-vision\n- #PAPER [Escaping the Big Data Paradigm with Compact Transformers (Hassani 2021)](https://arxiv.org/abs/2104.05704) ^cctransformer\n\t- Compact Convolutional Transformer (CCT)\n\t- #CODE https://github.com/SHI-Labs/Compact-Transformers\n\t- #CODE https://keras.io/examples/vision/cct/\n\t- ViTs (or a typical Transformer-based architecture) do not have well-informed inductive biases (such as convolutions for processing images)\n\t- Attempt to combine the benefits of convolution and the benefits of Transformers in a single network architecture\n\t- These benefits include parameter-efficiency, and self-attention to process long-range and global dependencies (interactions between different regions in an image)\n- #PAPER [CvT: Introducing Convolutions to Vision Transformers (Wu 2021)](https://arxiv.org/abs/2103.15808)\n\t- #CODE https://github.com/leoxiaobin/CvT\n\t- Convolutional vision Transformers (CvT) improves ViT in performance and efficienty by introducing convolutions into ViT to yield the best of both disignes\n\t- This is accomplished through two primary modifications: a hierarchy of Transformers containing a new convolutional token embedding, and a convolutional Transformer block leveraging a convolutional projection\n\t- These changes introduce desirable properties of convolutional neural networks (CNNs) to the ViT architecture (e.g. shift, scale, and distortion invariance) while maintaining the merits of Transformers (e.g. dynamic attention, global context, and better generalization)\n- #PAPER [Combining EfficientNet and Vision Transformers for Video Deepfake Detection (Coccomini 2021)](https://arxiv.org/abs/2107.02612)\n\t- [Vision Transformers or Convolutional Neural Networks? Both!](https://towardsdatascience.com/vision-transformers-or-convolutional-neural-networks-both-de1a2c3c62e4)\n- #PAPER [Early Convolutions Help Transformers See Better (Xiao 2021)](https://arxiv.org/abs/2106.14881)\n\t- https://syncedreview.com/2021/07/06/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-55/\n\t- replacing the ViT patchify stem with a standard convolutional stem in early visual processing results in marked improvements in terms of optimizer stability and final model accuracy\n- #PAPER [ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases (d'ascoli 2021)](https://arxiv.org/abs/2103.10697)\n\t- #CODE https://github.com/facebookresearch/convit\n\t- https://ai.facebook.com/blog/computer-vision-combining-transformers-and-convolutional-neural-networks/\n- #PAPER [CMT: Convolutional Neural Networks Meet Vision Transformers (Guo 2021)](https://arxiv.org/abs/2107.06263)\n- #PAPER [CoAtNet: Marrying Convolution and Attention for All Data Sizes (Dai 2021)](https://arxiv.org/abs/2106.04803)\n\t- https://ai.googleblog.com/2021/09/toward-fast-and-accurate-neural.html\n- #PAPER [UniFormer: Unifying Convolution and Self-attention for Visual Recognition (Li 2022)](https://arxiv.org/abs/2201.09450v1)\n\t- #CODE https://paperswithcode.com/paper/uniformer-unifying-convolution-and-self?from=n24\n- #PAPER [Convolutional Xformers for Vision (Jeevan 2022)](https://arxiv.org/abs/2201.10271v1)\n\t- #CODE https://arxiv.org/abs/2201.10271v1\n\n\n## Multi-modal transformers\nSee [Multimodal learning](AI/Deep%20learning/Multimodal%20learning.md)\n\n## For RL\nSee ^decisiontransformer in [Reinforcement learning](AI/Reinforcement%20learning.md)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/FairAI":{"title":"Fair AI","content":"## Resources\n- The term ‚Äò‚Äòfair AI‚Äô‚Äô refers to probabilistic decision support that prevents disparate harm (or benefit) to different subgroups\n- [Timnit Gebru Launches Independent AI Research Institute On Anniversary of Ouster from Google](https://www.dair-institute.org/press-release)\n- [Socially acceptable and fair AI](https://fair-ai.ch/)\n\n## References\n- #PAPER [Fair AI : Challenges and Opportunities (Feuerriegel 2020)](https://www.zora.uzh.ch/id/eprint/188091/)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Feature-learning":{"title":"Feature learning","content":"## Resources\n- In ML, feature learning or representation learning is a set of techniques that allows a system to automatically discover the representations needed for feature detection or classification from raw data. This replaces manual feature engineering and allows a machine to both learn the features and use them to perform a specific task.\n- https://en.wikipedia.org/wiki/Feature_learning\n- [Feature Engineering for Machine Learning](https://towardsdatascience.com/feature-engineering-for-machine-learning-434c9b4912c6)\n\n### Unsupervised case\n- Dictionary learning\n- Autoencoders\n- ICA\n- Matrix factorization\n\n### Supervised case\n- Representational Learning (RL) refers to learning latent representations using non-parametric (i.e. non-statistical) methods to _extract features_\n- Deep supervised models (Multilayer perceptron, Supervised neural networks) are able to learn automatically features from data","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Forecasting":{"title":"Forecasting","content":"See: \n- [Time Series analysis](AI/Time%20Series%20analysis.md)\n- [Regression](AI/Supervised%20Learning/Regression.md)\n- [RNNs](AI/Deep%20learning/RNNs.md)\n- \"Sequence time series modelling\" section in [CNNs](AI/Deep%20learning/CNNs.md)\n- \"For NLP\" section in [Transformers](AI/Deep%20learning/Transformers.md)\n\n## Resources\n- https://en.wikipedia.org/wiki/Forecasting\n- [Microsoft - Time Series Forecasting Best Practices \u0026 Examples](https://github.com/microsoft/forecasting)\n- Forecasting with a Time Series Model using Python: \n\t- https://www.bounteous.com/insights/2020/09/15/forecasting-time-series-model-using-python-part-one/\n\t- https://www.bounteous.com/insights/2020/09/15/forecasting-time-series-model-using-python-part-two/\n- https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775\n- https://towardsdatascience.com/automl-for-time-series-advanced-approaches-with-fedot-framework-4f9d8ea3382c\n\n## Code\n- #CODE [Darts](https://github.com/unit8co/darts)\n\t- https://unit8co.github.io/darts/\n\t- Python library for easy manipulation and forecasting of time series. It contains a variety of models, from classics such as ARIMA, Prophet,  deep neural networks (NBEATS, RNNs, Transformers)\n\t- https://towardsdatascience.com/darts-swiss-knife-for-time-series-forecasting-in-python-f37bb74c126\n- #CODE [Neuralforecast](https://github.com/Nixtla/neuralforecast)\n\t- NeuralForecast is a Python library for time series forecasting with deep learning models. It includes benchmark datasets, data-loading utilities, evaluation functions, statistical tests, univariate model benchmarks and SOTA models implemented in PyTorch and PyTorchLightning\n\t- https://nixtla.github.io/neuralforecast\n- #CODE [Prophet (Facebook)](https://github.com/facebook/prophet)\n\t- https://facebook.github.io/prophet/\n\t- Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data.\n\t- https://research.fb.com/prophet-forecasting-at-scale/\n\t- http://blog.fastforwardlabs.com/2017/03/22/prophet.html\t\n- #CODE [NeuralProphet](https://github.com/ourownstory/neural_prophet)\n\t- https://ourownstory.github.io/neural_prophet/\n\t- A simple forecasting model based on Neural Networks in PyTorch\n- #CODE [Hcrystalball](https://github.com/heidelbergcement/hcrystalball)\n\t- Library that unifies the API for most commonly used libraries and modeling techniques for time-series forecasting in Python\n- #CODE [AtsPy: Automated Time Series Forecasting in Python](https://github.com/firmai/atspy)\n- #CODE [Greykite (Linkedin)](https://github.com/linkedin/greykite)\n\t- https://linkedin.github.io/greykite/\n\t- A flexible, intuitive and fast forecasting library\n- #CODE [Scalecast](https://github.com/mikekeith52/scalecast)\n\t- https://towardsdatascience.com/introducing-scalecast-a-forecasting-library-pt-1-33b556d9b019\n- #CODE [Skforecast](https://github.com/JoaquinAmatRodrigo/skforecast)\n- #CODE [Deep_XF](https://github.com/ajayarunachalam/Deep_XF)\n\t- Package towards building Explainable Forecasting and Nowcasting Models with State-of-the-art Deep Neural Networks and Dynamic Factor Model on Time Series data sets with single line of code\n\t- https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html\n\t\n\n## Books\n- #BOOK [Forescasting: principles and practice (Hyndman 2018, R)](https://otexts.com/fpp2/)\n\n\n## References\n- #PAPER [Time Series Forecasting With Deep Learning: A Survey (Lim 2020)](https://arxiv.org/abs/2004.13408)\n- #PAPER [N-BEATS: Neural basis expansion analysis for interpretable time series forecasting (Oreshkin 2020)](https://arxiv.org/abs/1905.10437)\n- #PAPER [A flexible forecasting model for production systems (Hosseini 2021)](https://arxiv.org/abs/2105.01098)\n- #PAPER [An Experimental Review on Deep Learning Architectures for Time Series Forecasting (Lara-Benitez 2021)](https://arxiv.org/abs/2103.12057)\n- #PAPER [Temporal Fusion Transformers for interpretable multi-horizon time series forecasting (Lim 2021)](https://www.sciencedirect.com/science/article/pii/S0169207021000637)\n\t- https://ai.googleblog.com/2021/12/interpretable-deep-learning-for-time.html\n\t- [Transformers](AI/Deep%20learning/Transformers.md)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Learning-to-rank":{"title":"Learning to rank","content":"## Resources\n- https://en.wikipedia.org/wiki/Learning_to_rank\n- Learning to rank or machine-learned ranking (MLR) is the application of machine learning, typically supervised, semi-supervised or reinforcement learning, in the construction of ranking models for information retrieval systems. Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model's purpose is to rank, i.e. produce a permutation of items in new, unseen lists in a way which is \"similar\" to rankings in the training data in some sense.\n\n### Ordinal regression (classification)\n- https://en.wikipedia.org/wiki/Ordinal_regression\n- OR (also called \"ordinal classification\" or ‚Äúranking learning‚Äù) is a type of [Regression](AI/Supervised%20Learning/Regression.md) analysis used for predicting an ordinal variable, i.e. a variable whose value exists on an arbitrary scale where only the relative ordering between different values is significant. It can be considered an intermediate problem between regression and classification.\n- http://stackoverflow.com/questions/3495157/ordinal-classification-packages-and-algorithms\n- http://stats.idre.ucla.edu/r/dae/ordinal-logistic-regression/\n\n## Code\n- #CODE [Adarank](https://github.com/rueycheng/AdaRank)\n- #CODE [Pyltr - LambdaMART](https://github.com/jma127/pyltr)\n- #CODE [Mord - Ordinal Regression in Python](https://github.com/fabianp/mord)\n\t- https://pythonhosted.org/mord/\n\t- http://fa.bianp.net/blog/2013/logistic-ordinal-regression/\n\n## References\n### DL-based ranking\n- #PAPER [TF-Ranking: Scalable TensorFlow Library for Learning-to-Rank (Kumar Pasumarthi 2019)](https://research.google/pubs/pub48160/)\n\t- #CODE https://github.com/tensorflow/ranking\n\t- [New Keras-based TF-Ranking version](https://ai.googleblog.com/2021/07/advances-in-tf-ranking.html)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Machine-Learning":{"title":"Machine Learning","content":"## Resources\n- Machine learning identifies patterns using statistical learning and computers by unearthing boundaries in data sets. \n- [Awesome ML](https://github.com/josephmisiti/awesome-machine-learning)\n- [Machine Learning Research Articles](https://deepai.org/publications/statistics-machine-learning/1)\n- [Rules of ML (Google)](https://developers.google.com/machine-learning/rules-of-ml/)\n- [Jason's Machine Learning 101 (Google)](https://www.youtube.com/watch?v=JpTYbmpoHT0)\n\t- https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/preview\n- [Machine Learning Glossary (Google)](https://developers.google.com/machine-learning/glossary/)\n- [ML Resources (MIT student)](https://sgfin.github.io/learning-resources/)\n- [Machine Learning \u0026 Deep Learning Tutorials](https://github.com/ujjwalkarn/Machine-Learning-Tutorials/)\n- [A visual introduction to machine learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n- [ML Algorithms: Strengths and Weaknesses](https://elitedatascience.com/machine-learning-algorithms)\n- [A friendly introduction to linear algebra for ML (ML Tech Talks)](https://www.youtube.com/watch?v=LlKAna21fLE)\n- [Best practices for ML engineering (Google)](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf)\n- [Recommendation System Algorithms](https://blog.statsbot.co/recommendation-system-algorithms-ba67f39ac9a3)\n- [Training Machine Learning Models More Efficiently with Dataset Distillation](http://ai.googleblog.com/2021/12/training-machine-learning-models-more.html \"Training Machine Learning Models More Efficiently with Dataset Distillation\")\n\n### Cheatsheets and notes\n- https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/super-cheatsheet-machine-learning.pdf\n- https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks\n- [ML-AI guide](https://csinva.io/blog/compiled_notes/_build/html//intro.html)\n\n### Naive/homemade implementations\n- https://github.com/trekhleb/homemade-machine-learning\n- https://github.com/anhquan0412/basic_model_scratch\n- https://github.com/rushter/MLAlgorithms\n- https://github.com/ahmedbesbes/Neural-Network-from-scratch\n- https://github.com/eriklindernoren/ML-From-Scratch\n\n### Open datasets (for ML, DL and DS)\nSee [Open ML data](AI/DS%20and%20DataEng/Open%20ML%20data.md)\n\n\n## Books\n- #BOOK [The elements of statistical learning (Hastie 2015, SPRINGER)](https://web.stanford.edu/~hastie/ElemStatLearn/)\n- #BOOK [An Introduction to Statistical Learning (James 2013, SPRINGER)](http://www-bcf.usc.edu/~gareth/ISL/)\n\t- https://github.com/JWarmenhoven/ISLR-python\n-  #BOOK [Recommender Systems - The Textbook (Aggarwal, 2016 SPRINGER)](http://charuaggarwal.net/Recommender-Systems.pdf)\n-  #BOOK [Mathematics for ML (Deisenroth, 2018 CAMBRIDGE)](https://mml-book.github.io/)\n-  #BOOK Introduction to Machine Learning with Python - A Guide for Data Scientists (Muller, 2016 O'REILLY)\n\t\t- https://www.academia.edu/42736911/Introduction_to_Machine_Learning_with_Python_A_Guide_for_Data_Scientists\n\t\t- https://github.com/amueller/introduction_to_ml_with_python\n- #BOOK [Machine Learning for Dummies (Hurwitz, 2018 WILEY-IBM)](https://www-01.ibm.com/common/ssi/cgi-bin/ssialias?htmlfid=IMM14209USEN)\n- #BOOK Python Machine Learning (Raschka 2015, PACKT)\n\t\t- http://diggerdnepr.ddns.net/wp-content/uploads/2019/02/python-machine-learning-2nd.pdf\n\t\t- https://github.com/rasbt/python-machine-learning-book\n- #BOOK [Mastering Machine Learning with scikit-learn (Hackeling 2014, PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/mastering-machine-learning-scikit-learn)\n- #BOOK [Designing Machine Learning Systems with Python (Julian 2016, PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/designing-machine-learning-systems-python)\n- #BOOK [Evaluating Machine Learning Models (Zheng 2015, OREILLY)](https://www.oreilly.com/ideas/evaluating-machine-learning-models)\n- #BOOK [Introduction to Machine Learning Interviews Book](https://huyenchip.com/ml-interviews-book/)\n\n## Courses\n- #COURSE [Machine Learning (CS229, Stanford)](http://cs229.stanford.edu/)\n\t- [Lecture notes](https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf)\n\t- [Cheat sheets](https://github.com/afshinea/stanford-cs-229-machine-learning)\n- #COURSE [Machine Learning (Coursera-Stanford)](https://www.coursera.org/learn/machine-learning)\n- #COURSE [Machine Learning Crash Course with TensorFlow APIs (Google)](https://developers.google.com/machine-learning/crash-course/)\n- #COURSE [Data Mining and Machine Learning (STAT 365/665, Yale)](http://euler.stat.yale.edu/~tba3/stat665/)\n- #COURSE [Applied machine learning (U Columbia)](https://github.com/amueller/applied_ml_spring_2017)\n- #COURSE [L'apprentissage face √† la mal√©diction de la grande dimension (College de France)](https://www.college-de-france.fr/site/stephane-mallat/course-2017-2018.htm)\n- #COURSE [The Machine Learning Summer School, MLSS Tubingen 2020 (virtual)](http://mlss.tuebingen.mpg.de/2020/)\n\t- https://www.youtube.com/channel/UCBOgpkDhQuYeVVjuzS5Wtxw/videos\n\n## Code \n- #CODE [Benchmarks of ML libraries](https://github.com/szilard/benchm-ml)\n- #CODE [Scikit-learn](https://github.com/scikit-learn/scikit-learn)\n\t- http://scikit-learn.org/stable/\n\t- [Contrib packages](https://github.com/scikit-learn-contrib)\n\t- #TALK [PyData tutorial by Sebastian Raschka](https://www.youtube.com/watch?v=9fOWryQq9J8)\n\t- #CODE [scikit-plot](http://scikit-plot.readthedocs.io/en/stable/Quickstart.html)\n\t- #CODE [Lightning](http://contrib.scikit-learn.org/lightning/)\n\t\t- Large-scale linear classification, [Regression](AI/Supervised%20Learning/Regression.md) and ranking ([Learning to rank](AI/Learning%20to%20rank.md)] in Python\n- #CODE [mlinsights](https://github.com/sdpython/mlinsights/)\n\t- http://www.xavierdupre.fr/app/mlinsights/helpsphinx/notebooks/piecewise_linear_regression.html\n- #CODE [PyCaret](https://github.com/pycaret/pycaret)\n\t- https://pycaret.org/\n\t- PyCaret is an open-source, low-code machine learning library in Python that automates machine learning workflows\n\t- PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, LightGBM, CatBoost, spaCy, Optuna, Hyperopt, Ray, and many more\n\t- PyCaret \u003e= 2.2 provides the option to use GPU for select model training and hyperparameter tuning\n- #CODE [Hypertools](https://github.com/ContextLab/hypertools)\n\t-  A python toolbox for visualizing and manipulating high-dimensional data\n\t- http://hypertools.readthedocs.io/en/latest/\n\t- https://github.com/ContextLab/hypertools-paper-notebooks\n\t- http://blog.kaggle.com/2017/04/10/exploring-the-structure-of-high-dimensional-data-with-hypertools-in-kaggle-kernels/\n- #CODE [PySAL: Python Spatial Analysis Library Meta-Package](https://github.com/pysal/pysal)\n\t- http://pysal.org/pysal/\n- #CODE [MLxtend](http://rasbt.github.io/mlxtend/)\n\t- A library of extension and helper modules for Python's data analysis and machine learning libraries\n- #CODE [H2O](https://github.com/h2oai/)\n\t- http://www.h2o.ai/\n\t- https://github.com/h2oai/h2o-3\n\t- https://github.com/h2oai/h2o4gpu\n\t- https://github.com/h2oai/h2o-tutorials\n\t- #TALK [Getting started with H2O on Python (pydata)](https://www.youtube.com/watch?v=OYJYl8egLQs)\n\t- http://www.jowanza.com/post/156015716294/why-h2o-sparkling-water\n\t- https://github.com/h2oai/h2o-3/tree/master/h2o-py/demos\n- #CODE [Dlib (C++ with python interface)](http://dlib.net/)\n- #CODE [Shogun](http://shogun-toolbox.org/)\n- #CODE [Vowpal Wabbit](https://github.com/VowpalWabbit/vowpal_wabbit)\n\t- ML system which pushes the frontier of machine learning with techniques such as online, hashing, allreduce, reductions, learning2search, active, and interactive learning\n\t- http://hunch.net/~vw/\n\t- https://github.com/JohnLangford/vowpal_wabbit/wiki\n- #CODE [DMTK (Microsoft)](https://github.com/Microsoft/DMTK)\n\t- http://www.dmtk.io/\n\t- [Light LDA - Scalable, fast, and lightweight system for large-scale topic modeling](http://www.dmtk.io)\n- #CODE [RAPIDS - GPU data science](https://github.com/rapidsai, https://rapids.ai/)\n\t- #CODE [cuML - RAPIDS Machine Learning Library](https://github.com/rapidsai/cuml)\n\t- #CODE [cuspatial - CUDA-accelerated GIS and spatiotemporal algorithms](https://github.com/rapidsai/cuspatial)\n\t- #CODE [cuSignal - RAPIDS Signal Processing Library](https://github.com/rapidsai/cusignal)\n\t- #CODE [cuGraph - RAPIDS Graph Analytics Library](https://github.com/rapidsai/cugraph)\n\t- #CODE [cuDF - GPU DataFrame Library](https://github.com/rapidsai/cudf)\n- #CODE [scikit-learn-intelex](https://github.com/intel/scikit-learn-intelex)\n\t- Intel(R) Extension for Scikit-learn is a seamless way to speed up your Scikit-learn application\n\t- https://intel.github.io/scikit-learn-intelex/\n- #CODE [CuPy - NumPy-like API accelerated with CUDA](https://github.com/cupy/cupy)\n\t- https://cupy.chainer.org/\n\t- https://docs-cupy.chainer.org/en/stable/\n\t- https://docs-cupy.chainer.org/en/stable/tutorial/\n- #CODE [ArrayFire](https://github.com/arrayfire/arrayfire-python)\n\t- ArrayFire is a high performance library for parallel computing with an easy-to-use API. It enables users to write scientific computing code that is portable across CUDA, OpenCL and CPU devices. This project provides Python bindings for the ArrayFire library.\n\t- https://arrayfire.com/\n- #CODE [TuriCreate (Apple)](https://github.com/apple/turicreate)\n\t- TuriCreate simplifies the development of custom machine learning models. You don't have to be a machine learning expert to add recommendations, object detection, image classification, image similarity or activity classification to your app\n\t- https://developer.apple.com/videos/play/wwdc2018/712/\n- #CODE [ThunderSVM - A Fast SVM Library on GPUs and CPUs](https://github.com/zeyiwen/thundersvm)\n- #CODE [PyGAM](https://github.com/dswah/pyGAM) - Generalized Additive Models in Python\n\t- https://pygam.readthedocs.io\n- #CODE [SurPRISE - A Python scikit for building and analyzing recommender systems](http://surpriselib.com)\n- #CODE [Facets](https://github.com/PAIR-code/facets)\n\t- visualizations for understanding and analyzing machine learning datasets: Facets Overview and Facets Dive. The visualizations are implemented as Polymer web components, backed by Typescript code and can be easily embedded into Jupyter notebooks or webpages\n\t- https://pair-code.github.io/facets/\n- #CODE [PyCM](https://github.com/sepandhaghighi/pycm)\n\t- PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters\n\t- http://www.pycm.ir/\n\n### ML platforms\n- #CODE [Azure (Microsoft)](https://azure.microsoft.com/en-gb/)\n\t- [Azure ML Studio](https://azure.microsoft.com/en-us/services/machine-learning/)\n\t- [Microsoft Cognitive Services](https://azure.microsoft.com/en-in/services/cognitive-services/)\n- #CODE [Google Cloud Platform](https://cloud.google.com/)\n\t- https://codelabs.developers.google.com/\n\t- https://cloud.google.com/products/ai/\n\t- https://medium.com/google-cloud/jupyter-tensorflow-nvidia-gpu-docker-google-compute-engine-4a146f085f17\n\t- [Cloud AI building blocks](https://cloud.google.com/products/ai/building-blocks/)\n\t- [Cloud ML Engine](https://cloud.google.com/ml/)\n\t\t- [Google Cloud Machine Learning platform](https://cloud.google.com/ml-engine/docs/)\n\t\t- #TALK [Machine Intelligence at Google Scale: Vision/Speech API (Guillaume Laforge)](https://www.youtube.com/watch?v=zqWt8oI4gEw)\n\t\t- https://www.slideshare.net/matthiasfeys/machine-learning-at-scale-with-google-cloud-platform\n\t\t- https://github.com/Fematich/mlengine-boilerplate\n\t- [AI Hub](https://cloud.google.com/ai-hub/)\n\t- [Cloud AutoML](https://cloud.google.com/automl/)\n- #CODE [Amazon web services (AWS)](https://aws.amazon.com/)\n\t- https://github.com/donnemartin/awesome-aws\n\t- [ML on AWS](https://aws.amazon.com/machine-learning/)\n\t- [SageMaker](https://aws.amazon.com/sagemaker/)\n\t- [AI on AWS](https://aws.amazon.com/lex/) \n\t\t- https://aws.amazon.com/polly\n\t\t- https://aws.amazon.com/rekognition\n- #CODE [Watson (IBM)](http://www.ibm.com/watson/)\n\t- [IBM Watson APIs](https://www.ibm.com/watson/developer/)\n\t- http://www.datasciencecentral.com/profiles/blogs/ibm-watson-does-your-taxes-question-answering-machine-versus-expe\n\t- https://www.codecademy.com/learn/ibm-watson\n\t- https://www.ibm.com/cloud/watson-studio\n\t- https://www.ibm.com/watson/services/knowledge-studio/\n- #CODE [Dataiku DSS](https://www.dataiku.com/)\n- #CODE [Domino DataLab](https://www.dominodatalab.com/)\n- #CODE [RapidMiner](https://rapidminer.com/)\n- #CODE [Knime](https://www.knime.org/knime-analytics-platform)\n\n\n## References\n- #PAPER [Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence (Raschka 2020)](https://arxiv.org/abs/2002.04803)\n- #PAPER [How to avoid machine learning pitfalls: a guide for academic researchers (Lones 2021)](https://arxiv.org/abs/2108.02497)\n\t- https://venturebeat.com/2021/08/23/the-dos-and-donts-of-machine-learning-research/\n\n\n### Machine learning for scientific discovery\n- [NeurIPS - Machine Learning and the Physical Sciences](https://neurips.cc/Conferences/2021/Schedule?showEvent=21862)\n- #PAPER [Machine learning and the physical sciences (Carleo 2019)](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.91.045002)\n- #PAPER [Machine Learning for Scientific Discovery (Surana 2021)](https://arxiv.org/abs/2102.12712)\n- #PAPER [Machine Intelligence for Scientific Discovery and Engineering Invention (Daniels 2021)](https://cset.georgetown.edu/publication/machine-intelligence-for-scientific-discovery-and-engineering-invention/). White paper\n- #PAPER [Optimizing the synergy between physics and machine learning (2021)](https://www.nature.com/articles/s42256-021-00416-w). Editorial\n\n\n## Subtopics\n\n### Feature selection\nSee [Feature selection](AI/Supervised%20Learning/Feature%20selection.md)\n\n### Feature learning\nSee [Feature learning](AI/Feature%20learning.md)\n\n### Anomaly and Outlier Detection\nSee [Anomaly and Outlier Detection](AI/Anomaly%20and%20Outlier%20Detection.md)\n\n### Time Series analysis and forecasting\nSee [Time Series analysis](AI/Time%20Series%20analysis.md) and [Forecasting](AI/Forecasting.md)\n\n### AutoML\nSee [AutoML](AI/AutoML.md)\n\n### Deep Learning\nSee [DL](AI/Deep%20learning/DL.md)\n\n### Reinforcement learning\nSee [Reinforcement learning](AI/Reinforcement%20learning.md)\n\n### Unsupervised learning\nSee [Unsupervised learning](AI/Unsupervised%20learning/Unsupervised%20learning.md)\n\n### Supervised learning\nSee [Supervised learning](AI/Supervised%20Learning/Supervised%20learning.md)\n\n### Weakly-supervised learning\nSee [Weakly-supervised learning](AI/Weakly-supervised%20learning.md). It includes these topics: [Semi-supervised learning](AI/Semi-supervised%20learning.md), [Active learning](AI/Active%20learning.md) and [Transfer learning](AI/Transfer%20learning.md)\n\n### One, few-shot learning\nSee [One, few-shot learning](AI/One,%20few-shot%20learning.md)\n\n### Self-supervised learning\nSee [Self-supervised learning](AI/Self-supervised%20learning.md)\n\n### Learning to rank and ordinal regression\nSee [Learning to rank](AI/Learning%20to%20rank.md)\n\n### Generative modelling\nSee [Generative modelling](AI/Deep%20learning/Generative%20modelling.md)\n\n### Explainable AI\nSee [XAI](AI/XAI.md)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Math-and-Statistics/Distances":{"title":"Distances","content":"## Resources\n- [Anscombe dataset](http://datascienceplus.com/the-importance-of-data-visualization/)\n- Distance = 1 - Similarity \n- Having a set of points (space), a distance d is a function d(x,y) that takes 2 point in the space and produces a real number. It must satisfy 4 axioms:\n\t1. d(x,y)\u003e=0, no negative distances\n\t2. d(x,y)=0 if and only if x=y, positive distances except the from a point to itself\n\t3. d(x,y) = d(y,x), distance is symmetric \n\t4. d(x,y) \u003c= d(x,z)+d(z,y), the triangle inequality says that to travel from x to y, we cannot obtain any benefit if we are forced to travel via some particular third point z. \n- http://www.benfrederickson.com/distance-metrics/ (notebook kind of post using pandas, d3)\n- https://github.com/andrecosta90/distance-similarity-measures\n\n### Minkowski\n- The Minkowski distance is the generalized Lp -norm of the difference. \n- Lp-norm is the distance d defined as: d = (sum|x_i - y_i|^p)^1/p \n\n### Euclidean\n- Same as L2-norm (Lp-norm when p=2)\n- Most familiar distance measure, defined as the square root of the sum of the square distances: d = sqrt(sum((x_i - y_i)^2)\n- An equivalent to the L2-norm is the Squared Euclidean distance or sum of squared difference (SSD). This is the fundamental metric in least squares problems and linear algebra. It‚Äôs very sensitive to outliers (because of the square). The Mean Squared Error (MSE) is the normalized version of the SSD. \n\n### Manhattan\n- https://en.wikipedia.org/wiki/Taxicab_geometry\n- Same as L1-norm (Lp-norm when p=1)\n- Also known as Taxicab norm and SAD\n- Distance defined as the sum of the absolute differences of the coordinates: d = sum(|x_i - y_i|)\n- In solving an underdetermined system of linear equations, the regularisation term for the parameter vector is expressed in terms of the-norm (taxicab geometry) of the vector. This approach appears in the signal recovery framework called compressed sensing.\n- The Mean-Absolute Error (MAE) is a normalized version of the SAD: d_MAE(x,y) = d_SAD(x,y)/n = 1/n sum(|x_i - y_i|)\n\n### Cosine\n- The cosine distance contains the dot product scaled by the product of the Euclidean distances from the origin. It represents the angular distance of two vectors while ignoring their scale. \n\n### Jaccard\n- The Jaccard distance, is a measure of how _dissimilar_ two sets are. It is the complement of the Jaccard index and can be found by subtracting the Jaccard Index from 100%\n- https://en.wikipedia.org/wiki/Jaccard_index\n\n### Hamming\n- The hamming distance represents the number of entries in the two sample vectors which are different. It is a fundamental distance measure in information theory but less relevant in non-integer numerical problems. \n\n### Pearson\n- The Pearson distance is a correlation distance based on Pearson's product-momentum correlation coefficient of the two sample vectors. Since the correlation coefficient falls between [-1, 1], the Pearson distance lies in [0, 2] and measures the linear relationship between the two vectors. \nd_pearson(x,y) = 1 - Correlation(x,y)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Math-and-Statistics/Linear-Algebra":{"title":"Linear Algebra","content":"## Resources\n- https://en.wikipedia.org/wiki/Linear_algebra\n- [The Matrix Cookbook (Brandt 2012)](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)\n- [Stanford, Linear algebra refresher](https://stanford.edu/~shervine/teaching/cme-102/linear-algebra)\n- Stanford CS229, algebra and calculus refresher: \n\t- https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf\n\t- http://cs229.stanford.edu/section/cs229-linalg.pdf\n- http://people.duke.edu/~ccc14/sta-663/LinearAlgebraReview.html\n- https://www.khanacademy.org/math/linear-algebra\n- http://nbviewer.jupyter.org/github/relopezbriega/relopezbriega.github.io/blob/master/downloads/LinearAlgebraPython.ipynb\n\n### Matrix decompositions\n- https://en.wikipedia.org/wiki/Matrix_decomposition\n- http://people.duke.edu/~ccc14/sta-663/LinearAlgebraMatrixDecompWithSolutions.html\n- http://hameddaily.blogspot.be/2016/12/simple-matrix-factorization-with.html\n- https://sites.google.com/site/igorcarron2/matrixfactorizations\n- http://blog.ethanrosenthal.com/2017/06/20/matrix-factorization-in-pytorch/\n- https://tryolabs.com/blog/introduction-to-recommender-systems/\n- Alternating Least-squares\n\t- [Fast Python Collaborative Filtering for Implicit Datasets](https://github.com/benfred/implicit)\n\t- [Recommender system using matrix factorization (SVD, ALS)](http://www.benfrederickson.com/matrix-factorization/)\n- Eigen decomposition: \n\t- https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix\n\t- http://setosa.io/ev/eigenvectors-and-eigenvalues/\n- [LU decomposition](https://en.wikipedia.org/wiki/LU_decomposition)\n- [QR decomposition](https://en.wikipedia.org/wiki/QR_decomposition)\n\n#### SVD\n- [Singular Value Decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition)\n- https://mathworld.wolfram.com/SingularValueDecomposition.html\n- [Geometric explanation of SVD and applications](http://www.ams.org/publicoutreach/feature-column/fcarc-svd)\n- [Singular Value Decomposition as Simply as Possible](https://gregorygundersen.com/blog/2018/12/10/svd/)\n- https://jeremykun.com/2016/04/18/singular-value-decomposition-part-1-perspectives-on-linear-algebra/\n- #TALK [SVD (MIT, Gilbert Strang)](https://www.youtube.com/watch?v=mBcLRGuAFUk)\n- #TALK [Singular Value Decomposition (SVD): Mathematical Overview](https://www.youtube.com/watch?v=nbBvuuNVfco)\n\n##### Randomized Singular Value Decomposition\n- https://gregorygundersen.com/blog/2019/01/17/randomized-svd/\n- [Fast Randomized SVD (Meta/Facebook research)](https://research.facebook.com/blog/2014/09/fast-randomized-svd/)\n- #TALK [Randomized Singular Value Decomposition (SVD)](https://www.youtube.com/watch?v=fJ2EyvR85ro)\n\n## Code\n- #CODE [Tensorly](https://github.com/tensorly/tensorly)\n\t- http://tensorly.org\n\t- TensorLy is a Python library that aims at making tensor learning simple and accessible. It allows to easily perform tensor decomposition, tensor learning and tensor algebra. Its backend system allows to seamlessly perform computation with NumPy, PyTorch, JAX, MXNet, TensorFlow or CuPy, and run methods at scale on CPU or GPU\n\t- https://github.com/JeanKossaifi/tensorly-notebooks/\n\t- http://tensorly.org/stable/modules/api.html#module-tensorly.decomposition\n- #CODE [Eigen - Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms](http://eigen.tuxfamily.org/index.php?title=Main_Page)\n- #CODE [Nimfa](https://github.com/marinkaz/nimfa)\n- #CODE [Pymf](https://github.com/cthurau/pymf)\n\n## Books\n- #BOOK [Templates for the Solution of Algebraic Eigenvalue Problems (Bai, Demmel 2000)](https://www.cs.ucdavis.edu/~bai/ET/contents.html)\n- #BOOK [High Dimensional Data Analysis 2020 (HDA2020)](https://statomics.github.io/HDA2020/index.html)\n\n\n## References\n- #PAPER [Singular value decomposition and least squares solutions (Golub \u0026 Reinsch 1970)](https://link.springer.com/article/10.1007/BF02163027)\n\t- http://people.duke.edu/~hpgavin/SystemID/References/Golub+Reinsch-NM-1970.pdf","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Math-and-Statistics/Math-and-Statistics":{"title":"Math and Statistics","content":"## Resources\n- https://en.wikipedia.org/wiki/Portal:Mathematics\n- https://en.wikipedia.org/wiki/Mathematics\n- [Statistics cheatsheet](https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-statistics)\n- https://github.com/rouseguy/intro2stats\n- [Stanford-cs-229 ML, probability and stats refresher](https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-probabilities-statistics.pdf)\n- https://www.khanacademy.org/math/statistics-probability\n- http://christopherroach.com/articles/statistics-for-hackers/\n- [Trigonometry refresher](https://stanford.edu/~shervine/teaching/cme-102/trigonometry)\n\n## Books\n- #BOOK [Essential Mathematics and Statistics for Science (Currell 2009, WILEY)](https://www.wiley.com/en-us/Essential+Mathematics+and+Statistics+for+Science%2C+2nd+Edition-p-9780470694480)\n\t- http://www.stewartschultz.com/statistics/books/Essential%20Mathematics.pdf\n- #BOOK [Think Stats - Exploratory Data Analysis in Python (Downey 2014)](https://greenteapress.com/wp/think-stats-2e/)\n\t- Think Stats is an introduction to Probability and Statistics for Python programmers\n- #BOOK [An Introduction to Statistics with Python (Haslwanter, 2015 6 SPRINGER)](https://www.springer.com/fr/book/9783319283159)\n\t- Applications in the life sciences\n\t- https://es.scribd.com/document/338198132/An-Introduction-to-Statistics-With-Python-With-Applications-in-the-Life-Sciences\n- #BOOK [Statistical Thinking for the 21st Century (Poldrack 2018)](http://statsthinking21.org/index.html)\n\t- R language\n- #BOOK [Jupyter Guide to Linear Algebra](https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/intro.html)\n\n## Courses\n- #COURSE [Statistical inference for data science](https://www.coursera.org/learn/statistical-inference)\n\t- https://leanpub.com/LittleInferenceBook\n\t- [Coursera Inference Version 3](https://www.youtube.com/playlist?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ)\n- #COURSE [Probability and Statistics (Stanford online)](https://lagunita.stanford.edu/courses/course-v1:OLI+ProbStat+Open_Jan2017/about)\n- #COURSE [Modern Applied Statistics: Elements of Statistical Learning (Statistics 315a, Stanford)](http://statweb.stanford.edu/~tibs/stat315a/)\n- #TALK [Statistics in Python (Varoquaux 2015 Euroscipy)](https://www.youtube.com/watch?v=yaSgoGLXKOg)\n\n## Code\n- #CODE [Numpy](https://numpy.org/)\n\t- #PAPER [Array programming with NumPy (Harris 2020)](https://www.nature.com/articles/s41586-020-2649-2)\n- #CODE [Scipy](https://www.scipy.org/)\n- #CODE [Statsmodels](http://www.statsmodels.org/)\n- #CODE [PyLops](https://github.com/PyLops/pylops)\n\t- https://pylops.readthedocs.io/en/latest/index.html\n\t- Python library is inspired by the MATLAB Spot ‚Äì A Linear-Operator Toolbox project\n- #CODE [Bayesian bootstrap](https://github.com/lmc2179/bayesian_bootstrap)\n\n### A/B testing\n- #CODE [Sixpack](https://github.com/sixpack/sixpack)\n- #CODE [Expan (Zalando)](https://github.com/zalando/expan)\n\t- A Python library for statistical analysis of randomised control trials (A/B tests)\n\t- #TALK https://www.youtube.com/watch?v=furJxiZlo6w\n- #CODE Proctor (Indeed): \n\t- https://github.com/indeedeng/proctor\n\t- http://opensource.indeedeng.io/proctor/\n\n\n## Subtopics\n### Calculus\n- [Calculus refresher](https://stanford.edu/~shervine/teaching/cme-102/calculus)\n- Ordinary Differential Equations\n\t- https://stanford.edu/~shervine/teaching/cme-102/cheatsheet-first-ode\n\t- https://stanford.edu/~shervine/teaching/cme-102/cheatsheet-second-ode\n\t- https://stanford.edu/~shervine/teaching/cme-102/cheatsheet-applications\n- [Stanford-cs-229 ML, algebra and calculus refresher](https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf)\n- https://scipy-latinamerica.github.io/revista.io/blog/2018/10/20/introduccion-al-calculo-con-python/\n- https://www.khanacademy.org/math/multivariable-calculus\n\n- #COURSE [Calculus introductory courses (MIT)](https://ocw.mit.edu/high-school/mathematics/)\n\t- [Single Variable Calculus (18.01SC)](https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010)\n\t- [Multivariable Calculus (18.02SC)](https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010)\n\t- [Highlights of calculus (Strang)](https://ocw.mit.edu/resources/res-18-005-highlights-of-calculus-spring-2010)\n\n### Linear Algebra\nSee [Linear Algebra](AI/Math%20and%20Statistics/Linear%20Algebra.md)\n\n\n### Distances\nSee [Distances](AI/Math%20and%20Statistics/Distances.md)\n\n\n### Descriptive stats\n- https://en.wikipedia.org/wiki/Descriptive_statistics\n- http://debrouwere.org/2017/02/01/unlearning-descriptive-statistics/\n\n#### Correlation and dependance\n- https://www.datascience.com/blog/introduction-to-correlation-learn-data-science-tutorials\n- https://en.wikipedia.org/wiki/Correlation_and_dependence\n- Correlation is a statistical measure that describes the association between random variables. Why is correlation a useful metric?\n\t- Correlation can help in predicting one quantity from another\n\t- Correlation can (but often does not, as we will see in some examples below) indicate the presence of a causal relationship\n\t- Correlation is used as a basic quantity and foundation for many other modeling techniques\n- Types:\n\t- Pearson‚Äôs Correlation: \n\t\t- Pearson is the most widely used correlation coefficient. Pearson correlation measures the linear association between continuous variables. In other words, this coefficient quantifies the degree to which a relationship between two variables can be described by a line. Raw observations are centered by subtracting their means and re-scaled by a measure of standard deviations.\n\t\t- `Ro_X,Y = E[(X - mu_X)(Y - mu_Y)] / simga_X sigma_Y `\n\t\t- numerator  -\u003e covariance\n\t\t- Dividing the covariance between two variables by the product of standard deviations ensures that correlation will always fall between -1 and 1 (much easier to interpret)\n\t- Spearman's Correlation:\n\t\t- Spearman's rank correlation coefficient can be defined as a special case of Pearson œÅapplied to ranked (sorted) variables. Rather than comparing means and variances, Spearman's coefficient looks at the relative order of values for each variable. The formula for Spearman's coefficient looks very similar to that of Pearson, with the distinction of being computed on ranks instead of raw scores. \n\t- Kendall's Tau:\n\t\t- Also based on variable ranks, however, unlike Spearman's coefficient, Kendall‚Äôs tau does not take into account the difference between ranks‚Äî only directional agreement.\n- Covariance (matrix)\n\t- https://en.wikipedia.org/wiki/Covariance\n\t- In probability theory and statistics, covariance is a measure of the joint variability of two random variables. The sign of the covariance therefore shows the tendency in the linear relationship between the variables. The magnitude of the covariance is not easy to interpret. The normalized version of the covariance, the correlation coefficient, however, shows by its magnitude the strength of the linear relation. \n\t- [In multidimensional case: covariance matrix](https://en.wikipedia.org/wiki/Covariance_matrix)\n- Correlation \u0026 Causation \n\t- https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation\n\t- \"Correlation does not imply causation\" is a phrase used in statistics to emphasize that a correlation between two variables does not imply that one causes the other. Spurious statistical associations can be found in a multitude of quantities, simply due to chance.\n\t- Often, a relationship may appear to be causal through high correlation due to some unobserved variables. For example, the number of grocery stores in a city can be strongly correlated with the number of ice cream creameries. However, there is an obvious hidden variable here‚Äî the population size of the city.\n\t- https://medium.com/@akelleh/a-technical-primer-on-causality-181db2575e41#.4csn3na8j\n\t- https://www.khanacademy.org/math/probability/scatterplots-a1/creating-interpreting-scatterplots/v/correlation-and-causality\n\t- Also, weak or no correlation does not imply lack of association. Correlation is only one data summary statistic that by no means tells the complete story of relationships in the data.\n\n\n### Experimental design\nSee [Active learning](AI/Active%20learning.md)\n- [Coursera - data scientist's toolbox](https://www.youtube.com/watch?v=vSXOJnGNtM4)\n- Good experiment: replication, measure variability, generalise to the problem, transparent\n- Confounding variable - strategies: randomization, stratifying \n- Prediction is not and inference. Both are important and depend on the problem. Prediction is more challenging that inference. For prediction there are key quantities (metrics): sensitivity, specificity, positive predictive value, negative predictive value, accuracy\n\n#### A/B testing\n- https://en.wikipedia.org/wiki/A/B_testing\n- In marketing and business intelligence, A/B testing is a term for a randomized experiment with two variants, A and B, which are the control and variation in the controlled experiment. A/B testing is a form of statistical hypothesis testing with two variants leading to the technical term, two-sample hypothesis testing, used in the field of statistics. Other terms used for this method include bucket tests and split-run testing.\n- https://www.optimizely.com/ab-testing/\n- https://www.wired.com/2012/04/ff_abtesting/\n- http://data36.com/ab-testing-5-rules/\n- https://www.udacity.com/course/ab-testing--ud257\n- https://tech.okcupid.com/the-pitfalls-of-a-b-testing-in-social-networks/\n- https://www.quora.com/What-kind-of-A-B-testing-questions-should-I-expect-in-a-data-scientist-interview-and-how-should-I-prepare-for-such-questions\n- http://www.kdnuggets.com/2017/05/must-know-key-issues-problems-ab-testing.html\n\n#### Multi-armed bandit\n- http://blog.actblue.com/2015/04/29/the-multi-armed-bandit-new-and-much-improved-ab-testing-tools-2/\n- https://conversionxl.com/bandit-tests/\n- https://support.google.com/analytics/answer/2844870?hl=en\n- https://vwo.com/blog/multi-armed-bandit-algorithm/\n\n### Statistical Inference\n- https://en.wikipedia.org/wiki/Statistical_inference\n- https://www.youtube.com/watch?v=WkOinijQmPU\u0026feature=youtu.be\u0026list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/\n- Statistical inference : the process of generating conclusions about a population from a noisy sample. Without statistical inference we‚Äôre simply living within our data. With statistical inference, we‚Äôre trying to generate new knowledge. The use of probability models as the connection between our data and a populations represents the most effective way to obtain inference.\n- Question to answer: Are the statistics calculated on a small sample representative of the ones of the whole population?\n- http://www.datasciencecentral.com/profiles/blogs/the-death-of-the-statistical-test-of-hypothesis\n\n#### Frequentist inference\n- https://en.wikipedia.org/wiki/Frequentist_inference\n- [Statistical Hypothesis testing](http://youtu.be/Wqvx6_12ZMs?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ)\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-hypothesis-testing\n\t- Hypothesis testing is concerned with making decisions using data. \n\t- To make decisions using data, we need to characterize the kinds of conclusions we can make. Classical hypothesis testing is concerned with deciding between two decisions (things get much harder if there‚Äôs more than two). The first, a null hypothesis is specified that represents the status quo. This hypothesis is usually labeled, H_0. This is what we assume by default. The alternative or research hypothesis is what we require evidence to conclude. This hypothesis is usually labeled H_a, or sometimes H_1 (or some other number other than 0). So to reiterate, the null hypothesis is assumed true and statistical evidence is required to reject it in favor of a research or alternative hypothesis\t\n\t- t-test\n\t\t- http://www.cs.cornell.edu/~asampson/blog/statsmistakes.html\n\t\t- https://www.quora.com/What-is-an-intuitive-explanation-of-the-t-test-in-hypothesis-testing\n\t\t- https://medium.freecodecamp.org/the-t-distribution-a-key-statistical-concept-discovered-by-a-beer-brewery-dbfdc693184\n\t- z-test\n\t- f-test\n- Confidence intervals\n\t- http://youtu.be/u85aQ0mtiZ8?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-confidence-intervals\n\t- Confidence intervals are methods for quantifying uncertainty in our estimates. The fact that the interval has width characterizes that there is randomness that prevents us from getting a perfect estimate.\n\t- t-confidence intervals\n\t\t- http://youtu.be/pHXrDMjzyYg?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-t-confidence-intervals\n- Null hypothesis\n\t- https://en.wikipedia.org/wiki/Null_hypothesis\n\t- The term \"null hypothesis\" is a general statement or default position that there is no relationship between two measured phenomena, or no association among groups.\n\t- H_0 is generally assumed to be true until evidence indicates otherwise.\n- P-value\n\t- https://en.wikipedia.org/wiki/P-value\n\t- A p-value is the probability that, using a given statistical model, the statistical summary (such as the sample mean difference between two compared groups) would be the same as or more extreme than the actual observed results, when the null hypothesis is true.\n\t- After choosing the models H_0, H_1 and a threshold value alpha for p (the significance level of the test, traditionally 5% or 1%), if the p-value is less than or equal to alpha, the test suggests that the observed data is inconsistent with the null hypothesis, so the null hypothesis must be rejected. However, that does not prove that the tested hypothesis is true. When the p-value is calculated correctly, this test guarantees that the Type I error rate is at most alpha. For typical analysis, using the standard alpha= 0.05 cutoff, the null hypothesis is rejected when p\u003c .05 and not rejected when p\u003e .05. \n\t- The p-value does not, in itself, support reasoning about the probabilities of hypotheses but is only a tool for deciding whether to reject the null hypothesis (it can only provide evidence against a hypothesis).\n\t- http://youtu.be/Ky68x_7iK6c?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-p-values\n\t- P-values are the most common measure of statistical significance. Their ubiquity, along with concern over their interpretation and use makes them controversial among statisticians.\n\t- http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values\n\t- A P value is the probability of obtaining an effect at least as extreme as the one in your sample data, assuming the truth of the null hypothesis.\n\t- For example, suppose that a vaccine study produced a P value of 0.04. This P value indicates that if the vaccine had no effect, you‚Äôd obtain the observed difference or more in 4% of studies due to random sampling error. \n\t- P values address only one question: how likely are your data, assuming a true null hypothesis? It does not measure support for the alternative hypothesis.\n\t- http://machinelearningmastery.com/use-statistical-significance-tests-interpret-machine-learning-results/\n\t- https://www.nature.com/news/big-names-in-statistics-want-to-shake-up-much-maligned-p-value-1.22375\n- Statistical Power\n\t- https://en.wikipedia.org/wiki/Statistical_power\n\t- #TALK Statistical power:\n\t\t- http://youtu.be/-TsBOLiW4rQ?list=PLpl-gQkQivXiB1mGyzLrUjzsblmQsLtkzJ\n\t\t- http://youtu.be/GRS2b1aedmk?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-power\n\t- Power is the probability of rejecting the null hypothesis when it is false. Ergo, power (as its name would suggest) is a good thing; you want more power. A type II error (a bad thing, as its name would suggest) is failing to reject the null hypothesis when it‚Äôs false; the probability of a type II error is usually called Beta. Note Power = 1 - Beta.\n- [Effect size](https://en.wikipedia.org/wiki/Effect_size)\n- [Goodness of fit](https://en.wikipedia.org/wiki/Goodness_of_fit)\n\t- [Chi squared](https://en.wikipedia.org/wiki/Chi-squared_test)\n\n### Bootstrap and permutation tests\n- http://youtu.be/0hNQx9nagq4?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-bootstrap-and-resampling\n- The bootstrap is a tremendously useful tool for constructing confidence intervals and calculating standard errors for difficult statistics. That‚Äôs the bootstrap principle: investigate the sampling distribution of a statistic by simulating repeated realizations from the observed distribution.\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-permutation-tests\n- Consider comparing means between the group. However, let‚Äôs use the calculate the distribution of our statistic under a null hypothesis that the labels are irrelevant (exchangeable). This is a handy way to create a null distribution for our test statistic by simply permuting the labels over and over and seeing how extreme our data are with respect to this permuted distribution. \n- The procedure would be as follows: \n\t- consider a data from with count and spray,\n\t- permute the spray (group) labels,\n\t- recalculate the statistic (such as the difference in means),\n\t- calculate the percentage of simulations where the simulated statistic was more extreme (toward the alternative) than the observed.\n\n#### Bayesian bootstrap\n- http://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/\n\n### Probability theory\nSee [Probability Theory](AI/Math%20and%20Statistics/Probability%20Theory.md)\n\n### Bayesian modelling\nSee [Bayesian modelling](AI/Bayesian%20modelling.md)\n\n### Monte Carlo methods\nSee [Monte Carlo methods](AI/Math%20and%20Statistics/Monte%20Carlo%20methods.md)\n\n### Mathematical Optimization\nSee [Mathematical Optimization](AI/Math%20and%20Statistics/Mathematical%20Optimization.md)\n\n### Time series analysis\nSee [Time Series analysis](Time%20Series%20analysis.md)\n\n### Regression analysis\nSee [Regression](AI/Supervised%20Learning/Regression.md)\n- https://en.wikipedia.org/wiki/Regression_analysis\n- Regression analysis is widely used for prediction and forecasting, where its use has substantial overlap with the field of [Machine Learning](AI/Machine%20Learning.md)\n\n### Compressed sensing\n- https://en.wikipedia.org/wiki/Compressed_sensing\n- Compressed sensing(also known as compressive sensing, compressive sampling, or sparse sampling) is a signal processing technique for efficiently acquiring and reconstructing a signal, by finding solutions to underdetermined linear systems. This is based on the principle that, through optimization, the sparsity of a signal can be exploited to recover it from far fewer samples than required by the Shannon-Nyquist sampling theorem.\n- There are two conditions under which recovery is possible: \n\t- Sparsity, which requires the signal to be sparse in some domain. \n\t- Incoherence, which is applied through the isometric property which is sufficient for sparse signals\n- https://calculatedcontent.com/2012/12/28/foundations-theory-of-compressed-sensing/amp/\n\n#### Nyquist theorem\n- https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem\n- In the field of digital signal processing, the sampling theorem is a fundamental bridge between continuous-time signals(often called \"analog signals\") and discrete-time signals(often called \"digital signals\"). It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.\n\n#### Matching pursuit\n- https://en.wikipedia.org/wiki/Matching_pursuit\n- Matching pursuit (MP) is asparse approximation algorithm which involves finding the \"best matching\" projections of multidimensional data onto the span of an over-complete (i.e., redundant) dictionary D.\n- Orthogonal Matching Pursuit\n\t- Extension of MP: after every step, all the coefficients extracted so far are updated, by computing the orthogonal projection of the signal onto the set of atoms selected so far. This can lead to better results than standard MP, but requires more computation.\n\t- http://scikit-learn.org/stable/auto_examples/linear_model/plot_omp.html","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Math-and-Statistics/Mathematical-Optimization":{"title":"Mathematical Optimization","content":"## Resources\n- https://en.wikipedia.org/wiki/Mathematical_optimization\n- [A birds-eye view of optimization algorithms (Pedregosa)](http://fa.bianp.net/teaching/2018/eecs227at/)\n- http://people.duke.edu/~ccc14/sta-663/BlackBoxOptimization.html\n- http://www.benfrederickson.com/numerical-optimization/ (notebook kind of post with python, d3)\n- http://www.kdnuggets.com/2016/12/hard-thing-about-deep-learning.html\n- https://www.neuraldesigner.com/blog/5_algorithms_to_train_a_neural_network\n- [Why Momentum works](http://distill.pub/2017/momentum/)\n\n### Heuristics\n- A heuristic is any algorithm which is not guaranteed (mathematically) to find the solution, but which is nevertheless useful in certain practical situations.\n- Genetic algorithms\n\t- https://en.wikipedia.org/wiki/Genetic_algorithm\n\t- Metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms(EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on bio-inspired operators such as mutation, crossover and selection.\n- Nelder‚ÄìMead method\n\t- https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method\n\t- The Nelder‚ÄìMead method or downhill simplex method or amoeba method is a commonly applied numerical method used to find the minimum or maximum of an objective function in a multidimensional space. It is applied to nonlinear optimization problems for which derivatives may not be known. However, the Nelder‚ÄìMead technique is a heuristic search method that can converge to non-stationary points on problems that can be solved by alternative methods.\n\t- The method uses the concept of a simplex, which is a special polytope of n+ 1 vertices in n dimensions. Examples of simplices include a line segment on a line, a triangle on a plane, a tetrahedron in three-dimensional space and so forth. The method approximates a local optimum of a problem with n variables when the objective function varies smoothly and is unimodal.\n\t- Nelder‚ÄìMead in n dimensions maintains a set of n+1test points arranged as a simplex. It then extrapolates the behavior of the objective function measured at each test point, in order to find a new test point and to replace one of the old test points with the new one, and so the technique progresses. The simplest approach is to replace the worst point with a point reflected through the centroid of the remaining n points. If this point is better than the best current point, then we can try stretching exponentially out along this line. On the other hand, if this new point isn't much better than the previous value, then we are stepping across a valley, so we shrink the simplex towards a better point.\n\n### Iterative methods\nThe iterative methods used to solve problems of nonlinear programming differ according to whether they evaluate Hessians, gradients, or only function values.\n- Gradient descent\n\t- https://en.wikipedia.org/wiki/Gradient_descent\n\t- Gradient descent is a first-order iterative optimization algorithm. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or of the approximate gradient) of the function at the current point. Gradient descent is also known as steepest descent, or the method of steepest descent.\n\t- [An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/index.html)\n\t- https://towardsdatascience.com/gradient-descent-demystified-bc30b26e432a\n\t- https://www.jeremyjordan.me/gradient-descent/\n- [Conjugate gradient method](https://en.wikipedia.org/wiki/Conjugate_gradient_method)\n- [Interior point method](https://en.wikipedia.org/wiki/Interior_point_method)\n\n\n## Code\n- #CODE [Nevergrad (Facebook) - A Python toolbox for performing gradient-free optimization](https://code.fb.com/ai-research/nevergrad/)\n- #CODE [scikit-optimize](https://scikit-optimize.github.io/)\n- #CODE [GPflowOpt - library for Bayesian Optimization with GPflow](https://gpflowopt.readthedocs.io/en/latest/index.html )\n- #CODE [JAX](https://github.com/google/jax) ^jax\n\t- JAX is Autograd and XLA, brought together for high-performance machine learning research. It can automatically differentiate native Python and NumPy functions\n\t- #TALK [JAX: Accelerated Machine Learning Research | SciPy 2020 | VanderPlas](https://www.youtube.com/watch?v=z-WSrQDXkuM)\n\t- https://towardsdatascience.com/deep-learning-with-jax-and-elegy-c0765e3ec31a\n\t- #TALK [Machine Learning with JAX - From Zero to Hero](https://www.youtube.com/watch?v=SstuvS-tVc0)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Math-and-Statistics/Monte-Carlo-methods":{"title":"Monte Carlo methods","content":"## Resources\n- https://en.wikipedia.org/wiki/Monte_Carlo_method\n\n### Sequential Monte Carlo (SMC or particle filter)\n- Particle filters or Sequential Monte Carlo (SMC) methods are a set of Monte Carlo algorithms used to solve filtering problems arising in signal processing and Bayesian statistical inference. The filtering problem consists of estimating the internal states in dynamical systems when partial observations are made, and random perturbations are present in the sensors as well as in the dynamical system. The objective is to compute the posterior distributions of the states of some Markov process, given some noisy and partial observations.\n\n### Markov Process\n- https://en.wikipedia.org/wiki/Markov_chain\n- https://en.wikipedia.org/wiki/Markov_property\n- A stochastic process has the Markov property if the conditional probability distribution of future states of the process (conditional on both past and present states) depends only upon the present state, not on the sequence of events that preceded it. A process with this property is called a Markov process.\n- [Markov Chains Explained Visually](http://setosa.io/ev/markov-chains/)\n\n#### Hidden Markov Model (HMM)\n- https://en.wikipedia.org/wiki/Hidden_Markov_model\n- Hidden Markov Model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (i.e. hidden) states.\n- HMM is a Markov chain for which the state is only partially observable. In other words, observations are related to the state of the system, but they are typically insufficient to precisely determine the state. Several well-known algorithms for hidden Markov models exist. \n- https://www.quora.com/What-is-a-hidden-Markov-Model-HMM-and-how-can-it-be-used-in-speech-recognition\n- https://www.quora.com/Why-do-we-use-Hidden-Markov-Models-for-speech-recognition\n- http://scikit-learn.sourceforge.net/stable/modules/hmm.html\n- https://github.com/hmmlearn/hmmlearn\n- http://hmmlearn.readthedocs.io/en/latest/tutorial.html#available-models\n\n### MCMC\n- MCMC methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by recording states from the chain\n- https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo\n\n### Nested Sampling\n- https://en.wikipedia.org/wiki/Nested_sampling_algorithm\n- The nested sampling algorithm is a computational approach to the problem of comparing models in Bayesian statistics. \n\n\n## Code\n- [A list of Python-based MCMC packages. Also here‚Äôs a nice list of MCMC algorithms](https://gabriel-p.github.io/pythonMCMC/)\n- #CODE [Sampyl - MCMC samplers for Bayesian estimation in Python, including Metropolis-Hastings, NUTS, and Slice](http://mcleonard.github.io/sampyl/)\n- #CODE [emcee](http://dan.iel.fm/emcee/current/)\n- #CODE UltraNest - A Pythonic implementation of the Nested Sampling integration algorithm for Bayesian model comparison and parameter estimation\n\t- https://johannesbuchner.github.io/UltraNest/\n\t- https://johannesbuchner.github.io/UltraNest/testsuite/","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Math-and-Statistics/Probability-Theory":{"title":"Probability Theory","content":"## Resources\n- https://en.wikipedia.org/wiki/Probability_theory\n- https://stanford.edu/~shervine/teaching/cme-106/key-concepts\n- [A visual introduction to probability and statistics](http://students.brown.edu/seeing-theory/)\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-probability\n- Probability forms the foundation for almost all treatments of statistical inference. Probability is a law that assigns numbers to the long run occurrence of random phenomena after repeated unrelated realizations\n- http://nbviewer.jupyter.org/url/norvig.com/ipython/Probability.ipynb\n- https://en.wikipedia.org/wiki/Probability_interpretations\n- https://en.wikipedia.org/wiki/Bayesian_probability\n- [The Coursera Statistical Inference class](http://youtu.be/oTERv_vrmJM?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ)\n- [Monty Hall problem](https://en.wikipedia.org/wiki/Monty_Hall_problem)\n- [Coded in Python](https://github.com/cs109/2015lab1/blob/master/hw0.ipynb)\n- Cheatsheets:\n\t- https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-probability\n\t- Probability Cheatsheet (Chen): \n\t\t- http://www.wzchen.com/probability-cheatsheet/\n\t\t- This is an 10-page probability cheatsheet compiled from Harvard's Introduction to Probability course, taught by Joe Blitzstein (@stat110). The probability formula sheet summarizes important probability probability concepts, formulas, and distributions, with figures, examples, and stories.\n\t- Review of Probability Theory (CS229 Stanford)\n\t\t- http://cs229.stanford.edu/section/cs229-prob.pdf\t\n\t\t- http://cs229.stanford.edu/section/cs229-prob-slide.pdf\n\n#### Random variables\n- http://youtu.be/Shzt9uZ8BII?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-random-variables\n- Random variable is a numerical outcome of an experiment. The random variables that we study will come in two varieties, discrete or continuous. Discrete random variables are random variables that take on only a countable number of possibilities. Mass functions will assign probabilities that they take specific values. Continuous random variable can conceptually take any value on the real line or some subset of the real line and we talk about the probability that they lie within some range. Densities will characterize these probabilities.\n- For all of these kinds of random variables, we need convenient mathematical functions to model the probabilities of collections of realizations. These functions, called mass functions and densities, take possible values of the random variables, and assign the associated probabilities. These entities describe the population of interest.\n- PDF - probability density function\n\t- https://en.wikipedia.org/wiki/Probability_density_function\n\t- http://youtu.be/mPe0Us4VYDM?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-probability-density-functions\n\t- A probability density function (pdf), is a function associated with a continuous random variable. Because of the peculiarities of treating measurements as having been recorded to infinite decimal expansions, we need a different set of rules. This leads us to the central dogma of probability density functions: Areas under PDFs correspond to probabilities for that random variable. \n\t- A PDF, or density of a continuous random variable, is a function, whose value at any given sample (or point) in the sample space(the set of possible values taken by the random variable) can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample.\n\t- The PDF is used to specify the probability of the random variable falling within a particular range of values, as opposed to taking on any one value.\n\n#### Conditional probability\n- http://youtu.be/u6AH6qsSVA4?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-conditional-probability\n- Conditioning is a central subject in statistics. If we are given information about a random variable, it changes the probabilities associated with it. For example, the probability of getting a one when rolling a (standard) die is usually assumed to be one sixth. If you were given the extra information that the die roll was an odd number (hence 1, 3 or 5) then conditional on this new information, the probability of a one is now one third.\n- http://setosa.io/ev/conditional-probability/\n\n#### Independance\n- https://en.wikipedia.org/wiki/Independence_(probability_theory)\n- http://youtu.be/MY1EfrR1ZUs?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-independence\n- Statistical independence of events is the idea that the events are unrelated. Consider successive coin flips. Knowledge of the result of the first coin flip tells us nothing about the second.\n- The important principle is that probabilities of independent things multiply! This has numerous consequences, including the idea that we shouldn‚Äôt multiply non-independent probabilities.\n- [IID samples ](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)\n\t- IID - Independent and identically distributed \n\t- In probability theory and statistics, a sequence or other collection of random variables is independent and identically distributed(i.i.d.) if each random variable has the same probability distribution as the others and all are mutually independent.\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-iid-random-variables\n\t- Random variables are said to be independent and identically distributed (iid) if they are independent and all are drawn from the same population. The reason iid samples are so important is that they are a model for random samples. This is a default starting point for most statistical inferences.\n  \n#### Common distributions\n- https://stanford.edu/~shervine/teaching/cme-106/distribution-tables\n- https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-some-common-distributions\n- [Normal distribution](http://efavdb.com/normal-distributions/)\n- Bernoulli\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-bernoulli-distribution\n\t- TheBernoulli distribution arises as the result of a binary outcome, such as a coin flip.\n- Normal\n\t- http://youtu.be/dUTWvKa0Leo?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-normal-distribution\n\t- The normal distribution is easily the handiest distribution in all of statistics. It can be used in an endless variety of settings. Moreover, as we‚Äôll see later on in the course, sample means follow normal distributions for large sample sizes.\n\t- The normal distribution only requires two numbers to characterize it, mean and variance.\n- Poisson\n\t- http://youtu.be/ZPLZg7qz4xE?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-poisson-distribution\n\t- The Poisson distribution is used to model counts. It is perhaps only second to the normal distribution usefulness. In fact, the Bernoulli, binomial and multinomial distributions can all be modeled by clever uses of the Poisson.\n\t- The Poisson distribution is especially useful for modeling unbounded counts or counts per unit of time (rates). Like the number of clicks on advertisements, or the number of people who show up at a bus stop. There is also a deep connection between the Poisson distribution and popular models for so-called event-time data.\n\n#### Expected value\n- https://en.wikipedia.org/wiki/Expected_value\n- In probability theory, the expected value of a random variable, intuitively, is the long-run average value of repetitions of the experiment it represents.\n- Less roughly, the law of large numbers states that the arithmetic mean of the values almost surely converges to the expected value as the number of repetitions approaches infinity. The expected value is also known as the expectation, mathematical expectation, EV, average, mean value, mean, or first moment.\n- [Expected values](http://youtu.be/zljxRbu6jyc?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ)\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-expected-values\n- Expected values characterize a distribution. The most useful expected value, the mean, characterizes the center of a density or mass function. Another expected value summary, the variance, characterizes how spread out a density is. Yet another expected value calculation is the skewness, which considers how much a density is pulled toward high or low values.\n\n#### Central limit theorem\n- https://en.wikipedia.org/wiki/Central_limit_theorem\n- http://youtu.be/FAIyVHmniK0?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-central-limit-theorem\n- CLT is one of the most important theorems in statistics. For our purposes, the CLT states that the distribution of averages of iid variables becomes that of a standard normal as the sample size increases.\n\n#### Kullback-Leibler Divergence\n- https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n- https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained\n\n\n## Books\n- #COURSE [Introduction to Probability and Statistics (MIT)](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/NLP":{"title":"Natural Language Processing (NLP)","content":"---\n\n## Resources\n- NLP is a branch of data science that consists of systematic processes for analyzing, understanding, and deriving information from the text data in a smart and efficient manner. By utilizing NLP and its components, one can organize the massive chunks of text data, perform numerous automated tasks and solve a wide range of problems such as ‚Äì automatic summarization, machine translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation etc.\n- https://en.wikipedia.org/wiki/Natural_language_processing\n- A Computer Science field connected to Artificial Intelligence and Computational Linguistics which focuses on interactions between computers and human language and a machine‚Äôs ability to understand, or mimic the understanding of human language\n- https://github.com/keon/awesome-nlp\n- [The most important NLP highlights of 2018](https://github.com/omarsar/nlp_highlights)\n- [NLP - Udemy ML](https://github.com/jmportilla/Udemy","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/One-few-shot-learning":{"title":"One, few-shot learning","content":"## Resources\n- https://en.wikipedia.org/wiki/One-shot_learning\n- One-shot learning is an object categorization problem, found mostly in computer vision. Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of samples/images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training samples/images.\n- https://medium.com/sap-machine-learning-research/deep-few-shot-learning-a1caa289f18\n- https://sorenbouma.github.io/blog/oneshot/\n- https://github.com/Goldesel23/Siamese-Networks-for-One-Shot-Learning\n- [Zero-Shot Visual Imitation](https://pathak22.github.io/zeroshot-imitation/)\n- #TALK [Neural Networks - One Shot Learning](https://www.youtube.com/watch?v=r8LLorRACPM)\n\n\n## Code\n- #CODE [LibFewShot](https://github.com/rl-vig/libfewshot)\n\t- #PAPER [LibFewShot: A Comprehensive Library for Few-shot Learning (Li 2021)](https://arxiv.org/abs/2109.04898)\n\t- LibFewShot: A Comprehensive Library for Few-shot Learning (pytorch)\n\n## References\n- #PAPER [Siamese Neural Networks for One-shot Image Recognition (Koch 2015)](http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\n\t- Few-Shot learning has seen great progress over the last years. A classic approach is based on metric learning using Siamese neural networks.\n\t- #CODE https://sorenbouma.github.io/blog/oneshot/\n- #PAPER [One-Shot Imitation Learning (Duan 2017)](https://arxiv.org/abs/1703.07326)\n- #PAPER [One-shot texture segmentation (Ustyuzhaninov 2018)](https://arxiv.org/abs/1807.02654)\n\t- We solve the task of one-shot texture segmentation in three steps. First, we compute embeddings of an input image and a reference patch; second, we search for the reference texture in the embedding space to produce a rough segmentation mask; and, finally, we employ a decoding network to produce the output segmentation.\n- #PAPER [One-shot instance segmentation (Michaelis 2018)](https://arxiv.org/abs/1811.11507 )\n\t- We tackle one-shot visual search by example for arbitrary object categories: Given an example image of a novel reference object, find and segment all object instances of the same category within a scene. To address this problem, we propose Siamese Mask R-CNN. \n\t- It extends Mask R-CNN by a Siamese backbone encoding both reference image and scene, allowing it to target detection and segmentation towards the reference category.\n- #PAPER [FIGR: Few-shot Image Generation with Reptile (Clouatre 2019)](https://arxiv.org/abs/1901.02199)\n- #PAPER [Generalizing from a Few Examples: A Survey on Few-Shot Learning (Wang 2020)](https://arxiv.org/abs/1904.05046)\n- #PAPER ['Less Than One'-Shot Learning: Learning N Classes From M \u003c N Samples (Sucholutsky 2020)](https://arxiv.org/abs/2009.08449)\n\t- https://www.technologyreview.com/2020/10/16/1010566/ai-machine-learning-with-tiny-data/\n\t- AI model able to accurately recognize more objects than the number of examples it was trained on\n\t- The trick, was to create images that blend multiple digits together and then feed them into an AI model with hybrid, or ‚Äúsoft,‚Äù labels\n\n\n### Few/one-shot learning GANs \n- #PAPER [MetaGAN: An Adversarial Approach to Few-Shot Learning (Zhang 2018)](https://papers.nips.cc/paper/7504-metagan-an-adversarial-approach-to-few-shot-learning)\n- #PAPER [SinGAN: Learning a Generative Model from a Single Natural Image, SinGAN (Rott Shaham, ICCV 2019 Best Paper)](https://arxiv.org/abs/1905.01164 )\n\t- [ Paper explained](https://www.youtube.com/watch?v=-f8sz8AExdc )\n\t- [ Paper explained](https://www.youtube.com/watch?v=Xc9Rkbg6IZA)\n- #PAPER [DAWSON: A Domain Adaptive Few Shot Generation Framework (Liang 2020)](https://arxiv.org/abs/2001.00576)\n- #PAPER [LARGE: Latent-Based Regression through GAN Semantics (Nitzan 2021)](https://arxiv.org/abs/2107.11186)\n\t- #CODE https://github.com/YotamNitzan/LARGE","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Problem-Solving-and-Search":{"title":"Problem Solving and Search","content":"## Resources\n- [Solving problems by searching](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture2.md)\n- [Problem solving and search](https://www.emse.fr/~picard/cours/ai/chapter03.pdf)\n- Constraint satisfaction problems:\n\t- Constraint satisfaction problems (CSPs) are mathematical questions defined as a set of objects whose state must satisfy a number of constraints or limitations. CSPs represent the entities in a problem as a homogeneous collection of finite constraints over variables, which is solved by constraint satisfaction methods. CSPs are the subject of intense research in both artificial intelligence and operations research, since the regularity in their formulation provides a common basis to analyze and solve problems of many seemingly unrelated families. \n\t- [Constraint satisfaction problems](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture3.md)\n\t- [Constraint satisfaction problems](https://www.emse.fr/~picard/cours/ai/chapter06.pdf)\n- Adversarial Search\n\t- [Games and adversarial search](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture4.md)\n\t- [Adversarial search](https://www.emse.fr/~picard/cours/ai/chapter05.pdf)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Reinforcement-learning":{"title":"Reinforcement learning","content":"## Resources\n- Reinforcement learning is the task of learning what actions to take, given a certain situation/environment, so as to maximize a reward signal. The interesting difference between supervised and reinforcement learning is that this reward signal simply tells you whether the action (or input) that the agent takes is good or bad. It doesn‚Äôt tell you anything about what the best action is. Contrast this to CNNs where the corresponding label for each image input is a definite instruction of what the output should be for each input.  Another unique component of RL is that an agent‚Äôs actions will affect the subsequent data it receives. For example, an agent‚Äôs action of moving left instead of right means that the agent will receive different input from the environment at the next time step.\n- https://en.wikipedia.org/wiki/Reinforcement_learning\n- [Curriculum for Reinforcement Learning](https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html)\n- [Andrej Karpathy's introduction to RL](http://karpathy.github.io/2016/05/31/rl/)\n- [Evolution strategies vs RL](https://blog.openai.com/evolution-strategies/)\n\t- https://github.com/openai/evolution-strategies-starter\n- [Reinforcement learning derivations (math)](http://www.alexirpan.com/rl-derivations/)\n- [Introduction to various RL algos](https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287)\n- [Q-learning](https://en.wikipedia.org/wiki/Q-learning)\n- Temporal differencing (TD) learning  is a prediction-based machine learning method. \n\t- It has primarily been used for the reinforcement learning problem, and is said to be \"a combination ofMonte Carlo ideas and dynamic programming (DP) ideas.\" \n\t- TD resembles a Monte Carlo method because it learns by sampling the environment according to some policy, and is related to dynamic programming techniques as it approximates its current estimate based on previously learned estimates (a process known as bootstrapping). The TD learning algorithm is related to the temporal difference model of animal learning. As a prediction method, TD learning considers that subsequent predictions are often correlated in some sense.\n\t- TD-Lambda: This algorithm was famously applied by Gerald Tesauro to createTD-Gammon, a program that learned to play the game of backgammon at the level of expert human players. The lambda parameter refers to the trace decay parameter, with 0\u003c= lambda \u003c=1. Higher settings lead to longer lasting traces; that is, a larger proportion of credit from a reward can be given to more distant states and actions when lambda is higher, with lambda=1 producing parallel learning to Monte Carlo RL algorithms.\n- [SARSA](https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action)\n\n\n## Courses, talks and books\n- #COURSE [Reinforcement Learning (UCL)](https://www.davidsilver.uk/teaching/)\n\t- [Videos](https://www.youtube.com/watch?v=2pWv7GOvuf0\u0026list=PLzuuYNsE1EZAXYR4FJ75jcJseBmo4KQ9-)\n- #COURSE [CS294-112 Deep Reinforcement Learning Sp17](https://www.youtube.com/playlist?list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX)\n- #COURSE [Practical Reinforcement Learning (Yandex)](https://github.com/yandexdataschool/Practical_RL)\n- #COURSE [Tutorial: Introduction to Reinforcement Learning](https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W3D2_BasicReinforcementLearning/student/W3D2_Tutorial1.ipynb)\n- #TALK [Deep Learning and Reinforcement Learning Summer School, Toronto 2018](http://videolectures.net/DLRLsummerschool2018_toronto/)\n- #TALK [Deep RL Bootcamp](https://sites.google.com/view/deep-rl-bootcamp/lectures\t  )\n- #BOOK [Deep Reinforcement Learning (2020 SPRINGER)](https://www.springer.com/gp/book/9789811540943)\n\t- https://deepreinforcementlearningbook.org/\n\n\n## Code\n- #CODE [Acme: a research framework for reinforcement learning](https://github.com/deepmind/acme)\n- #CODE [Deep Reinforcement Learning Model ZOO](https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement_learning)\n- #CODE [Open.ai Gym - A toolkit for developing and comparing reinforcement learning algorithms](https://github.com/openai/gym)\n\t- https://gym.openai.com/\n\t- #PAPER http://arxiv.org/abs/1606.01540\n- #CODE [Horizon (Facebook) - The first open source reinforcement learning platform for large-scale products and services](https://github.com/facebookresearch/Horizon)\n- #CODE [Keras-rl - Deep Reinforcement Learning for Keras](https://github.com/keras-rl/keras-rl)\n- #CODE [TRFL (pronounced \"truffle\") is a library built on top of TensorFlow that exposes several useful building blocks for implementing Reinforcement Learning agents](https://github.com/deepmind/trfl/)\n- #CODE [Surreal - Open-Source Distributed Reinforcement Learning Framework by Stanford Vision and Learning Lab](https://github.com/SurrealAI/surreal)\n\t- https://surreal.stanford.edu\n- #CODE Tensorforce - Tensorforce is an open-source deep reinforcement learning framework, with an emphasis on modularized flexible library design and straightforward usability for applications in research and practice. \n\t- https://github.com/tensorforce/tensorforce\n\t- https://reinforce.io/blog/introduction-to-tensorforce/\n- #CODE [Tensorlayer](https://github.com/tensorlayer/tensorlayer)\n\t- Deep Learning and Reinforcement Learning Library for Scientists and Engineers\n\t- https://tensorlayer.readthedocs.io/en/latest/index.html\n\n\n## References\n### Deep RL\n- [Spinning Up as a Deep RL Researcher](https://spinningup.openai.com/en/latest/spinningup/spinningup.html)\n\nReview papers:\n- #PAPER [A Brief Survey of Deep Reinforcement Learning (Arulkumaran 2017)](https://arxiv.org/abs/1708.05866)\n\t- Many of the successes in DRL have been based on scaling up prior work in RL to high-dimensional problems. This is due to the learning of low-dimensional feature representations and the powerful function approximation properties of neural networks. By means of representation learning, DRL can deal efficiently with the curse of dimensionality, unlike tabular and traditional non-parametric methods.\n\t- https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-2-Reinforcement-Learning\n- #PAPER [An Introduction to Deep Reinforcement Learning (Fancois-Lavet 2018)](https://arxiv.org/abs/1811.12560)\n- #PAPER [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems (Levine 2020)](https://arxiv.org/abs/2005.01643)\n\n- #PAPER [DQN: Human-level control through Deep Reinforcement Learning (Mnih 2015)](https://deepmind.com/research/dqn/)\n\t- https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf\n- #PAPER [Learning to Optimize (Li 2016)](https://arxiv.org/abs/1606.01885)\n\t- [Learning to Optimize with Reinforcement Learning](https://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/)\n- #PAPER [Deep Recurrent Q-Learning for Partially Observable MDPs (Hausknecht 2017)](https://arxiv.org/abs/1507.06527)\n- #PAPER [Neural Episodic Control (Pritzel 2017)](https://arxiv.org/abs/1703.01988)\n\t- Deep reinforcement learning methods attain super-human performance in a wide range of environments. Such methods are grossly inefficient, often taking orders of magnitudes more data than humans to achieve reasonable performance\n\t- Neural Episodic Control: a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them. \n\t- The agent uses a semi-tabular representation of the value function: a buffer of past experience containing slowly changing state representations and rapidly updated estimates of the value function\n\t- https://www.technologyreview.es/s/6656/olvidese-del-aprendizaje-profundo-el-nuevo-enfoque-de-google-funciona-mucho-mejor\n\t- [Explanation of Neural Episodic Control](https://rylanschaeffer.github.io/content/research/neural_episodic_control/main.html)\n- #PAPER [Supervising strong learners by amplifying weak experts (Christiano 2018)](https://arxiv.org/abs/1810.08575)\n\t- [Learning Complex Goals with Iterated Amplification](https://blog.openai.com/amplifying-ai-training/)\n- #PAPER [MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model (Schrittwieser 2019)](https://deepmind.com/research/publications/MasterinModel)\n\t- https://medium.com/dataseries/deepminds-muzero-is-one-of-the-most-important-deep-learning-systems-ever-created-347442a6793g-Atari-Go-Chess-and-Shogi-by-Planning-with-a-Learned-\n- #PAPER [Decision Transformer: Reinforcement Learning via Sequence Modeling (Chen 2021)](https://arxiv.org/abs/2106.01345v1) ^decisiontransformer\n\t- #CODE https://paperswithcode.com/paper/decision-transformer-reinforcement-learning\n\t- [Paper explained](https://www.youtube.com/watch?v=-buULmf7dec)\n- #PAPER [Reward is enough (Silver 2021)](https://www.sciencedirect.com/science/article/pii/S0004370221000862)\n\t- https://towardsdatascience.com/reward-is-enough-ml-paper-review-e448ee0a6092\n\t- From the authors of ‚ÄúAttention is all you need‚Äù, this paper proposes an intriguing hypothesis that incentivizing AI agents with reward is enough to achieve General Artificial Intelligence\n\t- \"General intelligence, of the sort possessed by humans and perhaps also other animals, may be defined as the ability to flexibly achieve a variety of goals in different contexts. According to our hypothesis, general intelligence can instead be understood as, and implemented by, maximising a singular reward in a single, complex environment4\"","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Self-supervised-learning":{"title":"Self-supervised learning","content":"## Resources\n- https://github.com/jason718/awesome-self-supervised-learning\n- https://hackernoon.com/self-supervised-learning-gets-us-closer-to-autonomous-learning-be77e6c86b5a\n- [Self-Supervised Representation Learning](https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html)\n- [Self-Supervised Vision Models (2021, Dr. Ishan Misra - FAIR)](https://www.youtube.com/watch?v=EXJmodhu4_4)\n- [Self-supervised learning: The dark matter of intelligence](https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/)\n\t- The general technique of self-supervised learning is to predict any unobserved or hidden part (or property) of the input from any observed or unhidden part of the input\n\t- [Blog post explained](https://www.youtube.com/watch?v=Ag1bw8MfHGQ\u0026t=6s)\n\t\n \n## Code\n- #CODE [VISSL](https://github.com/facebookresearch/vissl)\n\t- FAIR's library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images\n- #CODE [Solo-learn](https://github.com/vturrisi/solo-learn)\n\t- A library of self-supervised methods for unsupervised visual representation learning powered by PyTorch Lightning\n\t- Methods available: Barlow Twins, BYOL, DeepCluster V2, DINO, MoCo V2+, NNCLR, ReSSL, SimCLR + Supervised Contrastive Learning, SimSiam, Swav, VICReg, W-MSE\n\t- https://arxiv.org/abs/2108.01775v2\n- #CODE [Lightly](https://github.com/lightly-ai/lightly)\n\t- A python library for self-supervised learning on images\n- #CODE [OpenSelfSup](https://github.com/open-mmlab/OpenSelfSup)\n\t- Self-Supervised Learning Toolbox and Benchmark\n- #CODE [Curator](https://github.com/spaceml-org/Self-Supervised-Learner)\n\t- A No-Code, Self-Supervised Learning and Active Labeling Tool to Create Labeled Image Datasets from Petabyte-Scale Imagery\n\n\n## References\n- #PAPER [Self-Supervised Learning of Pretext-Invariant Representations (Misra 2019)](https://arxiv.org/abs/1912.01991)\n- #PAPER [A Framework For Contrastive Self-Supervised Learning And Designing A New Approach (Falcon 2020)](https://arxiv.org/abs/2009.00104)\n\t- https://towardsdatascience.com/a-framework-for-contrastive-self-supervised-learning-and-designing-a-new-approach-3caab5d29619\n- #PAPER [RegNet - Designing Network Design Spaces (Radosavovic 2020)](https://arxiv.org/abs/2003.13678v1)\n- #PAPER [Transferable Visual Words: Exploiting the Semantics of Anatomical Patterns for Self-supervised Learning (Haghighi 2021)](https://arxiv.org/abs/2102.10680)\n- #PAPER [Instance Localization for Self-supervised Detection Pretraining (Yang 2021)](https://arxiv.org/abs/2102.08318)\n- #PAPER [Supervised Contrastive Learning (Khosla 2021)](https://arxiv.org/abs/2004.11362)\n\t- #CODE https://github.com/google-research/google-research/tree/master/supcon\n\t- #CODE https://keras.io/examples/vision/supervised-contrastive-learning/\n\t- extended the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information\n\t- clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Semi-supervised-learning":{"title":"Semi-supervised learning","content":"## Resources\n- https://en.wikipedia.org/wiki/Semi-supervised_learning\n- Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data).\n- In contrast (to active learning), semi-supervised learning attempts to automatically exploit unlabeled data in addition to labeled data to improve learning performance, where no human intervention is assumed. \n- https://deepai.org/machine-learning-glossary-and-terms/semi-supervised-learning\n- https://scikit-learn.org/stable/modules/label_propagation.html\n\n## Code\n- #CODE [TorchSSL](https://github.com/TorchSSL/TorchSSL)\n\t- A PyTorch-based Toolbox for Semi-Supervised Learning\n\n## References\n- #PAPER [Semi-Supervised Learning Literature Survey (2008)](http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf)\n- #PAPER [Learning Loss Functions for Semi-supervised Learning via Discriminative Adversarial Networks (Nogueira Dos Santos 2017)](https://arxiv.org/abs/1707.02198)\n- #PAPER [Semi-Supervised Learning with Normalizing Flows (Izmailov, 2019)](https://arxiv.org/abs/1912.13025)\n\t- #CODE https://github.com/izmailovpavel/flowgmm\n- #PAPER [Self-training with Noisy Student improves ImageNet classification (Xie 2020)](https://arxiv.org/abs/1911.04252)\n\t- [Paper explained](https://www.youtube.com/watch?v=q7PjrmGNx5A)\n\t- Noisy Student Training, a semi-supervised learning approach that works well even when labeled data is abundant. Noisy Student Training extends the idea of self-training and distillation with the use of equal-or-larger student models and noise added to the student during learning. On ImageNet, we first train an EfficientNet model on labeled images and use it as a teacher to generate pseudo labels for 300M unlabeled images. We then train a larger EfficientNet as a student model on the combination of labeled and pseudo labeled images. We iterate this process by putting back the student as the teacher. During the learning of the student, we inject noise such as dropout, stochastic depth, and data augmentation via RandAugment to the student so that the student generalizes better than the teacher.\n\t- #CODE https://github.com/google-research/noisystudent\n- #PAPER [Big Transfer (BiT):General Visual Representation Learning (Kolesnikov 2020)](https://arxiv.org/abs/1912.11370)\n\t- [Paper explained](https://www.youtube.com/watch?v=k1GOF2jmX7c)\n- #PAPER [Towards a Deeper Understanding of Adversarial Losses (Dong 2020)](https://arxiv.org/abs/1901.08753)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Class-imbalance":{"title":"Class imbalance","content":"## Resources\n- https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis\n- http://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation\n- http://www.alfredo.motta.name/cross-validation-done-wrong/\n- http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/\n- http://www.chioka.in/class-imbalance-problem/\n- http://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html\n- https://svds.com/learning-imbalanced-classes/\n\t- Conventional algorithms are often biased towards the majority class because their loss functions attempt to optimize quantities such as error rate, not taking the data distribution into consideration. Result: a trivial classifier that classifies every example as the majority class.\n\n## Code\n- #CODE [Imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn )\n\t- https://imbalanced-learn.readthedocs.io/en/stable/\n\t- https://imbalanced-learn.readthedocs.io/en/stable/api.html\n- #CODE [Smote_variants](https://github.com/analyticalmindsltd/smote_variants)\n\t- http://smote-variants.readthedocs.io/\n\t-  The package implements 85 variants of the Synthetic Minority Oversampling Technique (SMOTE). Besides the implementations, an easy to use model selection framework is supplied to enable the rapid evaluation of oversampling techniques on unseen datasets. \n\n## Approaches\n### Resampling\n- Balance the training dataset\n- #PAPER [Survey of resampling techniques for improving classification performance in unbalanced datasets (More 2016)](https://arxiv.org/abs/1608.06048)\n\n#### Oversampling\n- #PAPER [SMOTE: Synthetic Minority Over-sampling Technique (Chaula 2002)](https://jair.org/index.php/jair/article/view/10302)\n\t- There are a number of methods available to oversample a dataset used in a typical classification problem (using a classification algorithm to classify a set of images, given a labelled training set of images). The most common technique is known as SMOTE. \n\t- https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n- #PAPER [ADASYN: Adaptive synthetic sampling approach for imbalanced learning (He 2008)](https://ieeexplore.ieee.org/document/4633969)\n\t- https://sci2s.ugr.es/keel/pdf/algorithm/congreso/2008-He-ieee.pdf\n\t- ADASYN builds on the methodology of SMOTE, by shifting the importance of the classification boundary to those minority classes which are difficult. ADASYN uses a weighted distribution for different minority class examples according to their level of difficulty in learning, where more synthetic data is generated for minority class examples that are harder to learn.\n\n#### Undersampling\n- Down-sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm. The most common heuristic for doing so is resampling without replacement.\n- https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n- Cluster. Cluster centroids is a method that replaces cluster of samples by the cluster centroid of a K-means algorithm, where the number of clusters is set by the level of undersampling.\n- Tomek links. Tomek links remove unwanted overlap between classes where majority class links are removed until all minimally distanced nearest neighbor pairs are of the same class. Tomek links are pairs of instances of opposite classes who are their own nearest neighbors. Tomek‚Äôs algorithm looks for such pairs and removes the majority instance of the pair.\n\t- [Classification of Imbalance Data using Tomek Link (T-Link) Combined with Random Under-sampling (RUS) as a Data Reduction Method](https://pdfs.semanticscholar.org/6ec4/18f9071f3a96d5548e87e34be3665703119e.pdf)\n- Throw away minority examples and switch to an anomaly detection framework\n\n### Adjust the class importance or the metric\n- At the algorithm level, or after: Adjust the class weight (misclassification costs), adjust the decision threshold. Many machine learning toolkits have ways to adjust the ‚Äúimportance‚Äù of classes (classifiers that take an optional class_weight). \n- Change the metric. \n\t- Evaluating the classifier: Accuracy is not a good metric for imbalanced classes!!\n\t- Use a ROC curve\n\t- Don‚Äôt get hard classifications (labels) from your classifier (via score or predict). Instead, get probability estimates via proba or predict_proba\n\t- No matter what you do for training, always test on the natural (stratified) distribution your classifier is going to operate upon. Seesklearn.cross_validation.StratifiedKFold\n\t- For a singe metric (value): AUC, F1 (harmonic mean of precision and recall), Cohen‚Äôs Kappa (evaluation statistic that takes into account how much agreement would be expected by chance)\n\t- https://medium.com/towards-data-science/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba\n\t- http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\n\t- The following performance measures that can give more insight into the accuracy of the model than traditional classification accuracy:\n\t\t- Confusion Matrix: A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned).\n\t\t- Precision: A measure of a classifiers exactness.\n\t\t- Recall: A measure of a classifiers completeness\n\t\t- F1 Score (or F-score): A weighted average of precision and recall.\n\t\t- Kappa (or Cohen‚Äôs kappa): Classification accuracy normalized by the imbalance of the classes in the data.\n\t\t- ROC Curves: Like precision and recall, accuracy is divided into sensitivity and specificity and models can be chosen based on the balance thresholds of these values.\n\n### Cost-sensitive training\n- Cost-Sensitive Training. For this tactic we use penalized learning algorithms that increase the cost of classification mistakes on the minority class. A popular algorithm for this technique is Penalized-SVM. During training, we can use the argument class_weight='balanced'  to penalize mistakes on the minority class by an amount proportional to how under-represented it is.\n\n### Select or create a suitable algorithm\n- Create new algorithm for the imbalanced classes situation, or use one which handles the data imbalance\n- #PAPER [Boosting/bagging. Comparing Boosting and Bagging Techniques With Noisy and Imbalanced Data (Khoshgoftaar 2010)](https://ieeexplore.ieee.org/document/5645694?arnumber=5645694)\n\t- The experiments show that the bagging techniques generally outperform boosting, and hence in noisy data environments, bagging is the preferred method for handling class imbalance.","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Classification":{"title":"Classification","content":"---\n\n## Resources\n- https://github.com/jmportilla/Udemy","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Ensemble-learning":{"title":"Ensemble learning","content":"## Resources\n- https://en.wikipedia.org/wiki/Ensemble_learning\n- In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. By analogy, ensemble techniques have been used also in [Unsupervised learning](AI/Unsupervised%20learning/Unsupervised%20learning.md) scenarios, for example in consensus clustering or in anomaly or [Anomaly and Outlier Detection](AI/Anomaly%20and%20Outlier%20Detection.md)\n- In general, ensembling is a technique of combining two or more algorithms of similar or dissimilar types called base learners. This is done to make a more robust system (improving generalizability / robustness over a single estimator) which incorporates the predictions from all the base learners.\n- http://scikit-learn.org/stable/modules/ensemble.html\n- http://mlwave.com/kaggle-ensembling-guide/\n- https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n- http://www.datasciencecentral.com/profiles/blogs/improving-predictions-with-ensemble-model\n- http://www.kdnuggets.com/2016/11/data-science-basics-intro-ensemble-learners.html\n- https://medium.com/diogo-menezes-borges/ensemble-learning-when-everybody-takes-a-guess-i-guess-ec35f6cb4600\n- https://blog.statsbot.co/ensemble-learning-d1dcd548e936\n- [How to Reduce Variance in the Final DL Model With a Horizontal Voting Ensemble](https://machinelearningmastery.com/horizontal-voting-ensemble/)\n\n### Bagging\n- With bootstrap aggregating (Bagging) we build models of smaller datasets by sampling with replacement. The results of these bootstrap samples are then aggregated, using majority voting (equal weighting of models)\n- See [Random forest](AI/Supervised%20Learning/Random%20forest.md)\n\n### Boosting\nSee [Gradient boosting](AI/Supervised%20Learning/Gradient%20boosting.md)\n- Same as bagging but operates via weighted voting. Algorithm proceeds iteratively (one tries to reduce the bias of the combined estimator); new models are influenced by previous ones. E.g. AdaBoost (Adaptive Boosting) and LogitBoost\n- https://en.wikipedia.org/wiki/AdaBoost\n\n### Stacking\n- uses a meta learner (as opposed to bagging/boosting which use voting schemes)\n- It consists in training multiple learners/algorithms (as opposed to bagging/boosting which train a single learner).  Each learner uses a subset of data. \n- A \"combiner\" is trained on a validation set. This combiner can be any ensemble technique, but logistic regression is often found to be an adequate and simple algorithm to perform this combining.\n- http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/\n- https://machinelearningmastery.com/ensemble-methods-for-deep-learning-neural-networks/","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Feature-selection":{"title":"Feature selection","content":"See:\n- \"Regularized regression\" section in [Regression](AI/Supervised%20Learning/Regression.md)\n- [Feature learning](AI/Feature%20learning.md)\n\n## Resources\n- https://en.wikipedia.org/wiki/Feature_selection\n- http://machinelearningmastery.com/an-introduction-to-feature-selection/\n- http://scikit-learn.org/stable/modules/feature_selection.html\n- [Removing features with low variance](http://scikit-learn.org/stable/modules/feature_selection.html#removing-features-with-low-variance)\n- [Univariate feature selection](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)\n- [Recursive feature elimination](http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination)\n- Regularization: \n\t- http://scikit-learn.org/stable/modules/feature_selection.html#l1-based-feature-selection\n\t- https://en.wikipedia.org/wiki/Regularization_(mathematics)\n\t- Penalized regression has been applied widely across many research disciplines, but it is a great fit for business data with many columns, even data sets with more columns than rows, and for data sets with a lot of correlated variables. L1/LASSO penalties drive unnecessary regression parameters to zero, selecting a small, representative subset of regression parameters for the regression model while avoiding potential multiple comparison problems that arise in forward, backward, and stepwise variable selection. Tikhonov/L2/ridge penalties help preserve parameter estimate stability, even when many correlated variables exist in a wide data set or important predictor variables are correlated. It‚Äôs also important to know penalized regression techniques don‚Äôt always create confidence intervals, t-statistics, or p-values for regression parameters. These types of measures are typically only available through iterative methods or bootstrapping that can require extra computing time.\n\t- https://www.quora.com/What-is-regularization-in-machine-learning\n\t- The loss function is penalized by adding an L1 or L2 norm of the weights vector W (the vector of the learned parameters in the linear regression):\n\t\t- L(X,Y) + lambda N(W), where N is either the L1, L2 or any other norm.\n\t\t- This helps avoiding overfitting and performs fetuses selection for the case of the L1 regularization. Lambda can be chosen by cross-validation. \n- Tree-based methods\n\t- [Random forest, extra trees. Feature importances with forests of trees](http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)\n\t- XGBoost, Feature importance and why it‚Äôs important: \n\t\t- http://datawhatnow.com/feature-importance/\n\t\t- http://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/\n\t\t- Importance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity (Gini index) used to select the split points or another more specific error function. The feature importances are then averaged across all of the the decision trees within the model.\n\n## Books\n- #BOOK [Feature Engineering and Selection: A Practical Approach for Predictive Models (Kuhn 2018)](http://www.feat.engineering/index.html)\n\n## Code \n- #CODE [Scikit-feature](https://github.com/jundongl/scikit-feature)\n\t- http://featureselection.asu.edu/\n- #CODE Feature-selector - Feature selector is a tool for dimensionality reduction of machine learning datasets.\n\t- Methods: Missing Values, Single Unique Values, Collinear Features, Zero Importance Features, Low Importance Features\n    - https://github.com/WillKoehrsen/feature-selector/blob/master/Feature%20Selector%20Usage.ipynb\n    - https://towardsdatascience.com/a-feature-selection-tool-for-machine-learning-in-python-b64dd23710f0\n- #CODE [ITMO_FS](https://github.com/ctlab/ITMO_FS)\n\t- Feature selection library in python\n\t- https://itmo-fs.readthedocs.io/en/latest/","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Gaussian-Process":{"title":"Gaussian Process","content":"## Resources\n- In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i.e. every finite linear combination of them is normally distributed. The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.\n- A machine-learning algorithm that involves a Gaussian process uses lazy learning and a measure of the similarity between points (the kernel function) to predict the value for an unseen point from training data. The prediction is not just an estimate for that point, but also has uncertainty information‚Äîit is a one-dimensional Gaussian distribution (which is the marginal distribution at that point).\n- https://en.wikipedia.org/wiki/Gaussian_process\n- http://scikit-learn.org/stable/modules/gaussian_process.html\n- [A Practical Guide to Gaussian Processes](https://drafts.distill.pub/gp/ )\n- A Visual Exploration of Gaussian Processes\n\t- https://www.jgoertler.com/visual-exploration-gaussian-processes/\n\t- https://blog.dominodatalab.com/fitting-gaussian-process-models-python/\n- [Gaussian processes](http://krasserm.github.io/2018/03/19/gaussian-processes/)\n- [Deep Neural Networks and Gaussian Processes: Similarities, Differences, and Trade-Offs](https://towardsdatascience.com/deep-neural-networks-vs-gaussian-processes-similarities-differences-and-trade-offs-18647376d799)\n\n## Code\n- #CODE [GPy](https://github.com/SheffieldML/GPy)\n- #CODE [GPyTorch](https://github.com/cornellius-gp/gpytorch)\n\t- https://gpytorch.ai/\n- #CODE [GPFlow](https://github.com/GPflow/GPflow)\n\t- https://gpflow.readthedocs.io/en/master/intro.html\n- #CODE [GPflux](https://github.com/secondmind-labs/GPflux)\n\t- GPflux uses the mathematical building blocks from GPflow and marries these with the powerful layered deep learning API provided by Keras. \n\t- https://secondmind-labs.github.io/GPflux/tutorials.html\n\n\n## Books and review papers\n- #BOOK [Bayesian Optimization Book (Garnett 2021)](https://bayesoptbook.com/)\n- #PAPER [An Intuitive Tutorial to Gaussian Processes Regression (Wang 2021)](https://arxiv.org/abs/2009.10862)\n- #PAPER [Deep Gaussian Processes: A Survey (Jakkala 2021)](https://arxiv.org/abs/2106.12135)\n\n\n## References\n- #PAPER [Gaussian Processes for Machine Learning (Rasmussen and Williams 2006)](http://www.gaussianprocess.org/gpml/)\n\t- http://www.gaussianprocess.org/gpml/chapters/RW.pdf\n- #PAPER [Convolutional Gaussian Processes (van der Wilk 2017)](https://arxiv.org/abs/1709.01894)\n\t- #CODE https://gpflow.readthedocs.io/en/master/notebooks/advanced/convolutional.html\n- #PAPER [Deep convolutional Gaussian processes (Blomqvist 2018)](https://arxiv.org/abs/1810.03052)\n\t- #CODE https://github.com/kekeblom/DeepCGP\n\t- https://github.com/kekeblom/DeepCGP/blob/master/notebooks/Inspect.ipynb\n- #PAPER [Gaussian processes meet NeuralODEs: A Bayesian framework for learning the dynamics of partially observed systems from scarce and noisy data (Aziz Bhouri 2021)](https://arxiv.org/abs/2103.03385)\n\t- #CODE https://github.com/PredictiveIntelligenceLab/GP-NODEs","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Gradient-boosting":{"title":"Gradient boosting","content":"See  [Ensemble learning](AI/Supervised%20Learning/Ensemble%20learning.md)\n\n## Resources\n- Outperforms Random Forests and AdaBoost. RF is easier to tune and less prone to overfitting\n- http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html\n- http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html\n- https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/\n- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n\n## Code\n- #CODE [Xgboost](https://github.com/dmlc/xgboost)\n\t- Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library, for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Flink and DataFlow\n\t- https://xgboost.readthedocs.org/\n\t- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n- #CODE [Light GBM](https://github.com/microsoft/LightGBM)\n\t- a very high-performance gradient boosting tree framework (supporting GBDT, GBRT, GBM, and MART), and its distributed implementation. Part of DMTK (Microsoft)\n\t- https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/\n\t- https://www.techleer.com/articles/489-lightgbm-a-light-gradient-boosting-machine/\n- #CODE [CatBoost](https://github.com/catboost/catboost/)\n\t- https://catboost.ai/\n\t- https://catboost.ai/docs/\n\t- A fast, scalable, high performance Gradient Boosting on Decision Trees library, used for ranking, classification, regression and other machine learning tasks for Python, R, Java, C++. Supports computation on CPU and GPU\n\t- [CatBoost vs. Light GBM vs. XGBoost](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db)\n- #CODE https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n\n\n## References\n- #PAPER [Probabilistic Gradient Boosting Machines for Large-Scale Probabilistic Regression (Sprangers 2021)](https://arxiv.org/abs/2106.01682v2)\n\t- #CODE https://paperswithcode.com/paper/probabilistic-gradient-boosting-machines-for?from=n11","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Model-selection-and-tuning":{"title":"Model selection and tuning","content":"See:  \n- [AutoML](AI/AutoML.md)\n- [Data engineering and computer science](AI/DS%20and%20DataEng/Data%20engineering%20and%20computer%20science.md)\n\n\n## Resources\n- [Model selection and evaluation](https://scikit-learn.org/stable/model_selection.html)\n\n## Code\nSee [ML Ops](AI/DS%20and%20DataEng/ML%20Ops.md)\n- #CODE [Optuna - A hyperparameter optimization framework](https://github.com/optuna/optuna)\n\t- https://optuna.org/\n- #CODE [Yellowbrick. Visual analysis and diagnostic tools to facilitate machine learning model selection](http://www.scikit-yb.org/en/latest/)\n- #CODE [Tune-sklearn](https://github.com/ray-project/tune-sklearn)\n\t- Tune-sklearn is a drop-in replacement for Scikit-Learn‚Äôs model selection module (GridSearchCV, RandomizedSearchCV) with cutting edge hyperparameter tuning techniques\n- #CODE [Talos. Hyperparameter Optimization for Keras Models](https://autonomio.github.io/docs_talos/#introduction)\n- #CODE [Hyperopt. Distributed Asynchronous Hyperparameter Optimization in Python](http://hyperopt.github.io/hyperopt)\n\t- [Hyperparameter optimization for neural networks](https://github.com/hyperopt/hyperopt-nnet)\n\t- [Hyperopt-sklearn](http://hyperopt.github.io/hyperopt-sklearn/)\n\t- #CODE [Hyperas- Keras + Hyperopt: A very simple wrapper for convenient hyperparameter optimization](https://github.com/maxpumperla/hyperas)\n\t\t- http://maxpumperla.github.io/hyperas/\n- #CODE [Hyperband - A Novel Bandit-Based Approach to Hyperparameter Optimization](https://github.com/zygmuntz/hyperband)\n\t- #PAPER https://arxiv.org/abs/1603.06560\n\t- http://fastml.com/tuning-hyperparams-fast-with-hyperband/\n\n## Bias-variance trade-off\n- Problem of minimizing two sources of errors that prevent a supervised learning algorithm from generalizing beyond the training set:\n\t- High bias  -\u003e  underfitting\n\t- High variance  -\u003e  overfitting\n- [Validation curves: plotting scores to evaluate models](https://scikit-learn.org/stable/modules/learning_curve.html)\n- https://www.quora.com/How-would-you-explain-the-bias-variance-tradeoff-to-a-five-year-old\n- http://scott.fortmann-roe.com/docs/BiasVariance.html\n- http://scott.fortmann-roe.com/docs/MeasuringError.html\n- https://elitedatascience.com/bias-variance-tradeoff\n- [Overfitting](https://en.wikipedia.org/wiki/Overfitting)\n\t- https://www.quora.com/What-is-an-intuitive-explanation-of-overfitting\n\t- https://www.quora.com/How-can-I-avoid-overfitting\n\t- https://www.quora.com/How-do-we-detect-overfitting-and-under-fitting-in-Machine-Learning\n\n## Cross-validation\n- [Train, test and validation](https://machinelearningmastery.com/difference-test-validation-datasets/)\n- [Train, test, validation split and cross-validation (scikit-learn documentation)](http://scikit-learn.org/stable/modules/cross_validation.html)\n- http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n- https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html\n- https://blog.dataiku.com/model-sucks-evaluating-models-validation-set-infographic\n- [Making Predictive Models Robust: Holdout vs Cross-Validation](https://www.kdnuggets.com/2017/08/dataiku-predictive-model-holdout-cross-validation.html)\n- [How to Train a Final ML Model](http://machinelearningmastery.com/train-final-machine-learning-model/)\n- http://nbviewer.jupyter.org/github/cs109/content/blob/master/lec_10_cross_val.ipynb\n- [Hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning))\n- [Tuning the hyper-parameters of an estimator (scikit-learn documentation)](https://scikit-learn.org/stable/modules/grid_search.html)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Random-forest":{"title":"Random forest","content":"See [Ensemble learning](AI/Supervised%20Learning/Ensemble%20learning.md)\n\n## Resources\n- https://github.com/kjw0612/awesome-random-forest\n- https://sebastianraschka.com/faq/docs/bagging-boosting-rf.html\n- Bagging and random forests are ‚Äúbagging‚Äù algorithms that aim to reduce the complexity of models that overfit the training data. In contrast, boosting is an approach to increase the complexity of models that suffer from high bias, that is, models that underfit the training data\n- https://scikit-learn.org/stable/modules/ensemble.html#random-forests\n- http://www.listendata.com/2014/11/random-forest-with-r.html\n- https://medium.com/rants-on-machine-learning/the-unreasonable-effectiveness-of-random-forests-f33c3ce28883\n- In particular, trees that are grown very deep tend to learn highly irregular patterns: they overfit their training set or have low bias, but very high variance. Random forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance. This comes at the expense of a small increase in the bias and some loss of interpretability, but generally greatly boosts the performance of the final model.\n\n\n## References\n- #THESIS/PHD [Understanding Random Forests: From Theory to Practice (Louppe 2014)](https://arxiv.org/abs/1407.7502)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Regression":{"title":"Regression","content":"---\n\nSee: \n- [Time Series analysis](AI/Time%20Series%20analysis.md)\n- [RNNs](AI/Deep%20learning/RNNs.md)\n- \"Sequence time series modelling\" section in [CNNs](AI/Deep%20learning/CNNs.md)\n\n\n## Resources\n- https://www.analytics. idhya.com/blog/2015/08/comprehensive-guide-regression/\n- https://towardsdatascience.com/a-beginners-guide-to-regression-analysis-in-machine-learning-8a828b491bbf\n- http://www.datasciencecentral.com/profiles/blogs/10-types-of-regressions-which-one-to-use\n- http://www.datasciencecentral.com/profiles/blogs/23-types-of-regression\n- [Curve fitting vs regression](https://blog.datazar.com/curve-fitting-vs-regression-752ce295b0b1)\n- Goodness of fit:\n\t- [Coefficient of determination (The R-squared measure of goodness of fit)](http://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)\n\t- Reduced chi-squared\n- [Linear models](http://scikit-learn.org/stable/modules/linear_model.html)\n\n\n### Linear Regression\n- https://en.wikipedia.org/wiki/Linear_regression\n- In statistics, linear regression is an approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression.\n- http://www.datasciencecentral.com/profiles/blogs/linear-regression-geometry\n- https://github.com/jmportilla/Udemy","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Supervised-Learning/Supervised-learning":{"title":"Supervised Learning","content":"## Resources\n- https://en.wikipedia.org/wiki/Supervised_learning\n- [Supervised Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning)\n- http://scikit-learn.org/stable/supervised_learning.html\n- Metrics:\n\t- http://docs.aws.amazon.com/machine-learning/latest/dg/binary-model-insights.html\n\t- ROC curves, AUC\n\t\t- http://www.dataschool.io/roc-curves-and-auc-explained/\n\t\t- http://corysimon.github.io/articles/what-is-an-roc-curve/\n\n\n### Classification\nSee [Classification](AI/Supervised%20Learning/Classification.md)\n\n### Regression\nSee [Regression](AI/Supervised%20Learning/Regression.md)\n\n### Structured learning\n- https://en.wikipedia.org/wiki/Structured_prediction\n\n### Ensemble learning\nSee [Ensemble learning](AI/Supervised%20Learning/Ensemble%20learning.md)\n\n### Class imbalance\nSee [Class imbalance](AI/Supervised%20Learning/Class%20imbalance.md)\n\n### Model selection and tuning\nSee [Model selection and tuning](AI/Supervised%20Learning/Model%20selection%20and%20tuning.md)\n\n### Probability calibration\n- https://en.wikipedia.org/wiki/Calibration_(statistics)\n- https://scikit-learn.org/stable/modules/calibration.html\n- When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction. \n- Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class.\n- https://scikit-learn.org/stable/auto_examples/calibration/plot_compare_calibration.html\n- Isotonic regression: \n\t- https://scikit-learn.org/stable/modules/isotonic.html\n\t- Isotonic regression is a probability calibration technique which can calibrate classifier scores to approximate probability values by fitting a stepwise non-decreasing function along the scores returned by the classifier.","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Time-Series-analysis":{"title":"Time series analysis","content":"See: \n- [Forecasting](AI/Forecasting.md)\n- [RNNs](AI/Deep%20learning/RNNs.md)\n- \"Sequence (time series) modelling\" section in [CNNs](AI/Deep%20learning/CNNs.md)\n- \"Deep learning for tabular data\" section in [DL](AI/Deep%20learning/DL.md)\n\n## Resources\n- https://en.wikipedia.org/wiki/Time_series\n- https://github.com/MaxBenChrist/awesome_time_series_in_python\n- https://github.com/frutik/awesome-timeseries\n- https://github.com/cuge1995/awesome-time-series\n- http://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n- [Python to work with time series data](https://github.com/MaxBenChrist/awesome_time_series_in_python)\n- [timeseriesAI](https://github.com/timeseriesAI)\n\n## Code\nSee code in [Forecasting](AI/Forecasting.md)\n\n- #CODE [Orbit](https://github.com/uber/orbit)\n\t- A Python package for Bayesian forecasting with object-oriented design and probabilistic models under the hood.\n\t- https://eng.uber.com/the-new-version-of-orbit-v1-1-is-released/\n- #CODE [TSflex](https://github.com/predict-idlab/tsflex)\n\t- https://predict-idlab.github.io/tsflex/\n- #CODE [Merlion](https://github.com/salesforce/merlion)\n\t- #PAPER [Merlion: A Machine Learning Library for Time Series (Bhatnagar 2021)](https://arxiv.org/abs/2109.09265)\n\t- Merlion is a Python library for time series intelligence\n- #CODE [Kats](https://github.com/facebookresearch/Kats) ^kats\n\t- Kats, a kit to analyze time series data, a lightweight, easy-to-use, generalizable, and extendable framework to perform time series analysis, from understanding the key statistics and characteristics, detecting change points and anomalies, to forecasting future trends\n\t- https://facebookresearch.github.io/Kats/\n\t- https://engineering.fb.com/2021/06/21/open-source/kats/\n\t- https://towardsdatascience.com/kats-a-generalizable-framework-to-analyze-time-series-data-in-python-3c8d21efe057\n- #CODE [Sktime](https://github.com/alan-turing-institute/sktime)\n\t- https://towardsdatascience.com/sktime-a-unified-python-library-for-time-series-machine-learning-3c103c139a55\n- #CODE [Tsfresh - Time Series Feature extraction based on scalable hypothesis tests](https://github.com/blue-yonder/tsfresh)\n\t- [Automatic extraction of relevant features from time series](http://tsfresh.readthedocs.io)\n- #CODE [TSFEL](https://github.com/fraunhoferportugal/tsfel)\n\t- #PAPER [TSFEL: Time Series Feature Extraction Library (Barandas 2020)](https://www.sciencedirect.com/science/article/pii/S2352711020300017)\n- #CODE [Tslearn - A machine learning toolkit dedicated to time-series data](https://github.com/rtavenar/tslearn)\n- #CODE [Pmdarima](https://github.com/alkaline-ml/pmdarima)\n\t- Pyramid bridges one more gap between R and Python by bringing R's auto.arima to Python. Pyramid wraps statsmodels' well-tested ARIMA and SARIMAX estimators.\n - #CODE [Tick](https://github.com/X-DataInitiative/tick)\n\n\n\n## Subtopics\n\n### Time Series Forecasting\nSee [Forecasting](AI/Forecasting.md)\n\n### Anomaly and Outlier Detection\nSee [Anomaly and Outlier Detection](AI/Anomaly%20and%20Outlier%20Detection.md)\n\n### TS models\n- [Autoregressive](https://en.wikipedia.org/wiki/Autoregressive)\n- [Moving average](https://en.wikipedia.org/wiki/Moving_average_model)\n- [Autoregressive moving average (ARMA)](https://en.wikipedia.org/wiki/Autoregressive_moving_average)\n- [Autoregressive integrated moving average (ARIMA)](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average)\n- [Generalized additive model (GAM)](https://en.wikipedia.org/wiki/Generalized_additive_model)\n\t- http://www.kdnuggets.com/2017/04/time-series-analysis-generalized-additive-models.html\n\n### TS classification\n- [UEA \u0026 UCR Time Series Classification Repository](http://www.timeseriesclassification.com/)\n\t- [Datasets](http://www.timeseriesclassification.com/dataset.php)\n- [Dynamic time warping](https://en.wikipedia.org/wiki/Dynamic_time_warping)\n\t- DTW is one of the algorithms for measuring similarity between two temporal sequences, which may vary in speed\n- https://medium.com/@hassanismailfawaz/deep-learning-for-time-series-classification-a-brief-overview-73b58767ed0f\n\n- #PAPER [ROCKET: Exceptionally fast and accurate time series classification using random convolutional kernels (Dempster 2019)](https://arxiv.org/abs/1910.13051)\n- #PAPER [InceptionTime: Finding AlexNet for Time Series Classification (Ismail Fawaz 2019)](https://arxiv.org/abs/1909.04939)\n- #PAPER [Deep learning for time series classification: a review (Ismail Fawaz 2019)](https://arxiv.org/abs/1809.04356)\n\t- #CODE https://github.com/hfawaz/dl-4-tsc\n\t- https://medium.com/@hassanismailfawaz/deep-learning-for-time-series-classification-a-brief-overview-73b58767ed0f\n- #PAPER [TS-CHIEF: A Scalable and Accurate Forest Algorithm for Time Series Classification (Shifaz 2020)](https://arxiv.org/abs/1906.10329)\n\n\n### Time-frequency analysis\n- [Fourier analysis](https://en.wikipedia.org/wiki/Fourier_analysis)\n\t- [Fast Fourier transform](https://en.wikipedia.org/wiki/Fast_Fourier_transform)\n\t\t- A fast Fourier transform (FFT) is an algorithm that computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IDFT).\n- [Continuous wavelet transform](https://en.wikipedia.org/wiki/Continuous_wavelet_transform)\n  \n### Causality\nSee [Causality](AI/Causality.md)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Transfer-learning":{"title":"Transfer learning","content":"## Resources\n- https://en.wikipedia.org/wiki/Transfer_learning\n- Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem\n- https://github.com/artix41/awesome-transfer-learning\n- [Domain adaptation](https://en.wikipedia.org/wiki/Domain_adaptation)\n\t- Domain adaptation is a field associated with machine learning and transfer learning. This scenario arises when we aim at learning from a source data distribution a well performing model on a different (but related) target data distribution\n\n\n## Code\n- #CODE [pytorch-adapt](https://github.com/KevinMusgrave/pytorch-adapt)\n\t- Domain adaptation made easy. Fully featured, modular, and customizable\n\t- https://kevinmusgrave.github.io/pytorch-adapt/\n- #CODE [TLlib](https://github.com/thuml/Transfer-Learning-Library)\n\t- open-source and well-documented library for Transfer Learning. It is based on pure PyTorch with high performance and friendly API\n- #code [Salad](https://github.com/domainadaptation/salad)\n\t- https://domainadaptation.org/\n- #code [Robustness](https://github.com/bethgelab/robustness)\n\t- https://domainadaptation.org/robusta/\n\n\n## References\n- #PAPER [A Brief Review of Domain Adaptation (Farahani 2020)](https://arxiv.org/abs/2010.03978)\n- #PAPER [On the Opportunities and Risks of Foundation Models (Bommasani 2021)](https://arxiv.org/abs/2108.07258)\n\t- A foundation model is any model that is trained on broad data at scale and can be adapted (e.g., fine-tuned) to a wide range of downstream tasks; current examples include BERT, GPT-3, and CLIP\n\t- Foundation models are based on deep neural networks and self-supervised learning\n\t- On a technical level, foundation models are enabled by transfer learning and scale\n\t- The idea of transfer learning is to take the ‚Äúknowledge‚Äù learned from one task (e.g., object recognition in images) and apply it to another task (e.g., activity recognition in videos).\n\t- Within deep learning, pretraining is the dominant approach to transfer learning: a model is trained on a surrogate task (often just as a means to an end) and then adapted to the downstream task of interest via fine-tuning\n\t- Transfer learning is what makes foundation models possible, but scale is what makes them powerful. Scale required three ingredients: improvements in computer hardware, the development of the Transformer model architecture that leverages the parallelism of the hardware to train much more expressive models than before and the availability of much more training data","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Unsupervised-learning/Clustering":{"title":"Clustering","content":"## Resources\n- Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters).\n- http://scikit-learn.org/stable/modules/clustering.html\n- Hierarhical clustering: Method of cluster analysis which seeks to build a hierarchy of clusters. Strategies for hierarchical clustering generally fall into two types:\n\t- Agglomerative: This is a \"bottom up\" approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.\n\t- Divisive: This is a \"top down\" approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.\n\t- The results of hierarchical clustering are usually presented in a dendrogram. The complexity of agglomerative clustering is O(n^2log(n)), slow for large data. Divisive clustering with an exhaustive search is O(2^n), which is even worse.\n\t- https://blog.alookanalytics.com/2017/04/11/intuition-vs-unsupervised-learning-agglomerative-clustering-in-practice/\n\t- Single linkage: Single-linkage clustering is one of several methods of hierarchical clustering. It is based on grouping clusters in bottom-up fashion (agglomerative clustering), at each step combining two clusters that contain the closest pair of elements not yet belonging to the same cluster as each other. A drawback of this method is that it tends to produce long thin clusters in which nearby elements of the same cluster have small distances, but elements at opposite ends of a cluster may be much farther from each other than to elements of other clusters. The naive version has a time complexity of O(n^3). There are improvements: SLINK and Kruskal's algo, with time complexity O(n^2).\n\t- Mean linkage\n\t\t- [Unweighted Pair Group Method with Arithmetic Mean](https://en.wikipedia.org/wiki/UPGMA)\n\t    - [Weighted Pair Group Method with Arithmetic Mean](https://en.wikipedia.org/wiki/WPGMA)\n\t- Ward‚Äôs method: Ward's minimum variance criterion minimizes the total within-cluster variance.\n\t  To implement this method, at each step find the pair of clusters that leads to minimum increase in total within-cluster variance after merging. This increase is a weighted squared distance between cluster centers. At the initial step, all clusters are singletons (clusters containing a single point).\n\t- Complete linkage: The method is also known as farthest neighbour clustering. At the beginning of the process, each element is in a cluster of its own. The clusters are then sequentially combined into larger clusters until all elements end up being in the same cluster. At each step, the two clusters separated by the shortest distance are combined. \n\t  The definition of 'shortest distance' is what differentiates between the different agglomerative clustering methods. \n\t  In complete-linkage clustering, the link between two clusters contains all element pairs, and the distance between clusters equals the distance between those two elements (one in each cluster) that are farthest away from each other. Complexity O(n^3), CLINK version with O(n^2).\n- [K-means](https://en.wikipedia.org/wiki/K-means_clustering)\n\t- k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. The standard k-means algorithm is called Lloyd's algorithm:\n\t\t- Initialization: Forgy method (taking k random observations from the data set), random partitioning or k-means++ methods \n\t\t- 2 steps: assignment and update (the \"assignment\" step is also referred to as expectation step, the \"update step\" as maximization step, making this algorithm a variant of the generalized expectation-maximization algorithm):\n\t\t\t- Assignment: Assign each observation to the cluster whose mean yields the least within-cluster sum of squares (WCSS). Also called ‚ÄúExpectation step‚Äù because it involves updating our expectation of which cluster each point belongs to\n\t\t\t- Update step: Calculate the new means to be the centroids of the observations in the new clusters. This also minimizes the within-cluster sum of squares (WCSS) objective. Also called ‚ÄúMaximization step‚Äù because it involves maximizing some fitness function that defines the location of the cluster centers ‚Äî in this case, that maximization is accomplished by taking a simple mean of the data in each cluster\n\t  - http://stanford.edu/~cpiech/cs221/handouts/kmeans.html  \n\t  - [Five Minutes With Ingo - K Means Clustering](https://www.youtube.com/watch?v=wGzumILN5ww)\n- DBSCAN \n\t- [Density-based spatial clustering of applications with noise](https://en.wikipedia.org/wiki/DBSCAN)\n- [HDBSCAN](http://hdbscan.readthedocs.io/en/latest/soft_clustering_explanation.html)\n- Embeddings\n\t- http://projector.tensorflow.org\n\t- https://www.tensorflow.org/versions/master/how_tos/embedding_viz/index.html\n\n\n## References\n- #PAPER [k-means++: the advantages of careful seeding (Arthur 2007)](https://dl.acm.org/doi/10.5555/1283383.1283494)\n- #PAPER [A Comparative Study of Efficient Initialization Methods for the K-Means Clustering Algorithm (Celebi 2012)](https://arxiv.org/abs/1209.1960)\n- #PAPER [SCAN: Learning to Classify Images without Labels (Van Gansbeke 2020)](https://arxiv.org/abs/2005.12320)\n\t- #CODE https://github.com/wvangansbeke/Unsupervised-Classification\n\t- [Paper explained](https://www.youtube.com/watch?v=hQEnzdLkPj4)\n\t- grouping images into semantically meaningful clusters when ground-truth annotations. This is tackling the task of unsupervised image classification in [Computer vision](AI/Computer%20Vision/Computer%20vision.md)\n\t- advocate a two-step approach where feature learning and clustering are decoupled. First, a self-supervised task from representation learning is employed to obtain semantically meaningful features.Second, we use the obtained features as a prior in a learnable clustering  approach.  In  doing  so,  we  remove  the  ability  for  cluster  learning to depend on low-level features, which is present in current end-to-end learning approaches\n- #PAPER [Deep Robust Clustering by Contrastive Learning (Zhong 2020)](https://arxiv.org/abs/2008.03030)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Unsupervised-learning/Dimensionality-reduction-and-low-rank-modeling":{"title":"Dimensionality reduction and low-rank modeling","content":"## Resources and references\n- [The Beginner's Guide to Dimensionality Reduction](https://idyll.pub/post/visxai-dimensionality-reduction-1dbad0a67a092b007c526a45/)\n- [Distances, Neighborhoods, or Dimensions? Projection Literacy for the Analysis of Multivariate Data](https://visxprojections.dbvis.de/client/index.html)\n- [Decomposing signals in components (matrix factorization problems)](https://scikit-learn.org/stable/modules/decomposition.html)\n- Projection techniques transform high-dimensional data to a lower-dimensional space while preserving its main structure. Often, the data is transformed to two-dimensional space and visualized as a scatter plot as a means to analyze and understand the data\n- Two categories: linear and non-linear projection techniques. \n\n### Linear methods\n- Linear projection techniques produce a linear transformation of data dimensions in lower-dimensional space. Proximity between data points indicates similarity. The more similar data points are, the closer they are located to each other and vice versa. This is why linear projection techniques are also known as global techniques.\n\n#### Principal component analysis (PCA)\n- Principal component analysis(PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. The number of principal components is less than or equal to the number of original variables. This transformation is defined in such a way that the first principal component has the largest possible variance(that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors are an uncorrelated orthogonal basis set.\n- http://setosa.io/ev/principal-component-analysis/\n- https://www.neuraldesigner.com/blog/principal-components-analysis\n- #PAPER [EigenGame: PCA as a Nash Equilibrium (Gemp 2021)](https://openreview.net/forum?id=NzTU59SYbNq)\n\t- https://pub.towardsai.net/deepmind-wants-to-reimagine-one-of-the-most-important-algorithms-in-machine-learning-381884d42de\n\n#### Non-negative matrix factorization (NMF)\n- Non-negative matrix factorization (NNMF, or NMF) is a method for factorizing a matrix into two lower rank matrices with strictly non-negative elements.\n- https://en.wikipedia.org/wiki/Non-negative_matrix_factorization\n- https://yliapis.github.io/Non-Negative-Matrix-Factorization/\n- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\n- https://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py\n\n#### Generalized Low Rank Models\n- Extension of the idea of PCA to handle arbitrary data sets consisting of numerical, Boolean, categorical, ordinal, and other data types. This framework encompasses many well known techniques in data analysis, such as nonnegative matrix factorization, matrix completion, sparse and robust PCA,-means,-SVD, and maximum margin matrix factorization. The method handles heterogeneous data sets, and leads to coherent schemes for compressing, denoising, and imputing missing entries across all data types simultaneously. It also admits a number of interesting interpretations of the low rank factors, which allow clustering of examples or of features.\n\t- https://github.com/cehorn/GLRM\n\t- #TALK [Generalized Low Rank Models - Madeleine Udell](https://www.youtube.com/watch?v=zwvzGuS82MA)\n\t- #TALK Introduction to generalized low-rank models and missing values (OREILLY): \n\t  - https://conferences.oreilly.com/strata/strata-eu-2016/public/schedule/detail/49771\n\t  - http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glrm.html\n\n#### Dynamic mode decomposition\n- https://en.wikipedia.org/wiki/Dynamic_mode_decomposition\n- linear dimensionality reduction technique for high-dimensional time-series originating from fluid dynamics. DMD combines the best of two worlds: PCA and Fourier transform. Mathematically, it is related to a fundamental operator in dynamical system theory known as the Koopman operator\n- [A case against PCA for time-series analysis](https://towardsdatascience.com/a-case-against-pca-for-time-series-analysis-ac66b47629e0)\n\t- Recent studies have shown that DMD behaves as a source separation algorithm (e.g. ICA), although this framework can be more flexible\n\t- For a similar computational cost, it moreover provides a far more interpretable model than PCA\n\n### Non-linear methods\n- Non-linear projection techniques, also known as local projection techniques, aim at preserving the local neighborhoods across the features in the data. Hereby, proximity highlights differences and coherences between observations and is not to put on the same level as similarity\n\n#### Multidimensional scaling (MDS)\n- Multidimensional scaling (MDS) is a means of visualizing the level of similarity of individual cases of a dataset. It refers to a set of related ordination techniques used in information visualization, in particular to display the information contained in a distance matrix. It is a form of non-linear dimensionality reduction.\n\n#### Self organizing maps (SOM)\n- https://en.wikipedia.org/wiki/Self-organizing_map\n- unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while preserving the topological structure of the data\n- https://stackabuse.com/self-organizing-maps-theory-and-implementation-in-python-with-numpy/\n\n#### T-distributed Stochastic Neighbor Embedding (t-SNE)\n- http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n- t-SNE is a tool to visualize high-dimensional data. It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with different initializations we can get different results.\n- t-SNE is a technique for nonlinear dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. The technique can be implemented via Barnes-Hut approximations, allowing it to be applied on large real-world datasets. It is particularly well-suited for embedding high-dimensional data into a space of two or three dimensions, which can then be visualized in a scatter plot. Specifically, it models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points.\n- https://mark-borg.github.io/blog/2016/tsne/\n- https://blog.alookanalytics.com/2017/02/28/analytical-market-segmentation-with-t-sne-and-clustering-pipeline/\n- [How to Use t-SNE Effectively (Interactive)](http://distill.pub/2016/misread-tsne/)\n\n#### Uniform Manifold Approximation and Projection (UMAP)\n- #PAPER [UMAP - Uniform Manifold Approximation and Projection for Dimension Reduction (McInnes 2020)](https://arxiv.org/abs/1802.03426)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Unsupervised-learning/Unsupervised-learning":{"title":"Unsupervised learning","content":"## Resources\n- https://en.wikipedia.org/wiki/Unsupervised_learning\n- [Unsupervised Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-unsupervised-learning)\n- Unsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from \"unlabeled\" data (a classification or categorization is not included in the observations).\n\n## Sub-topics\n### Kernel density estimation\n- https://en.wikipedia.org/wiki/Kernel_density_estimation\n- kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable\n- https://scikit-learn.org/stable/modules/density.html\n- https://stackabuse.com/kernel-density-estimation-in-python-using-scikit-learn/\n\n### Dimensionality reduction and low rank modeling\nSee [Dimensionality reduction and low rank modeling](AI/Unsupervised%20learning/Dimensionality%20reduction%20and%20low%20rank%20modeling.md)\n\n### Clustering \nSee [Clustering](AI/Unsupervised%20learning/Clustering.md)\n\n### Blind source separation\n- Blind signal separation (BSS), also known as blind source separation, is the separation of a set of source signals from a set of mixed signals, without the aid of information (or with very little information) about the source signals or the mixing process.\n\n#### Independent component analysis (ICA)\n- https://en.wikipedia.org/wiki/Independent_component_analysis\n- In signal processing, independent component analysis (ICA) is a computational method for separating a multivariate signal into additive subcomponents. This is done by assuming that the subcomponents are non-Gaussian signals and that they are statistically independent from each other.\n- https://scikit-learn.org/stable/modules/decomposition.html#ica\n- https://scikit-learn.org/stable/auto_examples/decomposition/plot_ica_blind_source_separation.html\n\n### Anomaly and Outlier Detection\nSee [Anomaly and Outlier Detection](AI/Anomaly%20and%20Outlier%20Detection.md)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/Weakly-supervised-learning":{"title":"Weakly supervised learning","content":"See:\n- [Transfer learning](AI/Transfer%20learning.md)\n- [Active learning](AI/Active%20learning.md)\n- [Semi-supervised learning](AI/Semi-supervised%20learning.md)\n\n## Resources\n- Weak supervision is a branch of machine learning where noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts of training data in a supervised learning setting. This approach alleviates the burden of obtaining hand-labeled data sets, which can be costly or impractical. Instead, inexpensive weak labels are employed with the understanding that they are imperfect, but can nonetheless be used to create a strong predictive model.\n- Other areas of machine learning exist that are likewise motivated by the demand for increased quantity and quality of labeled training data but employ different high-level techniques to approach this demand. These other approaches include [active learning](AI/Active%20learning.md), [semi-supervised learning](AI/Semi-supervised%20learning.md), and [transfer learning](AI/Transfer%20learning.md).\n- Related to [One, few-shot learning](AI/One,%20few-shot%20learning.md). The most relevant problem to few-shot learning is weakly supervised learning with incomplete supervision where only a small amount of samples have supervised. By definition, weakly supervised learning with incomplete supervision includes only classification and regression, while few-shot learning also includes reinforcement learning problems. Moreover, weakly supervised learning with incomplete supervision mainly uses unlabeled data as additional information in E, while few-shot learning leverages various kinds of prior knowledge such as pretrained models, supervised data from other domains or modalities and does not restrict to using unlabeled data. Therefore, few-shot learning becomes weakly supervised learning problem only when prior knowledge is unlabeled data and the task is classification or regression.information.\n- [Weakly Supervised Learning: Introduction and Best Practices](https://datasciencemilan.medium.com/weakly-supervised-learning-introduction-and-best-practices-c65f490d4a0a)\n\n\n## References\n- #PAPER [A brief introduction to weakly supervised learning (2018)](https://academic.oup.com/nsr/article/5/1/44/4093912 )\n- #PAPER [A Graph-Based Method for Active Outlier Detection With Limited Expert Feedback (2019)](https://ieeexplore.ieee.org/document/8871105)\n\n### Incomplete supervision\n- In this case, only a (usually small) subset of training data is given with labels while the other data remain unlabeled (e.g., in image categorization the ground-truth labels are given by human annotators, and only a small subset of images can be annotated due to the human cost)\n- #PAPER [Learning from Incomplete and Inaccurate Supervision (Zhang 2021)](https://ieeexplore.ieee.org/document/9361098)\n\n### Inexact supervision\n- In this case, only coarse-grained labels are given. Consider the image categorization task again. It is desirable to have every object in the images annotated; however, usually we only have image-level labels rather than object-level labels. \n- #PAPER [Labeled Data Generation with Inexact Supervision (Dai 2021)](https://arxiv.org/abs/2106.04716)\n\n### Inaccurate supervision\n- The given labels are not always ground-truth (e.g., the image annotator is careless, or some images are difficult to categorize)\n - #PAPER [Auxiliary Image Regularization for Deep CNNs with Noisy Labels (2016)](https://arxiv.org/abs/1511.07069v2)\n - #PAPER [Anomaly detection with inexact labels (2019)](https://arxiv.org/abs/1909.04807)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI/XAI":{"title":"XAI","content":"## Resources\n- Explainable AI (XAI), or Interpretable AI, is artificial intelligence (AI) in which the results of the solution can be understood by humans\n- https://en.wikipedia.org/wiki/Explainable_artificial_intelligence\n- https://github.com/anguyen8/XAI-papers\n- [Ideas on interpreting machine learning](https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning)\n- [Explainable AI demos](https://lrpserver.hhi.fraunhofer.de/)\n- [Why you need to care about Explainable Machine Learning](https://medium.com/james-blogs/why-you-need-to-care-about-explainable-machine-learning-d01196a6af76)\n- [Interpreting machine learning models](https://towardsdatascience.com/interpretability-in-machine-learning-70c30694a05f)\n- [I.am.ai. Explaining artificial intelligence](https://www.i-am.ai/)\n- [Baking recipes made by AI](https://cloud.google.com/blog/topics/developers-practitioners/baking-recipes-made-ai)\n- A Review of Different Interpretation Methods:\n\t- https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-1-saliency-map-cam-grad-cam-3a34476bc24d\n\t- https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-2-input-gradient-layerwise-e077609b6377\n\t- https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-3-shap-integrated-gradients-918fc9fedd9b\n\n\n## Events, talks\n- [Workshop on Visualization for AI Explainability](http://visxai.io/)\n- [ACM Conference on Fairness, Accountability, and Transparency](https://facctconference.org/)\n- [Explainable AI xAI 2020](https://human-centered.ai/explainable-ai-2020/)\n- #TALK [Synthesizing Explainable and Deceptive Behavior for Human-AI Interaction (AAAI 2020 Tutorial)](https://yochan-lab.github.io/tutorial/AAAI-2020/)\n\t- https://www.youtube.com/watch?v=r6KhJ3ORYnc\n- #TALK [Explainable AI in Industry (Tutorial)](https://sites.google.com/view/explainable-ai-tutorial)\n\t- https://www.youtube.com/watch?list=PLewjn-vrZ7d3x0M4Uu_57oaJPRXkiS221\u0026v=rcUw7PXHWF4\n- #TALK [Explainable AI: Foundations, Industrial Applications, Practical Challenges, and Lessons Learned (AAAI 2020)](https://xaitutorial2020.github.io/)\n\t- https://xaitutorial2020.github.io/raw/master/slides/aaai_2020_xai_tutorial.pdf\n\n\n## Courses\n- #COURSE [Interpretable Machine Learning for Computer Vision (CVPR 2020)](https://interpretablevision.github.io/index_cvpr2020.html)\n\n\n## Books\n- #BOOK [ Interpretable Machine Learning (Molnar 2021)](https://christophm.github.io/interpretable-ml-book/)\n\n\n## Code\n- https://towardsdatascience.com/explainable-ai-xai-a-guide-to-7-packages-in-python-to-explain-your-models-932967f0634b\n\n- #CODE [CARLA](https://github.com/carla-recourse/CARLA)\n\t- CARLA is a python library to benchmark counterfactual explanation and recourse models\n\t- #PAPER [CARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms (Pawelczyk 2021)](https://arxiv.org/abs/2108.00783)\n\t- https://www.marktechpost.com/2021/08/22/university-of-tubingen-researchers-open-source-carla-a-python-library-for-benchmarking-counterfactual-explanation-methods-across-data-sets-and-machine-learning-models/\n- #CODE [Shapash](https://github.com/MAIF/shapash)\n\t- https://shapash.readthedocs.io/en/latest/\n- #CODE [ExplainerDashboard](https://github.com/oegedijk/explainerdashboard)\n\t- https://explainerdashboard.readthedocs.io/en/latest/index.html#\n\t- library for quickly building interactive dashboards for analyzing and explaining the predictions and workings of (scikit-learn compatible) machine learning models, including xgboost, catboost and lightgbm\n\t- #TALK https://www.youtube.com/watch?v=1nMlfrDvwc8\n- #CODE [AIX360](https://github.com/Trusted-AI/AIX360) ^aix360\n\t- Interpretability and explainability of data and machine learning models\n\t- http://aix360.mybluemix.net/\n- #CODE [LIME: Local Interpretable Model-agnostic Explanations](https://github.com/marcotcr/lime) ^limegithub\n- #CODE [Skater](https://github.com/datascienceinc/Skater)\n\t- Skater is a python package for model agnostic interpretation of predictive models. With Skater, you can unpack the internal mechanics of arbitrary models; as long as you can obtain inputs, and use a function to obtain outputs, you can use Skater to learn about the models internal decision policies.\n\t- https://datascienceinc.github.io/Skater/overview.html\n\t- Understanding How and Why Your Model Works:  https://www.datascience.com/learn-data-science/fundamentals/model-interpretation-algorithms\n\t- https://www.datascience.com/resources/tools/skater\n- #CODE [FairML - Auditing Black-Box Predictive Models](https://github.com/adebayoj/fairml)\n\t- FairML is a python toolbox auditing the machine learning models for bias. \n\t- http://blog.fastforwardlabs.com/2017/03/09/fairml-auditing-black-box-predictive-models.html\n- #CODE [ELI5](https://github.com/TeamHG-Memex/eli5)\n\t- ELI5 is a Python library which allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides a way to explain black-box models.\n\t- http://eli5.readthedocs.io/en/latest/\n- #CODE [BlackBox Auditing](https://github.com/algofairness/BlackBoxAuditing)\n- #CODE [SHAP](https://github.com/slundberg/shap) ^shapgithub\n\t- Unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations.\n- #CODE [FastTreeSHAP](https://github.com/linkedin/FastTreeSHAP)\n\t- Fast SHAP value computation for interpreting tree-based models\n\t- [LinkedIn Researchers Open-Source FastTreeSHAP](https://www.marktechpost.com/2022/03/20/linkedin-researchers-open-source-fasttreeshap-a-python-package-that-enables-an-efficient-interpretation-of-tree-based-machine-learning-models/)\n- #CODE [InterpretML](https://github.com/interpretml/interpret). Microsoft open-source package that incorporates state-of-the-art machine learning interpretability techniques under one roof\n- #CODE [imodels](https://github.com/csinva/imodels)\n\t- Python package for concise, transparent, and accurate predictive modeling. All sklearn-compatible and easy to use\n\t- [UC Berkeley Researchers Introduce ‚Äòimodels: A Python Package For Fitting Interpretable Machine Learning Models](https://www.marktechpost.com/2022/02/10/uc-berkeley-researchers-introduce-imodels-a-python-package-for-fitting-interpretable-machine-learning-models/)\n\n### Deep NNs XAI\n- #CODE [Quantus](https://github.com/understandable-machine-intelligence-lab/Quantus)\n\t- Quantus is an eXplainable AI toolkit for responsible evaluation of neural network explanations\n- #CODE [TruLens (tf.keras and pytorch): Explainability for Neural Networks](https://github.com/truera/trulens)\n\t- https://www.trulens.org/\n- #CODE [Captum (pytorch)](https://github.com/pytorch/captum)\n\t- Interpretability of models across modalities including vision, text, and more\n\t- https://captum.ai/\n\t- https://captum.ai/api/\n- #CODE [Saliency](https://github.com/PAIR-code/saliency)\n\t- XRAI, SmoothGrad, Vanilla Gradients, Guided Backpropogation, Integrated Gradients, Occlusion, Grad-CAM, Blur IG\n- #CODE [iNNvestigate](https://github.com/albermax/innvestigate) ^innvestigate\n\t- Vanilla gradient, SmoothGrad, DeConvNet, Guided BackProp, PatternNet, DeepTaylor, PatternAttribution, LRP, IntegratedGradients, DeepLIFT\n- #CODE [TF-explain](https://github.com/sicara/tf-explain)\n\t- implements interpretability methods as Tensorflow 2.x callbacks to ease neural network's understanding\n- #CODE [TensorSpace (Tensorflow.js)](https://github.com/tensorspace-team/tensorspace)\n\t- Neural network 3D visualization framework\n\t- https://tensorspace.org\n- #CODE [Lucid (Tensorflow 1) - A collection of infrastructure and tools for research in neural network interpretability](https://github.com/tensorflow/lucid)\n- #CODE [tf-keras-vis](https://github.com/keisen/tf-keras-vis)\n\t- Neural network visualization toolkit for tf.keras\n\t- Activation Maximization\n\t- Class Activation Maps (GradCAM, GradCAM++, ScoreCAM, Faster-ScoreCAM)\n\t- Saliency Maps (Vanilla Saliency, SmoothGrad)\n- #CODE [Keras-vis](https://github.com/raghakot/keras-vis)\n\t- https://raghakot.github.io/keras-vis/\n\t- Activation maximization, Saliency maps, Class activation maps\n- #CODE [DeepExplain (TensorFlow 1)](https://github.com/marcoancona/DeepExplain)\n\t- Saliency maps, Gradient * Input, Integrated Gradients, DeepLIFT, Œµ-LRP\n- #CODE [LRP toolbox](https://github.com/sebastian-lapuschkin/lrp_toolbox)\n\n\n## References\n- #PAPER [The Mythos of Model Interpretability (Lipton 2017)](https://arxiv.org/abs/1606.03490)\n- #PAPER [A Survey of Methods for Explaining Black Box Models (Guidotti, 2018)](https://dl.acm.org/doi/10.1145/3236009)\n- #PAPER [Making the Black Box More Transparent: Understanding the Physical Implications of Machine Learning (McGovern et al. 2019)](https://journals.ametsoc.org/bams/article/100/11/2175/343787/Making-the-Black-Box-More-Transparent)\n- #PAPER [Towards Explainable Artificial Intelligence (Samek \u0026 Muller 2019)](https://arxiv.org/abs/1909.12072)\n- #PAPER [Explaining Explanations: An Overview of Interpretability of Machine Learning (Gilpin et al. 2019)](https://arxiv.org/abs/1806.00069)\n- #PAPER [One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques (Arya 2019)](https://arxiv.org/abs/1909.03012)\n\t- #CODE See Code section\n- #PAPER [Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead (Rudin 2019)](https://www.nature.com/articles/s42256-019-0048-x)\n\t- https://arxiv.org/abs/1811.10154\n- #PAPER [Explainable Machine Learning for Scientific Insights and Discoveries (Roscher 2020)](https://arxiv.org/abs/1905.08883)\n- #PAPER [Review Study of Interpretation Methods for Future Interpretable Machine Learning (Jian-Xun 2020)](https://ieeexplore.ieee.org/document/9234594)\n- #PAPER [Explainable neural networks that simulate reasoning (Blazek 2021)](https://www.nature.com/articles/s43588-021-00132-w)\n- #PAPER [Turning biases into hypotheses through method: A logic of scientific discovery for machine learning (Aagaard Enni 2021)](https://journals.sagepub.com/doi/full/10.1177/20539517211020775)\n\t- bridging the gap in the understanding of ML models and their reasonableness requires a focus on developing an improved methodology for their creation\n\t- this process has been likened to ‚Äúalchemy‚Äù and criticized for involving a large degree of ‚Äúblack art,‚Äù owing to its reliance on poorly understood ‚Äúbest practices‚Äù\n\t- authors soften this critique and argue that the seeming arbitrariness often is the result of a lack of explicit hypothesizing stemming from an empiricist and myopic focus on optimizing for predictive performance rather than from an occult or mystical process\n\n\n### Model-agnostic methods\n- https://christophm.github.io/interpretable-ml-book/agnostic.html\n\t- The great advantage of model-agnostic interpretation methods over model-specific ones is their flexibility\n\t- An alternative to model-agnostic interpretation methods is to use only interpretable models, which often has the big disadvantage that predictive performance is lost compared to other machine learning models and you limit yourself to one type of model\n\n- #PAPER [Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation (Goldstein 2014)](https://arxiv.org/abs/1309.6392)\n- #PAPER [Model-Agnostic Interpretability of Machine Learning (Tulio Ribeiro 2016)](https://arxiv.org/abs/1606.05386)\n- #PAPER [SHAP - A Unified Approach to Interpreting Model Predictions (Lundberg 2017)](https://arxiv.org/abs/1705.07874)\n\t- SHAP (SHapley Additive exPlanations)\n\t- #CODE See [Code](#Code) section\n\t- Can be used for computer vision tasks\n- #PAPER [Fast TreeSHAP: Accelerating SHAP Value Computation for Trees (Yang 2021)](https://arxiv.org/abs/2109.09847)\n\n#### Partial Dependence Plot\n- The partial dependence plot (short PDP or PD plot) shows the marginal effect one or two features have on the predicted outcome of a machine learning model\n- https://christophm.github.io/interpretable-ml-book/pdp.html\n- https://scikit-learn.org/stable/modules/partial_dependence.html\n\n#### Individual Conditional Expectation\n- Individual Conditional Expectation (ICE) plots display one line per instance that shows how the instance's prediction changes when a feature changes\n- https://christophm.github.io/interpretable-ml-book/ice.html\n- https://scikit-learn.org/stable/modules/partial_dependence.html\n\n#### Permutation Feature Importance\n- Permutation feature importance measures the increase in the prediction error of the model after we permuted the feature's values, which breaks the relationship between the feature and the true outcome\n- https://christophm.github.io/interpretable-ml-book/feature-importance.html\n- https://scikit-learn.org/stable/modules/permutation_importance.html\n\t- The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled\n\t- Tree-based models provide an alternative measure of feature importances based on the mean decrease in impurity (MDI). Impurity is quantified by the splitting criterion of the decision trees (Gini, Entropy or Mean Squared Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data\n\n#### Surrogate models\n- A surrogate model is a simple model that is used to explain a complex model. Surrogate models are usually created by training a linear regression or decision tree on the original inputs and predictions of a complex model. Coefficients, variable importance, trends, and interactions displayed in the surrogate model are then assumed to be indicative of the internal mechanisms of the complex model. There are few, possibly no, theoretical guarantees that the simple surrogate model is highly representative of the more complex model.\n- The globally interpretable attributes of a simple model are used to explain global attributes of a more complex model. However, there is nothing to preclude fitting surrogate models to more local regions of a complex model's conditional distribution, such as clusters of input records and their corresponding predictions and their corresponding input rows. Because small sections of the conditional distribution are more likely to be linear, monotonic, or otherwise well-behaved, local surrogate models can be more accurate than global surrogate models.\n- #PAPER [LIME - \"Why Should I Trust You?\": Explaining the Predictions of Any Classifier (2016)](https://arxiv.org/abs/1602.04938) ^lime\n\t- #CODE See [Code](#Code) section\n\t- Formalized approach for local surrogate models. It is meant to shed light on how decisions are made for specific observations. LIME requires that a set of explainable records be found, simulated, or created.\n\t- https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime\n\t- https://github.com/albahnsen/Talk_Demystifying_Machine_Learning\n\t- [Interpreting ML models prediction power](http://www.datasciencecentral.com/profiles/blogs/deep-learning-epic-fail-right-answer-wrong-reason)\n\t- https://medium.com/@ageitgey/natural-language-processing-is-fun-part-3-explaining-model-predictions-486d8616813c\n\t- https://www.slideshare.net/albahnsen/demystifying-machine-learning-using-lime\n\t- https://github.com/albahnsen/Talk_Demystifying_Machine_Learning\n\n\n### Maximum activation analysis\n- See [Neural Networks explainability](#Neural%20Networks%20explainability)\n- In maximum activation analysis, examples are found or simulated that maximally activate certain neurons, layers, or filters in a neural network or certain trees in decision tree ensembles. For the purposes of maximum activation analysis, low residuals for a certain tree are analogous to high-magnitude neuron output in a neural network.\n- Maximum activation analysis elucidates internal mechanisms of complex models by determining the parts of the response function that specific observations or groups of similar observations excite to the highest degree, either by high-magnitude output from neurons or by low residual output from trees.\n\n\n### Sensitivity analysis\n- See [Neural Networks explainability](#Neural%20Networks%20explainability)\n- Sensitivity analysis investigates whether model behavior and outputs remain stable when data is intentionally perturbed or other changes are simulated in data. \n- Beyond traditional assessment practices, sensitivity analysis of machine learning model predictions is perhaps the most important validation technique for machine learning models. \n- Machine learning models can make drastically differing predictions from minor changes in input variable values. In practice, many linear model validation techniques focus on the numerical instability of regression parameters due to correlation between input variables or between input variables and the dependent variable\n- Sensitivity analysis can also test model behavior and outputs when interesting situations or known corner cases are simulated. Output distributions, error measurements, plots, and interpretation techniques can be used to explore the way models behave in important scenarios, how they change over time, or if models remain stable when data is subtly and intentionally corrupted\n\n\n### Variable importance measures\n- Variable importance measures are typically seen in tree-based models but are sometimes also reported for other models.\n- A simple heuristic rule for variable importance in a decision tree is related to the depth and frequency at which a variable is split on in a tree, where variables used higher in the tree and more frequently in the tree are more important. \n- For a single decision tree, a variable's importance is quantitatively determined by the cumulative change in the splitting criterion for every node in which that variable was chosen as the best splitting candidate. \n- For a gradient boosted tree ensemble, variable importance is calculated as it is for a single tree but aggregated for the ensemble. \n- For random forests:\n\t- Variable importance is also calculated as it is for a single tree and aggregated, but an additional measure of variable importance is provided by the change in out-of-bag accuracy caused by shuffling the independent variable of interest, where larger decreases in accuracy are taken as larger indications of importance\n\t- The default method to compute variable importance is the mean decrease in impurity (or gini importance) mechanism: At each split in each tree, the improvement in the split-criterion is the importance measure attributed to the splitting variable, and is accumulated over all the trees in the forest separately for each variable. Note that this measure is quite like the R^2 in regression on the training set\n\t- [This example highlights the limitations of impurity-based feature importance in contrast to permutation-based feature importance](https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html)\n\t- #PAPER [Understanding variable importances in forests of randomized trees (Louppe 2013)](https://papers.nips.cc/paper/4928-understanding-variable-importances-in-forests-of-randomized-trees.pdf)\n\t\t- #POSTER https://orbi.uliege.be/bitstream/2268/155642/3/poster.pdf\n\t- #PAPER [Trees, forests, and impurity-based variable importance (Scornet 2020)](https://arxiv.org/abs/2001.04295)\n- For neural networks, variable importance measures are typically associated with the aggregated, absolute magnitude of model parameters for a given variable of interest. \n- Global variable importance techniques are typically model specific, and practitioners should be aware that unsophisticated measures of variable importance can be biased toward larger scale variables or variables with a high number of categories.\n\n\n### Neural Networks explainability\nSee [Code](#Code) section\n\n#### Resources \n- [Using ML to Explore Neural Network Architecture](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html)\n- [The Building Blocks of Interpretability](https://distill.pub/2018/building-blocks/)\n- [Feature Visualization](https://distill.pub/2017/feature-visualization/)\n- [Applying deep learning to real-world problems (labeled data, imbalance, black box models)](https://medium.com/merantix/applying-deep-learning-to-real-world-problems-ba2d86ac5837)\n- [Unblackboxing webinar (deepsense.io)](https://github.com/deepsense-io/unblackboxing_webinar)\n- [The Dark Secret at the Heart of AI](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/amp/)\n- [How AI detectives are cracking open the black box of deep learning](http://www.sciencemag.org/news/2017/07/how-ai-detectives-are-cracking-open-black-box-deep-learning)\n- [Visualization of activations and filters](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html) \n\t- https://github.com/jacobgil/keras-filter-visualization\n- https://towardsdatascience.com/understanding-your-convolution-network-with-visualizations-a4883441533b\n- https://imatge.upc.edu/web/publications/visual-saliency-prediction-using-deep-learning-techniques\n- [Attributing a deep network‚Äôs prediction to its input features](http://www.unofficialgoogledatascience.com/2017/03/attributing-deep-networks-prediction-to.html)\n\t- Integrated gradients method\n\t- It involves a few calls to a gradient operator yielding insightful results for a variety of deep networks\n- [Pixel Attribution (Saliency Maps)](https://christophm.github.io/interpretable-ml-book/pixel-attribution.html)\n\n  \n#### References\n- #PAPER [Visualization of neural networks using saliency maps (Morch 1995)](https://www.researchgate.net/publication/3623243_Visualization_of_neural_networks_using_saliency_maps)\n- #PAPER [Deep inside CNNs: Visualising Image Classification Models and Saliency Maps (Simonyan 2014)](https://arxiv.org/abs/1312.6034)\n\t- Presented two visualisation techniques for deep classification ConvNets\n\t\t- The first generates an artificial image, which is representative of a class of interest\n\t\t- The second computes an image-specific class saliency map, highlighting the areas of the given image, discriminative wrt the given class\n- #PAPER [Understanding Neural Networks Through Deep Visualization (Yosinski 2015)](https://arxiv.org/abs/1506.06579)\n\t- http://yosinski.com/deepvis\n- #PAPER [SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability (Raghu 2017)](https://arxiv.org/abs/1706.05806)\n\t- [Interpreting Deep Neural Networks with SVCCA](https://ai.googleblog.com/2017/11/interpreting-deep-neural-networks-with.html)\n- #PAPER [Axiomatic Attribution for Deep Networks (Sundararajan 2017)](https://arxiv.org/abs/1703.01365)\n- #PAPER [SmoothGrad: removing noise by adding noise (Smilkov 2017)](https://arxiv.org/abs/1706.03825)\n\t- https://pair-code.github.io/saliency/\n- #PAPER [iNNvestigate Neural Networks! (Alber 2018)](http://arxiv.org/abs/1808.04260)\n\t- #CODE See [Code](#Code) section\n- #PAPER [XRAI: Better Attributions Through Regions (Kapishnikov 2019)](https://arxiv.org/abs/1906.02825)\n- #PAPER [DeepLIFT - Learning Important Features Through Propagating Activation Differences (Shrikumar 2019)](https://arxiv.org/abs/1704.02685)\n - #PAPER [Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges (Borji 2019)](https://arxiv.org/abs/1810.03716)\n- #PAPER [DAX: Deep Argumentative eXplanation for Neural Networks (Albini 2020)](https://arxiv.org/abs/2012.05766)\n- #PAPER [Interpreting Deep Neural Networks Through Variable Importance (Ish-Horowicz 2020)](https://arxiv.org/abs/1901.09839)\n\t- Their strategy is specifically designed to leverage partial covariance structures and incorporate variable interactions into our proposed feature ranking.  \n\t- Extended the recently proposed ‚ÄúRelATive cEntrality‚Äù (RATE) measure (Crawford et al., 2019) to the Bayesian deep learning setting\n\t- Given a trained network, RATE applies an information theoretic criterion to the posterior distribution of effect sizes to assess feature significance\n- #PAPER [Determining the Relevance of Features for Deep Neural Networks (Reimers 2020)](https://link.springer.com/chapter/10.1007%2F978-3-030-58574-7_20)\n\t- Their approach builds upon concepts from causal inference\n\t- Interpret machine learning in a structural causal model and use Reichenbach‚Äôs common cause principle to infer whether a feature is relevant\n- #PAPER [Explainable Deep Learning Models in Medical Image Analysis (Singh 2020)](https://arxiv.org/abs/2005.13799)\n- #PAPER [Efficient Saliency Maps for Explainable AI (Mundhenk 2020)](https://arxiv.org/abs/1911.11293)\n- #PAPER [Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications (Samek 2021)](https://ieeexplore.ieee.org/document/9369420)\n- #PAPER [Logic Explained Networks (Ciravegna 2021)](https://arxiv.org/abs/2108.05149)\n\t- https://syncedreview.com/2021/08/18/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-85/\n- #PAPER [Toward Explainable AI for Regression Models (Letzgus 2021)](https://arxiv.org/abs/2112.11407)\n- #PAPER [Explaining in Style: Training a GAN to explain a classifier in StyleSpace (Lang 2021)](https://explaining-in-style.github.io/)\n\t- https://ai.googleblog.com/2022/01/introducing-stylex-new-approach-for.html\n\n \n##### Layer-wise Relevance Propagation (LRP)\n- LRP is an inverse method which calculates the contribution of a single pixel to the prediction made by a DNN in an image classification task\n- http://heatmapping.org/\n- [Interactive demo](https://lrpserver.hhi.fraunhofer.de/image-classification)\n- https://medium.com/@ODSC/layer-wise-relevance-propagation-means-more-interpretable-deep-learning-219ff5158914\n- https://towardsdatascience.com/indepth-layer-wise-relevance-propagation-340f95deb1ea\n- Saliency map is a broader term from the field of computer vision (https://en.wikipedia.org/wiki/Saliency\\_map). The first reference of saliency maps applied to the predictions of DNNs is Morch et al 1995. Simonyan et al (2014) first proposed a method to produce saliency maps using back-propagation through a CNN, but note that you could compute \"saliency\" from an image in many ways that do not deal with back-propagating the prediction scores of DNNs. \n- There are several approaches for calculating attributions by back-propagating the prediction score through each layer of the network, back to the input features /pixels (DeConvNet, SmoothGrad, GradCam, LRP, XRAI). LRP is just one of them. In the first LRP paper, they talk about heatmaps or relevance maps, probably to avoid confusion with older saliency map techniques\n\n- #PAPER [On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation (Bach 2015)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140)\n\t- #CODE [Tutorial: Implementing Layer-Wise Relevance Propagation](https://git.tu-berlin.de/gmontavon/lrp-tutorial)\n- #PAPER [Understanding Individual Decisions of CNNs via Contrastive Backpropagation (Gu 2019)](https://arxiv.org/abs/1812.02100)\n- #PAPER [Beyond saliency: understanding convolutional neural networks from saliency prediction on layer-wise relevance propagation (Li 2019)](https://arxiv.org/abs/1712.08268)\n\t- proposed a novel two-step understanding method, namely Salient Relevance (SR) map, which aims to shed light on how deep CNNs recognize images and learn features from attention areas\n\t- starts out with a layer-wise relevance propagation (LRP) step which estimates a pixel-wise relevance map over the input image. Following, we construct a context-aware saliency map, SR map, from the LRP-generated map which predicts areas close to the foci of attention instead of isolated pixels that LRP reveals\n- #PAPER [Towards Best Practice in Explaining Neural Network Decisions with LRP (Kohlbrenner 2020)](https://arxiv.org/abs/1910.09840)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI4G/AI4good":{"title":"AI for good (AI4G)","content":"## References\n- #PAPER [AI for social good: unlocking the opportunity for positive impact (Tomasev 2020)](https://www.nature.com/articles/s41467-020-15871-z)\n\n## Resources\n- (Legacy) Overview of the Data Science and AI for good movement, on [Medium](https://towardsdatascience.com/data-science-and-ai-for-good-an-overview-577c9c2a3dcb)\n- [Public lecture slides: Beyond the Hype - how we can make AI work for humanity (Yoshua Bengio)](https://docs.google.com/presentation/d/e/2PACX-1vRTUkjOSeF1bEt1MNNkTWST1DEPTwr6C8_0mnICcv-9R4px8xCQjbBPHQE2rO-HJGGIGxS-ry8mgYzP/pub)\n- [Twitter : data4good hashtag](https://twitter.com/hashtag/data4good?lang=en)\n- [DS for Good resources](https://github.com/darenasc/data-science-for-good)\n- [Report - AI for Good](https://www.diplomaticourier.com/report-ai-for-good/)\n- [How to Use Data for Good to Impact Society](https://www.gartner.com/doc/3880666/use-data-good-impact-society#a1960121054)\n- [Challenges and opportunities of Artificial Intelligence for Good.](https://news.itu.int/challenges-and-opportunities-of-artificial-intelligence-for-good/)\n- [La inteligencia artificial al servicio del bien social en Am√©rica Latina y el Caribe](https://publications.iadb.org/publications/spanish/document/La-inteligencia-artificial-al-servicio-del-bien-social-en-America-Latina-y-el-Caribe-Panor%C3%A1mica-regional-e-instant%C3%A1neas-de-doce-paises.pdf) \n- [A skeptic‚Äôs guide to thinking about AI](https://www.fastcompany.com/90252753/a-skeptics-guide-to-thinking-about-ai)\n- [Why ‚Äúdata for good‚Äù lacks precision](https://towardsdatascience.com/why-data-for-good-lacks-precision-87fb48e341f1)\n- [Five principles for applying data science for social good](https://www.oreilly.com/ideas/five-principles-for-applying-data-science-for-social-good)\n- [Artificial Intelligence as a Force for Good](https://ssir.org/articles/entry/artificial_intelligence_as_a_force_for_good)\n- [AI for the Common Good?! Pitfalls, challenges, and Ethics Pen-Testing (paper on Arxiv)](https://arxiv.org/abs/1810.12847)\n- [AI for Good ‚Äì An Overview of Benevolent AI Initiatives (AI by nonprofits and companies in education, environment and health sectors)](https://emerj.com/ai-sector-overviews/ai-for-good-initiatives/)\n- [Why AI for social good is a thing (podcast)](https://www.techtarget.com/searchcio/podcast/Why-AI-for-social-good-is-a-thing)\n- [Is the Purpose of Artificial Intelligence to Sell Sugar Water?](https://medium.com/intuitionmachine/is-the-purpose-of-ai-to-sell-sugar-water-e6466d574ec0)\n\n\n### Sustainable Development Goals (SDGs)\n- [United Nations SDGs](https://www.un.org/sustainabledevelopment/sustainable-development-goals/)\n- [17goals.org - learn about the SDGs](http://17goals.org/)\n- [SDG Academy](https://sdgacademy.org/)\n- [SDGs dashboard](http://www.sdgsdashboard.org/) \n- [SDG index](http://sdgindex.org/) \n- [A Guide to SDG Interactions: from Science to Implementation](https://council.science/publications/a-guide-to-sdg-interactions-from-science-to-implementation)\n- [The trouble with the UN SDGs 2030 global goals](https://medium.com/@lauraom/the-trouble-with-the-un-sdgs-2030-global-goals-99111a176585)\n\n### Healthcare (resources, applications and challenges)\n- [Stanford AI for healthcare](https://medium.com/stanford-ai-for-healthcare)\n- [Fighting Tuberculosis with GPUs and Deep Learning](https://blogs.nvidia.com/blog/2017/07/20/fighting-tuberculosis/)\n- [Hearth disese diagnosis with DL](https://blog.insightdatascience.com/heart-disease-diagnosis-with-deep-learning-c2d92c27e730)\n- [Intro to biomedical image analysis with tensorflow/DLTK](https://medium.com/tensorflow/an-introduction-to-biomedical-image-analysis-with-tensorflow-and-dltk-2c25304e7c13)\n- [ML in biomed](https://github.com/chvlyl/ML_in_Biomed)\n- [Course - Data Science in Stratified Healthcare and Precision Medicine](https://www.coursera.org/learn/datascimed)\n- [Meaningless comparisons lead to false optimism in medical machine learning (paper on Arxiv)](https://arxiv.org/abs/1707.06289)\n\n### Bootcamps and fellowships¬†\nSee [Bootcamps and fellowships](AI4G/Bootcamps%20and%20fellowships.md)\n\n### Entrepreneurship\nSee [Entrepreneurship](AI4G/Entrepreneurship.md)\n\n### Inititatives\n- [AI commons](https://www.aicommons.com/)\n\t- Addressing the world‚Äôs grandest challenges with Artificial Intelligence.\n\t- We seek to gather a true ecosystem to democratize access to AI capabilities, to allow anyone, anywhere to benefit from the possibilities that AI can provide.\n\t- We are working to connect problem owners with the community of solvers, to collectively create solutions with AI. We aim to implement a framework for participation and cooperation to make using and benefiting from AI available to all.\n- [ITU AI repository](https://www.itu.int/en/ITU-T/AI/Pages/ai-repository.aspx)\n\t- Following the success of the first AI for Good Global Summit, ITU has launched a global Artificial Intelligence (AI) repository to identify AI related projects, research initiatives, think-tanks and organizations that can accelerate progress towards the ‚Äú17 UN Sustainable Development Goals (SDGs)‚Äù.\n\t- The \"AI Repository\" is open to all and we invite anyone working in the field of AI to contribute to this resource. To submit a project, just fill in the on-line questionnaire below and provide all relevant details of your project. You will also be asked to map your project to the relevant WISIS action lines and UN Sustainable Development Goals. Approved projects will be officially registered in the repository database and your project details will become visible on the website, connecting you with likeminded AI stakeholders, world-wide. It‚Äôs that simple!\n- [The Ethics and Governance of AI](https://aiethicsinitiative.org/)\n\t- Launched in 2017, the Ethics and Governance of AI Initiative is a hybrid research effort and philanthropic fund that seeks to ensure that technologies of automation and machine learning are researched, developed, and deployed in a way which vindicate social values of fairness, human autonomy, and justice. The Initiative is a joint project of the MIT Media Lab and the Harvard Berkman-Klein Center for Internet and Society. It incubates a range of research, prototyping, and advocacy activities within these two anchor institutions and across the broader ecosystem of civil society. \n- [AI for Good (UK)](https://www.aiforgood.co.uk/)\n\t- On a mission to help 100 million people by solving some of the toughest challenges facing humanity\n- [AI for Good (Microsoft)](https://www.microsoft.com/en-us/ai/ai-for-good)\n\t- #TALK [AI for Good: Deploying Microsoft AI to help solve society‚Äôs greatest challenges](https://www.youtube.com/watch?v=YtiWxpuD1Rc)\n- [Google AI for social good](https://ai.google/social-good)\n- [Partnership for sustainable development data](http://www.data4sdgs.org/index.php/)\n\t- The Global Partnership for Sustainable Development Data is a global network bringing together governments, the private sector, and civil society organizations dedicated to using the data revolution to achieve the Sustainable Development Goals.\n- [Data for democracy](https://www.datafordemocracy.org/)\n\t- [https://github.com/Data4Democracy](https://github.com/Data4Democracy)\n\t- Data for Democracy is a worldwide community of passionate volunteers working together to promote trust and understanding in data and technology.\n- [Data for good (Canada)](https://dataforgood.ca/)\n\t- Data For Good is a collective of do gooders, who want to use their powers for good, and not evil, to help make our communities better through data. We are a national not for profit organization, with chapters across the county, that help other not for profit, and non-governmental, organizations harness the power of their data to make more informed and better decisions in their quest to make their communities flourish.\n- [Data for good (France)](https://dataforgood.fr/)\n\t- Les technologies num√©riques sont incroyablement puissantes et red√©finissent le fonctionnement de notre soci√©t√©. Mais tous les domaines ne se transforment pas √† la m√™me vitesse. Tr√®s souvent, les acteurs qui ≈ìuvrent pour l‚Äôint√©r√™t g√©n√©ral (citoyens, associations, institutions publiques et entreprises √† fort impact social) sont en retard par rapport aux startups et aux g√©ants de la tech. Data for Good existe pour r√©tablir l‚Äô√©quilibre.\n- [AI for good (Netherlands)](https://www.aiforgood.nl/)\n\t- LET'S USE A.I. FOR GOOD\n\t- Met AI for GOOD brengen we twee werelden bij elkaar: talent op het gebied van kunstmatige intelligentie (artificial intelligence) en niet-commerci√´le organisaties zoals NGOs en Gemeentes. Samen gaan we op zoek naar oplossingen voor uitdagende data-challenges.\n- [ESA EO4SD](http://eo4sd.esa.int/)\n\t- EO4SD ‚Äì Earth Observation for Sustainable Development ‚Äì is a new ESA initiative which aims to achieve a step increase in the uptake of satellite-based environmental information in the IFIs regional and global programs. It will follow a systematic, userdriven approach in order to meet longer-term, strategic geospatial information needs in the individual developing countries, as well as international and regional development organizations.\n- [DSSG Berlin](https://dssg-berlin.org/)\n- [Data for good lab](http://www.ise.bgu.ac.il/labs/fire/index.html)\n\t- Our name-the Data Science for Social Good Lab-reflects our goal: to improve the world through data. A gigantic volume of data is now available in the world, and much can be accomplished if we attain and utilize it in an effective manner. Our aim is to make our research reproducible and open on this website.\n\n\n### Organizations\n- [AI for good foundation](https://ai4good.org/)\n\t- Chartered in 2016, the AI for Good Foundation fosters activities to maximize the benefit of AI technologies for social good through the lens of global sustainable development.\n\t- [Applying data science for a sustainable planet](https://ai4good.org/what-we-do/fragile-earth/)\n- [Partnership on AI](https://www.partnershiponai.org/)\n\t- The Partnership on AI to Benefit People and Society was established to study and formulate best practices on AI technologies, to advance the public‚Äôs understanding of AI, and to serve as an open platform for discussion and engagement about AI and its influences on people and society.\n- [Copernicus Institute of Sustainable Development](https://www.uu.nl/en/research/copernicus-institute-of-sustainable-development)\n\t- The Copernicus Institute of Sustainable Development is the scientific institute for sustainability research and teaching of Utrecht University. We contribute to the transition to a sustainable society through scientific excellence in a multi-disciplinary environment.\n- [The Alan Turing institute](https://www.turing.ac.uk/)\n\t- The Alan Turing Institute is the national institute for data science and artificial intelligence, with headquarters at the British Library\n- [AI2 - Allen Institute for Artificial Intelligence](https://allenai.org/)\n\t- AI2 was founded in 2014 with the mission of conducting high-impact AI research and engineering in service of the common good. AI2 is the creation of Paul Allen, Microsoft co-founder, and is led by Dr. Oren Etzioni, a leading AI researcher.\n- [Nesta](https://www.nesta.org.uk/)\n\t- Nesta is a global innovation foundation. We back new ideas to tackle the big challenges of our time, from the pressures of an ageing population to stretched public services and a fast changing jobs market.\n- [Delta Analytics](http://www.deltanalytics.org/)\n\t- Delta Analytics has two parallel goals. First, we bridge the skill gap faced by nonprofits by providing free data consulting and data services. Second, we build technical capacity in communities around the world by providing free trainings to help democratize access to machine learning and data tools. We are a non-profit run entirely without a full-time staff; instead, our work is possible because of the volunteer efforts of a rich community of data professionals.\n- [Data Orchard](http://dataorchard.co.uk/)\n\t- Data Orchard is a unique research company. Our work combines specialist skills in research, statistics and data with shared passions around making the world a better place socially, economically and environmentally.\n- [DataKind](http://www.datakind.org/)\n\t- This is, without hyperbole, a historic time for humanity. Mobile phones, sensors, and new software have created an abundance of data that can be mined, understood, and harnessed to gain new insights about our world and transform almost every sector. The same algorithms and techniques that companies use to boost profits can be leveraged by mission-driven organizations to improve the world, from battling hunger to advocating for child well-being and more. However, most social change organizations don‚Äôt have the budget or staff to take full advantage of this data revolution and most data scientists don't realize just how valuable their skills can be.\n\t- http://www.datakind.org/chapters/\n- [AI 4 all](http://ai-4-all.org/)\n\t- AI4ALL is Educating the Next Generation of AI Technologists, Thinkers, and Leaders\n- [Hack 4 impact](https://hack4impact.org/)\n\t- Hack4Impact is a 501 (c)(3) nonprofit organization founded at the University of Pennsylvania in Philadelphia, with chapters at various colleges across the United States. We collaborate with nonprofits and other socially responsible organizations to develop software that meets important social and humanitarian needs.\n- [Accel.AI](https://www.accel.ai/)\n\t- Shaping the Next Generation of AI Engineers \u0026 Enthusiasts. Accel.AI was founded in September of 2016, our mission is to lower the barriers to entry in engineering artificial intelligence. We focus on integrating AI and Social Impact through consulting, workshops, and research on ethical AI development and applied AI engineering.\n\n\n### Challenges, competitions\n- [AI4EO](https://ai4eo.eu/)\n\t- AI4EO is organising several artificial intelligence-based challenges with world-class partners and sponsors. Through these challenges we will foster the growth of the AI4EO community, support researchers and coders by promoting their work and use AI to extract more information from EO to solve some of the pressing challenges faced by our society.\n- [Big data for social good (IBM)](https://ibmhadoop.devpost.com/)\n\t- IBM invites developers and data enthusiasts to take a deep dive into real world civic issues using big data and IBM Bluemix‚Äôs Analytics for Hadoop service. Analyze one of our curated datasets or bring your own (provided it meets these requirements)! Use Hadoop and your data to create a clickable and interactive data visualization to highlight insights that you‚Äôve found.\n- [Data Science Bowl](https://datasciencebowl.com/)\n\t- For us, data science is more than a skill or profession. It is a calling and a way of life. It rewards grit as much as talent. Failure, curiosity, and small successes lead to discovery. Data science grants the power of entire nations or corporations to the individual. It gives a megaphone to those who were previously silent. Our purpose is bigger than any one of us.\n- [Call for Code - Global](https://callforcode.org/)\n\t- Developers have revolutionized the way people live and interact with virtually everyone and everything. Where most people see challenges, developers see possibilities. That‚Äôs why David Clark Cause is launching Call for Code alongside Founding Partner IBM. This multi-year global initiative is a rallying cry to developers to use their skills and mastery of the latest technologies, and to create new ones, to drive positive and long-lasting change across the world with their code. The inaugural Call for Code Challenge theme is Natural Disaster Preparedness and Relief.\n- [Zindi](https://zindi.africa/)\n- [Data Science for good on Kaggle](https://www.kaggle.com/search?q=data+science+for+good)\n\t- Zindi hosts the largest community of African data scientists, working to solve the world‚Äôs most pressing challenges using machine learning and AI. We connect data scientists with organisations, and provide a place to learn, hone your skills and find a job. We want to transform the African continent and showcase African data science talent to the world\n\t- https://techcrunch.com/2021/12/02/south-african-crowd-solving-startup-zindi-building-a-community-of-data-scientists-and-using-ai-to-solve-real-world-problems/?guccounter=1\n- [Driven Data competitions](https://www.drivendata.org/competitions/)\n\t- At DrivenData, we bring cutting-edge practices in data science and crowdsourcing to some of the world's biggest social challenges and the organizations taking them on. We host online challenges, usually lasting 2-3 months, where a global community of data scientists competes to come up with the best statistical model for difficult predictive problems that make a difference.\n- [AI to solve the world's challenges (IBM, XPrize)](https://www.xprize.org/prizes/artificial-intelligence)\n\t- The $5 million IBM Watson AI XPRIZE is a global competition challenging teams to develop and demonstrate how humans can collaborate with powerful AI technologies to tackle the world‚Äôs Grand Challenges.\n- [GEOSS + AWS](http://www.earthobservations.org/aws.php)\n\t- $1.5 million worth of cloud services available for projects that improve understanding of our planet\n- [Grand Challenges in Biomedical Image Analysis](https://grand-challenge.org/)\n\n\n### Open data\n- [Data for Humanity: An Open Letter](http://www.bigdata.uni-frankfurt.de/dataforhumanity/)\n- [Datasets for Social Good Projects](https://github.com/shreyashankar/datasets-for-good)\n- [Medical imaging datasets](https://github.com/sfikas/medical-imaging-datasets)\n- [Open Knowledge International](https://okfn.org/)\n\t- [How to open data](https://okfn.org/opendata/how-to-open-data/)\n\t- [The Global Open Data Index](https://index.okfn.org/)\n\t\t- The Global Open Data Index provides the most comprehensive snapshot available of the state of open government data publication\n- [UN data](http://data.un.org/Explorer.aspx?d=GHG)\n\t- UNdata is a web-based data service for the global user community. It brings international statistical databases within easy reach of users through a single-entry point. Users can search and download a variety of statistical resources compiled by the United Nations (UN) statistical system and other international agencies. The numerous databases or tables collectively known as \"datamarts\" contain over 60 million data points and cover a wide range of statistical themes including agriculture, crime, communication, development assistance, education, energy, environment, finance, gender, health, labour market, manufacturing, national accounts, population and migration, science and technology, tourism, transport and trade.\n- [Datahub](https://datahub.io/)\n- [Humanitarian Data Exchange](https://data.humdata.org/)\n- [UCI ML repository](http://archive.ics.uci.edu/ml/datasets.html?sort=nameUp\u0026view=list)\n- [EnergyData](https://energydata.info/)\n\n### Events\n- [ACM FAT*](https://www.fatconference.org/)- ACM Conference on Fairness, Accountability, and Transparency (ACM FAT*)\n- [Re-work - AI for good summit](https://www.re-work.co/events/ai-for-good-summit-seattle-2022)\n- [AI for good global summit (ITU)](https://www.itu.int/en/ITU-T/AI/Pages/default.aspx)\n- [Data4good conference](https://www.data4goodconf.org.uk/)\n- [NeurIPS, ICML, ICLR - AI for social good workshop](https://aiforsocialgood.github.io/2018/)\n- DS for Social Good (SoGood)\n- [SoGood 2021](https://sites.google.com/view/ecmlpkddsogood2021/home)- The 6th Workshop on Data Science for Social Good \n- [Data For Good Exchange](https://www.bloomberg.com/company/d4gx/) - D4GX, an initiative of Bloomberg‚Äôs Office of the CTO, brings together data scientists with nonprofits and government agencies to solve some of the world‚Äôs biggest problems\n- [AI for Social Good (CCC)](https://cra.org/ccc/events/ai-social-good/#overview)\n- Data for good meetups\n\t- [Data for Good - Toronto (Toronto, ON)](https://www.meetup.com/DataforGood/)\n\t- [Data for Good - Calgary (Calgary, AB)](https://www.meetup.com/Data-for-Good-Calgary/)\n\t- [Data for Good - Vancouver (Vancouver, BC)](https://www.meetup.com/DataforGood-Vancouver/)\n\t- [Data for Good - Waterloo Region (Waterloo, ON)](https://www.meetup.com/Data-for-Good-WR/)\n\t- [Data for Good - Ottawa (Ottawa, ON)](https://www.meetup.com/DataforGoodYOW/)\n\t- [Data for Good (Paris, France)](https://www.meetup.com/Data-for-Good-FR/)\n\t- [Data For Good Barcelona (Barcelona, Spain)](https://www.meetup.com/Data-For-Good-Barcelona/)\n\t- [Data for Good (San Francisco, CA)](https://www.meetup.com/DataScienceforGood/)\n\t- [Data + the Greater Good (New York, NY)](https://www.meetup.com/greatergood/)\n\t- [Sheffield Data for Good (Sheffield, United Kingdom)](https://www.meetup.com/Sheffield-Data-for-Good/)","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI4G/Bootcamps-and-fellowships":{"title":"AI4G - Bootcamps and fellowships","content":"## AI4Good lab\n- https://www.ai4goodlab.com/\n- We train and mentor women to succeed in AI\n\n\n## Data Science for Social Good\n- https://www.dssgfellowship.org/\n- The Data Science for Social Good Fellowship is a full-time summer program to train aspiring data scientists to work on machine learning, data science, and AI projects with social impact in a fair and equitable manner. Working closely with governments and nonprofits, fellows take on real-world problems in education, health, criminal justice, sustainability, public safety, workforce development, human services, transportation, economic development, international development, and more.\n\n\n## Data Fellows Programme\n- [https://centre.humdata.org/data-fellows-programme/](https://centre.humdata.org/data-fellows-programme/)\n- The Centre hosts Data Fellows in The Hague in June and July each year. Through this programme, the Fellows design and deliver targeted projects that contribute to the overall goals of the Centre. The programme is residential, with Fellows living and working in The Hague under the direction of the Data Fellows Programme Coordinator and with support from the entire Centre team.\n\n\n## Uptake data fellows\n- [https://www.uptake.org/data-fellows.html](https://www.uptake.org/data-fellows.html)\n- The Uptake.org Data Fellows program is a six-month fellowship designed to connect data professionals at non-profits, foundations, governmental agencies, and social enterprises to experts in data science and security. The fellowship begins with a week in Chicago where fellows meet with mentors, participate in workshops on topics in data science, and network with like-minded data-for-good professionals.\n\n\n## Frontier development lab\n- In USA: [https://frontierdevelopmentlab.org/#!/](https://frontierdevelopmentlab.org/#!/)\n- In Europe: [https://fdleurope.org](https://fdleurope.org/)\n- FDL is an applied artificial intelligence research accelerator established to maximize new AI technologies and capacities emerging in academia and the private sector and apply them to challenges in the space sciences.\n- Commercial, international and academic partners, such as Nvidia, Intel, Google, IBM and Lockheed Martin, SpaceResources Luxembourg, USC MASCLE, KBRWyle, XPrize, Kx and Miso Technologies provide capital, expertise and vast compute resources necessary for rapid experimentation and iteration in data intensive areas.\n\n\n## Sabudh foundation internship\n- [http://sabudh.org/](http://sabudh.org/)\n- Sabudh foundation is welcoming aspiring Data Scientists to undergo six months internship and become a SABUDH FELLOW. The foundation works on Data Science projects having real social impact. The interns will be learning machine learning and AI from the leading lights in the industry and academia.\n- These interns will be working on real-world, high impact problems in areas such as agriculture, governance, healthcare, and education with potential employment offered after the completion of the internship.","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null},"/AI4G/Entrepreneurship":{"title":"AI4G - Entrepreneurship","content":"## Google impact challenge\n- https://www.google.org/opportunities/\n- Working together to apply AI for social good\n- Google.org is issuing an open call to organizations around the world to submit their ideas for how they could use AI to help address societal challenges. Selected organizations will receive support from Google‚Äôs AI experts, Google.org grant funding from a $25M pool, credit and consulting from Google Cloud, and more.\n- [Supporting social impact startups](https://www.blog.google/around-the-globe/google-europe/supporting-social-impact-startups/)\n\n## UNICEF Innovation Fund Call for DS \u0026 AI\n- [http://unicefstories.org/datascienceAI/](http://unicefstories.org/datascienceAI/)\n- The UNICEF Innovation Fund is looking to fund and support, with both data and technical expertise, startups that are working with sophisticated applications of computer science including data mining, data processing, machine learning, artificial intelligence, and others, to help make the world a better place.\n- For our Data-Science cohort of investees we are particularly interested in the following areas:\n\t- Generating large data collections\n\t- Understanding complex environments\n\t- Processing satellite images\n\t- Applying Artificial Intelligence\n\n## Climate Launchpad\n- [https://climatelaunchpad.org](https://climatelaunchpad.org/)\n- ClimateLaunchpad is the world‚Äôs largest green business ideas competition. Innovation and invention can lead the way to a clean future. That‚Äôs why we create a stage for the people who have great cleantech ideas and help them develop those ideas into startups making global impact. ClimateLaunchpad is part of the Entrepreneurship offerings of Climate-KIC.\n- Fixing climate change, one start-up at a time.\n\n## Microsoft AI for accessibility\n- [https://www.microsoft.com/en-us/ai-for-accessibility](https://www.microsoft.com/en-us/ai-for-accessibility)\n- A Microsoft grant program that harnesses the power of AI to amplify human capability for the more than one billion people around the world with a disability.\n\n## Microsoft AI for Earth grants\n- [https://www.microsoft.com/en-us/ai-for-earth/grants](https://www.microsoft.com/en-us/ai-for-earth/grants)\n- [https://www.microsoft.com/en-us/ai-for-earth](https://www.microsoft.com/en-us/ai-for-earth)\n- AI for Earth awards grants to support projects that change the way people and organizations monitor, model, and ultimately manage Earth‚Äôs natural systems. Depending on project need, our grants can award Microsoft Azure cloud computing resources (including AI tools) and/or data labeling services.\n\n\n## Social Nest\n- https://socialnest.org/\n- We are a global platform supporting entrepreneurs, corporates, governments and investors with needed resources, opportunities and tailored guidance so they can create solutions to the world's most pressing challenges.\n\n\n## Samsung For Impact\n- https://www.samsungforimpact.com/\n- Samsung For Impact is a European impact acceleration program designed to discover and bolster promising impact startups and entrepreneurs working to achieve social good through their business or developing innovative technologies with a social purpose.\n\n\n## Good AI capital\n- https://goodai.capital/\n- Based on a high conviction strategy, Good AI Capital invests in a small number of high-quality startups where we can add value and contribute towards their long-term success.","lastmodified":"2022-03-31T08:22:26.958977122Z","tags":null}}