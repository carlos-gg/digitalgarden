{"/":{"title":"CarlosGG's Knowledge Garden 🪴","content":"Welcome to my personal digital knowledge garden, a collection of notes and resources that I started to compile a couple of years ago as my best attempt to become a somewhat functional _information junkie_. Here I curate, organize and catalog the stuff I ~~read~~ [skim over](https://learningcenter.unc.edu/tips-and-tools/skimming/) everyday. \n\n## About digital knowledge gardens\n\nThe concept of a digital knowledge garden, a.k.a. \"second brain\", has been around for quite [some time](https://maggieappleton.com/garden-history) and is related to that of [personal knowledge management](https://en.wikipedia.org/wiki/Personal_knowledge_management). Digital gardens build upon note-taking methodologies such as [Zettelkasten](https://en.wikipedia.org/wiki/Zettelkasten) or [Evergreen](https://notes.andymatuschak.org/Evergreen_notes). In short, a digital garden is something in between a blog and a wiki; a way to accumulate personal knowledge over time in an explorable space and in a non-linear fashion, while benefiting from fancy features such as (bidirectional) links between different topics, and visual graphs or [mind maps](https://en.wikipedia.org/wiki/Mind_map). This GitHub [repository](https://github.com/MaggieAppleton/digital-gardeners) offers a complete list of tools and workflows for aspiring gardeners wishing to grow a knowledge garden. \n\nThroughout my journey with personal knowledge management, I have used a combination of different tools and practices with varying levels of success: curating lists of links as bookmarks or [Pocket](https://getpocket.com/) collections, compiling notes with [Evernote](https://evernote.com/) or [OneNote](https://www.microsoft.com/es-es/microsoft-365/onenote/digital-note-taking-app), organizing ideas in mind maps with [XMind](https://www.xmind.net/), and collecting bibliographic data in [Zotero](https://www.zotero.org/). Nowadays, I use [Obsidian](https://obsidian.md/) for growing my digital knowledge garden and managing my markdown notes locally. Although Obsidian cannot fully replace all one of the aforementioned tools, it comes really close to it by providing flexible workflows for personal knowledge management. Apart from Obsidian, I use [Quartz](https://quartz.jzhao.xyz/) for publishing and sharing the content of my vault using [GitHub pages](https://carlos-gg.github.io/digitalgarden/). \n\n## Main motivation for creating this knowledge garden\n\nKeeping up with the literature related to Artificial Intelligence (AI) and Machine Learning (ML) is ~~impossible~~ very difficult and, although tools like the [Deep Learning Monitor](https://deeplearn.org/) might be of help, the \"Fear Of Missing Out\" [(FOMO)](https://en.wikipedia.org/wiki/Fear_of_missing_out) information is hardly avoidable, especially if you are an _information junkie_ like me. While my personal knowledge garden is mainly focused on AI, it is [not meant to be a complete](https://nick.groenen.me/notes/digital-garden-notes-may-be-incomplete/) or exhaustive mapping of all there is to know about AI or ML. It is also not aimed at teaching anyone or to be pedagogical, though it can certainly point you to a multitude of educational resources. The content of this knowledge garden is based merely on my personal research notes, the topics that I have been interested in or that I have come across in my work as a researcher in AI/ML applied to Earth Sciences. \n\n## What to find in here\n\nMost notes in this knowledge garden are focused on specific topics (e.g., [GFlowNets](AI/Deep%20learning/GFlowNets.md)) but others are broader [_maps of content_](https://jing.io/garden/MOC/) (e.g., [AI for Earth Sciences](AI4ES/AI4ES.md) or [Deep Learning](AI/Deep%20learning/DL.md)). The notes are composed of common subsections:\n\n- **Resources**: definitions, wikipedia entries, blog posts and other useful stuff.\n- **Books**: well... books, mostly free or open source.\n- **Courses**: online and free/open courses mostly by recognized universities and institutions.\n- **References**: peer-reviewed publications and papers.\n- **Code**: open source code and relevant libraries.\n- **Talks**: talks, video summaries and video podcasts.\n\nMost of the entries (bullet points) in a note carry a specific tag, depending on the subsections they belong to, for example: _#PAPER_,  _#COURSE_, _#BOOK_ or _#CODE_. The following are some _maps of content_ or important pages you may want to start from:\n\n- [AI](AI/AI.md)\n- [Deep Learning](AI/Deep%20learning/DL.md)\n- [Machine Learning](AI/Machine%20Learning.md) \n- [Data Science](AI/DS%20and%20DataEng/Data%20Science.md)\n- [AI for Earth Sciences](AI4ES/AI4ES.md)\n- [AI for good](AI4G/AI4good.md)\n\nFeel free to look around, either by exploring the _maps of content_ above, checking out the main index of [notes related to AI](https://carlos-gg.github.io/digitalgarden/ai/), using the search box, or by interacting with the mind map on top of the page. Expect some broken links and all sort of bugs and errors. I hope you find something useful in this knowledge garden. Enjoy!","lastmodified":"2022-09-05T14:10:31.89403632Z","tags":null},"/AI/AI":{"title":"Artificial Intelligence","content":"\u003e The expression _artificial intelligence_ is an umbrella term encompassing a suite of technologies that can perform complex tasks when acting in conditions of uncertainty, including visual perception, speech recognition, natural language processing, reasoning, learning from data, and a range of optimisation problems.\n\n## Resources\n- https://en.wikipedia.org/wiki/Artificial_intelligence\n- [AtHomeWithAI | Deepmind](https://storage.googleapis.com/deepmind-media/research/New_AtHomeWithAI%20resources.pdf)\n- https://github.com/owainlewis/awesome-artificial-intelligence\n- https://github.com/amusi/awesome-ai-awesomeness\n- https://github.com/JosPolfliet/awesome-ai-usecases\n- [Stop Calling Everything AI, Machine-Learning Pioneer](https://spectrum.ieee.org/stop-calling-everything-ai-machinelearning-pioneer-says)\n- [Artificial Intelligence—The Revolution Hasn’t Happened Yet](https://hdsr.mitpress.mit.edu/pub/wot7mkc1/release/9)\n- [Making sense of artificial intelligence (Google)](https://atozofai.withgoogle.com/)\n- [People + AI guidebook (Google)](https://pair.withgoogle.com/guidebook/patterns )\n- [General AI Challenge](https://www.general-ai-challenge.org/)\n- [AI Index (Stanford)](https://aiindex.stanford.edu/report/ )\n- [AI Playbook](http://aiplaybook.a16z.com/)\n- [What’s the Difference Between AI, ML, and Deep Learning?](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)\n- [The AI takeover is coming. Let's embrace it](https://www.wired.com/2016/12/the-ai-takeover-is-coming-lets-embrace-it/)\n- [What worries me about AI](https://medium.com/@francois.chollet/what-worries-me-about-ai-ed9df072b704)\n- [Machine Learning Confronts the Elephant in the Room](https://www.quantamagazine.org/machine-learning-confronts-the-elephant-in-the-room-20180920/)\n- [AI Experiments](https://aiexperiments.withgoogle.com/ )\n- [Where will AGI come from? (Karpathy)](https://ivenzor.com/wp-content/uploads/2018/07/yconftalk-170902200916.pdf)\n- [AlphaGo Zero](https://deepmind.com/blog/alphago-zero-learning-scratch/)\n\t- [AlphaGo Zero Explained In One Diagram](https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0)\n\n### AI for scientific discovery\nSee [[AI/Deep learning/DL#Deep learning for scientific discovery]] and [[AI/Machine Learning#Machine learning for scientific discovery]]\n- [The AI revolution in science: applications and new research directions](https://blogs.royalsociety.org/in-verba/2019/08/07/the-ai-revolution-in-science-applications-and-new-research-directions/)\n- [The AI revolution in scientific research (The Royal Society, The Alan Turing Institute)](https://royalsociety.org/-/media/policy/projects/ai-and-society/AI-revolution-in-science.pdf)\n- [The AI revolution in science](https://www.sciencemag.org/news/2017/07/ai-revolution-science)\n- #TALK [Using AI to Accelerate Scientific Discovery (Demis Hassabis, Deepmind)](https://www.youtube.com/watch?v=jocWJiztxYA)\n- #PAPER [Artificial intelligence in research (Musib 2017)](https://science.sciencemag.org/content/357/6346/28)\n- #PAPER [OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark under Heterogeneous AI Computing Platforms (Zhuang 2022)](https://arxiv.org/pdf/2208.05616v1)\n\t- #CODE https://git.openi.org.cn/OpenMedIA\n\t- OpenMedIA is an open-source toolbox library containing a rich set of deep learning methods for medical image analysis under heterogeneous AI computing platforms\n\n### AI for Earth Sciences\nSee [[AI4ES/AI4ES]]\n\n### AI for good\nSee [[AI4G/AI4good]]\n\n## Events\n- [Neural Information Processing Systems Conference (NeurIPS)](https://nips.cc/)\n\t- [Proceedings](http://papers.nips.cc/)\n\t- [Videos](https://nips.cc/Conferences/2018/Videos)\n- [International Conference on Machine Learning (ICML)](https://icml.cc/)\n- [International Conference for Learning Representations (ICLR)](https://iclr.cc/)\n- [AI \u0026 Deep Learning Conference (NVIDIA)](https://www.nvidia.com/en-us/gtc/)\n- [AAAI Conference on Artificial Intelligence](http://www.aaai.org/Conferences/conferences.php)\n- [World summit AI](https://worldsummit.ai/)\n\n\n## Books\n- #BOOK [AI Transformation Playbook (Andrew Ng, 2018)](https://landing.ai/ai-transformation-playbook/)\n- #BOOK [Artificial Intelligence - Foundations of Computational Agents (Poole 2017, Cambridge)](http://artint.info/2e/index.html)\n- #BOOK [The Future of Machine Intelligence (Beyer 2016, O'REILLY)](https://www.oreilly.com/library/view/the-future-of/9781492042334/)\n- #BOOK [Artificial Intelligence - A Modern Approach (Russell \u0026 Norvig, 2010)](http://aima.cs.berkeley.edu/)\n\t- https://github.com/aimacode\n\t- [Javascript visualization (and implementation) of algorithms](http://aimacode.github.io/aima-javascript/)\n- #BOOK [The quest for AI - A history of ideas and achievements (Nilson 2010, Cambridge)](http://ai.stanford.edu/~nilsson/QAI/qai.pdf)\n\n## Courses\n- #COURSE [Introduction to Artificial Intelligence (CS 188, Berkeley)](https://inst.eecs.berkeley.edu/~cs188/fa18/)\n- #COURSE [Intro to AI (CS188 , UC Berkeley)](http://ai.berkeley.edu/home.html, )\n\t- http://ai.berkeley.edu/lecture_videos.html\n- #COURSE [Introduction to Artificial Intelligence with Python (CS50, Harvard U)](https://pll.harvard.edu/course/cs50s-introduction-artificial-intelligence-python?delta=0)\n- #COURSE [Introduction to Artificial Intelligence (ULiege)](https://github.com/glouppe/info8006-introduction-to-ai)\n- #COURSE [Artificial General Intelligence (MIT 6.S099)](https://agi.mit.edu/)\n- #COURSE [Artificial General (MINES Saint-Etienne)](https://www.emse.fr/~picard/cours/ai/)\n- #COURSE [Elements of AI (Reaktor and the U of Helsinki)](https://www.elementsofai.com/)\n- #COURSE [Introduction to Artificial Intelligence (Coursera - UVA Darden )](https://www.coursera.org/learn/introduction-to-ai#reviews)\n- #COURSE [Artificial Intelligence (edX - Columbia U)](https://www.edx.org/course/artificial-intelligence-ai-columbiax-csmm-101x-0)\n- #COURSE [Artificial Intelligence Nanodegree (Udacity)](https://www.udacity.com/course/artificial-intelligence-nanodegree--nd889)\n- #COURSE [Self-Driving Car Engineer (Udacity)](https://www.udacity.com/drive)\n\t- https://github.com/udacity/self-driving-car\n\t- https://github.com/udacity/self-driving-car-sim\n\t- https://github.com/jessicayung/self-driving-car-nd\n\t- https://github.com/Everhusk/Self-Driving-Car-Engineering\n\n## Talks\n- #TALK [Lex Fridman Podcast](https://lexfridman.com/podcast/)\n- #TALK [Building machines that see, learn, and think like people (Tenenbaum)](https://www.youtube.com/watch?v=7ROelYvo8f0)\n- #TALK [The Rise of Artificial Intelligence through Deep Learning (Bengio)](https://www.youtube.com/watch?v=uawLjkSI7Mo)\n- #TALK [Creating human-level AI (Bengio)](https://www.youtube.com/watch?v=ZHYXp3gJCaI)\n- #TALK [A DARPA Perspective on Artificial Intelligence](https://www.youtube.com/watch?time_continue=2\u0026v=-O01G3tSYpU)\n- #TALK [AI, Deep Learning, and Machine Learning: A Primer](https://a16z.com/2016/06/10/ai-deep-learning-machines/ )\n- #TALK [Symbolic, Statistical and Causal Artificial Intelligence, MLSS 2020](https://www.youtube.com/watch?v=8staJlMbAig)\n- #TALK [Francois Chollet - Intelligence and Generalisation (Interview/podcast)](https://www.youtube.com/watch?v=J0p_thJJnoo)\n\n\n## Related fields and concepts\n\n### Math and Statistics\nSee [[AI/Math and Statistics/Math and Statistics]]\n\n### Data engineering and computer science\nSee [[AI/DS and DataEng/Data engineering and computer science]]\n\n### Data Science\nSee [[AI/DS and DataEng/Data Science]]\n\n### Machine Learning\nSee [[AI/Machine Learning]]\n\n### Computer vision\nSee [[AI/Computer Vision/Computer vision]]\n\n### NLP\nSee [[AI/NLP]]\n\n### Deep Learning\nSee [[AI/Deep learning/DL]]\n\n### Causality\nSee [[AI/Causality]]\n\n### Problem Solving and Search\nSee [[AI/Problem Solving and Search]]\n\n### Automated planning\nSee [[AI/Automated planning]]\n\n### Fair AI\nSee [[AI/FairAI]]\n\n### Explainable AI\nSee [[AI/XAI]] and [[AI/Deep learning/Explainability methods for NNs]]\n\n### Neuro-Symbolic AI\nSee [[Neuro-symbolic AI]]","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Active-learning":{"title":"Active learning","content":"\u003e Active learning refers to algorithms that take an active role in the selection of which ex-amples are labeled. Active learning assumes that there is an ‘oracle’, such as a human expert, that can be queried to get ground-truth labels for selected unlabeled instances\n\n## Resources\n* https://en.wikipedia.org/wiki/Active_learning_(machine_learning). \n* There are situations in which unlabeled data is abundant but manually labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning. With this approach, there is a risk that the algorithm be overwhelmed by uninformative examples.\n- [Overview of Active Learning for Deep Learning](https://jacobgil.github.io/deeplearning/activelearning)\n- #PAPER [An open source machine learning framework for efficient and transparent systematic reviews (van de Schoot 2021)](https://www.nature.com/articles/s42256-020-00287-7)\n\t- #CODE https://github.com/asreview/asreview\n\n## References\n- #PAPER [Active learning literature survey (Settles 2010)](http://burrsettles.com/pub/settles.activelearning.pdf)\n- #PAPER [Active Learning for Convolutional Neural Networks: A Core-Set Approach (2018)](https://openreview.net/forum?id=H1aIuk-RW)\n- #PAPER [Rethinking deep active learning: Using unlabeled data at model training (Simeoni 2019)](https://arxiv.org/abs/1911.08177)\n- #PAPER [Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds (2020)](https://openreview.net/forum?id=ryghZJBKPS )\n\n\n### Active learning for anomaly discovery\n- #PAPER [Incorporating Expert Feedback into Active Anomaly Discovery (Das 2016)](https://ieeexplore.ieee.org/document/7837915)\n\t- http://web.engr.oregonstate.edu/~tgd/publications/das-wong-dietterich-fern-emmott-incorporating-expert-feedback-into-active-anomaly-discovery-icdm2016.pdf\n- #PAPER [Deep Active Learning for Anomaly Detection (Pimentel 2018)](https://arxiv.org/abs/1805.09411)","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Anomaly-and-Outlier-Detection":{"title":"Anomaly and Outlier Detection","content":"\u003e Most of the outlier detection approaches belong to [[AI/Unsupervised learning/Unsupervised learning]] although it might be framed as a [[AI/Semi-supervised learning]] problem. In data mining, anomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data. Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.\n\n\u003e See \"Active learning for anomaly discovery\" section in [[AI/Active learning]]\n\n## Resources\n- https://towardsdatascience.com/density-based-algorithm-for-outlier-detection-8f278d2f7983 \n- https://towardsdatascience.com/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561 \n- [Novelty and Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)\n- [Comparing anomaly detection algorithms for outlier detection on toy datasets](https://scikit-learn.org/stable/auto_examples/plot_anomaly_comparison.html)\n- #TALK [Anomaly detection with TensorFlow (VAEs)](https://www.youtube.com/watch?v=2K3ScZp1dXQ)\n- [Local outlier factor](https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py)\n- One-class SVM\n\t- https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/one-class-support-vector-machine\n\t- https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py\n  - Z-score\n\t- The z-score or standard score of an observation is a metric that indicates how many standard deviations a data point is from the sample’s mean, assuming a gaussian distribution. This makes z-score a parametric method. \n\t- Z-score is a simple, yet powerful method to get rid of outliers in data if you are dealing with parametric distributions in a low dimensional feature space. For nonparametric problems Dbscan and Isolation Forests can be good solutions.\n- Dbscan\n\t- Density Based Spatial Clustering of Applications with Noise\n\t- Dbscan is a density based clustering algorithm, it is focused on finding neighbors by density (MinPts) on an ‘n-dimensional sphere’ with radius ɛ. A cluster can be defined as the maximal set of 'density connected points' in the feature space.\n\t- Dbscan then defines different classes of points: core, border and outlier points.\n\n  \n## Code\n- #CODE [Pyod](https://github.com/yzhao062/pyod)\n\t- https://pyod.readthedocs.io/en/latest/\n\t- PyOD is a comprehensive and scalable Python toolkit for detecting outlying objects in multivariate data. This exciting yet challenging field is commonly referred as Outlier Detection or Anomaly Detection.\n - #CODE [Anomaly detection (Twitter, for R)](https://github.com/twitter/AnomalyDetection)\n  \n  \n## References\n- #PAPER [Isolation forest (Liu 2008)](https://ieeexplore.ieee.org/document/4781136 )\n\t- #TALK [Unsupervised Anomaly Detection with Isolation Forest - Pydata 2018](https://www.youtube.com/watch?v=5p8B2Ikcw-k)\n\t- https://quantdare.com/isolation-forest-algorithm/\n\t- https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py\n\t- https://towardsdatascience.com/outlier-detection-with-isolation-forest-3d190448d45e\n\t- Isolation forest’s basic principle is that outliers are few and far from the rest of the observations. To build a tree (training), the algorithm randomly picks a feature from the feature space and a random split value ranging between the maximums and minimums. This is made for all the observations in the training set. To build the forest a tree ensemble is made averaging all the trees in the forest.\n    - Then for prediction, it compares an observation against that splitting value in a “node”, that node will have two node children on which another random comparisons will be made. The number of “splittings” made by the algorithm for an instance is named: “path length”. As expected, outliers will have shorter path lengths than the rest of the observations.\n- #PAPER [Modeling Extreme Events in Time Series Prediction (Ding 2019)](http://staff.ustc.edu.cn/~hexn/papers/kdd19-timeseries.pdf)\n- #PAPER [Bayesian Anomaly Detection and Classification (2019)](https://arxiv.org/abs/1902.08627  )\n\n\n### DL-based\nSee \"GANs for anomaly detection\" section in [[AI/Deep learning/GANs]]\n\n- #PAPER [Learning Deep Features for One-Class Classification (Perera 2018)](https://arxiv.org/abs/1801.05365)\n- #PAPER [Deep One-Class Classification (Ruff 2018)](http://proceedings.mlr.press/v80/ruff18a.html)\n- #PAPER [Learning and Evaluating Representations for Deep One-Class Classification (Sohn 2021)](https://openreview.net/forum?id=HCSgyPUfeDj)\n\t- #CODE https://github.com/google-research/deep_representation_one_class\n\t- https://ai.googleblog.com/2021/09/discovering-anomalous-data-with-self.html\n- #PAPER [VOS: Learning What You Don't Know by Virtual Outlier Synthesis (Du 2022)](https://arxiv.org/pdf/2202.01197)\n\t- #CODE https://github.com/deeplearning-wisc/vos\n\t- [Paper explained](https://www.youtube.com/watch?v=i-J4T3uLC9M\u0026list=WL\u0026index=59\u0026t=4s)\n- #PAPER [AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly Detection (Dragoi 2022)](https://arxiv.org/pdf/2206.15476v1)\n\t- #CODE https://github.com/bit-ml/anoshift\n\n#### Code\n- #CODE [Anomalib](https://github.com/openvinotoolkit/anomalib)\n\t- An anomaly detection library comprising state-of-the-art algorithms and features such as experiment management, hyper-parameter optimization, and edge inference\n\t- https://openvinotoolkit.github.io/anomalib/\n\t- Anomalib is a deep learning library that aims to collect state-of-the-art anomaly detection algorithms for benchmarking on both public and private datasets\n- #CODE [Orion - A machine learning library for detecting anomalies in signals](https://github.com/signals-dev/Orion) ^oriontfanomalies\n\t- https://sintel.dev/Orion/\n\t- Orion is a machine learning library built for unsupervised time series anomaly detection","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/AutoML":{"title":"AutoML","content":"\u003e Automated machine learning (AutoML) is the process of automating the process of applying machine learning to real-world problems. AutoML covers the complete pipeline from the raw dataset to the deployable machine learning model. AutoML was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine learning.\n\n\u003e See [[AI/Supervised Learning/Model selection and tuning]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Automated_machine_learning\n- Automated machine learning can target various stages of the machine learning process. Steps to automate are:\n\t- Data preparation and ingestion (from raw data and miscellaneous formats)\n\t\t- Column type detection; e.g., boolean, discrete numerical, continuous numerical, or text\n\t\t- Column intent detection; e.g., target/label, stratification field, numerical feature, categorical text feature, or free text feature\n\t\t- Task detection; e.g., binary classification, regression, clustering, or ranking\n\t- Feature engineering\n\t\t- Feature selection\n\t\t- Feature extraction\n\t\t- Meta learning and transfer learning\n\t\t- Detection and handling of skewed data and/or missing values\n\t- Model selection. See [[AI/Supervised Learning/Model selection and tuning]]\n\t- Hyperparameter optimization of the learning algorithm and featurization\n\t- Pipeline selection under time, memory, and complexity constraints\n\t- Selection of evaluation metrics and validation procedures\n\t- Problem checking\n\t\t- Leakage detection\n\t\t- Misconfiguration detection\n\t- Analysis of results obtained\n\t- User interfaces and visualizations for automated machine learning\n- https://www.automl.org/\n- http://www.kdnuggets.com/2017/01/current-state-automated-machine-learning.html\n- https://medium.com/airbnb-engineering/automated-machine-learning-a-paradigm-shift-that-accelerates-data-scientist-productivity-airbnb-f1f8a10d61f8\n\n\n## Books\n-  #BOOK [AutoML: Methods, systems, challenges](https://www.automl.org/book/)\n\n\n## Code\n- #CODE [FLAML - Fast and Lightweight AutoML](https://github.com/microsoft/FLAML)\n\t- FLAML is powered by a new, cost-effective hyperparameter optimization and learner selection method invented by Microsoft Research\n- #CODE [EvalML - AutoML library written in python](https://github.com/alteryx/evalml)\n\t- https://innovation.alteryx.com/introducing-evalml/\n- #CODE [Model Search](https://github.com/google/model_search)\n\t- https://ai.googleblog.com/2021/02/introducing-model-search-open-source.html\n- #CODE [Auto-sklearn](https://github.com/automl/auto-sklearn)\n\t- http://automl.github.io/auto-sklearn/stable/\n\t- [Efficient and Robust Automated Machine Learning (Feurer 2015)](https://ml.informatik.uni-freiburg.de/papers/15-NIPS-auto-sklearn-preprint.pdf)\n\t- http://www.kdnuggets.com/2016/08/winning-automl-challenge-auto-sklearn.html\n- #CODE [TPOT](https://github.com/rhiever/tpot)\n\t- http://rhiever.github.io/tpot/\n\t- Consider TPOT yourData Science Assistant. TPOT is a Python tool that automatically creates and optimizes ML pipelines using genetic programming\n\t- https://blog.alookanalytics.com/2017/05/25/automate-your-machine-learning/\n- #CODE [AutoKeras](https://github.com/keras-team/autokeras)\n- #CODE [H2O autoML](https://blog.h2o.ai/2017/06/automatic-machine-learning/)\n- #CODE [Adanet - Fast and flexible AutoML with learning guarantees](https://github.com/tensorflow/adanet )\n\t- https://adanet.readthedocs.io\n\t- AdaNet is a lightweight TensorFlow-based framework for automatically learning high-quality models with minimal expert intervention\n- #CODE [FEDOT](https://github.com/nccr-itmo/FEDOT)\n\t- Automated modeling and machine learning framework\n\t- https://fedot.readthedocs.io/en/latest/\n\n\n## Neural architecture search (NAS)\n- NAS is closely related to hyperparameter optimization and is a subfield of automated machine learning (AutoML).\n- https://en.wikipedia.org/wiki/Neural_architecture_search\n\t- Neural architecture search (NAS) is a technique for automating the design of artificial neural networks (ANN), a widely used model in the field of machine learning. NAS has been used to design networks that are on par or outperform hand-designed architectures. Methods for NAS can be categorized according to the search space, search strategy and performance estimation strategy used:\n\t- The search space defines the type(s) of ANN that can be designed and optimized.\n\t- The search strategy defines the approach used to explore the search space.\n\t- The performance estimation strategy evaluates the performance of a possible ANN from its design (without constructing and training it).\n\n- [Literature on NAS](https://www.automl.org/automl/literature-on-neural-architecture-search/)\n- #PAPER [AdaNet: Adaptive Structural Learning of Artificial Neural Networks (Cortes 2017)](http://proceedings.mlr.press/v70/cortes17a.html)\n\t- https://ai.googleblog.com/2018/10/introducing-adanet-fast-and-flexible.html?m=1\n- #PAPER [Improving Neural Architecture Search Image Classifiers via Ensemble Learning, AdaNas (Macko 2019)](https://arxiv.org/abs/1903.06236)\n- #PAPER [Up to two billion times acceleration of scientific simulations with deep neural architecture search (Kasim 2020)](https://arxiv.org/abs/2001.08055)\n- #PAPER [Neural Architecture Search without Training (Mellor 2020)](https://arxiv.org/abs/2006.04647)\n\t- [Paper explained](https://www.youtube.com/watch?v=a6v92P0EbJc)\n- #PAPER [Automated Evolutionary Approach for the Design of Composite Machine Learning Pipelines (Nikitin 2021)](https://arxiv.org/abs/2106.15397)","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Automated-planning":{"title":"Automated planning","content":"\u003e AI Planning is a branch of artificial intelligence that concerns the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles. Unlike classical control and classification problems, the solutions are complex and must be discovered and optimized in multidimensional space.\n\n## Resources\n- [A brief overview of AI planning](https://users.aalto.fi/~rintanj1/jussi/planning.html)\n- Planning: \n\t- https://www.emse.fr/~picard/cours/ai/chapter-planning-intro.pdf\n\t- https://www.emse.fr/~picard/cours/ai/chapter-planning-space.pdf","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Bayesian-modelling":{"title":"Bayesian modelling","content":"\u003e See [[AI/Math and Statistics/Monte Carlo methods]] and [[AI/Deep learning/Probabilistic deep learning]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Bayesian_statistics\n- https://en.wikipedia.org/wiki/Bayesian_inference\n- http://brohrer.github.io/how_bayesian_inference_works.html\n- http://willwolf.io/en/2017/02/07/bayesian-inference-via-simulated-annealing/\n- #TALK Bayesian Inference, Shakir Mohamed, MLSS 2020:\n\t- [Part I](https://www.youtube.com/watch?v=x4Y90zPjbq0)\n\t- [Part II](https://www.youtube.com/watch?v=x4Y90zPjbq0\u0026feature=youtu.be)\n\n### Bayesian vs frequentist discussion\n- http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/\n- http://www.fharrell.com/2017/02/my-journey-from-frequentist-to-bayesian.html\n- https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/\n- https://aeon.co/essays/it-s-time-for-science-to-abandon-the-term-statistically-significant\n- http://www.fharrell.com/2017/02/a-litany-of-problems-with-p-values.html?m=1\n\n### Bayes theorem\n- http://blogs.scientificamerican.com/cross-check/bayes-s-theorem-what-s-the-big-deal/\n- http://www.analyticsvidhya.com/blog/2016/06/bayesian-statistics-beginners-simple-english/\n\n### MAP\n- https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation\n- In Bayesian statistics, a maximum a posteriori probability(MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data.It is closely related toFisher's method of maximum likelihood(ML) estimation, but employs an augmented optimization objective which incorporates a prior distribution(that quantifies the additional information available through prior knowledge of a related event) over the quantity one wants to estimate. MAP estimation can therefore be seen as a regularization of ML estimation.\n\n### MLE\n- https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\n- Maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters. MLE can be seen as a special case of the maximum a posteriori estimation (MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized.\n\n### Bayesian network\n- https://en.wikipedia.org/wiki/Bayesian_network\n\n### Naive Bayes algorithm\n- Supervised machine learning method\n- [Naive Bayes (scikit-learn)](https://scikit-learn.org/stable/modules/naive_bayes.html)\n\n### Variational Bayesian methods\n- See [[AI/Deep learning/Normalizing flows]]\n- [Variational Bayesian inference with normalizing flows: a simple example](https://towardsdatascience.com/variational-bayesian-inference-with-normalizing-flows-a-simple-example-1db109d91062)\n\t- #CODE https://github.com/fraseriainlewis/towardsdatascience\n\n### MCMC\n- See MCMC section in [[AI/Math and Statistics/Monte Carlo methods]]\n\n## Code\n- #CODE [Stan](https://github.com/stan-dev/stan)\n\t- http://mc-stan.org\n- #CODE [Pymc3 - Probabilistic Programming in Python](http://pymc-devs.github.io/pymc3/)\n- #CODE [Arviz - Exploratory analysis of Bayesian models with Python](https://arviz-devs.github.io/arviz/)\n- #CODE [BayesicFitting - A package for model fitting and bayesian evidence calculation](https://github.com/dokester/BayesicFitting)\n\n\n## Courses\n- #COURSE [Notes for Bayesian Models for Machine Learning (Columbia U)](http://www.columbia.edu/~jwp2128/Teaching/BML_lecture_notes.pdf)\n\n\n## Books\n- #BOOK [Think Bayes - Bayesian Statistics Made Simple (Downey 2012)](http://greenteapress.com/wp/think-bayes/)\n\t- Think Bayes is an introduction to Bayesian statistics using computational methods\n- #BOOK [Probabilistic programming and bayesian methods for hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)\n\t- https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers\n- #BOOK [Bayesian Modeling and Computation in Python (Martin 2021, CRC)](https://bayesiancomputationbook.com/welcome.html)\n\n\n## References\n- #PAPER [Bayesian model selection for complex dynamic systems (Mark 2018)](https://www.nature.com/articles/s41467-018-04241-5) ^1ef748","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Causality":{"title":"Causality","content":"## Resources\n- [To Build Truly Intelligent Machines, Teach Them Cause and Effect](https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/)\n- [Representing uncertain knowledge](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture5.md)\n- [Reasoning over time](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture7.md)\n- [Making decisions](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture8.md)\n- [Causal Analysis Introduction - Examples in Python and PyMC](https://engl.is/causal-analysis-introduction-examples-in-python-and-pymc.html)\n- [Granger causality](https://en.wikipedia.org/wiki/Granger_causality)\n\t- The Granger causality test is a statistical hypothesis test for determining whether one time series is useful in forecasting another, first proposed in 1969\n\t- Granger causality is a fundamental technique for causal inference in time series data, commonly used in the social and biological sciences\n- PCMCI:\n\t- https://jakobrunge.github.io/tigramite/#tigramite-pcmci-pcmci\n\t- PCMCI causal discovery for time series datasets. It is a 2-step causal discovery method for large-scale time series datasets. The first step is a condition-selection followed by the MCI conditional independence test.\n\n\n## Talks\n- #TALK [Interview - Causal Reasoning, Counterfactuals, and the Path to AGI (Judea Pearl)](https://www.youtube.com/watch?v=pEBI0vF45ic)\n- #TALK Causality, Bernhard Schölkopf and Stefan Bauer, MLSS 2020: \n\t- [Part I](https://www.youtube.com/watch?v=btmJtThWmhA\u0026feature=youtu.be)\n\t\t- https://drive.google.com/file/d/1qlUYuU7wfoD6C8Qo0x4Eyz5aT2k0B_jC/view\n\t- [Part II](https://www.youtube.com/watch?v=9DJWJpn0DmU\u0026feature=youtu.be)\n\t\t- https://drive.google.com/file/d/1_-bUoyY-Thfqu1ac4EwBSv6cCoS-qtnn/view\n- #TALK [Yoshua Bengio Guest Talk - Towards Causal Representation Learning](https://www.youtube.com/watch?v=rKZJ0TJWvTk)\n\n\n## Code\n- #CODE [Causalml](https://github.com/uber/causalml)\n- #CODE [Causality - Tools for causal analysis](https://github.com/akelleh/causality)\n\t- https://medium.com/@akelleh/causal-inference-with-pandas-dataframes-fc3e64fce5d\n- #CODE [CausalImpact (for R)](https://google.github.io/CausalImpact/)\n- #CODE [tfcausalimpact - Google's Causal Impact Algorithm Implemented on Top of TensorFlow Probability](https://github.com/WillianFuks/tfcausalimpact)\n\t- https://towardsdatascience.com/implementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126\n\n  \n## References\n- #PAPER [Causal inference with multiple time series: principles and problems (2013)](https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0613)\n- #PAPER [Towards a Learning Theory of Cause-Effect Inference (Lopez-Paz 2015)](https://arxiv.org/abs/1502.02398)\n- #PAPER [Unsupervised Discovery of El Nino Using Causal Feature Learning on Microlevel Climate Data (Chalupka 2016)](https://arxiv.org/abs/1605.09370)\n- #PAPER [Comparative Benchmarking of Causal Discovery Techniques (Singh 2017)](https://arxiv.org/abs/1708.06246)\n- #PAPER [A Physics-Based Approach to Unsupervised Discovery of Coherent Structures in Spatiotemporal Systems (Rupe 2017)](https://arxiv.org/abs/1709.03184) ^rupe17\n- #PAPER [A Primer on Causal Analysis (2018)](https://arxiv.org/abs/1806.01488)\n- #PAPER [DAGs with NO TEARS: Continuous Optimization for Structure Learning (Zheng 2018)](https://arxiv.org/abs/1803.01422)\n\t- #CODE https://github.com/xunzheng/notears\n- #PAPER [Local causal states and discrete coherent structures (Rupe 2018)](https://aip.scitation.org/doi/10.1063/1.5021130) ^f00b92\n- #PAPER [Learning Functional Causal Models with Generative Neural Networks (Goudet 2018)](https://arxiv.org/abs/1709.05321)\n- #PAPER [Variable-lag Granger Causality for Time Series Analysis (2019)](https://arxiv.org/abs/1912.10829)\n- #PAPER [Learning Sparse Nonparametric DAGs (Zheng 2020)](https://arxiv.org/abs/1909.13189)\n\t- #CODE https://github.com/xunzheng/notears\n\t- #CODE https://github.com/jmoss20/notears\n- #PAPER [When causal inference meets deep learning (Luo 2020)](https://www.nature.com/articles/s42256-020-0218-x)\n\t- Learning causal relations, rather than correlations, is a fundamental problem in both statistical Machine Learning and computer sciences\n\t- Bayesian networks (BNs) can capture causal relations, but learning such a network from data is NP-hard\n\t- Recent work has made it possible to approximate this problem as a continuous optimization task that can be solved efficiently with well-established numerical techniques\n\t- BNs encode the conditional independencies between variables using directed acyclic graphs (DAGs)\n- #PAPER [Spacetime Autoencoders Using Local Causal States (Rupe 2020)](https://arxiv.org/abs/2010.05451)\n\t- #CODE https://github.com/adamrupe/spacetime_autoencoders\n\t- Local causal states are latent representations that capture organized pattern and structure in complex spatiotemporal systems\n\t- We expand their functionality, framing them as space-time autoencoders\n- #PAPER [Algorithms for Causal Reasoning in Probability Trees (Genewein 2020)](https://arxiv.org/abs/2010.12237)\n\t- #CODE https://github.com/deepmind/deepmind-research/tree/master/causal_reasoning\n\t- https://syncedreview.com/2020/10/29/deepmind-introduces-algorithms-for-causal-reasoning-in-probability-trees/\n- #PAPER [Off-the-shelf deep learning is not enough, and requires parsimony, Bayesianity, and causality (Vasudevan 2021)](https://www.nature.com/articles/s41524-020-00487-0)\n- #PAPER [Towards Causal Representation Learning (Schölkopf 2021)](https://arxiv.org/abs/2102.11107)","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Background-subtraction":{"title":"Background subtraction","content":"---\n\n## Resources\n- https://en.wikipedia.org/wiki/Foreground_detection\n- https://github.com/murari023/awesome-background-subtraction\n- Foreground detection is one of the major tasks in the field of computer vision and image processing whose aim is to detect changes in image sequences. \n- Background subtraction is any technique which allows an image's foreground to be extracted for further processing (object recognition etc.).\n- [Background Subtraction Website (T. Bouwmans)](https://sites.google.com/site/thierrybouwmans/background-subtraction","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Computer-vision":{"title":"Computer Vision","content":"\u003e Computer vision is an interdisciplinary scientific field that deals with how computers can gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do\n\n\u003e See: \n\u003e - [[AI/Deep learning/CNNs]]\n\u003e - \"MLPs for vision and language\" section in [[AI/Deep learning/MLPs]]\n\u003e - \"For Computer Vision\" section in [[AI/Deep learning/Transformers]]\n\u003e - \"Generative models for Image data\" section in [[AI/Deep learning/Generative modelling]]\n\u003e - [[AI/Deep learning/GANs]]\n\u003e - [[AI/Unsupervised learning/Sparse dictionary learning]]\n\n\n## Resources\n- https://github.com/jbhuang0604/awesome-computer-vision\n- [Papers with code - computer vision](https://paperswithcode.com/area/computer-vision)\n- https://en.wikipedia.org/wiki/Computer_vision\n- [Denoising: wavelet thresholding](https://blancosilva.wordpress.com/teaching/mathematical-imaging/denoising-wavelet-thresholding/)\n\n## Books\n- #BOOK [Image Processing and Acquisition using Python (Chityala 2014)](https://www.crcpress.com/Image-Processing-and-Acquisition-using-Python/Chityala-Pudipeddi/p/book/9781466583757)\n- #BOOK [Computer Vision: A Modern Approach (Forsyth, 2011 PEARSON)](https://www.pearson.com/us/higher-education/program/Forsyth-Computer-Vision-A-Modern-Approach-2nd-Edition/PGM111082.html)\n\t- https://github.com/yihui-he/computer-vision-tutorial/blob/master/Computer%20Vision%20A%20Modern%20Approach%202nd%20Edition.pdf\n- #BOOK [Computer Vision: Models, Learning, and Inference (Prince, 2012 CAMBRIDGE)](http://www.computervisionmodels.com/)\n- #BOOK [Computer vision (chapter)](https://d2l.ai/chapter_computer-vision/index.html)\n\n## Courses\n- #COURSE [Computer vision (CS543/ECE549, UIUC)](https://courses.engr.illinois.edu/cs543/sp2015/)\n- #COURSE [Advances in Computer vision (MIT)](http://6.869.csail.mit.edu/fa18/)\n- #COURSE [Introduction to computer vision (Udacity, Georgia Tech)](https://www.udacity.com/course/introduction-to-computer-vision--ud810)\n- #COURSE [Deep Learning for Computer Vision (UPC TelecomBCN 2016)](http://imatge-upc.github.io/telecombcn-2016-dlcv/)\n- #COURSE [Convolutional Neural Networks for Visual Recognition (CS231n, Stanford)](http://cs231n.github.io/)\n\t- [Pre-version of the course](http://karpathy.github.io/neuralnets/)\n\t- [Notes (Karpathy)](http://cs231n.github.io/)\n\t- [Videos for each lecture](https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC)\n- #COURSE [Computer vision (NYU)](https://cs.nyu.edu/~fergus/teaching/vision/)\n- #COURSE [Digital image processing (U Tartu)](https://sisu.ut.ee/dev/imageprocessing/avaleht)\n- #COURSE Convolutional Neural Networks for Image Recognition (DeepMind x UCL | Deep Learning Lectures)\n\t- https://www.youtube.com/watch?v=shVKhOmT0HE\u0026list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\u0026index=3\u0026t=1s\n\t- https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L3%20-%20UUCLxDeepMind%20DL2020.pdf\n- #COURSE Advanced Models for Computer Vision (DeepMind x UCL | Deep Learning Lectures)\n\t- https://www.youtube.com/watch?v=_aUq7lmMfxo\u0026list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\u0026index=4\n\t- https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L4%20-%20UCLxDeepMind%20DL2020.pdf\n- #COURSE [Rendering course (TU Wien)](https://users.cg.tuwien.ac.at/zsolnai/gfx/rendering-course/)\n\t- This rendering course is an MSc-level class at the Technical University of Vienna. It is about ray tracing, photorealistic rendering and global illumination\n\t- [Playlist](https://www.youtube.com/playlist?list=PLujxSBD-JXgnGmsn7gEyN28P1DnRZG7qi)\n\n\n## Code\n- #CODE [Scikit-image. Image processing in Python](https://github.com/scikit-image/scikit-image)\n\t- http://scikit-image.org\n- #CODE [OpenCV (Open Source Computer Vision Library)](https://opencv.org/)\n\t- OpenCV is released under a BSD license and hence it’s free for both academic and commercial use. It has C++, Python and Java interfaces and supports Windows, Linux, Mac OS, iOS and Android. OpenCV was designed for computational efficiency and with a strong focus on real-time applications. Written in optimized C/C++, the library can take advantage of multi-core processing. Enabled with OpenCL, it can take advantage of the hardware acceleration of the underlying heterogeneous compute platform.\n\t- https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV\n\t- #PAPER [Real-time computer vision with OpenCV (Pulli 2012)](https://dl.acm.org/doi/10.1145/2184319.2184337)\n- #CODE [SimpleCV](https://github.com/sightmachine/SimpleCV)\n\t- http://simplecv.org/\n\t- SimpleCV is an open source framework for building computer vision applications. With it, you get access to several high-powered computer vision libraries such as OpenCV – without having to first learn about bit depths, file formats, color spaces, buffer management, eigenvalues, or matrix versus bitmap storage. This is computer vision made easy.\n- #CODE [Imgaug. Image augmentation for machine learning experiments](https://github.com/aleju/imgaug)\n\t- http://imgaug.readthedocs.io\n- #CODE [ChainerCV: a Library for Computer Vision in Deep Learning](https://github.com/chainer/chainercv)\n\t\t- http://chainercv.readthedocs.io/en/stable/\n\t\t- ChainerCV is a collection of tools to train and run neural networks for computer vision tasks using Chainer\n- #CODE [Openface. Free and open source face recognition with deep neural networks](https://cmusatyalab.github.io/openface/)\n- #CODE Vision - The torchvision package consists of popular datasets, model architectures, and common image transformations fo CV. \n\t- https://github.com/pytorch/vision\n- #CODE [Scenic](https://github.com/google-research/scenic)\n\t- https://www.marktechpost.com/2021/10/30/google-research-introduces-scenic-an-open-source-jax-library-for-computer-vision-research/\n\t- A Jax Library for Computer Vision Research and Beyond\n\t- codebase with a focus on research around attention-based models for computer vision\n\t- #PAPER [SCENIC: A JAX Library for Computer Vision Research and Beyond (2021)](https://arxiv.org/abs/2110.11403)\n- #CODE [Pytorch-image-models](https://github.com/rwightman/pytorch-image-models)\n\t- PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, EfficientNetV2, NFNet, Vision Transformer, MixNet, MobileNet-V3/V2, RegNet, DPN, CSPNet, and more\n\t- https://rwightman.github.io/pytorch-image-models/\n\n## References\n- #PAPER [Brief review of image denoising techniques (Fan 2019)](https://vciba.springeropen.com/articles/10.1186/s42492-019-0016-7)\n\n### Traditional CV techniques\nSee [[Traditional CV]]\n\n### Deep learning-based CV\nSee [[Deep CV]]","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Deep-CV":{"title":"Deep CV","content":"\u003e DL is used in the domain of digital image processing to solve difficult problems (e.g.image colorization, classification, segmentation and  detection). DL methods such as CNNs mostly improve prediction performance using big data and plentiful computing resources and have pushed the boundaries of what was possible. Problems which were assumed to be unsolvable are now solved with super-human accuracy (eg image classification). Since being reignited by Krizhevsky, Sutskever and Hinton in 2012, DL has dominated the domain ever since due to a substantially better performance compared to traditional methods.\n\n\u003e See:\n\u003e - [[AI/Deep learning/CNNs]]\n\u003e - [[AI/Deep learning/GANs]]\n\u003e - [[AI/Deep learning/Normalizing flows]] \n\u003e - \"For Computer Vision\" section in [[AI/Deep learning/Transformers]]\n\u003e - [[Deep image prior]]\n\n\n## Resources\n- https://github.com/kjw0612/awesome-deep-vision\n- https://github.com/timzhang642/3D-Machine-Learning\n- https://medium.com/@taposhdr/medical-image-analysis-with-deep-learning-i-23d518abf531\n- http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/\n\n### Applications\nSee:\n- [[AI/Computer Vision/Background subtraction]]\n- [[AI/Computer Vision/Image and video captioning]] \n- [[AI/Computer Vision/Image-to-image translation]]\n- [[AI/Computer Vision/Inpainting and restoration]]\n- [[AI/Computer Vision/Object classification, image recognition]]\n- [[AI/Computer Vision/Object detection]]\n- [[AI/Computer Vision/Semantic segmentation]]\n- [[AI/Computer Vision/Super-resolution]]\n- [[AI/Computer Vision/Video Frame Interpolation]]\n- [[AI/Computer Vision/Video segmentation and prediction]]\n\n## References\n- #PAPER [Deep Learning for Computer Vision: A Brief Review (Voulodimos 2017)](https://www.hindawi.com/journals/cin/2018/7068349/)\n- #PAPER [Deep Learning vs. Traditional Computer Vision (O'Mahony 2019)](https://arxiv.org/abs/1910.13796)\n- #PAPER [Deep learning encodes robust discriminative neuroimaging representations to outperform standard machine learning (Abrol 2021)](https://www.nature.com/articles/s41467-020-20655-6)\n- #PAPER [Deep learning-enabled medical computer vision (Esteva 2021)](https://www.nature.com/articles/s41746-020-00376-2)\n- #PAPER [Involution: Inverting the Inherence of Convolution for Visual Recognition, a brand new neural operator (Li 2021)](https://arxiv.org/abs/2103.06255)\n\t- #CODE https://github.com/d-li14/involution\n\t- #CODE https://github.com/PrivateMaRyan/keras-involution2Ds\n\t- [Paper explained](https://www.youtube.com/watch?v=pH2jZun8MoY)\n\t- https://keras.io/examples/vision/involution/\n\t- [Involution: Inverting the Inherence of Convolution for Visual Recognition](https://medium.com/analytics-vidhya/involution-a-step-towards-a-new-generation-of-neural-networks-for-visual-recognition-3b8ad75eb818)\n\t- involution is a general-purpose neural primitive that is versatile for a spectrum of deep learning models on different vision tasks\n\t- involution bridges convolution and self-attention in design, while being more efficient and effective than convolution, simpler than self-attention in form\n\t- the proposed involution operator could be leveraged as fundamental bricks to build the new generation of neural networks for visual recognition, powering different deep learning models on several prevalent benchmarks\n- #PAPER [Unifying Nonlocal Blocks for Neural Networks (Zhu 2021)](https://arxiv.org/abs/2108.02451v3)\n\t- #CODE https://github.com/zh460045050/SNL_ICCV2021\n- #PAPER [X-volution: On the unification of convolution and self-attention (Chen 2021)](https://arxiv.org/pdf/2106.02253)\n- #PAPER [Bivolution: A Static and Dynamic Coupled Filter (Hu 2022)](https://aaai-2022.virtualchair.net/poster_aaai2015)\n\t- #CODE https://github.com/neuralchen/Bivolution\t\n- #PAPER [Convolution of Convolution: Let Kernels Spatially Collaborate (Zhao 2022)](https://www.semanticscholar.org/paper/Convolution-of-Convolution%3A-Let-Kernels-Spatially-Zhao-Li/87e0f7adce75bac24f944f0b8fb7e2441b36cfb4)\n\t- #CODE https://github.com/Genera1Z/ConvolutionOfConvolution","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Deep-image-prior":{"title":"Deep image prior","content":"\u003e Deep Image Prior is a type of convolutional neural network used to enhance a given image with no prior training data other than the image itself. A neural network is randomly initialized and used as prior to solve inverse problems such as noise reduction, super-resolution, and inpainting. Image statistics is captured by the structure of a convolutional image generator rather than by any previously learned capabilities\n\n## Resources\n- https://en.wikipedia.org/wiki/Deep_Image_Prior\n\n\n## References\n- #PAPER [Deep Image Prior (Ulyanov 2018)](https://arxiv.org/pdf/1711.10925)            \n\t- https://dmitryulyanov.github.io/deep_image_prior\n\t- Paper explained: https://www.youtube.com/watch?v=_BPJFFkxSbw\n\t- #TALK [Dmitry Ulyanov - Deep Image Prior](https://www.youtube.com/watch?v=-g1NsTuP1_I)\n\t- #CODE https://github.com/DmitryUlyanov/deep-image-prior\n- #PAPER [A Bayesian Perspective on the Deep Image Prior (Cheng 2019)](https://arxiv.org/pdf/1904.07457)            \n- #PAPER [Uncertainty Estimation in Medical Image Denoising with Bayesian Deep Image Prior (Laves 2020)](https://arxiv.org/pdf/2008.08837)            \n\t- #TALK [Uncertainty Estimation in Medical Image Denoising with Bayesian Deep Image Prior](https://www.youtube.com/watch?v=ULMNkHJ6yBI)\n- #PAPER [A Mean-Field Variational Inference Approach to Deep Image Prior for Inverse Problems in Medical Imaging (Tolle 2021)](https://proceedings.mlr.press/v143/tolle21a.html)\n\t- #CODE https://github.com/maltetoelle/mfvi-dip","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Image-and-video-captioning":{"title":"Image and video captioning","content":"## References\n- #PAPER [Show and Tell: A Neural Image Caption Generator (Vinyals 2015)](https://arxiv.org/abs/1411.4555)\n- #PAPER [Deep Visual-Semantic Alignments for Generating Image Description](http://cs.stanford.edu/people/karpathy/cvpr2015.pdf)\n\t- http://cs.stanford.edu/people/karpathy/deepimagesent/\n- #PAPER [Mind’s Eye: A Recurrent Visual Representation for Image Caption Generation](http://www.cs.cmu.edu/~xinleic/papers/cvpr15_rnn.pdf)\n- #PAPER [Sequence to Sequence--Video to Text](http://arxiv.org/abs/1505.00487)\n- #PAPER [Describing Videos by Exploiting Temporal Structure (Yao 2015)](http://arxiv.org/abs/1502.08029)\n- #PAPER [3G structure for image caption generation (Yuan 2018)](https://arxiv.org/abs/1904.09544)\n- #PAPER #REVIEW [A Systematic Literature Review on Image Captioning (Staniute 2019)](https://www.mdpi.com/2076-3417/9/10/2024/htm)\n- #PAPER #REVIEW [Survey of convolutional neural networks for image captioning (Kalra 2020)](https://www.tandfonline.com/doi/abs/10.1080/02522667.2020.1715602)","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Image-to-image-translation":{"title":"Image-to-image translation","content":"\u003e The task of Image-to-image translation is to learn the mapping from a given image (X) to a specific target image (Y), e.g., mapping grayscale images to RGB images\n\n## Resources\n- Learning the mapping from one visual representation to another requires an understanding of underlying features that are shared between these representations, such features are either domain-independent or domain-specific.\n- https://paperswithcode.com/task/image-to-image-translation\n- https://github.com/weihaox/awesome-image-translation\n- [Deep Domain Adaptation In Computer Vision](https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f)\n\n## References\n- #PAPER #REVIEW [Image-to-Image Translation: Methods and Applications (Pang 2021)](https://arxiv.org/abs/2101.08629)\n\n\n### CNN-based\nSee [[AI/Deep learning/Encoder-decoder networks]]\n- Related to the task of supervised semantic segmentation but changing the Y and the loss (MAE, MSE or other reconstruction loss)\n\n\n### GAN-based\nSee [[AI/Deep learning/GANs#GANs for representation learning and image synthesis]]\n- #PAPER [Deep Generative Adversarial Networks for Image-to-Image Translation: A Review (Alotaibi 2020)](https://www.mdpi.com/2073-8994/12/10/1705/htm#) ^I2IGANs20\n\t- The powerful ability of deep feature learning to automatically utilize complex and high-level feature representations has significantly advanced the performance of state-of-the-art methods across computer applications\n\t- The underlying structure and distinctive (complex) features are both discovered via deep learning-based methods that can be classified further into discriminative feature-learning algorithms and generative feature-learning algorithms\n\t- Discriminative models focus on the classification-learning process by learning the conditional probability p (x|y) to map input x to class label y. One of the most popular methods used for image feature learning utilizes convolutional neural networks (CNN) for feature extraction and image classification (LeNet, AlexNet, VGGNet, ResNet and other supervised learning algorithms)\n\t- Generative models focus on the data distribution to discover the underlying features from large amounts of data in an unsupervised setting. Such models are able to generate new samples by learning the estimation of the joint probability distribution p (x,y) and predicting y\n\t- The most dominant and efficient deep generative models of recent years have been VAE and GAN. A variational autoencoder learns the underlying probability distribution and generates a new sample that is based on Bayesian inference by maximizing the lower bound of the data’s log-likelihood. In contrast, generative adversarial networks learn data distributions through the adversarial training process based on game theory instead of maximizing the likelihood.\n\t- I2I methods:\n\t\t- Supervised\n\t\t\t- Directional translation (Pix2Pix, StarGAN)\n\t\t\t- Bidirectional translation (BicycleGAN, CEGAN)\n\t\t- Unsupervised\n\t\t\t- Cyclic consistency (CycleGAN, DiscoGAN, DualGAN, QGAN, XGAN)\n\t\t\t- Autoencoder-based (UNIT, BranchGAN)\n\t\t\t- Disentangler representation (MUNIT, DIRT, DosGAN)\n- #PAPER [DCT-Net: Domain-Calibrated Translation for Portrait Stylization (Men 2022)](https://arxiv.org/pdf/2207.02426v1)\n\t- #CODE https://github.com/menyifang/DCT-Net\n\n#### Paired (supervised) translation \n- #PAPER [Image-to-Image Translation with Conditional Adversarial Networks, pix2pix (Isola 2016)](https://arxiv.org/abs/1611.07004) ^pix2pix\n\t- Loss function learned by the network itself instead of L2, L1 norms\n\t- UNET generator, CNN discriminator\n\t- Euclidean distance is minimized by averaging all plausible outputs, which causes blurring.  Coming up with loss functions that force the CNN to do what we really want– e.g., output sharp, realistic images – is an open problem and generally requires expert knowledge \n\t- Evaluating the quality of synthesized images is an open and difficult problem. Traditional metrics such as per-pixel mean-squared error do not assess joint statistics of the result, and therefore do not measure the very structure that structured losses aim to capture\n\t- #CODE https://github.com/phillipi/pix2pix\n\t- #CODE https://www.tensorflow.org/tutorials/generative/pix2pix \n\t- #CODE https://github.com/He-Jian/pix2pix-keras\n\t- https://affinelayer.com/pixsrv/\n\t- https://medium.com/deep-math-machine-learning-ai/ch-14-2-pix2pix-gan-and-cycle-gan-55cd84318fb8 \n\t- https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/\n\t- https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n\t- [Image-to-Image Translation in Tensorflow](https://affinelayer.com/pix2pix/)\n\t- [Two minutes papers](https://www.youtube.com/watch?v=u7kQ5lNfUfg)\n\t- [Paper walkthrough](https://www.youtube.com/watch?v=9SGs4Nm0VR4)\n\t- Stochastic inference: \n\t\t- https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/152\n\t\t\t- tried a few ways of adding z to the nets, e.g., adding z to a latent state, concatenating with a latent state, applying dropout, etc. The output tended not to vary much as a function of z\n\t\t\t- see follow up paper by Zhu et al 2017 (BicycleGAN). Shows one way of getting z to actually have a substantial effect\n\t\t- https://machinelearningmastery.com/how-to-implement-pix2pix-gan-models-from-scratch-with-keras/ \n\t\t\t- unlike traditional generator models in the GAN architecture, the U-Net generator does not take a point from the latent space as input. Instead, dropout layers are used as a source of randomness both during training and when the model is used to make a prediction, e.g. generate an image at inference time\n\t\t\t- similarly, batch normalization is used in the same way during training and inference, meaning that statistics are calculated for each batch and not fixed at the end of the training process. This is referred to as instance normalization, specifically when the batch size is set to 1 as it is with the Pix2Pix model\n\t\t\t- \"At inference time, we run the generator net in exactly the same manner as during the training phase. This differs from the usual protocol in that we apply dropout at test time, and we apply batch normalization using the statistics of the test batch, rather than aggregated statistics of the training batch.\"\n\t\t\t- in Keras, layers like Dropout and BatchNormalization operate differently during training and in inference model. We can set the “training” argument when calling these layers to “True” to ensure that they always operate in training-model, even when used during inference\n- #PAPER [Toward Multimodal Image-to-Image Translation, BicycleGAN (Zhu 2017)](https://arxiv.org/abs/1711.11586) ^bicyclegan\n\t- #CODE https://github.com/junyanz/BicycleGAN\n\t- #CODE https://github.com/clvrai/BicycleGAN-Tensorflow\n\t- #CODE https://github.com/prakashpandey9/BicycleGAN\n\t- Aimed to model a distribution of possible outputs in a conditional generative modeling setting\n\t-  The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. \n\t- Encouraged the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results\n- #PAPER [Bayesian Conditional Generative Adverserial Networks (Ehsan Abbasnejad 2017)](https://arxiv.org/abs/1706.05477)\n- #PAPER [Image-to-image translation with conditional GAN (Hu 2018)](https://cs230.stanford.edu/projects_spring_2018/reports/8289557.pdf)\n- #PAPER [High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs (Wang 2018)](https://tcwang0509.github.io/pix2pixHD/)\n\t- #CODE https://github.com/NVIDIA/pix2pixHD\n\t- https://youtu.be/3AIpPlzM_qs\n- #PAPER [StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation (Choi 2018)](https://arxiv.org/abs/1711.09020)\n\t- #CODE https://github.com/yunjey/stargan\n- #PAPER [Reversible GANs for Memory-efficient Image-to-Image Translation (van der Ouderaa 2019)](https://arxiv.org/abs/1902.02729)\n- #PAPER [StarGAN v2: Diverse Image Synthesis for Multiple Domains (Choi 2020)](https://arxiv.org/abs/1912.01865)\n\t- #CODE https://github.com/clovaai/stargan-v2\n\n\n#### Unpaired (unsupervised) translation\n- #PAPER [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, CycleGAN (Zhu, 2017)](https://arxiv.org/abs/1703.10593 )\n\t- #TALK https://www.youtube.com/watch?v=Fea4kZq0oFQ \n\t- #CODE https://github.com/clvrai/CycleGAN-Tensorflow\n\t- https://junyanz.github.io/CycleGAN/\n\t- CycleGAN is an approach to training deep convolutional networks for Image-to-Image translation tasks. Unlike other GANs models for image translation tasks, CycleGAN learns a mapping between one image domain and another using an unsupervised approach. This is done by training Generator Networks to learn a mapping from domain X into an image that looks like it came from domain Y (and vice-versa)\n\t- for the generator, residual functions (residual block) are used\n\t- https://medium.com/deep-math-machine-learning-ai/ch-14-2-pix2pix-gan-and-cycle-gan-55cd84318fb8 \n\t- https://towardsdatascience.com/image-to-image-translation-using-cyclegan-model-d58cfff04755\n\t- https://www.tensorflow.org/tutorials/generative/cyclegan \n\t- https://machinelearningmastery.com/cyclegan-tutorial-with-keras/\n\t- https://yanjia.li/gender-swap-and-cyclegan-in-tensorflow-2-0/\n- #PAPER [Learning to Discover Cross-Domain Relations with Generative Adversarial Networks (Kim 2017)](https://arxiv.org/abs/1703.05192)\n\t- #CODE https://github.com/SKTBrain/DiscoGAN\n\t- #CODE https://github.com/clvrai/DiscoGAN-Tensorflow\n\t- This paper introduced an awesome framework for finding one-to-one mapping between two domains in an unsupervised way. The high-level idea is the joint training of two GAN model G1 and G2 in parallel (one for A-\u003eB and the other one for B-\u003eA)\n\t- Besides the adversarial loss, there is also reconstruction loss to ensure the consistency. Specifically, we restrict that G2(G1(A)) = A and G1(G2(B)) = B\n- #PAPER [Unsupervised Image-to-Image Translation Networks (Liu 2018)](https://arxiv.org/abs/1703.00848)\n\t- #CODE https://github.com/mingyuliutw/UNIT/\n\t- https://www.youtube.com/watch?v=dqxqbvyOnMY\u0026feature=youtu.be\n\t- https://medium.com/@theehiproject/unet-unit-for-fast-unsupervised-image2image-translation-using-fastai-e366408eddb4\n- #PAPER [MUNIT: Multimodal UNsupervised Image-to-image Translation (Huang 2018)](https://arxiv.org/abs/1804.04732)\n\t- #CODE https://github.com/NVlabs/MUNIT\n- #PAPER [Fixed-point GAN - Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization (Siddiquee 2019)](https://arxiv.org/abs/1908.06965) ^fixedpointGAN\n\t- #CODE https://github.com/mahfuzmohammad/Fixed-Point-GAN\n- #PAPER [Contrastive Learning for Unpaired Image-to-Image Translation (Park 2020)](https://arxiv.org/abs/2007.15651)\n\t- https://taesung.me/ContrastiveUnpairedTranslation/\n\t- #CODE https://github.com/taesungp/contrastive-unpaired-translation\n\t- #TALK https://www.youtube.com/watch?v=jSGOzjmN8q0\n- #PAPER [Rethinking the Truly Unsupervised Image-to-Image Translation, TUNIT (Baek 2020)](https://arxiv.org/abs/2006.06500)\n\t- #CODE https://github.com/clovaai/tunit\n\t- [Paper explained](https://www.youtube.com/watch?v=sEG8hD64c_Q)\n- #PAPER [Implicit Pairs for Boosting Unpaired Image-to-Image Translation (Ginger 2020)](https://arxiv.org/abs/1904.06913v4)\n- #PAPER [TuiGAN: Learning Versatile Image-to-Image Translation with Two Unpaired Images (Lin 2020)](https://arxiv.org/pdf/2004.04634)            \n\t- #CODE https://github.com/linjx-ustc1106/TuiGAN-PyTorch\n\n### Flow-based\n- #CODE [Image-to-image translation with flow-based generative model](https://github.com/yenchenlin/pix2pix-flow)\n\n- #PAPER [Flow-based Image-to-Image Translation with Feature Disentanglement (Kondo 2019)](https://papers.nips.cc/paper/2019/file/ffedf5be3a86e2ee281d54cdc97bc1cf-Paper.pdf)\n- #PAPER [AlignFlow: Cycle Consistent Learning from Multiple Domains via Normalizing Flows (Grover, 2019)](https://arxiv.org/abs/1905.12892)\n\t-  A generative modeling framework that models each domain via a normalizing flow\n\t-  The use of normalizing flows allows for\n\t\t- flexibility in specifying learning objectives via adversarial training, maximum likelihood estimation, or a hybrid of the two methods\n\t\t- learning and exact inference of a shared representation in the latent space of the generative model. \n- #PAPER [Flow-based Deformation Guidance for Unpaired Multi-Contrast MRI Image-to-Image Translation (Duc Bui 2020)](https://arxiv.org/abs/2012.01777v1)\n\t- Normalizing flows for unpaired image-to-image translation\n\t- Utilized the temporal information between consecutive slices to provide more constraints to the optimization for transforming one domain to another in un-paired volumetric medical image","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Inpainting-and-restoration":{"title":"Inpainting and restoration","content":"\u003e  Inpainting is a conservation process where damaged, deteriorating, or missing parts of an artwork are filled in to present a complete image\n\n## Resources\n- https://en.wikipedia.org/wiki/Inpainting\n- https://paperswithcode.com/task/image-restoration\n- https://www.nvidia.com/research/inpainting/\n- [An Introduction to Image Inpainting using Deep Learning](https://wandb.ai/ayush-thakur/image-impainting/reports/An-Introduction-to-Image-Inpainting-using-Deep-Learning--Vmlldzo3NDU0Nw)\n- [GANs and Missing Data Imputation](https://towardsdatascience.com/gans-and-missing-data-imputation-815a0cbc4ece)\n\n## References\n- #PAPER #REVIEW [Image inpainting: A review (Elharrouss 2019)](https://arxiv.org/abs/1909.06399)\n\n### CNN-based\nSee [[AI/Computer Vision/Deep image prior]]\n- #PAPER [Feature Learning by Inpainting (Pathak 2016)](https://arxiv.org/abs/1604.07379v1)\n\t- #CODE https://github.com/pathak22/context-encoder\n- #PAPER [Image Inpainting for Irregular Holes Using Partial Convolutions (Liu 2018)](https://arxiv.org/abs/1804.07723)\n\t- https://nv-adlr.github.io/publication/partialconv-inpainting\n\t- #CODE https://github.com/NVIDIA/partialconv\n\t- #CODE https://github.com/naoto0804/pytorch-inpainting-with-partial-conv\n\t- #CODE https://github.com/MathiasGruber/PConv-Keras\n\t- #CODE [Various Keras Layers that can be used with TensorFlow 2.x](https://github.com/mvoelk/keras_layers)\n- #PAPER [Partial Convolution based Padding (Liu 2018)](https://arxiv.org/pdf/1811.11718)\n- #PAPER [Probabilistic Semantic Inpainting with Pixel Constrained CNNs (Dupont 2019)](https://arxiv.org/abs/1810.03728)\n\t- #CODE https://github.com/Schlumberger/pixel-constrained-cnn-tf\n- #PAPER [A Flexible Deep CNNs Framework for Image Restoration (2020)](https://ieeexplore.ieee.org/document/8820082)\n\t- https://www.researchgate.net/profile/Zhi_Jin6/publication/335500109_A_Flexible_Deep_CNN_Framework_for_Image_Restoration/links/5da7c1a9299bf1c1e4c837c3/A-Flexible-Deep-CNN-Framework-for-Image-Restoration.pdf\n- #PAPER [Deep learning-Based 3D inpainting of brain MR images (Kwan Kang 2021)](https://www.nature.com/articles/s41598-020-80930-w )\n\n\n### GAN-based\n- #PAPER [VIGAN: Missing View Imputation with Generative Adversarial Networks (Shang 2017)](https://arxiv.org/abs/1708.06724)\n\t- #CODE https://github.com/chaoshangcs/VIGAN\n- #PAPER [Patch-Based Image Inpainting with GANs (Demir 2018)](https://arxiv.org/abs/1803.07422)\n- #PAPER [GAIN: Missing Data Imputation using GANs (Yoon 2018)](https://arxiv.org/abs/1806.02920)\n\t- #CODE https://github.com/jsyoon0823/GAIN\n- #PAPER [MisGAN: Learning from Incomplete Data with Generative Adversarial Networks (Li 2019)](https://arxiv.org/abs/1902.09599)\n- #PAPER [CollaGAN : Collaborative GAN for Missing Image Data Imputation (Li 2019)](https://arxiv.org/abs/1901.09764)\n- #PAPER [DeepGIN: Deep Generative Inpainting Network for Extreme Image Inpainting (Li 2020)](https://arxiv.org/abs/2008.07173)\n\t- #CODE https://github.com/rlct1/DeepGIN\n\t- https://medium.com/analytics-vidhya/review-of-deepgin-deep-generative-inpainting-network-for-extreme-image-inpainting-de5b191562b0\n- #PAPER [The image inpainting algorithm used on multi-scale generative adversarial networks and neighbourhood (Mo 2020)](https://www.tandfonline.com/doi/full/10.1080/00051144.2020.1821535)","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Object-classification-image-recognition":{"title":"Object classification, image recognition","content":"\u003e See: \n\u003e - [[AI/Deep learning/CNNs]]\n\u003e - [[AI/Computer Vision/Object detection]]\n\u003e - [[AI/Computer Vision/Semantic segmentation]]\n\u003e - [[AI/Deep learning/Residual and dense neural networks]]\n\n## Resources\n- https://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception/\n- https://blog.paralleldots.com/data-science/must-read-path-breaking-papers-about-image-classification/\n\n## References\n- #PAPER [AlexNet: ImageNet Classification with Deep Convolutional Neural Networks (2012)](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)\n\t- This architecture was one of the first deep networks to push ImageNet Classification accuracy by a significant stride in comparison to traditional methodologies. It is composed of 5 convolutional layers followed by 3 fully connected layers.\n\t- AlexNet, proposed by Alex Krizhevsky, uses ReLu(Rectified Linear Unit) for the non-linear part, instead of a Tanh or Sigmoid function which was the earlier standard for traditional neural networks. Another problem that this architecture solved was reducing the over-fitting by using a Dropout layer after every FC layer.\n- #PAPER [Visualizing and Understanding Convolutional Networks (Zeiler and Fergus 2013)](https://arxiv.org/abs/1311.2901)\n- #PAPER [Very Deep Convolutional Networks for Large-Scale Image Recognition, VGG16 (Symonian 2014)](https://arxiv.org/abs/1409.1556)\n\t- This architecture is from VGG group, Oxford. It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3X3 kernel-sized filters one after another.\n- #PAPER [Going Deeper with Convolutions (Szegedy 2015)](https://ai.google/research/pubs/pub43022)\n\t- GoogLeNet (Inception-V1, 2015)\n\t- http://nicolovaligi.com/history-inception-deep-learning-architecture.html\n\t- GoogLeNet devised a module called inception module that approximates a sparse CNN with a normal dense construction(shown in the figure). Since only a small number of neurons are effective as mentioned earlier, the width/number of the convolutional filters of a particular kernel size is kept small. Also, it uses convolutions of different sizes to capture details at varied scales(5X5, 3X3, 1X1). Another salient point about the module is that it has a so-called bottleneck layer(1X1 convolutions in the figure). It helps in the massive reduction of the computation requirement. Another change that GoogLeNet made, was to replace the fully-connected layers at the end with a simple global average pooling which averages out the channel values across the 2D feature map, after the last convolutional layer. \n- #PAPER See Resnet in [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n- #PAPER See Resnext in [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n- #PAPER See Densenet in [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n- #PAPER [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and \u003c0.5MB model size (Iandola 2016)](https://arxiv.org/abs/1602.07360)\n\t- [Paper explained](https://www.youtube.com/watch?v=ge_RT5wvHvY )\n\t- https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7\n- #PAPER See SENets in [CNNs](AI/Deep%20learning/CNNs.md)\n- #PAPER [Aggregated Residual Transformations for Deep Neural Networks (Xie 2017)](https://arxiv.org/abs/1611.05431)\n\t- #CODE https://github.com/taki0112/SENet-Tensorflow\n- #PAPER [Local Relation Networks for Image Recognition (Hu 2019)](https://arxiv.org/abs/1904.11491)\n- #PAPER [Designing Network Design Spaces (Radosavovic 2020)](https://arxiv.org/abs/2003.13678v1)\n- #PAPER [NFNets. High-Performance Large-Scale Image Recognition Without Normalization (Brock 2021)](https://arxiv.org/abs/2102.06171)\n\t- #CODE https://github.com/deepmind/deepmind-research/tree/master/nfnets\n\t- https://towardsdatascience.com/deepmind-releases-a-new-state-of-the-art-image-classification-model-nfnets-75c0b3f37312\n- #PAPER [Patches Are All You Need? (2021)](https://openreview.net/forum?id=TVHS5Y4dNvM)\n\t- #CODE https://github.com/tmp-iclr/convmixer\n\t- https://syncedreview.com/2021/10/12/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-121/\n- #PAPER [CoAtNet: Marrying Convolution and Attention for All Data Sizes (Dai 2021)](https://arxiv.org/abs/2106.04803)\n\t- https://ai.googleblog.com/2021/09/toward-fast-and-accurate-neural.html\n\t- https://analyticsindiamag.com/a-guide-to-coatnet-the-combination-of-convolution-and-attention-networks/","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Object-detection":{"title":"Object detection","content":"\u003e See [[AI/Computer Vision/Semantic segmentation]]\n \n## Code\n- https://github.com/microsoft/computervision-recipes/tree/master/scenarios/detection\n- #CODE [MMdetection](https://github.com/open-mmlab/mmdetection)\n\t- OpenMMLab Detection Toolbox and Benchmark (pytorch)\n\t- https://mmdetection.readthedocs.io/\n- #CODE TensorFlow object detection API\n\t- [Repository](https://github.com/tensorflow/models/tree/master/research/object_detection)\n\t- [Model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)\n\t- https://medium.com/swlh/train-your-custom-object-detector-with-tensorflow-object-detector-api-65d38dcdf08c\n\t- https://modelzoo.co/model/objectdetection\n- #CODE [Detectron2](https://github.com/facebookresearch/detectron2)\n\t- Detectron2 is FAIR's next-generation platform for object detection and segmentation\n- #CODE https://github.com/jinwchoi/awesome-action-recognition#object-detection\n- #CODE [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/)\n\n## References\n- #PAPER [Multiple Object Recognition with Visual Attention (Ba 2015)](http://arxiv.org/abs/1412.7755)\n- #PAPER Is object localization for free? – Weakly Supervised Object Recognition with Convolutional Neural Networks (Oquab 2015): \n\t- http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Oquab_Is_Object_Localization_2015_CVPR_paper.pdf\n\t- https://www.di.ens.fr/willow/research/weakcnn/\n- #PAPER [DeepLab - Weakly-and semi-supervised learning of a DCNN for semantic image segmentation (Papandreou 2015)](http://arxiv.org/abs/1502.02734)\n- #PAPER [SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation (Badrinarayanan 2016)](http://arxiv.org/abs/1511.00561)\n- #PAPER [SSD. Single Shot MultiBox Detector (Liu 2016)](https://arxiv.org/abs/1512.02325)\n\t- #BOOK https://d2l.ai/chapter_computer-vision/ssd.html\n- #PAPER [YOLO. You Only Look Once: Unified, Real-Time Object Detection (Redmon 2016)](https://arxiv.org/abs/1506.02640)\n\t- YOLO or You Only Look Once is an object detection algorithm much different from the region based algorithms. In YOLO a single convolutional network predicts the bounding boxes and the class probabilities for these boxes.\n\t- How YOLO works is that we take an image and split it into an SxS grid, within each of the grid we take m bounding boxes. For each of the bounding box, the network outputs a class probability and offset values for the bounding box. The bounding boxes having the class probability above a threshold value is selected and used to locate the object within the image.\n- #PAPER [RetinaNet. Focal Loss for Dense Object Detection (Lin 2018)](https://arxiv.org/abs/1708.02002)\n\t- #CODE https://github.com/fizyr/keras-retinanet\n\t- https://keras.io/examples/vision/retinanet/\n\t- https://towardsdatascience.com/object-detection-on-aerial-imagery-using-retinanet-626130ba2203\n- #PAPER [CornerNet: Detecting Objects as Paired Keypoints (Law 2018)](https://arxiv.org/abs/1808.01244)\n\t- #CODE https://github.com/makalo/CornerNet\n- #PAPER #REVIEW [Deep learning for Generic Object Detection: A Survey (Liu 2019)](https://arxiv.org/abs/1809.02165v4)\n- #PAPER #REVIEW [Recent Advances in Object Detection in the Age of Deep CNNs (Agarwal 2019)](https://arxiv.org/abs/1809.03193)\n- #PAPER [ExtremeNet. Bottom-up Object Detection by Grouping Extreme and Center Points (Zhou 2019)](https://arxiv.org/abs/1901.08043)\n\t- #CODE https://github.com/xingyizhou/ExtremeNet\n- #PAPER [EfficientDet: Scalable and Efficient Object Detection (Tan 2020)](https://arxiv.org/pdf/1911.09070.pdf)\n\t- #CODE https://github.com/xuannianz/EfficientDet\n\t- Included in the TF object detection API\n- #CODE [YOLOX: Exceeding YOLO Series in 2021 (Ge 2021)](https://arxiv.org/abs/2107.08430v1)\n\t- #CODE https://paperswithcode.com/paper/yolox-exceeding-yolo-series-in-2021\n\nRegion-based CNNs (R-CNNs):\n- https://www.pyimagesearch.com/2020/07/06/region-proposal-object-detection-with-opencv-keras-and-tensorflow/\n- #BOOK [Region-based RCNNs](https://d2l.ai/chapter_computer-vision/rcnn.html)\n- #PAPER [Regional CNN (R-CNN)](https://arxiv.org/abs/1311.2524)\n\t- The goal of R-CNN is to take in an image, and correctly identify where the main objects (via a bounding box) in the image.\n\t- R-CNN creates these bounding boxes, or region proposals, using a process called Selective Search. \n\t- Once the proposals are created, R-CNN warps the region to a standard square size and passes it through to a modified version of AlexNet (the winning submission to ImageNet 2012 that inspired R-CNN).\n\t- On the final layer of the CNN, R-CNN adds a Support Vector Machine (SVM) that simply classifies whether this is an object, and if so what object. \n- #PAPER [Fast R-CNN](https://arxiv.org/abs/1504.08083)\n\t- RoI (Region of Interest) Pooling. At its core, RoIPool shares the forward pass of a CNN for an image across its subregions. \n\t- The second insight of Fast R-CNN is to jointly train the CNN, classifier, and bounding box regressor in a single model. \n- #PAPER [Faster R-CNN](https://arxiv.org/abs/1506.01497)\n\t- The insight of Faster R-CNN was that region proposals depended on features of the image that were already calculated with the forward pass of the CNN (first step of classification).\n\t- So why not reuse those same CNN results for region proposals instead of running a separate selective search algorithm?\n\t- A single CNN is used to both carry out region proposals and classification. This way, only one CNN needs to be trained and we get region proposals almost for free. Faster R-CNN adds a Fully Convolutional Network on top of the features of the CNN creating what’s known as the Region Proposal Network.\n- #PAPER [Mask R-CNN (He 2018)](https://arxiv.org/abs/1703.06870)\n\t- Extending Faster R-CNN for Pixel Level Segmentation\n\t- Mask R-CNN does this by adding a branch to Faster R-CNN that outputs a binary mask that says whether or not a given pixel is part of an object. The branch, as before, is just a Fully Convolutional Network on top of a CNN based feature map. \n\t- But the Mask R-CNN authors had to make one small adjustment to make this pipeline work as expected: Realigning RoIPool to be More Accurate.\n\t- https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46\n\t- https://modelzoo.co/model/mask-r-cnn-keras\n\t- https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Semantic-segmentation":{"title":"Semantic segmentation","content":"\u003e See:\n\u003e - [[AI/Deep learning/Encoder-decoder networks]] for image segmentation \n\u003e - [[AI/Computer Vision/Object detection]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Image_segmentation\n- https://github.com/mrgloom/awesome-semantic-segmentation\n- https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4\n- [Overview of semantic image segmentation](https://www.jeremyjordan.me/semantic-segmentation/)\n\n## Code\n- #CODE [DeepLab2](https://github.com/google-research/deeplab2)\n\t- DeepLab2 is a TensorFlow library for deep labeling, aiming to provide a unified and state-of-the-art TensorFlow codebase for dense pixel labeling tasks.\n- #CODE [Segmentation models with pretrained backbones (PyTorch)](https://github.com/qubvel/segmentation_models)\n- #CODE https://github.com/qubvel/segmentation_models\n\t- Python library with Neural Networks for Image Segmentation based on Keras and TensorFlow\n- #CODE https://www.tensorflow.org/tutorials/images/segmentation\n- #CODE https://github.com/yassouali/pytorch-segmentation\n\n## References\n- #PAPER [Fully Convolutional Networks for Semantic Segmentation (Long 2015)](https://arxiv.org/abs/1411.4038)\n- #PAPER [CGNet: A Light-weight Context Guided Network for Semantic Segmentation (Wu 2018)](https://arxiv.org/abs/1811.08201) \n\t- Context Guided (CG) block learns the joint feature of both local feature and surrounding context, and further improves the joint feature with the global context\n\t- CGNet captures contextual information in all stages of the network and is specially tailored for increasing segmentation accuracy \n\t- CGNet is also elaborately designed to reduce the number of parameters and save memory footprint\n- #PAPER #REVIEW [Deep learning for cardiac image segmentation: A review (2019)](https://arxiv.org/abs/1911.03723)\n- #PAPER [Panoptic-DeepLab: A Simple, Strong, and Fast Baseline for Bottom-Up Panoptic Segmentation (Cheng 2020)](https://arxiv.org/abs/1911.10194)\n\t- #CODE https://github.com/bowenc0221/panoptic-deeplab\n- #PAPER [Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation (Wang 2020)](https://arxiv.org/abs/2003.07853)\n\t- #CODE https://github.com/csrhddlam/axial-deeplab\n\t- [Paper explained](https://www.youtube.com/watch?v=hv3UO3G0Ofo)\n- #PAPER #REVIEW [Evolution of Image Segmentation using Deep Convolutional Neural Network: A Survey (Sultana, 2020)](https://arxiv.org/abs/2001.0407430)\n- #PAPER [Towards infield, live plant phenotyping using a reduced-parameter CNN (Atanbori 2020)](https://link.springer.com/article/10.1007%2Fs00138-019-01051-7)\n- #PAPER [Learning What Not to Segment: A New Perspective on Few-Shot Segmentation (Lang 2022)](https://arxiv.org/pdf/2203.07615v2)            \n- #PAPER [k-means Mask Transformer (Yu 2022)](https://arxiv.org/pdf/2207.04044v1)\n\t- #CODE https://github.com/google-research/deeplab2\n\t- rethought the relationship between pixels and object queries and propose to reformulate the cross-attention learning as a clustering process\n\t- k-means Mask Xformer (kMaX-DeepLab) for segmentation tasks is inspired by the traditional k-means clustering algorithm\n\n### Unsupervised or self-supervised\n- #PAPER [Unsupervised Semantic Segmentation by Distilling Feature Correspondences (Hamilton 2022)](https://arxiv.org/pdf/2203.08414)            \n\t- https://www.engadget.com/mit-computer-vision-algorithm-identifies-images-down-to-the-pixel-130051112.html?guccounter=1","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Super-resolution":{"title":"Super-resolution","content":"\u003e See [[AI/Computer Vision/Image-to-image translation]]\n\n## Resources\n- [Papers and related resources, mainly state-of-the-art and novel works in ICCV, ECCV and CVPR about image super-resolution and video super-resolution](https://github.com/HymEric/latest-development-of-ISR-VSR)\n- https://github.com/ptkin/Awesome-Super-Resolution\n- https://github.com/ChaofWang/Awesome-Super-Resolution\n- https://keras.io/examples/vision/super_resolution_sub_pixel/\n- [Image Super-Resolution: A Comprehensive Review (2020)](https://blog.paperspace.com/image-super-resolution/ )\n\n\n## Talks\n- #TALK [How Super Resolution Works (2019)](https://www.youtube.com/watch?v=KULkSwLk62I)\n- #TALK [Can you enhance that? Single Image Super Resolution (Pydata 2019)](https://www.youtube.com/watch?v=lmUxbRY7H2I)\n\n## Code\n- #CODE [BasicSR: Open Source Image and Video Restoration Toolbox for Super-resolution, Denoise, Deblurring (Pytorch)](https://github.com/xinntao/BasicSR)\n\t- It includes EDSR, RCAN, SRResNet, SRGAN, ESRGAN, EDVR, etc\n- #CODE [Single Image Super Resolution benchmark (Keras)](https://github.com/hieubkset/Keras-Image-Super-Resolution)\n\t- EDSR, SRGAN, SRFeat, RCAN, ESRGAN and ERCA (not published)\n- #CODE [Single Image Super-Resolution with EDSR, WDSR and SRGAN (Keras)](https://github.com/krasserm/super-resolution)\n\t- http://krasserm.github.io/2019/09/04/super-resolution/\n\n\n## References\n### Supervised CNN-based\n- #PAPER [Image Super-Resolution Using Deep Convolutional Networks, SRCNN (Dong 2015)](https://arxiv.org/abs/1501.00092)\n\t- #CODE https://github.com/MarkPrecursor/SRCNN-keras\n\t- #CODE https://github.com/yukia18/srcnn-keras\n- #PAPER [Accurate Image Super-Resolution Using Very Deep Convolutional Networks (2015)](http://arxiv.org/abs/1511.04587)\n- #PAPER [Deep Networks for Image Super-Resolution with Sparse Prior (Wang 2015)](http://www.ifp.illinois.edu/~dingliu2/iccv15/)\n\t- http://www.ifp.illinois.edu/~dingliu2/iccv15/iccv15.pdf\n- #PAPER [FSRCNN - Accelerating the Super-Resolution Convolutional Neural Network (Dong 2016)](https://arxiv.org/abs/1608.00367)\n\t- http://mmlab.ie.cuhk.edu.hk/projects/FSRCNN.html\n\t- Uses deconvolution layers (transposed convolution)\n\t- #CODE https://github.com/GeorgeSeif/FSRCNN-Keras\n- #PAPER [Deconvolution and Checkerboard Artifacts (Odena 2016)](https://distill.pub/2016/deconv-checkerboard/)\n\t- Identifies the learned upsample operation (often called deconvolutions) in generative networks as a source of noise\n\t- Overall lesson here is that if you use transposed convolutions, be careful that your kernel size is a multiple of your stride\n\t- However if you use a nearest neighbor or bilinear upsample approach followed by a convolution (termed the ‘resize convolution’) checkerboard artifacts should not appear\n\t- They have more succes with nearest neighbor than with bilinear, possibly because bilinear upsampling smooths away important high frequency signals\n- #PAPER [Perceptual Losses for Real-Time Style Transfer and Super-Resolution (Johnson 2016)](http://arxiv.org/abs/1603.08155)\n\t- http://cs.stanford.edu/people/jcjohns/papers/fast-style/fast-style-supp.pdf\n- #PAPER [ESPCN - Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network (Shi 2016)](https://arxiv.org/abs/1609.05158)\n\t- https://medium.datadriveninvestor.com/review-espcn-real-time-sr-super-resolution-8dceca249350\n\t- #CODE https://keras.io/examples/vision/super_resolution_sub_pixel/\n\t- [SubPixelUpscaling implementation here](https://github.com/pavitrakumar78/Anime-Face-GAN-Keras/blob/master/misc_layers.py)\n\t- [Subpixel convolution is the same as pixel-shuffle](https://nico-curti.github.io/NumPyNet/NumPyNet/layers/pixelshuffle_layer.html)\n\t- A drawback of the interpolation upsampling is that upsampling errors are introduced that can be hard to correct sub-sequently\n\t- The idea of pixel shuffling is to rearrange the pixels of multiple low-resolution images, or in this case feature activations, to one high-resolution out-put image by periodic shuffling of the image points. It thus represents a learnable upsampling operation\n\t- Through the constant periodicity, the previous operations of the neural network can learn to distribute content across the feature dimension which is then shuffled to yield the high-resolution output\n\t- This allows to process the image entirely in low-resolution space\n- #PAPER [Checkerboard artifact free sub-pixel convolution: A note on sub-pixel convolution, resize convolution and convolution resize (Aitken 2017)](https://arxiv.org/abs/1707.02937)\n\t- #CODE https://github.com/Golbstein/EDSR-Keras/blob/master/subpixel.py\n- #PAPER [EDSR - Enhanced Deep Residual Networks for Single Image Super-Resolution (Lim 2017)](https://arxiv.org/abs/1707.02921)\n\t- #CODE https://github.com/Golbstein/EDSR-Keras\n\t- #CODE https://github.com/hieubkset/Keras-Image-Super-Resolution\n- #PAPER [Pixel Deconvolutional Networks (Gao 2017)](https://arxiv.org/abs/1705.06820)\n- #PAPER #REVIEW [Deep Learning for Single Image Super-Resolution: A Brief Review (2018)](https://arxiv.org/abs/1808.03344)\n- #PAPER [RDN - Residual Dense Network for Image Super-Resolution (Zhang 2018)](https://arxiv.org/abs/1802.08797)\n\t- #CODE https://github.com/idealo/image-super-resolution\n\t- #CODE https://github.com/hengchuan/RDN-TensorFlow\n- #PAPER [WDSR - Wide Activation for Efficient and Accurate ImageSuper-Resolution (Yu 2018)](https://arxiv.org/abs/1808.08718)\n- #PAPER [RecResNet: A Recurrent Residual CNN Architecture for Disparity Map Enhancement (Batsos 2018)](https://ieeexplore.ieee.org/document/8490974)\n\t- https://mordohai.github.io/public/Batsos_RecResNet18.pdf\n\t- #CODE https://github.com/kbatsos/RecResNet\n- #PAPER [RCAN - Image Super-Resolution Using Very Deep Residual Channel Attention Networks (Zhang 2018)](https://arxiv.org/abs/1807.02758)\n\t- #CODE https://github.com/yulunzhang/RCAN\n- #PAPER [Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks (Lai 2018)](http://vllab.ucmerced.edu/wlai24/LapSRN/)\n- #PAPER [Super-Resolution using Convolutional Neural Networks without Any Checkerboard Artifacts (Sugawara 2018)](https://arxiv.org/abs/1806.02658v1)\n- #PAPER [Supervised Deep Kriging for Single-Image Super-Resolution (Franchis 2018)](https://arxiv.org/abs/1812.04042)\n- #PAPER [Single Image Super Resolution based on a Modified U-net with Mixed Gradient Loss (Lu, 2019)](https://arxiv.org/abs/1911.09428)\n- #PAPER [Densely Residual Laplacian Super-Resolution (Anwar 2019)](https://arxiv.org/abs/1906.12021)\n\t- #CODE https://github.com/saeed-anwar/DRLN\n- #PAPER [Hyperspectral Image Super-Resolution with 1D–2D Attentional Convolutional Neural Network (Li 2019)](https://www.mdpi.com/2072-4292/11/23/2859/htm)\n- #PAPER [Deep Learning for Multiple-Image Super-Resolution (Kawulok 2019)](https://arxiv.org/abs/1903.00440)\n- #PAPER [RUNet: A Robust UNet Architecture for Image Super-Resolution (Hu 2019)](https://openaccess.thecvf.com/content_CVPRW_2019/papers/WiCV/Hu_RUNet_A_Robust_UNet_Architecture_for_Image_Super-Resolution_CVPRW_2019_paper.pdf)\n- #PAPER [Learned Image Downscaling for Upscaling using Content Adaptive Resampler (Sun 2019)](https://arxiv.org/abs/1907.12904)\n\t- #CODE https://github.com/sunwj/CAR\n\t- https://paperswithcode.com/paper/learned-image-downscaling-for-upscaling-using\n\t- The proposed resampler network generates content adaptive image resampling kernels that are applied to the original HR input to generate pixels on the downscaled image\n\t- Moreover, a differentiable upscaling (SR) module is employed to upscale the LR result into its underlying HR counterpart\n\t- By back-propagating the reconstruction error down to the original HR input across the entire framework to adjust model parameters, the proposed framework achieves a new state-of-the-art SR performance through upscaling guided image resamplers which adaptively preserve detailed information that is essential to the upscaling\n- #PAPER [Image Super-Resolution Using Attention Based DenseNet with Residual Deconvolution (Li 2019)](https://arxiv.org/abs/1907.05282)\n- #PAPER [Meta-SR: A Magnification-Arbitrary Network for Super-Resolution (Hu 2019)](https://arxiv.org/abs/1903.00875)\n\t- #CODE https://github.com/XuecaiHu/Meta-SR-Pytorch\n\t- #CODE https://github.com/smallsunsun1/Meta-SR/\n\t- #CODE https://github.com/jason71995/meta_sr/\n\t- Continuous, arbitrary scaling\n- #PAPER [Pixel Transposed Convolutional Networks (Gao 2019)](https://ieeexplore.ieee.org/document/8618415)\n\t- The pixel transposed convolutional layer (PixelTCL) is proposed to establish direct relationships among adjacent pixels on the up-sampled feature map\n\t- PixelTCL can largely overcome the checkerboard problem suffered by regular transposed convolutional operations\n- #PAPER [A Very Deep Spatial Transformer Towards Robust Single Image Super-Resolution (Jiang 2019)](https://ieeexplore.ieee.org/abstract/document/8679959)\n- #PAPER [ASDN: A Deep Convolutional Network for Arbitrary Scale Image Super-Resolution (Shen 2020)](https://arxiv.org/abs/2010.02414v1)\n- #PAPER [LIIF - Learning Continuous Image Representation with Local Implicit Image Function (Chen 2020)](https://arxiv.org/abs/2012.09161)\n\t- https://yinboc.github.io/liif/\n\t- #CODE https://github.com/yinboc/liif\n\t- Continuous, arbitrary scaling\n- #PAPER [NTIRE 2020 Challenge on Perceptual Extreme Super-Resolution: Methods and Results (Zhang 2020)](https://arxiv.org/abs/2005.01056)\n\t- https://data.vision.ee.ethz.ch/cvl/ntire20/\n\t- Jointly with NTIRE 2020 workshop we have an NTIRE challenge on perceptual extreme super-resolution, that is,the task of super-resolving an LR image to a perceptually pleasant HR image with a magnification factor x16\n- #PAPER [Fixed smooth convolutional layer for avoiding checkerboard artifacts in CNNs (Kinoshita 2020)](https://arxiv.org/abs/2002.02117v1)\n- #PAPER [Efficient Image Super-Resolution Using Pixel Attention (Zhao 2020)](https://arxiv.org/abs/2010.01073) ^srwithpixelattention\n\t-  #CODE See code in [CNNs](AI/Deep%20learning/CNNs.md)\n\t-  #CODE https://github.com/zhaohengyuan1/PAN\n- #PAPER #REVIEW [A Deep Journey into Super-resolution: A survey (Anwar 2020)](https://arxiv.org/abs/1904.07523)\n\t- https://github.com/saeed-anwar/SRsurvey\n- #PAPER #REVIEW [Deep Learning for Image Super-resolution: A Survey (Wang 2020)](https://arxiv.org/abs/1902.06068 )\n- #PAPER #REVIEW [A Comprehensive Review of Deep Learning-based Single Image Super-resolution (Bashir 2021)](https://arxiv.org/abs/2102.09351)\n- #PAPER [Dense U-net for super-resolution with shuffle pooling layer (Lu 2021)](https://arxiv.org/abs/2011.05490)\n- #PAPER [OverNet: Lightweight Multi-Scale Super-Resolution with Overscaling Network (Behjati 2021)](https://arxiv.org/abs/2008.02382)\n\t- https://www.youtube.com/watch?v=_YAn5TaIJfM\n- #PAPER [Revolution: A Spatial-specific Convolution for Image Super-Resolution (Zhang 2021)](https://ieeexplore.ieee.org/document/9525588) \n\n\n### GAN-based\n- #PAPER [SRGAN: Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (Ledig 2016)](https://arxiv.org/abs/1609.04802)\n\t- #CODE https://github.com/idealo/image-super-resolution\n\t- #CODE https://github.com/tensorlayer/srgan\n\t- #CODE https://github.com/leftthomas/SRGAN\n\t- #TALK https://www.youtube.com/watch?v=BXIR_SVCrsE\n\t- First proposed the perceptual loss: content loss + adversarial loss\n\t\t- content loss ensures high-level content is preserved by computing the MSE in the VGG feature-space (instead of pixel image space)\n\t\t- adversarial loss ensures the reconstructed images look real (textures detail)\n\t- Model based on VGG architecture and DCGAN\n- #PAPER [Class-Conditional Superresolution with GANs (Chen 2017)](http://cs231n.stanford.edu/reports/2017/pdfs/314.pdf )\n\t- #CODE https://github.com/vincentschen/cgan-superres\n- #PAPER [ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks (Wang 2018)](https://arxiv.org/abs/1809.00219)\n\t\t- #CODE https://github.com/xinntao/ESRGAN\n- #PAPER [tempoGAN: A temporally coherent, volumetric GAN for super-resolution fluid flow (Xie 2018)](https://arxiv.org/abs/1801.09710)\n- #PAPER [Unsupervised Single-Image Super-Resolution with Multi-Gram Loss (Shi 2019)](https://www.mdpi.com/2079-9292/8/8/833/htm)\n- #PAPER [TecoGAN: Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation (Chu 2020)](https://ge.in.tum.de/publications/2019-tecogan-chu/)\n\t- #CODE https://github.com/thunil/TecoGAN\n\t- [Paper explained](https://www.youtube.com/watch?v=MwCgvYtOLS0)\n- #PAPER [TSRGAN: Generative Adversarial Network for Image Super-Resolution Combining Texture Loss (Jiang 2020)](https://www.mdpi.com/2076-3417/10/5/1729/htm)\n- #PAPER [Residual Channel Attention Generative Adversarial Network for Image Super-Resolution and Noise Reduction (Cai 2020)](https://arxiv.org/abs/2004.13674)\n- #PAPER [Meta-SRGAN - Arbitrary Scale Super-Resolution for Brain MRI Images (Tan 2020)](https://arxiv.org/abs/2004.02086)\n\t- #CODE https://github.com/pancakewaffles/metasrgan-tutorial/\n- #PAPER [MSG-GAN: Multi-Scale Gradients for Generative Adversarial Networks (Karnewar 2020)](https://arxiv.org/abs/1903.06048)\n- #PAPER [MRI Super-Resolution with GAN and 3D Multi-Level DenseNet: Smaller, Faster, and Better (Chen 2020)](https://arxiv.org/abs/2003.01217)\n- #PAPER [Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data (Wnag 2021)](https://arxiv.org/abs/2107.10833v1) ^real-esrgan\n\t- #CODE https://github.com/xinntao/Real-ESRGAN\n\t- Super-resolution with a hint of image restoration\n\t- Proposed a high-order degradation modeling process to better simulate complex real-world degradations (blur, downsampling, noise, etc and combinations)\n- #PAPER [Deep Hierarchical Super-Resolution for Scientific Data Reduction and  Visualization (Wurster 2021)](https://arxiv.org/pdf/2107.00462)\n\n\n### Transformer-based\nSee [[AI/Deep learning/Transformers]]\n- #PAPER [Learning Texture Transformer Network for Image Super-Resolution (Yang 2020)](https://arxiv.org/abs/2006.04139) \n\t- #CODE https://github.com/researchmm/TTSR\n\t- Texture Transformer Network for Image Super-Resolution (TTSR)\n\t- LR and Ref images are formulated as queries and keys in a transformer, respectively\n\t- The proposed texture transformer consists of a learnable texture extractor which learns a jointly feature embedding for further attention computation and two attention based modules which transfer HR textures from the Ref image. \n\t- Furthermore, the proposed texture transformer can be stacked in a cross-scale way with the proposed CSFI module to learn a more powerful feature representation\n- #PAPER [Fusformer: A Transformer-based Fusion Approach for Hyperspectral Image  Super-resolution (Hu 2021)](https://arxiv.org/pdf/2109.02079)\n- #PAPER [Transformer for Single Image Super-Resolution (Lu 2022)](https://arxiv.org/pdf/2108.11084)\n\t- #CODE https://github.com/luissen/ESRT\n\n\n### Diffusion models-based\n- #PAPER [Image Super-Resolution via Iterative Refinement (Saharia 2021)](https://arxiv.org/abs/2104.07636)\n\t- https://iterative-refinement.github.io/\n\t- Related to [[AI/Deep learning/Diffusion models]]\n\t- SR3 is inspired by recent work on Denoising Diffusion Probabilistic Models (DDPM) and denoising score matching\n\t- SR3 adapts denoising diffusion probabilistic models to conditional image generation and performs super-resolution through a stochastic denoising process\n\t- Inference starts with pure Gaussian noise and iteratively refines the noisy output using a U-Net model trained on denoising at various noise levels\n\t- #CODE https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement\n\t- #CODE https://paperswithcode.com/paper/image-super-resolution-via-iterative\n\t- https://beebom.com/google-new-ai-models-turn-low-resolution-images-into-high-quality/","lastmodified":"2022-09-05T14:10:31.882035456Z","tags":null},"/AI/Computer-Vision/Traditional-CV":{"title":"Traditional Computer Vision (CV) techniques","content":"\u003e See [[AI/Computer Vision/Computer vision]]\n\n## Resources\n### Background subtraction\nSee [[AI/Computer Vision/Background subtraction]]\n\n### Image interpolation\n- https://pixinsight.com/doc/docs/InterpolationAlgorithms/InterpolationAlgorithms.html\n- https://www.cambridgeincolour.com/tutorials/image-interpolation.htm\n- https://www.unioviedo.es/compnum/expositive/presentations/T3C_Interpolation_image.pdf\n\n### Geometric transformations\n- https://en.wikipedia.org/wiki/Geometric_transformation\n- https://www.graphicsmill.com/docs/gm/affine-and-projective-transformations.htm\n- https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html\n- http://eeweb.poly.edu/~yao/EL5123/lecture12_ImageWarping.pdf\n\n#### Affine transformations \n- https://en.wikipedia.org/wiki/Affine_transformation\n- Affine transformations are combinations of linear transformations and translations. Properties of affine transformations:\n- Lines map to lines\n- Parallel lines remain parallel\n- Ratios are preserved\n- Closed under composition\n\n#### Projective transformations \n- https://en.wikipedia.org/wiki/Projective_transformation\n- Projective transformations are combos of Affine transformations, and projective warps. Properties of projective transformations:\n- Lines map to lines\n- Parallel lines do not necessarily remain parallel\n- Ratios are not preserved\n- Closed under composition\n- Models change of basis\n- Projective matrix is defined up to a scale (8 DOF)\n\n\n### Filtering\n- For each pixel we compute a function of local neighborhood and output a new value. Use cases:\n\t- Enhance images: Denoise, smooth, increase contrast, etc.\n\t- Extract information from images: Texture, edges, distinctive points, etc.\n\t- Detect patterns: Template matching\n\n#### Spatial domain\n- https://en.wikipedia.org/wiki/Kernel_(image_processing)\n- [Convolutions in image processing](https://www.youtube.com/watch?v=8rrHTtUzyZA)\n- [Convolution and kernels](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n- [Image Kernels visualization](http://setosa.io/ev/image-kernels/)\n- [OpenCV - Image Gradients](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_gradients/py_gradients.html)\n- http://scikit-image.org/docs/dev/api/skimage.filters.html\n- https://dsp.stackexchange.com/questions/12684/difference-between-correlation-and-convolution-on-an-image\n- Examples:\n\t- [Box filter. Replaces each pixel with an average of its neighborhood (smoothing effect)](https://en.wikipedia.org/wiki/Box_blur)\n\t- Sharpening filter. Accentuates differences with local average. \n\t\t- http://northstar-www.dartmouth.edu/doc/idl/html_6.2/Sharpening_an_Image.html\n\t\t- https://en.wikipedia.org/wiki/Box_blur\n\t- Sobel filter. This filter is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. \n\t\t- http://aishack.in/tutorials/sobel-laplacian-edge-detectors/\n\t\t- https://en.wikipedia.org/wiki/Sobel_operator\n\t- [Gaussian filter. Smoothing. Remove “high-frequency” components from the image (low-pass filter)](https://en.wikipedia.org/wiki/Gaussian_filter)\n\t- [Median filter. Non linear filter for image smoothing. Robustness to outliers](https://en.wikipedia.org/wiki/Median_filter)\n\t- [Bilateral filter. A bilateral filter is a non-linear, edge-preserving, and noise-reducing smoothing filter for images. It replaces the intensity of each pixel with a weighted average of intensity values from nearby pixels](https://en.wikipedia.org/wiki/Bilateral_filter)\n\t- Laplacian filter. Filtering with a Laplacian operator: \n\t\t- http://aishack.in/tutorials/sobel-laplacian-edge-detectors/\n\t\t- https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.html\n```\n0\t 1\t  0\n1 \t-4\t  1\n0 \t 1\t  0\n```\n  \n#### Frequency domain\n- Fourier transform stores the magnitude and phase at each frequency. The magnitude encodes how much signal there is at a particular frequency while the phase encodes spatial information (indirectly). \n- The Convolution Theorem:\n\t- The Fourier transform of the convolution of two functions is the product of their Fourier transforms\n\t- The inverse Fourier transform of the product of two Fourier transforms is the convolution of the two inverse Fourier transforms\n\t- Convolution in spatial domain is equivalent to multiplication in frequency domain\n\n\n### Template matching\n- https://en.wikipedia.org/wiki/Template_matching\n\n#### Template based\n- See the \"Filtering\" section\n- http://aishack.in/tutorials/template-matching/\n- For templates without strong features, or for when the bulk of the template image constitutes the matching image, a template-based approach may be effective.\n- Cross-correlation. Linear filtering: function is a weighted sum/difference of pixel values (dot products at each position)\n\t- https://en.wikipedia.org/wiki/Cross-correlation\n- [Using image pyramids](https://en.wikipedia.org/wiki/Pyramid_(image_processing))\n\n#### Feature based\n- Feature-based approach relies on the extraction of image features such, i.e. shapes, textures , colors, to match in the target image or frame. This approach is currently achieved by using Neural Networks and Deep Learning classifiers such as VGG, AlexNet, ResNet. Deep Convolutional Neural Networks process the image by passing it through different hidden layers and at each layer produce a vector with classification information about the image. These vectors are extracted from the network and are used as the features of the image. Feature extraction by using Deep Neural Networks is extremely effective and thus is the standard in state of the art template matching algorithms.\n- This method is considered more robust and is state of the art as it can match templates with non-rigid and out of plane transformation, it can match with high background clutter and illumination changes.\n\n### Feature extraction\n- [The Computer Vision Pipeline: feature extraction](https://freecontent.manning.com/the-computer-vision-pipeline-part-4-feature-extraction/)\n\t- Feature extraction is a core component of the computer vision pipeline. In fact, the entire deep learning model works around the idea of extracting useful features which clearly define the objects in the image. We’re going to spend a little more time here because it’s important that you understand what a feature is, what a vector of features is, and why we extract features.\n\t- A feature in Machine Learning is an individual measurable property or characteristic of a phenomenon being observed. Features are the input that you feed to your machine learning model to output a prediction or classification. Suppose you want to predict the price of a house, your input features (properties) might include: square_foot, number_of_rooms, bathrooms, etc. and the model will output the predicted price based on the values of your features. Selecting good features that clearly distinguish your objects increases the predictive power of machine learning algorithms.\n- In image processing, algorithms are used to detect and isolate various desired portions or shapes (features) of a digitized image or video stream. It is particularly important in the area of optical character recognition. \n\t- Low-level: Edge detection, Corner detection, Blob detection, Ridge detection, Scale-invariant feature transform,\n\t- Curvature: Edge direction, changing intensity, autocorrelation\n\t- Image motion: Motion detection. Area based, differential approach, [Optical flow](https://en.wikipedia.org/wiki/Optical_flow)\n\t- Shape based: Thresholding, Blob extraction, Template matching, Hough transform\n\t\t- Lines: Circles/ellipses, Arbitrary shapes (generalized Hough transform). Works with any parameterizable feature (class variables, cluster detection, etc..)\n\t- Flexible methods: Deformable, parameterized shapesActive contours (snakes)\n\n#### Blob detection\n- https://en.wikipedia.org/wiki/Blob_detection\n- In computer vision, blob detection methods are aimed at detecting regions in a digital image that differ in properties, such as brightness or color, compared to surrounding regions. Informally, a blob is a region of an image in which some properties are constant or approximately constant; all the points in a blob can be considered in some sense to be similar to each other.\n- [The Laplacian of Gaussian](https://en.wikipedia.org/wiki/Blob_detection#The_Laplacian_of_Gaussian)\n- [The difference of Gaussians](https://en.wikipedia.org/wiki/Difference_of_Gaussians)\n- [The determinant of the Hessian](https://en.wikipedia.org/wiki/Blob_detection#The_determinant_of_the_Hessian)\n- [The hybrid Laplacian and determinant of the Hessian operator (Hessian-Laplace)](https://en.wikipedia.org/wiki/Blob_detection#The_hybrid_Laplacian_and_determinant_of_the_Hessian_operator_(Hessian-Laplace))\n- [Maximally stable extremal regions (MSER)](https://en.wikipedia.org/wiki/Maximally_stable_extremal_regions)\n\n#### Edge detection\n- https://en.wikipedia.org/wiki/Template_matching\n- [Canny edge detector](https://en.wikipedia.org/wiki/Canny_edge_detector)\n\t- The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images.\n\t- The Process of Canny edge detection algorithm can be broken down to 5 different steps:\n\t\t1. Apply Gaussian filter to smooth the image in order to remove the noise\n\t\t2. Find the intensity gradients of the image\n\t\t3. Apply non-maximum suppression to get rid of spurious response to edge detection\n\t\t4. Apply double threshold to determine potential edges\n\t\t5. Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n\t- http://aishack.in/tutorials/canny-edge-detector/\n- Robert cross\n\t- https://en.wikipedia.org/wiki/Roberts_cross\n\t- The Roberts cross operator is used in image processing and computer vision for edge detection. \n\t- As a differential operator, the idea behind the Roberts cross operator is to approximate the gradient of an image through discrete differentiation which is achieved by computing the sum of the squares of the differences between diagonally adjacent pixels.\n- Prewitt operator\n\t- https://en.wikipedia.org/wiki/Prewitt_operator\n\t- The Prewitt operator is used in image processing, particularly within edge detection algorithms. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Prewitt operator is either the corresponding gradient vector or the norm of this vector. The Prewitt operator is based on convolving the image with a small, separable, and integer valued filter in horizontal and vertical directions and is therefore relatively inexpensive in terms of computations like Sobel and Kayyali operators. On the other hand, the gradient approximation which it produces is relatively crude, in particular for high frequency variations in the image.\n- Deriche edge detector\n\t- https://en.wikipedia.org/wiki/Deriche_edge_detector\n\t- The Prewitt operator is used in image processing, particularly within edge detection algorithms. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Prewitt operator is either the corresponding gradient vector or the norm of this vector. The Prewitt operator is based on convolving the image with a small, separable, and integer valued filter in horizontal and vertical directions and is therefore relatively inexpensive in terms of computations like Sobel and Kayyali operators. On the other hand, the gradient approximation which it produces is relatively crude, in particular for high frequency variations in the image.\n\n#### Corner detection\n- https://en.wikipedia.org/wiki/Corner_detection\n- http://aishack.in/tutorials/corner-detection-opencv/\n- Corner detection is an approach used within computer vision systems to extract certain kinds of features and infer the contents of an image.\n- [Harris operator: detects corners (patches that have strong gradients in two orthogonal directions)](https://en.wikipedia.org/wiki/Harris_Corner_Detector)\n- [Förstner corner detector](https://en.wikipedia.org/wiki/Corner_detection#The_F%C3%B6rstner_corner_detector)\n- [The Wang and Brady corner detection algorithm](https://en.wikipedia.org/wiki/Corner_detection#The_Wang_and_Brady_corner_detection_algorithm)\n- [The SUSAN corner detector](https://en.wikipedia.org/wiki/Corner_detection#The_SUSAN_corner_detector)\n- [The Trajkovic and Hedley corner detector](https://en.wikipedia.org/wiki/Corner_detection#The_Trajkovic_and_Hedley_corner_detector)\n\n#### Feature descriptors\n- Scale-invariant feature transform (SIFT)\n\t- http://aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/\n\t- SIFT keypoints of objects are first extracted from a set of reference images and stored in a database. An object is recognized in a new image by individually comparing each feature from the new image to this database and finding candidate matching features based on Euclidean distance of their feature vectors. From the full set of matches, subsets of keypoints that agree on the object and its location, scale, and orientation in the new image are identified to filter out good matches. The determination of consistent clusters is performed rapidly by using an efficient hash table implementation of the generalised Hough transform. Each cluster of 3 or more features that agree on an object and its pose is then subject to further detailed model verification and subsequently outliers are discarded. Finally the probability that a particular set of features indicates the presence of an object is computed, given the accuracy of fit and number of probable false matches. Object matches that pass all these tests can be identified as correct with high confidence.\n\t- https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html\n\t- There are mainly five steps involved in SIFT algorithm.\n\t\t1. Scale-space Extrema Detection (using DoG)\n\t\t2. Keypoint Localization\n\t\t3. Orientation Assignment\n\t\t4. Keypoint Descriptor\n\t\t5. Keypoint Matching\n- [Histogram of oriented gradients (HOG)](https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients)\n- Speeded up robust features (SURF)\n\t- https://en.wikipedia.org/wiki/Speeded_up_robust_features\n\t- In computer vision, speeded up robust features (SURF) is a patented local feature detector and descriptor. It can be used for tasks such as object recognition, image registration, classification or 3D reconstruction. It is partly inspired by the scale-invariant feature transform (SIFT) descriptor. The standard version of SURF is several times faster than SIFT and claimed by its authors to be more robust against different image transformations than SIFT.\n\n#### Kanade–Lucas–Tomasi (KLT) feature tracker\n- https://en.wikipedia.org/wiki/Kanade%E2%80%93Lucas%E2%80%93Tomasi_feature_tracker\n- In computer vision, the Kanade–Lucas–Tomasi (KLT) feature tracker is an approach to feature extraction. It is proposed mainly for the purpose of dealing with the problem that traditional image registration techniques are generally costly. KLT makes use of spatial intensity information to direct the search for the position that yields the best match. It is faster than traditional techniques for examining far fewer potential matches between the images.\n- Summary of KLT tracking:\n\t- Find a good point to track (harriscorner)\n\t- Use intensity second moment matrix and difference across frames to find displacement\n\t- Iterate and use coarse-to-fine search to deal with larger movements \n\t- When creating long tracks, check appearance of registered patch against appearance of initial patch to find points that have drifted\n\n#### Optical flow\n- https://en.wikipedia.org/wiki/Optical_flow\n- Vector field function of the spatio-temporal image brightness variations \n- #PAPER [Large Displacement Optical Flow](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/brox_cvpr09.pdf)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Computer-Vision/Video-Frame-Interpolation":{"title":"Video Frame Interpolation","content":"\u003e The goal of **Video Frame Interpolation** is to synthesize several frames in the middle of two adjacent frames of the original video. Video Frame Interpolation can be applied to generate slow motion video, increase video frame rate, and frame recovery in video streaming\n\n## References\n- #PAPER [Asymmetric Bilateral Motion Estimation for Video Frame Interpolation (Park 2021)](https://arxiv.org/abs/2108.06815)\n\t- https://github.com/JunHeum/ABME\n- #PAPER [Enhanced Correlation Matching based Video Frame Interpolation (Lee 2021)](https://arxiv.org/abs/2111.08869v1)\n- #PAPER [FILM: Frame Interpolation for Large Motion (Reda 2022)](https://arxiv.org/abs/2202.04901v2)\n\t- #CODE https://github.com/google-research/frame-interpolation\n\t- https://www.youtube.com/watch?v=OAD-BieIjH4\n\t- present a single unified network, distinguished by a multi-scale feature extractor that shares weights at all scales, and is trainable from frames alone\n\t- to synthesize crisp and pleasing frames, proposed to optimize the network with the Gram matrix loss that measures the correlation difference between feature maps","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Computer-Vision/Video-segmentation-and-prediction":{"title":"Video segmentation and prediction","content":"\u003e See: \n\u003e - [[AI/Deep learning/Encoder-decoder networks]]\n\u003e - \"Deep learning for multi-dimensional data\" section in [[AI/Deep learning/DL]]\n\u003e - [[AI/Deep learning/RNNs]]\n\n## Resources\n- Spatiotemporal classification and regression\n- Hybrid convolutional and recurrent networks, 3dconv and related approaches\n- https://github.com/jinwchoi/awesome-action-recognition\n- http://blog.qure.ai/notes/deep-learning-for-videos-action-recognition-review\n- https://stackoverflow.com/questions/55926841/convolving-across-channels-in-keras-cnn-conv1d-depthwise-separable-conv-cccp\n- https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\n\n\n## Courses\n- #COURSE [Advanced Models for Computer Vision (DeepMind x UCL | Deep Learning Lectures)](https://www.youtube.com/watch?v=_aUq7lmMfxo\u0026list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\u0026index=4)\n\t- https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L4%20-%20UCLxDeepMind%20DL2020.pdf\n\n\n## References\n- #PAPER [Learning Spatiotemporal Features with 3D Convolutional Networks. C3D, 3D CNNs (Tran 2015)](https://arxiv.org/abs/1412.0767)\n- #PAPER [Unsupervised Learning of Video Representations using LSTMs (Srivastava 2016)](https://arxiv.org/abs/1502.04681)\n- #PAPER [Convolutional Gated Recurrent Networks for Video Segmentation (Siam 2016)](https://arxiv.org/abs/1611.05435)\n\t- Hybrid convolutional and recurrent networks\n- #PAPER [LRCN: Long-term Recurrent Convolutional Networks for Visual Recognition and Description (Donahue 2016)](https://arxiv.org/abs/1411.4389)\n\t- Hybrid convolutional and recurrent networks\n- #PAPER [Convolutional Two-Stream Network Fusion for Video Action Recognition (Feichtenhofer 2016)](https://arxiv.org/abs/1604.06573)\n- #PAPER [Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning (Lotter 2016)](https://arxiv.org/abs/1605.08104)\n\t- https://coxlab.github.io/prednet/\n- #PAPER [ContextVP: Fully Context-Aware Video Prediction (Byeon 2018)](https://arxiv.org/abs/1710.08518)\n\t- http://on-demand.gputechconf.com/gtc/2018/presentation/s8713-fully-context-aware-video-prediction.pdf \n- #PAPER [Machine Learning for Spatiotemporal Sequence Forecasting: A Survey (Shi, 2018)](https://arxiv.org/abs/1808.06865)\n- #PAPER [Residual Convolutional LSTM for Tweet Count Prediction (Wei 2018)](https://dl.acm.org/doi/fullHtml/10.1145/3184558.3191571)\n- #PAPER [A Closer Look at Spatiotemporal Convolutions for Action Recognition (Tran 2018)](https://arxiv.org/abs/1711.11248)\n\t- #CODE https://github.com/facebookresearch/VMZ\n\t- #CODE See Ghadiyaram 2019 below\n\t- #CODE https://github.com/juenkhaw/action_recognition_project\n\t- demonstrate that 3D ResNets significantly outperform 2D ResNets for the same depth when trained and evaluated on large-scale,challenging action recognition benchmarks\n\t- introduce two new forms of spatio temporal convolution that can be viewed as middle grounds between the extremes of 2D (spatial convolution) and full 3D: mixed convolution (MC) and consists in employing 3D convolutions only in the early layers of the network, with 2D convolutions in the top layers, and the R(2+1)D spatiotemporal conv block which explicitly factorizes 3D convolution into two separate and successive operations, a 2D spatial convolution and a 1D temporal convolution\n\t- the first advantage is an additional nonlinear rectification between these two operations. This effectively doubles the number of non-linearities compared to a network using full 3D convolutions for the same number of parameters, thus rendering the model capable of representing more complex functions.The second potential benefit is that the decomposition facilitates the optimization, yielding in practice both a lower training loss and a lower testing loss\n- #PAPER [Video Classification with Channel-Separated Convolutional Networks (Tran 2019)](https://arxiv.org/abs/1904.02811)\n\t- #CODE https://github.com/facebookresearch/VMZ\n- #PAPER [Dilated 3D Convolutional Neural Networks for Brain MRI Data Classification (Wang 2019)](https://ieeexplore.ieee.org/abstract/document/8840843)\n- #PAPER [Deep Learning for Spatio-Temporal Data Mining: A Survey (Wang 2019)](https://arxiv.org/abs/1906.04928)\n- #PAPER [Large-scale weakly-supervised pre-training for video action recognition (Ghadiyaram 2019)](https://arxiv.org/abs/1905.00561)\n\t- #CODE https://github.com/microsoft/computervision-recipes/tree/master/scenarios/action_recognition\n- #PAPER [Eidetic 3D LSTM A Model for Video Prediction and Beyond, E3D-LSTM (Wang 2019)](https://openreview.net/forum?id=B1lKS2AqtX)\n\t- #CODE https://github.com/google/e3d_lstm\n- #PAPER [Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition (Esat Kalfaoglu 2020)](https://arxiv.org/abs/2008.01232)\n- #PAPER [An Image is Worth 16x16 Words, What is a Video Worth? (Sharir 2021)](https://arxiv.org/abs/2103.13915)\n- #PAPER [UNETR: Transformers for 3D Medical Image Segmentation (Hatamizadeh 2021)](https://arxiv.org/abs/2103.10504)\n\t- https://theaisummer.com/medical-segmentation-transformers/\n\t- UNETR is the first successful transformer architecture for 3D medical image segmentation\n- #PAPER [Dense Unsupervised Learning for Video Segmentation (Araslanov 2021)](https://arxiv.org/abs/2111.06265)\n\t- https://github.com/visinf/dense-ulearn-vos\n\t- methods that learns spatio-temporal correspondences without any supervision ([[AI/Unsupervised learning/Unsupervised learning]], and achieves state-of-the-art accuracy of video object segmentation\n\t- #TALK https://www.youtube.com/watch?v=tSBWZ6nYld0\n- #PAPER [Mask2Former for Video Instance Segmentation (Cheng 2021)](https://arxiv.org/abs/2112.10764v1)\n\t- #CODE https://github.com/facebookresearch/Mask2Former\n- #PAPER [XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin  Memory Model (Cheng 2022)](https://arxiv.org/pdf/2207.07115v2)\n\t- #CODE https://github.com/hkchengrex/XMem\n\t- https://hkchengrex.github.io/XMem/\n- #PAPER [MinVIS: A Minimal Video Instance Segmentation Framework without  Video-based Training (Huang 2022)](https://arxiv.org/pdf/2208.02245v1)\n\t- #CODE https://github.com/NVlabs/MinVIS","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Dask":{"title":"Dask","content":"\u003e See:\n\u003e - [[AI/DS and DataEng/Xarray]]\n\u003e - [[AI4ES/Pangeo]]\n\n## Resources\n- [Parallel computing with Dask](https://xarray.pydata.org/en/v0.10.1/dask.html)\n- http://jcrist.github.io/introducing-dask-searchcv.html\n\n## Talks\n- #TALK [Dask for ad hoc distributed computing (Pydata)](https://www.youtube.com/watch?v=EEfI-11itn0)\n- #TALK [Using Dask for Parallel Computing in Python](https://www.youtube.com/watch?v=s4ChP7tc3tA)\n- #TALK [Parallelizing Scientific Python with Dask | SciPy 2017 Tutorial | James Crist](https://www.youtube.com/watch?v=mbfsog3e5DA)\n\n\n## Code\n- #CODE [Dask](https://github.com/dask/dask)\n\t- flexible parallel computing library for analytics\n\t- http://docs.dask.org/en/latest/cheatsheet.html\n- #CODE [Dask-Jobqueue](https://github.com/dask/dask-jobqueue)\n\t- https://jobqueue.dask.org/en/latest/\n\t- Easily deploy Dask on job queuing systems like PBS, Slurm, MOAB, SGE, LSF, and HTCondor\n\t- [Scalable interactive analysis workflows using dask on HPC Systems](https://medium.com/pangeo/dask-jobqueue-d7754e42ca53)\n- #code [Dask-ml - Machine Learning with Dask](https://github.com/dask/dask-ml)\n- #CODE [Dask-geopandas](https://github.com/geopandas/dask-geopandas)\n\t- Parallel GeoPandas with Dask\n\t- Tutorial: https://github.com/martinfleis/dask-geopandas-tutorial","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Data-Science":{"title":"Data Science","content":"\u003e Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains\n\n## Resources\n- https://en.wikipedia.org/wiki/Data_science\n- https://github.com/bulutyazilim/awesome-datascience\n- [Reproducible Data Analysis in Jupyter (Vanderplas)](https://jakevdp.github.io/blog/2017/03/03/reproducible-data-analysis-in-jupyter/)\n- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)\n- [An Executive's Guide To Understanding Cloud-based ML Services](https://www.forbes.com/sites/janakirammsv/2019/01/01/an-executives-guide-to-understanding-cloud-based-machine-learning-services/)\n- [Why data-driven science is more than just a buzzword](https://sydney.edu.au/news-opinion/news/2017/05/11/Why-data-driven-science-is-more-than-just-a-buzzword.html)\n- [A Complete Data Science Curriculum for Beginners](https://towardsdatascience.com/a-complete-data-science-curriculum-for-beginners-825a39915b54)\n\n### Cheatsheets\n- https://github.com/ml874/Data-Science-Cheatsheet\n- https://github.com/aaronwangy/Data-Science-Cheatsheet\n- https://github.com/FavioVazquez/ds-cheatsheets\n\n### Infographics\n- [Data Never Sleeps 3.0](https://www.domo.com/blog/data-never-sleeps-3-0/)\n- [The Data Science Industry - who does what](https://www.datacamp.com/community/tutorials/data-science-industry-infographic)\n- [Learn data science infographic](https://www.datacamp.com/community/tutorials/learn-data-science-infographic)\n- [DS Infographic](http://online.rutgers.edu/resources/infographics/what-can-you-do-with-a-career-in-data-science/)\n- [Data Science Venn Diagram v2.0](http://www.anlytcs.com/2014/01/data-science-venn-diagram-v20.html)\n- [Updated DS Venn diagram](http://www.kdnuggets.com/2016/09/new-data-science-venn-diagram.html)\n- [DS vs STATS vs DATA-ENG](https://www.analyticsvidhya.com/blog/2015/10/job-comparison-data-scientist-data-engineer-statistician/)\n\n### Data Science for good\n- See [[AI4G/AI4good]]\n\n## References\n- #PAPER [Science and data science (Blei 2017)](https://www.pnas.org/content/114/33/8689)\n- #PAPER [50 Years of Data Science (Donoho 2017)](https://www.tandfonline.com/doi/full/10.1080/10618600.2017.1384734)\n\t- #TALK 50 Years of Data Science (Donoho)\n\t\t- https://www.youtube.com/watch?v=GUFL-Mf0EWY\n\t\t- https://www.youtube.com/watch?v=E7w-gfFKPf8\n\t\t- https://www.youtube.com/watch?v=QTzNXYcZLbU\n\t\t- https://www.youtube.com/watch?v=BnRRwmeGBgU\n\t- Comments: \n\t\t- https://matloff.wordpress.com/2016/01/23/some-comments-on-donahos-50-years-of-data-science/\n\t\t- https://medium.com/@srowen/what-50-years-of-data-science-leaves-out-2366c9b61d3d\n\t\t- https://www.youtube.com/watch?v=zamQgXDytUA\n\t\t- #TALK [Big Data LDN 2016: What “50 Years of Data Science” Leaves Out](https://www.youtube.com/watch?v=zamQgXDytUA)\n- #PAPER [Theory-guided data science: a new paradigm for scientific discovery from data (Karpatne 2017)](https://ieeexplore.ieee.org/document/7959606)\n\n\n## Books\n- #BOOK [The field guide to DS (Booz Allen Hamilton Inc 2015)](https://www.boozallen.com/s/insight/publication/field-guide-to-data-science.html)\n\t- https://www.boozallen.com/content/dam/boozallen_site/sig/pdf/publications/2015-field-guide-to-data-science.pdf\n\t- https://github.com/booz-allen-hamilton/The-Field-Guide-to-Data-Science\n- #BOOK [Going pro in data science (Overton 2016, O'REILLY)](https://www.oreilly.com/library/view/going-pro-in/9781492048534/)\n\t- http://ds4100.weebly.com/uploads/8/6/5/9/8659576/going-pro-in-data-science.pdf\n- #BOOK [Weapons of Math Destruction - How big data increases inequality and threatens democracy (O'Neil, 2016)](https://weaponsofmathdestructionbook.com/)\n\t- https://we.riseup.net/assets/404114/Weapons+of+Math+Destruction+Cathy+O%27Neil.pdf\n- #BOOK [Introducing Data Science - Big Data, ML and more, using Python tools (Cielen 2016, MANNING)](https://www.manning.com/books/introducing-data-science)\n\t- http://bedford-computing.co.uk/learning/wp-content/uploads/2016/09/introducing-data-science-machine-learning-python.pdf\n- #BOOK [Mastering Python for Data Science (Madhavan 2015, PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/mastering-python-data-science)\n\t- http://nuovolabs.fauser.edu/~valeria/materiale-didattico/python/Packt.Mastering.Aug.2015.ISBN.1784390151.pdf\n- #BOOK [Python Data Science Handbook (VanderPlas, 2016 OREILLY)](https://jakevdp.github.io/PythonDataScienceHandbook/)\n\t-  http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb\n- #BOOK [Python for Data Analysis 2nd ed (McKinney, 2017 O'REILLY)](http://wesmckinney.com/pages/book.html)\n\t-  https://github.com/wesm/pydata-book\n- #BOOK [Scala for Data Science (Bugnion, 2016 PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/scala-data-science)\n- #BOOK [Scala: Guide for Data Science Professionals (Nicolas, 2017 PACKT)](http://shop.oreilly.com/product/9781787282858.do)\n- #BOOK [R for Data Science (Grolemund 2017 O'REILLY)](http://r4ds.had.co.nz/)\n- #BOOK [Data Science Live Book (in R)](https://livebook.datascienceheroes.com/)\n- #BOOK [R Programming for Data Science (Peng, 2020)](https://bookdown.org/rdpeng/rprogdatascience/)\n- #BOOK [Statistical Inference via Data Science (Ismay 2020)](https://moderndive.com/)\n- #BOOK [Data Science Live Book (Casas 2020)](https://livebook.datascienceheroes.com/)\n- #BOOK [Geographic Data Science with Python](https://geographicdata.science/book/intro.html)\n- #BOOK [Network Data Science](https://bdpedigo.github.io/networks-course/landing.html)\n- #BOOK [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html)\n- #BOOK [The Data Science Interview Book](https://dipranjan.github.io/dsinterviewqns/intro.html)\n- #BOOK [Statistics and Data Science](http://theoryandpractice.org/stats-ds-book/intro.html)\n\n\n## Courses\n- #COURSE Introduction to Computational Thinking (MIT)\n\t- [Fall 2020](https://computationalthinking.mit.edu/Fall20/)\n\t- [Spring 2021](https://computationalthinking.mit.edu/Spring21/)\n\t- Using Julia\n\t- CS, Math, ML and applications (image processing, climate modelling/change)\n- #COURSE [Mathematical Tools for Data Science (NYU Center for Data Science)](https://cds.nyu.edu/math-tools/)\n- - #COURSE [Python for Data Science workshop (Paris-Saclay Center for Data Science)](https://github.com/paris-saclay-cds/python-workshop)\n- #COURSE [Data Science (Harvard CS109)](http://cs109.github.io/2015/)\n- #COURSE [Data 8: The Foundations of Data Science (UC Berkeley)](http://data8.org/fa16/)\n\t-  https://www.inferentialthinking.com/index.html\n- #COURSE [Intro to Data Science (Udacity)](https://www.udacity.com/course/intro-to-data-science--ud359)\n- #COURSE [Introduction to Data Science in Python (Coursera, U Michigan)](https://www.coursera.org/learn/python-data-analysis)\n- #COURSE [Data Science in Stratified Healthcare and Precision Medicine (Coursera, U Edinburgh)](https://www.coursera.org/learn/datascimed)\n- #COURSE [Big Data Analytics in Healthcare (Udacity, Georgia Tech)](https://eu.udacity.com/course/big-data-analytics-in-healthcare--ud758)\n- #TALK [Building a Data Science Team with Open Source Tools](https://www.youtube.com/watch?v=mzTlqNTHTmc)\n- #TALK [Introduction to Python for Data Science (Seabold, PyCon 2018)](https://www.youtube.com/watch?v=W4WQi2OIy7o)\n\n\n## Code\n### Interactive Computing Environments\n- #CODE [Jupyter](AI/DS%20and%20DataEng/Jupyter.md)\n- #CODE [Zepelin](https://zeppelin.apache.org/)\n- #CODE [Rstudio](https://www.rstudio.com/products/rstudio/)\n- #CODE [Cauldron](https://github.com/sernst/cauldron)\n\t- http://www.unnotebook.com/\n- #CODE [Polynote](https://github.com/polynote/polynote)\n\t- https://polynote.org/\n\n### Browser IDEs\n- [Google Colaboratory](https://colab.research.google.com/)\n- [Binder](https://mybinder.org/)\n- [Cocal](https://cocalc.com/features/jupyter-notebook)\n- [Replit](https://replit.com/)\n- [Deepnote](https://deepnote.com/)\n\n\n## Related fields\n### Math and Statistics\nSee [[AI/Math and Statistics/Math and Statistics]]\n\n### Machine Learning\nSee [[AI/Machine Learning]]\n\n### Data engineering and Computer Science\nSee [[AI/DS and DataEng/Data engineering and computer science]]\n\n### Visualization\nSee [[AI/DS and DataEng/Visualization]]","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Data-engineering-and-computer-science":{"title":"Data Engineering and Computer Science","content":"\u003e Data engineering role is ensuring uninterrupted flow of data between servers and applications\n\n## Resources\n- https://github.com/ossu/computer-science\n- [What is Data Engineering and Why Is It So Important?](https://quanthub.com/what-is-data-engineering/)\n- [ETL (extract, transform, load)](https://en.wikipedia.org/wiki/Extract,_transform,_load)\n- [Have we bridged the gap between Data Science and DevOps?](https://jaxenter.com/bridge-gap-data-science-devops-134712.html)\n\n### Python\nSee [[Python]]\n\n### Julia \n- #TALK https://www.youtube.com/watch?v=AyvyVS6u8AM\n- https://julialang.org/learning/\n\n### Javascript\n- https://www.w3schools.com/js/\n- https://codesandbox.io\n- https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/JavaScript_basics\n- https://dtabio.gitbooks.io/data-science-with-javascript/content/links_and_resources.html\n- http://www.kdnuggets.com/2016/06/top-machine-learning-libraries-javascript.html\n\n### Bash\n- [free GNU/Linux Online Terminal and Programming IDE](http://www.webminal.org/)\n\n\n### CUDA\n- https://developer.nvidia.com/cuda-education\n- https://dragan.rocks/articles/18/Interactive-GPU-Programming-1-Hello-CUDA\n\n\n## Books\nsee \"\"Books\" section in [[AI/DS and DataEng/Python]]\n\n- #BOOK [Mining of Massive Datasets (Leskovec, 2014 CAMBRIDGE)](http://www.mmds.org/)\n- #BOOK [Advanced Analytics with Spark (Ryza, 2017 OREILLY)](http://shop.oreilly.com/product/0636920056591.do)\n\t- [Advanced Analytics with Spark, 2nd Edition.pdf](https://github.com/analystfreakabhi/btb_spark/blob/master/Advanced%20Analytics%20with%20Spark%2C%202nd%20Edition.pdf)\n- #BOOK [Pandas cookbook (Petrou, 2017 PACKT)](https://packtpub.com/big-data-and-business-intelligence/pandas-cookbook)\n- #BOOK [The Big Book of Data Engineering (Databricks)](https://databricks.com/p/ebook/the-big-book-of-data-engineering)\n\n### R\n- #BOOK [R para profesionales de los datos: una introducción](https://www.datanalytics.com/libro_r/)\n- #BOOK [Geocomputation with R](https://geocompr.robinlovelace.net/)\n- #BOOK [Efficient R programming](https://csgillespie.github.io/efficientR/)\n- #BOOK [Engineering Production-Grade Shiny Apps](https://engineering-shiny.org/)\n- #BOOK [Advanced R](https://adv-r.hadley.nz/)\n- #BOOK [Hands-On Programming with R](https://rstudio-education.github.io/hopr/)\n- #BOOK [R Packages (Wickham 2020)](https://r-pkgs.org/)\n\n## Courses\nSee \"Courses\" section in [[AI/DS and DataEng/Python]]\n\n- #COURSE [Intro to Hadoop and MapReduce](https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617)\n- #COURSE [Mining Massive Data Sets (CS246 Stanford)](http://web.stanford.edu/class/cs246/)\n\t- https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about\n- #COURSE [Getting and Cleaning Data (Coursera)](https://www.coursera.org/learn/data-cleaning)\n- SQL:\n\t- [Tutorial and exercises](http://sqlzoo.net)\n\t- SQL (basic, intermediate, advanced / pet problems): \n\t\t- https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/\n\t\t- https://github.com/FavioVazquez/ds-cheatsheets/tree/master/SQL\n\n\n## Code\n- #CODE [ABSL.flags](https://abseil.io/docs/python/guides/flags)\n\t- Defines a distributed command line system and manual argument parsing\n\t- https://999999999.hatenablog.com/entry/argument_parse_with_abseil\n\t- https://github.com/abseil/abseil-py/blob/main/smoke_tests/sample_app.py\n- #CODE [Memray](https://github.com/bloomberg/memray)\n\t- Memray is a memory profiler for Python\n\t- https://bloomberg.github.io/memray/\n\t- https://www.bloomberg.com/company/stories/bloomberg-memray-open-source-profiler-python-code/\n- #CODE [StreamAlert](https://github.com/airbnb/streamalert)\n\t- StreamAlert is a serverless, realtime data analysis framework which empowers you to ingest, analyze, and alert on data from any environment, using datasources and alerting logic you define\n- #CODE [Pandas](https://github.com/pandas-dev/pandas)\n\t- https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n\t- https://www.youtube.com/watch?v=9d5-Ti6onew\n\t- https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n\t- [Merge, Join and concatenate](http://pandas.pydata.org/pandas-docs/stable/merging.html)\n\t- [SQL for pandas](http://blog.yhat.com/posts/pandasql-intro.html)\n\t- [Plotting in pandas](http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n\t- http://jakevdp.github.io/blog/2017/03/22/group-by-from-scratch/\n\t- [Essential Descriptive Statistics in Pandas](https://simplyml.com/essential-descriptive-statistics-in-pandas/)\n\t- Selecting Subsets of Data in Pandas:\n\t\t- https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c\n\t\t- https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-39e811c81a0c\n- #CODE [Modin - Scale your pandas workflows by changing one line of code](https://github.com/modin-project/modin)\n- #CODE [Xarray](AI/DS%20and%20DataEng/Xarray.md)\n- #CODE [Dedupe - A python library for accurate and scaleable fuzzy matching, record deduplication and entity-resolution](https://github.com/dedupeio/dedupe)\n\t- http://blog.districtdatalabs.com/basics-of-entity-resolution\n- #CODE [PyTables](https://github.com/PyTables/PyTables)\n\t- http://www.pytables.org/\n- #CODE [H5py](https://github.com/h5py/h5py)\n- #CODE [Singer - Simple, Composable Open Source ETL](https://www.singer.io/)\n- #CODE [Docker](https://www.docker.com/)\n\t- https://towardsdatascience.com/docker-for-data-science-4901f35d7cf9\n- #CODE Kubernetes - K8s is an open-source system for automating deployment, scaling, and management of containerized applications.\n\t- https://kubernetes.io/\n\t- https://opensource.com/article/19/1/why-data-scientists-love-kubernetes\n\t- https://github.com/Langhalsdino/Kubernetes-GPU-Guide\n\t- https://blog.alexellis.io/kubernetes-in-10-minutes/\n\n ### Business Intelligence\n - #CODE [kuwala](https://github.com/kuwala-io/kuwala)\n\t - https://kuwala.io/\n \n ### Big data, distributed computing\n- #CODE [Dask](AI/DS%20and%20DataEng/Dask.md)\n- #CODE [Ray](https://github.com/ray-project/ray)\n\t- A system for parallel and distributed Python that unifies the ML ecosystem\n\t- https://ray.readthedocs.io/en/latest/\n\t- https://ray-project.github.io/\n\t- #TALK [Ray: A Distributed Execution Framework for AI | SciPy 2018 | Robert Nishihara](https://www.youtube.com/watch?v=D_oz7E4v-U0)\n\t- #TALK [Ray: A System for Scalable Python and ML |SciPy 2020| Robert Nishihara](https://www.youtube.com/watch?v=XIu8ZF7RSkw)\n- #CODE [PyGDF - GPU Data Frame](https://github.com/gpuopenanalytics/pygdf)\n\t- https://devblogs.nvidia.com/parallelforall/goai-open-gpu-accelerated-data-analytics/\n- #CODE [Apache Hadoop](http://hadoop.apache.org/)\n\t- The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models.\n\t- https://www.quora.com/What-is-the-difference-between-Apache-Spark-and-Apache-Hadoop-Map-Reduce\n\t- [Intro to Hadoop and MapReduce (Udacity)](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkXJ6LAV96gH8yxIfGaN3H-)\n\t- https://datawanderings.com/2017/01/15/your-first-diy-hadoop-cluster/\n\t- http://ruhanixedu.com/blog/interview-question-and-answers/big-data/\n- #CODE [Apache Spark](https://en.wikipedia.org/wiki/Apache_Spark)\n\t- http://cacm.acm.org/magazines/2016/11/209116-apache-spark/fulltext\n\t- http://www.kdnuggets.com/2015/11/introduction-spark-python.html\n\t- https://databricks.com/blog/2018/05/03/benchmarking-apache-spark-on-a-single-node-machine.html\n\t- #TALK [A brief introduction to Distributed Computing with PySpark (Pydata)](https://www.youtube.com/watch?v=bJouNc1REno)\n\t- #TALK [Connecting Python To The Spark Ecosystem](https://www.youtube.com/watch?v=niTAJYCEAUM)\n\t- http://tech.marksblogg.com/billion-nyc-taxi-rides-spark-2-1-0-emr.html\n\t- http://ruhanixedu.com/blog/interview-question-and-answers/apache-spark-interview-questions-answers/\n\t- [Text Normalization with Spark](http://www.treselle.com/blog/text-normalization-with-spark-part-1/)\n\t- [Spark ML](http://spark.apache.org/docs/latest/ml-guide.html)\n\t\t- https://www.infoq.com/articles/apache-sparkml-data-pipelines\n\t\t- https://commitlogs.com/2017/02/18/serve-spark-ml-model-using-play-framework-and-s3/\n\t\t- https://pages.databricks.com/definitive-guide-spark.html\n\t- [MLlib](http://spark.apache.org/mllib/, https://spark.apache.org/docs/latest/ml-guide.html)\n\t- [PySpark](https://spark.apache.org/docs/latest/api/python/index.html)\n\t- [Optimus](https://github.com/hi-primus/optimus)\n- #CODE [Apache Storm](https://storm.apache.org/)\n\t- http://zdatainc.com/2014/09/apache-storm-apache-spark/\n\t- http://www.collaberatact.com/understanding-hadoop-vs-spark-vs-storm/\n- #CODE [Apache Arrow](https://arrow.apache.org/)\n\t- http://wesmckinney.com/blog/apache-arrow-pandas-internals/\n- #CODE [Blaze](http://blaze.pydata.org/)\n\t- http://blaze.readthedocs.io/en/latest/index.html\n\n### Databases\n- SQL:\n\t- #CODE [SQLAlchemy](https://www.sqlalchemy.org/)\n\t\t- https://github.com/zzzeek/sqlalchemy\n\t- #CODE [Pyodbc](https://github.com/mkleehammer/pyodbc)\n\t- #CODE [ClickHouse](https://clickhouse.yandex/)\n- NoSQL:\n\t- [Neo4j](https://neo4j.com/product/)\n\t- [MongoDB](https://en.wikipedia.org/wiki/MongoDB)\n\t- [PyMongo](https://api.mongodb.com/python/current/)\n\t- [CouchDB](https://en.wikipedia.org/wiki/CouchDB)\n\n\n## Subtopics\n### Open datasets (for ML, DL and DS)\nSee [[AI/DS and DataEng/Open ML data]]\n\n### MLOps\nSee [[AI/DS and DataEng/ML Ops]]\n\n### Feature engineering\n- https://en.wikipedia.org/wiki/Feature_engineering\n- Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. It is fundamental to the application of ML, and is both difficult and expensive. The need for manual feature engineering can be obviated by automated feature learning\n- http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/\n- https://tech.zalando.com/blog/feature-extraction-science-or-engineering/\n\n#### Feature extraction\nSee [[AI/Feature learning]] techniques in [[AI/Computer Vision/Computer vision]]\n\n\n### Data mining\n- http://nbviewer.jupyter.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/tree/master/ipynb/\n- https://www.dataquest.io/course/apis-and-scraping\n\n#### Web scraping\n- https://www.dataquest.io/blog/web-scraping-tutorial-python/\n- http://thiagomarzagao.com/2013/11/12/webscraping-with-selenium-part-1/\n- https://medium.com/@hoppy/how-to-test-or-scrape-javascript-rendered-websites-with-python-selenium-a-beginner-step-by-c137892216aa#.hrjljvffd\n- https://antonio-maiolo.com/2016/12/01/web-crawler-scrapy-crawl-spider-tutorial/\n- http://stackoverflow.com/questions/19021541/scrapy-scrapping-data-inside-a-javascript\n\n#### API\n- [A categorized public list of APIs from round the web](https://github.com/abhishekbanthia/Public-APIs)\n- [A collective list of public JSON APIs for use in web development](https://github.com/toddmotto/public-apis)\n- [Public APIs](https://public-apis.io/)\n\n\n### Databases\n- https://en.wikipedia.org/wiki/Distributed_database\n- [ACID (Atomicity, Consistency, Isolation, Durability) ](https://en.wikipedia.org/wiki/ACID)\n- [SQL vs NoSQL](http://dataconomy.com/2014/07/sql-vs-nosql-need-know/)\n\n#### SQL\n- https://en.wikipedia.org/wiki/SQL\n- https://en.wikipedia.org/wiki/Relational_database\n- A relational database is a digital database whose organization is based on the relational model of data. \n- https://www.analyticsvidhya.com/blog/2017/01/46-questions-on-sql-to-test-a-data-science-professional-skilltest-solution/\n- [Tutorial and exercises](http://sqlzoo.net)\n- [SQL (basic, intermediate, advanced / pet problems)](https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/)\n- [List of SQL Commands](https://www.codecademy.com/articles/sql-commands)\n- [JOIN](https://en.wikipedia.org/wiki/Join_(SQL))\n\t- A SQL join clause combines columns from one or more tables in a relational database. It creates a set that can be saved as a table or used as it is. A JOIN is a means for combining columns from one (self-table) or more tables by using values common to each. ANSI-standard SQL specifies five types ofJOIN:INNER,LEFT OUTER,RIGHT OUTER,FULL OUTER and CROSS.\n\t- https://periscopedata.com/blog//how-joins-work.html\n- https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems\n- Python interface\n\t- https://www.tutorialspoint.com/python/python_database_access.htm\n\t- http://www.python-course.eu/sql_python.php\n\t- https://wiki.python.org/moin/DatabaseInterfaces\n\n#### NoSQL\n- https://en.wikipedia.org/wiki/NoSQL\n- Not only SQL: A NoSQL database provides a mechanism for storage and retrieval of data which is modeled in means other than the tabular relations used in relational databases. NoSQL databases are increasingly used in big data and real-time web applications. Many NoSQL stores compromise consistency (in the sense of theCAP theorem) in favor of availability, partition tolerance, and speed. \n- Column: Accumulo, Cassandra, Druid, HBase, Vertica, SAP HANA \n- #TALK [GOTO 2012 - Introduction to NoSQL - Martin Fowler](https://www.youtube.com/watch?v=qI_g07C_Q5I)\n- Graph: \n\t- A graph database is a database that uses graph structures for semantic queries with nodes, edges and properties to represent and store data. A key concept of the system is the graph (or edge or relationship), which directly relates data items in the store. The relationships allow data in the store to be linked together directly, and in many cases retrieved with a single operation.\n\t- Graph databases employ nodes, edges and properties.\n\t\t- Nodes represent entities/items you might want to keep track of (people, businesses, accounts).\n\t\t- Edges, also known as graphs or relationships, are the lines that connect nodes to other nodes; they represent the relationship between them.\n\t\t- Properties are pertinent information that relate to nodes (sort of keywords).\n\t\t- AllegroGraph, ArangoDB, InfiniteGraph, Apache Giraph, MarkLogic, Neo4J, OrientDB, Virtuoso, Stardog\n\t\t- https://neo4j.com/developer/graph-database/\n- Key-value\n\t- https://en.wikipedia.org/wiki/Key-value_database\n\t- A key-value store, or key-value database, is a data storage paradigm designed for storing, retrieving, and managing associative arrays, a data structure more commonly known today as a dictionary or hash.\n\t- Dictionaries contain a collection of objects, or records, which in turn have many different fields within them, each containing data. These records are stored and retrieved using a key that uniquely identifies the record, and is used to quickly find the data within the database.\n- [Document-oriented database](https://en.wikipedia.org/wiki/Document-oriented_database)\n\n### Data munging\n- https://www.coursera.org/learn/data-cleaning\n\n#### Data preparation\n- Data cleansing: Missing data\n\t- https://scikit-learn.org/stable/modules/impute.html\n\t- https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#two\n\t- https://www.quora.com/How-can-I-deal-with-missing-values-in-a-predictive-model\n- [Variables encoding](http://pbpython.com/categorical-encoding.html)\n- [Normalisation, scaling](http://scikit-learn.org/stable/modules/preprocessing.html)\n- [Outlier detection](https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#three)\n\n#### Exploratory data analysis\n- https://www.codementor.io/jadianes/data-science-python-r-exploratory-data-analysis-visualization-du107jjms\n- http://blog.districtdatalabs.com/data-exploration-with-python-2\n- https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/\n\n\n### Big data\n- http://www.datasciencecentral.com/profiles/blogs/25-big-data-terms-you-must-know-to-impress-your-date-or-whoever\n- [Architecture of Giants: Data Stacks at Facebook, Netflix, Airbnb, and Pinterest](https://blog.keen.io/architecture-of-giants-data-stacks-at-facebook-netflix-airbnb-and-pinterest-9b7cd881af54)\n\n#### MapReduce\n- https://en.wikipedia.org/wiki/MapReduce\n- MapReduce is a programming model and an associated implementation for processing and generating large data sets with a parallel, distributed algorithm on a cluster\n- A MapReduce program is composed of aMap() procedure (method) that performs filtering and sorting (such as sorting students by first name into queues, one queue for each name) and aReduce() method that performs a summary operation (such as counting the number of students in each queue, yielding name frequencies)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Distributed-DL":{"title":"Distributed Deep learning","content":"## Resources\n- https://d2l.ai/chapter_computational-performance/multiple-gpus.html \n- https://jhui.github.io/2017/03/07/TensorFlow-GPU/ \n- https://www.logicalclocks.com/blog/goodbye-horovod-hello-collectiveallreduce \n- [Twelve ways to fool the masses when reporting performance of deep learning workloads](https://htor.inf.ethz.ch/blog/index.php/2018/11/08/twelve-ways-to-fool-the-masses-when-reporting-performance-of-deep-learning-workloads/)\n- [Distributed Deep Learning 101: Introduction](https://towardsdatascience.com/distributed-deep-learning-101-introduction-ebfc1bcd59d9)\n\n## Talks\n- #TALK [ALCF Datascience frameworks: Tensorflow, PyTorch, Keras, and Horovod](https://www.alcf.anl.gov/files/Zheng_SDL_ML_Frameworks_1.pdf)\n- #TALK [Scaling Deep Learning for Scientific Workloads on the #1 Summit Supercomputer](https://insidehpc.com/2019/04/scaling-deep-learning-for-scientific-workloads-on-the-1-summit-supercomputer/)\n- #TALK [Scaling Neural Networks Training - Thorsten Kurth](https://www.youtube.com/watch?v=cRjiwIi_kuc)\n\n## Code\nSee \"Distributed training\" section in [[AI/DS and DataEng/Tensorflow, keras]]\n\n- #CODE [Analytics Zoo](https://github.com/intel-analytics/analytics-zoo)\n\t- Distributed Tensorflow, Keras and PyTorch on Apache Spark/Flink \u0026 Ray\n\t- https://analytics-zoo.readthedocs.io/en/latest/index.html\n- #CODE [Horovod](AI/DS%20and%20DataEng/Horovod.md)\n- #CODE [Colossal-AI: A Unified Deep Learning System for Large-Scale Parallel Training](https://github.com/hpcaitech/colossalai)\n\t- See [[#^colossalai]]\n\t-  https://www.marktechpost.com/2021/10/31/researchers-introduce-colossal-ai-a-pytorch-based-deep-learning-system-for-large-scale-parallel-training/\n\n## References\n- #PAPER [Evaluation of Deep Learning Frameworks over Different HPC Architectures (Shams 2017)](https://www.ibm.com/university/power/images/EvaluationofDeepLearningFrameworksoverDifferentHPCArchitectures.pdf)\n- #PAPER [Deep Learning at 15PF: Supervised and Semi-Supervised Classification for Scientific Data (Kurth 2017)](https://arxiv.org/abs/1708.05256)\n- #PAPER [Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis (Tal Ben-Nun and Torsten Hoefler 2018)](http://arxiv.org/abs/1802.09941) ^bennun18\n\t- #TALK [Hoefler 2018](https://www.youtube.com/watch?v=xtxxLWZznBI)\n\t- #TALK [Hoefler 2020](https://www.youtube.com/watch?v=uNzQ1vvJ82c)\n\t- #TALK [Ben-Nun 2020](https://www.youtube.com/watch?v=N5uIFSVR7jE)\n- #PAPER [Mesh-TensorFlow: Deep Learning for Supercomputers (Shazeer 2018)](https://arxiv.org/abs/1811.02084v1) ^f86598\n\t- #TALK https://www.youtube.com/watch?v=HgGyWS40g-g\n\t- #CODE [Mesh-TensorFlow](https://github.com/tensorflow/mesh)\n\t\t- Go beyond data-parallel training\n\t\t- More sophisticated parallel computations (big models that do not fit on one device)\n- #PAPER [GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism (Huang 2019)](http://arxiv.org/abs/1811.06965)\n- #PAPER [A Quantitative Study of Deep Learning Training on Heterogeneous Supercomputers (Han 2019)](https://ieeexplore.ieee.org/document/8890993)\n\t- http://people.cs.vt.edu/~butta/docs/cluster2019-DL.pdf\n- #PAPER [Channel and filter parallelism for large-scale CNN training (Dryden 2019)](https://dl.acm.org/doi/10.1145/3295500.3356207)\n\t- https://ndryden.com/data/papers/sc2019-chanfilt.pdf\n- #PAPER [Improving Strong-Scaling of CNN Training by Exploiting Finer-Grained Parallelism (Dryden 2019)](http://arxiv.org/abs/1903.06681)\n- #PAPER [Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training (Li 2019)](http://arxiv.org/abs/1811.03619)\n- #PAPER [Scalable Deep Learning on Distributed Infrastructures: Challenges, Techniques and Tools (Mayer 2019)](http://arxiv.org/abs/1903.11314)\n- #PAPER [Performance Analysis of Deep Learning Workloads on Leading-edge Systems (Ren 2019)](https://www.osti.gov/biblio/1571428-performance-analysis-deep-learning-workloads-leading-edge-systems)\n- #PAPER [TensorFlow on State-of-the-Art HPC Clusters: A Machine Learning use Case (Ramirez-Gargallo 2019)](https://ieeexplore.ieee.org/document/8752892) ^ramirez19\n\t- https://core.ac.uk/download/pdf/196280993.pdf \n\t- Compared MN4, Power9 and Dibona HPC clusters. Only CPUs compared (Power9 GPUs are not evaluated)\n- #PAPER [Exascale Deep Learning for Scientific Inverse Problems (Laanait 2019)](http://arxiv.org/abs/1909.11150)\n- #PAPER [TensorFlow Doing HPC (Chien 2019)](https://arxiv.org/abs/1903.04364)\n- #PAPER [ZeRO: memory optimizations toward training trillion parameter models (Rajbhandari 2019)](https://arxiv.org/abs/1910.02054)\n\t- #CODE [DeepSpeed](https://github.com/microsoft/DeepSpeed)\n\t\t- DeepSpeed is a deep learning optimization library that makes distributed training easy, efficient, and effective. For pytorch\n\t\t- www.deepspeed.ai/\n\t- https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/\n- #PAPER [Towards a Scalable and Distributed Infrastructure for Deep Learning Applications (Hasheminezhad 2020)](https://arxiv.org/abs/2010.03012)\n\t- Phylanx Deep Learning Framework\n\t- Good comparison with respect to SOTA\n\t- [Phylanx provides a high-productivity debugable Python-based interactive interface, JetLag](https://github.com/STEllAR-GROUP/JetLag)\n\t- Tests only on CPU. Does it support GPUs?\n- #PAPER [Distributed Training of Deep Learning Models: A Taxonomic Perspective (Langer 2020)](https://arxiv.org/abs/2007.03970)\n- #PAPER [Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training (Bian 2021)](https://arxiv.org/abs/2110.14883) ^colossalai\n- #PAPER [Pathways: Asynchronous Distributed Dataflow for ML (Barham 2022)](https://arxiv.org/pdf/2203.12533)            \n- #PAPER [Scaling Laws vs Model Architectures: How does Inductive Bias Influence  Scaling? (Tay 2022)](https://arxiv.org/pdf/2207.10551v1)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Horovod":{"title":"Horovod","content":"## References\n- #PAPER [Horovod: fast and easy distributed deep learning in TensorFlow (Sergeev 2018)](http://arxiv.org/abs/1802.05799 )\n\t- #CODE https://github.com/horovod/horovod \n\t- https://horovod.readthedocs.io/en/latest/keras.html \n\t- https://horovod.readthedocs.io/en/stable/tensorflow.html\n\t- https://eng.uber.com/horovod/\n\t- Horovod is a distributed training framework for TensorFlow, Keras, PyTorch, and MXNet. The goal of Horovod is to make distributed Deep Learning fast and easy to use. Horovod is hosted by the LF AI Foundation (Linux Foundation AI). Horovod implements all-reduce operations into the back-propagation computation to average the computed gradients and allow the distributed scaling among multiple GPUs. Based on Baidu ring allreduce (http://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/)\n\t- [Not straightforward from Jupyterlab](https://github.com/horovod/horovod/issues/622. Possible solution - Ipyparallel:)\n\t\t- [Interactive Distributed Deep Learning with Jupyter Notebooks](https://sc18.supercomputing.org/proceedings/tech_poster/poster_files/post206s2-file3.pdf)\n\t\t- https://github.com/sparticlesteve/cori-intml-examples \n\n## Examples\n- https://github.com/horovod/horovod/tree/master/examples\n- https://horovod.readthedocs.io/en/stable/running_include.html\n- https://github.com/horovod/tutorials/blob/master/fashion_mnist/README.md \n- [Distributed Deep Learning with Horovod (Jordi Torres)](https://towardsdatascience.com/distributed-deep-learning-with-horovod-2d1eea004cb2)\n- https://towardsdatascience.com/a-quick-guide-to-distributed-training-with-tensorflow-and-horovod-on-amazon-sagemaker-dae18371ef6e \n- [with SLURM on the BSC-P9 cluster](https://towardsdatascience.com/distributed-deep-learning-with-horovod-2d1eea004cb2)\n- With SLURM workload manager. See paper Ramirez-Gargallo 2019 in [[AI/DS and DataEng/Distributed DL]]\n- [Example with SLURM](http://www.idris.fr/eng/jean-zay/gpu/jean-zay-gpu-hvd-tf-multi-eng.html)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Jupyter":{"title":"Jupyter","content":"## Resources\n- #CODE [Jupyter](https://github.com/jupyter)\n\t- #CODE [Jupyterlab](https://github.com/jupyterlab/jupyterlab )\n\t- #CODE [Jupyter(hub)](https://jupyter.org/hub )\n\t- #CODE [Jupyterlite](https://github.com/jupyterlite)\n\t\t- https://blog.jupyter.org/jupyterlite-jupyter-%EF%B8%8F-webassembly-%EF%B8%8F-python-f6e2e41ab3fa\n\t- #CODE [Stickyland](https://github.com/xiaohk/stickyland)\n\t\t- Break the linear presentation of Jupyter Notebooks with sticky cells\n\t- #CODE [Nbterm](https://github.com/davidbrochart/nbterm) - Jupyter Notebooks in the terminal\n- #CODE [Papermill - Parameterize, execute, and analyze notebooks](https://github.com/nteract/papermill)\n- #CODE [Beaker kernels and extensions](http://beakerx.com/)\n- [Juypterbook - Books with Jupyter](https://jupyterbook.org/intro.html)\n- [Jupyter everywhere](https://blog.jupyter.org/jupyter-everywhere-f8151c2cc6e8)\n- [Executing notebooks from the command line](https://nbconvert.readthedocs.io/en/latest/execute_api.html#executing-notebooks-from-the-command-line \"Permalink to this headline\")\n\t- `$ jupyter nbconvert --to notebook --inplace --ExecutePreprocessor.timeout=None --execute mynotebook.ipynb`\n\n## Jupyter in HPC\n- High-level scripting languages such as Python, R and Julia, have become the go-to choices in the world of Data Science and ML/AI. Project Jupyter exists to develop open-source software, open-standards, and services for interactive computing across dozens of programming languages. For instance, the Jupyter Notebook is an open-source web-app that allows users to write portable documents containing executable code, narrative text, and equations, and to visualize the results of running the code directly in the web browser. The name comes from a combination of the three core programming languages of Jupyter (Julia, Python and R) though Jupyter is not limited to these languages.  \n- Tools in the Jupyter ecosystem are designed in a modular fashion, and behave similarly on a researcher's laptop, a high-performance computing center, or the cloud. As a result, Jupyter technologies have been widely adopted across a spectrum of scientific disciplines, including Earth Sciences (Perez et al. 2019).  \n- JupyterHub brings the power of notebooks to groups of users. It gives users access to computational environments and resources without burdening the users with installation and maintenance tasks. These are a few examples of JupyterHub systems running on supercomputing systems: \n\t- University Corporation for Atmospheric Research (UCAR, https://jupyterhub.ucar.edu/)  \n\t- CSCS, ETH Zurich (https://jupyter.cscs.ch/hub/login) \n\t- CHPC, University of Utah (https://www.chpc.utah.edu/documentation/software/jupyterhub.php#hub, http://notebook.chpc.utah.edu/) \n\t- Minesota supercomputing institute (https://www.msi.umn.edu/content/msi-beta) \n- A common denominator of these computing platforms is that they allow the interactive execution of Jupyter tools on HPC systems over multiple nodes. The user is offered to choose the job configuration options in order to allocate the resources to be used to run Jupyter: account, number of nodes, access to GPUs, wall-clock time, etc.  \n- [Interactive supercomputing with Jupyter lab](https://www.cscs.ch/publications/news/2019/interactive-supercomputing-with-jupyterlab/)\n\n- #PAPER [Jupyter as common technology platform for interactive HPC services (Milligan 2018)](https://arxiv.org/abs/1807.09929)\n- #PAPER [Jupyter meets the Earth: Enabling discovery in geoscience through interactive computing at scale (Perez 2019)](https://zenodo.org/record/3369939 )\n- #PAPER [Interactive Supercomputing with Jupyter (Thomas 2021)](https://authorea.com/doi/full/10.22541/au.161230518.84458221) ^thomas21hpcjupyter","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/ML-Ops":{"title":"Machine Learning Operations (MLOps)","content":"\u003e Set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently. The word is a compound of \"machine learning\" and the continuous development practice of DevOps in the software field\n\n## Resources\n- https://en.wikipedia.org/wiki/MLOps\n- https://github.com/GokuMohandas/MadeWithML\n- https://github.com/visenger/awesome-mlops\n- https://github.com/EthicalML/awesome-production-machine-learning\n\n## Code\n### Experiment tracking\n- https://neptune.ai/blog/best-ml-experiment-tracking-tools\n- #CODE [Weights \u0026 Biases](https://docs.wandb.com/)\n\t- Library that -helps you keep track of your machine learning projects. Use our tool to log hyperparameters and output metrics from your runs, then visualize and compare results and quickly share findings with your colleagues.\n- #CODE [Aim](https://github.com/aimhubio/aim)\n\t- The open-source tool for ML experiment comparison\n\t- https://aimstack.io/\n- #CODE [ClearML](https://github.com/allegroai/clearml)\n\t- https://clear.ml/\n\n### Workflow managers\n- #CODE [Kedro](https://github.com/kedro-org/kedro)\n\t- A Python framework for creating reproducible, maintainable and modular data science code\n\t- https://kedro.readthedocs.io/\n\t- #CODE [kedro-viz](https://github.com/kedro-org/kedro-viz)\n- #CODE [MLrun](https://github.com/mlrun/mlrun)\n\t- The Open-Source MLOps Orchestration Framework\n\t- https://docs.mlrun.org/en/stable/\n- #CODE [Metaflow](https://github.com/Netflix/metaflow)\n\t- Metaflow is a human-friendly Python/R library that helps scientists and engineers build and manage real-life data science projects\n\t- Originally developed at Netflix to boost productivity of data scientists who work on a wide variety of projects from classical statistics to state-of-the-art deep learning\n\t- https://metaflow.org/\n\t- #CODE [metaflow-ui](https://github.com/Netflix/metaflow-ui)\n\t\t- https://netflixtechblog.com/open-sourcing-a-monitoring-gui-for-metaflow-75ff465f0d60\n- #CODE [Flyte](https://github.com/flyteorg/flyte)\n\t- Kubernetes-native workflow automation platform for complex, mission-critical data and ML processes at scale. It has been battle-tested at Lyft, Spotify, Freenome, and others and is truly open-source\n\t- https://flyte.org/\n- #CODE [MLFlow](https://github.com/mlflow/mlflow/ )\n\t- [An open source platform for the machine learning lifecycle](https://mlflow.org)\n- #CODE [Airflow: Apache Airflow - A platform to programmatically author, schedule, and monitor workflows](https://github.com/apache/airflow)\n\t- http://nerds.airbnb.com/airflow/\n\t- https://medium.com/datasd/why-data-automation-matters-4391d59e1952\n- #CODE [Luigi (Spotify)](https://github.com/spotify/luigi)\n\t- https://luigi.readthedocs.io/en/latest/\n- #CODE [Kale](https://github.com/kubeflow-kale/kale)\n- #CODE [Azkaban](https://github.com/azkaban/azkaban)\n- #CODE [PredictionIO (Apache)](https://predictionio.apache.org)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Open-ML-data":{"title":"Open ML data","content":"## Resources\n- https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research\n- https://paperswithcode.com/datasets\n- [OpenML (open-source datasets)](http://www.openml.org/)\n\t- [API](https://docs.openml.org/APIs/)\n- [Awesome Public Datasets (high quality datasets from communities such as academia, education etc)](https://github.com/awesomedata/awesome-public-datasets)\n- [Registry of Open Data on AWS](https://registry.opendata.aws/)\n- [Gym (OpenAI) - For reinforcement learning algorithms](https://gym.openai.com/)\n- [Data Is Plural - newsfeed](http://tinyletter.com/data-is-plural/archive)\n- [Datasets for data mining (ML)](http://www.inf.ed.ac.uk/teaching/courses/dme/html/datasets0405.html)\n- [Greatest Public Datasets for AI/ML](https://medium.com/startup-grind/fueling-the-ai-gold-rush-7ae438505bc2)\n- [Open knowledge foundation repository (varied formats and sources)](https://datahub.io/dataset)\n- [Stanford Large Network Dataset Collection](http://snap.stanford.edu/data/#!)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Python":{"title":"Python","content":"\u003e Python is a programming language that lets you work quicklyand integrate systems more effectively\n\n## Resources\n- https://www.python.org/\n- https://github.com/vinta/awesome-python\n- https://github.com/FavioVazquez/ds-cheatsheets/tree/master/Python\n- https://github.com/ujjwalkarn/DataSciencePython\n- [Optimizing Python code performance with cProfile](https://blog.alookanalytics.com/2017/03/21/python-profiling-basics/)\n- [Consistent Python code with Black](https://www.mattlayman.com/blog/2018/python-code-black/)\n- [Writing proper classes](https://aboucaud.github.io/slides/2016/python-classes)\n- [Compiled C or Fortran to Python](http://people.duke.edu/~ccc14/sta-663/FromCompiledToPython.html)\n- [Using Python as glue](https://docs.scipy.org/doc/numpy-1.13.0/user/c-info.python-as-glue.html)\n- [Extending Python with Compiled Code](https://github.com/AstroHackWeek/AstroHackWeek2014/blob/master/day4/ExtendingPython.ipynb)\n- [Wrapping C/C++ for Python](https://intermediate-and-advanced-software-carpentry.readthedocs.io/en/latest/c++-wrapping.html)\n\n### Python and open source for science\n- [Open source Science (IBM)](https://opensource.science/)\n\t- https://opensource.science/open-source-science-white-paper-c4940a0e9098\n- [Python-for-Scientists](https://github.com/TomNicholas/Python-for-Scientists)\n- [pyOpenSci](https://www.pyopensci.org/)\n\t- pyOpenSci promotes open and reproducible research through peer-review of scientific Python packages\n- [Python for Scientific Computing](https://www.msi.umn.edu/tutorials/python-scientific-computing)\n- #BOOK [Learning Scientific Programming with Python (Hill 2020)](https://scipython.com/about/the-book/)\n\n## Books\n- #BOOK [Problem Solving with Algorithms and Data Structures using Python (Interactive book)](https://runestone.academy/runestone/books/published/pythonds/index.html)\n- #BOOK [Large Scale Machine Learning with Python (Sjandin 2016, PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/large-scale-machine-learning-python)\n- #BOOK [From Python to Numpy (Rougier 2017)](http://www.labri.fr/perso/nrougier/from-python-to-numpy/)\n\n## Courses\n- #COURSE [Data Structures \u0026 Algorithms - Python](https://pythonschool.net/category/data-structures-algorithms.html)\n- #COURSE [Python in High Performance Computing](https://www.futurelearn.com/courses/python-in-hpc)\n- #COURSE [Scientific Computing with Python](https://www.freecodecamp.org/learn/scientific-computing-with-python/)\n- #COURSE [SoloLearn Python 3 Tutorial](https://www.sololearn.com/Course/Python/)\n- #COURSE https://www.learneroo.com/modules/65/nodes/366\n\n## Code\nMost of the code entries in this digital knowledge garden are in Python. Just look around!\n\n### Package documentation\n- https://realpython.com/documenting-python-code/\n- [Documenting Python code](https://aboucaud.github.io/slides/2016/python-docstrings)\n- #CODE [Mkdocs](https://github.com/mkdocs/mkdocs/)\n\t- [Mkdocstrings](https://github.com/mkdocstrings/mkdocstrings)\n\t\t- https://mkdocstrings.github.io/\n\t- [Pytkdocs](https://github.com/mkdocstrings/pytkdocs)\n\t- [docstring_parser](https://github.com/rr-/docstring_parser)\n\t- [mkapi](https://github.com/daizutabi/mkapi)\n\t\t- A documentation generation tool for MkDocs\n- #CODE [Pdoc](https://pdoc.dev/)\n\t- [How to Generate Professional API Docs in Minutes from Docstrings](https://towardsdatascience.com/how-to-generate-professional-api-docs-in-minutes-from-docstrings-aed0341bbda7)\n- #CODE [mkgendocs](https://github.com/davidenunes/mkgendocs)\n\t- https://towardsdatascience.com/five-tips-for-automatic-python-documentation-7513825b760e\n\n### Packaging and dependency management\n- [Python Packaging User Guide](https://packaging.python.org/en/latest/)\n- [Packaging Your Code](https://docs.python-guide.org/shipping/packaging/)\n- #CODE [Poetry](https://github.com/python-poetry/poetry)\n\t- https://python-poetry.org/","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Pytorch":{"title":"Pytorch","content":"## Resources\n- [Named Tensors using First-class Dimensions in PyTorch](https://github.com/facebookresearch/torchdim)\n\n\n## Courses\n- #COURSE [Intro to Deep Learning with PyTorch (Udacity)](https://www.udacity.com/course/deep-learning-pytorch--ud188)\n\n\n## Code\n- #CODE [PyTorch (Facebook)](https://github.com/pytorch/pytorch)\n\t- http://pytorch.org\n\t- [Ecosystem tools](https://pytorch.org/ecosystem/)\n\t- Tensors and Dynamic neural networks in Python with strong GPU acceleration\n\t- https://sagivtech.com/2017/09/19/optimizing-pytorch-training-code/\n- #CODE [TorchStudio](https://www.torchstudio.ai/)\n\t- IDE for PyTorch and its ecosystem\n\t- https://www.assemblyai.com/blog/beginners-guide-to-torchstudio-pytorch-only-ide/\n- #CODE [Pytorch-lightning](https://pytorchlightning.ai/)\n\t- https://medium.com/pytorch/introducing-lightning-flash-the-fastest-way-to-get-started-with-deep-learning-202f196b3b98\n- #CODE [Fastai](https://github.com/fastai/fastai)\n\t- fastai simplifies training fast and accurate neural nets using modern best practices\n\t- https://docs.fast.ai/\n\t- #PAPER [Fastai: A Layered API for Deep Learning (Howard 2020)](https://www.mdpi.com/2078-2489/11/2/108/htm)\n- #CODE [kornia](https://github.com/kornia/kornia)\n\t- Open Source Differentiable Computer Vision Library\n\t- https://kornia.github.io/\n- #CODE [NMF](https://github.com/facebookresearch/mmf)\n\t- A modular framework for vision \u0026 language multimodal research from Facebook AI Research (FAIR)\n\t- https://mmf.sh/\n- #CODE [Pytext (Facebook) - A natural language modeling framework based on PyTorch](https://github.com/facebookresearch/pytext )\n\t- https://fb.me/pytextdocs\n\t- PyText is a deep-learning based NLP modeling framework built on PyTorch\n- #CODE [Pytorch tabular](https://github.com/manujosephv/pytorch_tabular) ^pytorchtab\n\t- https://deep-and-shallow.com/2021/01/27/pytorch-tabular-a-framework-for-deep-learning-for-tabular-data/\n- #CODE [Clearml](https://github.com/allegroai/clearml)\n\t- ClearML - Auto-Magical CI/CD to streamline your ML workflow. Experiment Manager, [[AI/DS and DataEng/ML Ops]] and Data-Management\n\t- https://clear.ml/docs\n- #CODE [Composer](https://github.com/mosaicml/composer)\n\t- A PyTorch Library for Efficient Neural Network Training\n- #CODE [ColossalAI](https://github.com/hpcaitech/ColossalAI)\n\t- Colossal-AI: A Unified Deep Learning System for Large-Scale Parallel Training\n\t- https://analyticsindiamag.com/a-guide-to-parallel-deep-learning-with-colossal-ai/\n\n\n## References\n- #PAPER [PyTorch: An Imperative Style, High-Performance Deep Learning Library (Paszke 2019)](https://arxiv.org/abs/1912.01703)\n\t- Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Tensorflow-keras":{"title":"Tensorflow, Keras","content":"## Resources\n- http://playground.tensorflow.org/\n- [TensorFlow Hub](https://tfhub.dev/)\n\t- https://www.tensorflow.org/hub\n\t- Hundreds of trained, ready-to-deploy machine learning models in one place\n- [Keras Applications](https://keras.io/api/applications/)\n\t- DL models that are made available alongside pre-trained weights. These models can be used for prediction, feature extraction, and fine-tuning\n- [Transfer Learning Guide](https://neptune.ai/blog/transfer-learning-guide-examples-for-images-and-text-in-keras): A Practical Tutorial With Examples for Images and Text in Keras\n- https://cloud.google.com/blog/big-data/2016/07/understanding-neural-networks-with-tensorflow-playground\n- https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc#.dg41ldof5\n- https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0\n- [Tensorflow 2.0: models migration and new design](https://pgaleone.eu/tensorflow/gan/2018/11/04/tensorflow-2-models-migration-and-new-design/)\n- http://planspace.org/20170404-how_not_to_program_the_tensorflow_graph/\n- [Understanding Tensorflow's tensors shape: static and dynamic](https://pgaleone.eu/tensorflow/2018/07/28/understanding-tensorflow-tensors-shape-static-dynamic/)\n\n\n### Distributed training\n- https://missinglink.ai/guides/tensorflow/tensorflow-distributed-training-introduction-tutorials/ \n- TF.Distribute\n\t- https://www.tensorflow.org/guide/distributed_training \n\t- https://www.tensorflow.org/guide/gpu\n\t- https://keras.io/guides/distributed_training/\n\t- #TALK [Inside TensorFlow: tf.data + tf.distribute](https://www.youtube.com/watch?v=ZnukSLKEw34)\n- [Numpy to tf.record](https://gist.github.com/swyoon/8185b3dcf08ec728fb22b99016dd533f)\n- https://www.tensorflow.org/tutorials/distribute/keras \n- https://www.tensorflow.org/tutorials/distribute/custom_training \n- https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#scrollTo=9iagoTBfijUz \n- [Train a Neural Network on multi-GPU with TensorFlow (Jordi Torres)](https://towardsdatascience.com/train-a-neural-network-on-multi-gpu-with-tensorflow-42fa5f51b8af)\n- [Multinode example](https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md)\n- MultiWorkerMirroredStrategy:\n\t- https://www.tensorflow.org/api_docs/python/tf/distribute/MultiWorkerMirroredStrategy (after TF v2)\n\t- https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy\n\t- https://blog.tensorflow.org/2020/12/whats-new-in-tensorflow-24.html (TF v2.4)\n\t- https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras \n\t- https://github.com/tensorflow/tensorflow/issues/36094\n- https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/SlurmClusterResolver \n- https://lambdalabs.com/blog/tensorflow-2-0-tutorial-05-distributed-training-multi-node/ \n\nData lazy loading: \n- Tf.data:\n\t- https://www.tensorflow.org/api_docs/python/tf/data/Dataset \n\t- https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator\n\t- https://www.tensorflow.org/tutorials/distribute/input\n- Tensorflow data netcdf, MATEX tensorflow (seems to be abandoned) :https://github.com/matex-org/matex/wiki/DataSet-Reader \n\n\n\n## Code\n- #CODE [Tensorflow (Google)](https://github.com/tensorflow/tensorflow)\n- #CODE [TF Compression](https://github.com/tensorflow/compression)\n\t- TensorFlow Compression (TFC) contains data compression tools for TensorFlow\n- #CODE [TF Similarity](https://github.com/tensorflow/similarity)\n\t- https://blog.tensorflow.org/2021/09/introducing-tensorflow-similarity.html\n\t- Metric learning is different from traditional classification as it's objective is different. The model learns to minimize the distance between similar examples and maximize the distance between dissimilar examples, in a supervised or self-supervised fashion\n- #CODE [TF Probability](https://github.com/tensorflow/probability)\n\t- Probabilistic reasoning and statistical analysis in TensorFlow\n\t- https://www.tensorflow.org/probability\n- #CODE [TF Decision Forests](https://github.com/tensorflow/decision-forests)\n\t- A collection of state-of-the-art algorithms for the training, serving and interpretation of Decision Forest models in Keras\n\t- https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html\n\t- https://towardsdatascience.com/tensorflow-decision-forests-train-your-favorite-tree-based-models-using-keras-875d05a441f\n\t- [Decision forests in TF](https://www.youtube.com/watch?v=5qgk9QJ4rdQ)\n- #CODE [TF Datasets](https://github.com/tensorflow/datasets)\n- #CODE [TF Agents](https://github.com/tensorflow/agents)\n\t- A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning\n- #CODE [TF Recommenders](https://github.com/tensorflow/recommenders )\n\t- Library for building recommender system models using TensorFlow.\n- #CODE [TF Graphics](https://github.com/tensorflow/graphics)\n\t- Differentiable Graphics Layers for TensorFlow\n- #CODE [TF Ranking](https://github.com/tensorflow/ranking)\n\t- Learning to Rank in TensorFlow\n- #CODE [Tensorboard](https://github.com/tensorflow/tensorboard)\n\t- https://tensorboard.dev/\n\t- https://www.tensorflow.org/tensorboard/get_started (use as a jupyterlab magic)\n- #CODE [Tensorflow.js](https://www.tensorflow.org/js/)\n- #CODE [TF On Spark](https://github.com/yahoo/TensorFlowOnSpark)\n- #CODE [Sonnet](https://github.com/deepmind/sonnet)\n\t- https://deepmind.com/blog/open-sourcing-sonnet/\n- #CODE [seq2seq](https://github.com/google/seq2seq)\n- #CODE [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor)\n\t- https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html\n- #CODE [Graph Nets - Build Graph Nets in Tensorflow](https://github.com/deepmind/graph_nets)\n\t- https://arxiv.org/abs/1806.01261\n- [TF Graph Visualizer](http://idl.cs.washington.edu/papers/tfgraph/)\n- #CODE [Tensorpack - It's Yet Another TF high-level API, with speed, and flexibility built together](https://github.com/tensorpack/tensorpack)\n- #CODE [Cleverhans - A library for benchmarking vulnerability to adversarial examples](https://github.com/tensorflow/cleverhans)\n\t- http://karpathy.github.io/2015/03/30/breaking-convnets/\n\t- https://blog.openai.com/adversarial-example-research/\n\n\n### Keras\n- #CODE [Keras](https://github.com/keras-team/keras )\n\t- Keras is a deep learning API written in Python, running on top of the machine learning platform Tensorflow\n\t- http://keras.io/\n\t- https://keras.io/getting_started/intro_to_keras_for_researchers/\n\t- [Modern Keras design patterns](https://www.youtube.com/watch?v=FCz9m4T0DI0)\n- #CODE [AutoKeras - Auto-Keras is an open source software library for automated machine learning (AutoML)](https://github.com/keras-team/autokeras)\n\t- http://autokeras.com/\n\t- #PAPER [Auto-Keras: An Efficient Neural Architecture Search System (Jin 2019)](https://arxiv.org/abs/1806.10282)\n\t- https://towardsdatascience.com/autokeras-the-killer-of-googles-automl-9e84c552a319\n- #CODE [Ktrain](https://github.com/amaiya/ktrain)\n\t- https://analyticsindiamag.com/a-complete-guide-to-ktrain-a-wrapper-for-tensorflow-keras/","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Visualization":{"title":"Visualization","content":"## Resources\n- https://github.com/fasouto/awesome-dataviz\n- http://keshif.me/demo/VisTools\n- [The visualization universe](http://visualizationuniverse.com/)\n\t- http://visualizationuniverse.com/charts/\n- [Dataviz project](https://datavizproject.com/)\n- [UW Interactive Data Lab](http://idl.cs.washington.edu/)\n- [Flowing Data Tutorials](https://flowingdata.com/category/tutorials/)\n- http://www.coolinfographics.com/blog/2017/1/10/digital-marketing-tools-landscape.html\n- https://www.analyticsvidhya.com/blog/2015/09/infographic-tools-data-visualization/\n- https://visme.co/blog/examples-data-visualizations/\n- https://towardsdatascience.com/3rd-wave-data-visualization-824c5dc84967\n- [What's so hard about histograms?](https://tinlizzie.org/histograms/)\n- [Dataviz tools](http://visualizationuniverse.com/tools/)\n- [Data visualization tools and books](https://keshif.me/demo/VisTools)\n- [Python data viz tools](http://blog.yhat.com/posts/python-data-viz-landscape.html)\n- [Dataviz.tools: A curated guide to the best tools, resources and technologies for data viz](http://dataviz.tools/)\n- [Dashboard design (how-to)](http://www.designyourway.net/blog/inspiration/showcase-of-beautiful-dashboard-ui-designs/    )\n- Python Data Visualization 2018 (Anaconda)\n\t1. Why So Many Libraries?: https://www.anaconda.com/blog/developer-blog/python-data-visualization-2018-why-so-many-libraries/\n\t2. Moving Toward Convergence: https://www.anaconda.com/blog/developer-blog/python-data-visualization-moving-toward-convergence/\n\t3. Where Do We Go From Here?: https://www.anaconda.com/blog/developer-blog/python-data-visualization-2018-where-do-we-go-from-here/\n\n## Books\n- [Dataviz books](http://visualizationuniverse.com/books/?sortBy=volume\u0026sortDir=desc)\n- #BOOK [Fundamentals of Data Visualization (Wilke 2020)](https://clauswilke.com/dataviz/)\n- #BOOK [Data Visualization (Healy 2020)](https://socviz.co/)\n- #BOOK [R Graphics Cookbook, 2nd edition](https://r-graphics.org/)\n\n## Courses\n- #COURSE [Information Visualization (CS 465, Middlebury)](http://www.cs.middlebury.edu/~candrews/archive/infovis_s14/)\n- #COURSE [Data Visualization (CSE512, U Washington)](http://courses.cs.washington.edu/courses/cse512/14wi/)\n\t- https://github.com/uwdata/d3-tutorials\n- #COURSE [Data Science: Visualization (Harvard-edX)](https://www.edx.org/course/data-science-visualization-harvardx-ph125-2x)\n- #COURSE [Reading and interpreting data (Khan academy)](https://www.khanacademy.org/math/pre-algebra/pre-algebra-math-reasoning)\n- #TALK [23 Visualizations and When to Use Them in 30 Minutes](https://www.youtube.com/watch?v=RG_BKQRbJZw)\n- #TALK The Python Visualization Landscape (Vanderplas, Pycon 2017): \n\t- https://www.youtube.com/watch?v=FytuB8nFHPQ\n\t- https://us.pycon.org/2017/schedule/presentation/616/\n- #TALK [Everything we know about how humans interpret graphics (Elliot 2016)](https://www.youtube.com/watch?v=s0J6EDvlN30)\n- #TALK [Constructive Code Review (Rose, PyCon 2017)](https://www.youtube.com/watch?v=iNG1a--SIlk)\n\n## Code\n- #CODE [Matplotlib](https://matplotlib.org/)\n\t- http://nbviewer.jupyter.org/github/cs109/content/blob/master/lec_03_statistical_graphs.ipynb\n- #CODE [Seaborn](http://seaborn.pydata.org/)\n- #CODE [Bokeh](https://github.com/bokeh/bokeh)\n- #CODE [Plotly](https://github.com/plotly)\n\t- https://github.com/plotly/plotly.js\n\t- http://blog.yhat.com/posts/visualize-nba-pipelines.html\n- #CODE [Lightning](http://lightning-viz.org/)\n\t- Lightning is a data-visualization server providing API-based access to reproducible, web-based, interactive visualizations\n\t- https://github.com/lightning-viz/lightning-python\n- #CODE [Perspective](https://jpmorganchase.github.io/perspective/)\n- #CODE [D3.js](https://d3js.org/)\n\t- http://chimera.labs.oreilly.com/books/1230000000345/index.html\n\t- https://github.com/d3/d3/wiki/Tutorials\n\t- https://blog.datazar.com/the-best-resources-when-learning-d3-js-7da4ba0a783e#.oyw1gyxzz\n\t- https://learningd3.com/\n\t- https://learningd3.com/blog/generative-art/\n\t- http://blog.thedataincubator.com/2015/08/embedding-d3-in-an-ipython-notebook/\n\t- https://datawanderings.com/2017/01/29/data-visualisation-from-scratch-with-d3-js-part-1-canvas-setup/\n\t- [D3 Tips and Tricks](https://leanpub.com/D3-Tips-and-Tricks)\n\t- [Blocks - database of examples](https://bl.ocks.org/)\n\t- [Building a storytelling scroller with D3](http://vallandingham.me/scroller.html)\n\t- [Interactive Data Visualization for the Web](http://chimera.labs.oreilly.com/books/1230000000345/index.html)\n\t- https://www.analyticsvidhya.com/blog/2017/08/visualizations-with-d3-js/\n\t- [PykCharts.js](https://github.com/pykih/PykCharts.js)\n\t- [dc.js](https://dc-js.github.io/dc.js/)\n- #CODE [deck.gl (Uber) - deck.gl is a WebGL-powered framework for visual exploratory data analysis of large datasets](https://eng.uber.com/deck-gl-framework/)\n- #CODE [Visdom (Facebook) - A flexible tool for creating, organizing, and sharing visualizations of live, rich data. Supports Torch and Numpy](https://github.com/facebookresearch/visdom)\n- #CODE [Vega](https://github.com/vega/vega)\n\t- https://github.com/vega/vega-lite\n\t- https://github.com/vega/voyager\n\t- https://github.com/vega/lyra\n- #CODE [Altair](https://altair-viz.github.io/)\n\t- #TALK [Jake VanderPlas - Exploratory Data Visualization with Vega, Vega-Lite, and Altair - PyCon 2018](https://www.youtube.com/watch?v=ms29ZPUKxbU)\n- #CODE [Bqplot (Bloomberg) - Plotting library for IPython/Jupyter Notebooks](https://github.com/bloomberg/bqplot)\n\t- #TALK [PyData Ann Arbor: Dhruv Madeka | Interactive Data Visualization in Jupyter Notebook Using bqplot](https://www.youtube.com/watch?v=wJS4S0WB4Jw)\n- #CODE [Chartify (Spotify)](https://github.com/spotify/chartify/)\n\t- https://labs.spotify.com/2018/11/15/introducing-chartify-easier-chart-creation-in-python-for-data-scientists/\n\t- Chartify is a Python library that makes it easy for data scientists to create charts.\n- #CODE [ggplot2 (for R)](http://ggplot2.org/)\n- Graphs, networks:\n\t- #CODE [NetworkX](https://networkx.github.io/)\n\t- #CODE [Gephi](https://gephi.org/)\n\t- #CODE [Graph-tool](https://graph-tool.skewed.de/)\n\t- #CODE [igraph](http://igraph.org/)\n\t- #CODE [Graphviz](http://www.graphviz.org/)\n- Dashboards (webapps):\n\t- #CODE [Dash - Interactive, reactive web apps in pure python](https://plot.ly/products/dash)\n\t\t- https://medium.com/@plotlygraphs/introducing-dash-5ecf7191b503\n\t\t- #TALK [Dash - A New Framework for Building User Interfaces for Technical Computing | SciPy 2017 | Chris Par](https://www.youtube.com/watch?v=sea2K4AuPOk)\n\t- #CODE [Redash](https://redash.io/)\n\t- #CODE Superset:  http://airbnb.io/projects/superset/\n\t\t- https://medium.com/airbnb-engineering/caravel-airbnb-s-data-exploration-platform-15a72aa610e5\n\t\t- https://indatalabs.com/blog/data-strategy/open-source-data-visualization-tool-superset\n\t- #CODE Shiny (for R)\n\t\t- https://shiny.rstudio.com/\n\t\t- http://www.htmlwidgets.org/\n\t- #CODE Pyxley - Python helpers for building dashboards using Flask and React: \n\t\t- https://github.com/stitchfix/pyxley\n\t\t- http://multithreaded.stitchfix.com/blog/2015/07/16/pyxley/\n\t- #CODE [Spyre](https://github.com/adamhajari/spyre)\n\t- #CODE [Bowtie](http://bowtie-py.readthedocs.io/en/latest/)\n\t- #CODE [Stackimpact-python](https://stackimpact.com)\n- #CODE [PyViz](https://github.com/pyviz)\n\t- [HoloViews](https://holoviews.org/)\n\t- [Panel](https://panel.pyviz.org/)\n\t- [Datashader](http://datashader.org)\n\t - [GeoViews](http://geoviews.org/ )\n\t - [Hvplot](https://hvplot.pyviz.org/)\n- #CODE [Ipyvolume](https://ipyvolume.readthedocs.io/en/latest/)\n- #CODE [Vaex](https://vaex.io/)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/DS-and-DataEng/Xarray":{"title":"Xarray","content":"\u003e See: \n\u003e - [[AI/DS and DataEng/Dask]]\n\u003e - [[AI4ES/Pangeo]]\n\n## Code\n- #CODE [Xarray - N-D labeled arrays and datasets in Python](https://github.com/pydata/xarray)\n\t- #PAPER [Xarray - N-D labeled Arrays and Datasets in Python (Hoyer 2017)](https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/)\n\t- http://xarray.pydata.org/en/stable/why-xarray.html\n\t- [Breaking up arrays up into chunks for fun and science with Xarray and Dask](https://www.youtube.com/watch?v=0dO-iC16xUo)\n- #CODE [Xarray-spatial](https://github.com/makepath/xarray-spatial)\n\t- Raster-based Spatial Analytics for Python\n\t- https://xarray-spatial.org/\n- #CODE [rioxarray](https://github.com/corteva/rioxarray)\n\t- geospatial xarray extension powered by rasterio","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Autoencoders":{"title":"Autoencoders","content":"\u003e An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). The encoding is validated and refined by attempting to regenerate the input from the encoding. The autoencoder learns a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore insignificant data (“noise”)\n\n## Resources\n- https://en.wikipedia.org/wiki/Autoencoder\n- [Dimensionality Reduction](https://www.cs.toronto.edu/~hinton/science.pdf)\n- The classical approach for unsupervised learning using neural networks. The basic version consists of a Multilayer Perceptron (MLP) where the input and output layer have the same size and a smaller hidden layer is trained to recover the input. Once trained, the output from the hidden layer corresponds to data representation that can be useful for clustering, dimensionality reduction, improving supervised classification and even for data compression.\n- https://blog.keras.io/building-autoencoders-in-keras.html\n- https://blog.insightdatascience.com/isee-removing-eyeglasses-from-faces-using-deep-learning-d4e7d935376f\n- https://github.com/nanopony/keras-convautoencoder\n- [Meta’s AI Takes an Unsupervised Step Forward](https://spectrum.ieee.org/unsupervised-learning-meta)\n\n### VAEs\n- Variational autoencoders are generative models. Traditional autoencoders that just do reconstruction don’t have an obvious generative interpretation. There are some cases in between, like denoising autoencoders, where it is possible to construct a Markov chain that uses the autoencoder to sample from the data distribution, but the autoencoder doesn’t give direct explicit access to an estimate of the density or the ability to sample directly.\n- VAE is a type of autoencoder with added constraints on the encoded representations being learned. More precisely, it is an autoencoder that learns a latent variable model for its input data. So instead of letting your neural network learn an arbitrary function, you are learning the parameters of a probability distribution modeling your data. If you sample points from this distribution, you can generate new input data samples: a VAE is a \"generative model\".\n- [Introduction to deep generative modeling: Variational Auto-Encoders](https://jmtomczak.github.io/blog/4/4_VAE.html)\n- [Introduction to deep generative modeling: Priors in VAEs](https://jmtomczak.github.io/blog/7/7_priors.html)\n- [Introduction to deep generative modeling: Hierarchical VAEs](https://jmtomczak.github.io/blog/9/9_hierarchical_lvm_p1.html)\n- [Variational Autoencoders Explained](http://kvfrans.com/variational-autoencoders-explained/)\n- [Intuitively understanding VAEs](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)\n- [An Intuitive Comparison of Autoencoders with Variational Autoencoders](https://thilospinner.com/towards-an-interpretable-latent-space/)\n- http://blog.fastforwardlabs.com/post/148842796218/introducing-variational-autoencoders-in-prose-and\n- [Variational Autoencoders (youtube)](https://www.youtube.com/watch?v=9zKuYvjFFS8)\n- [From Autoencoder to Beta-VAE](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)\n\n\n## Code\n- #CODE [benchmark_VAE](https://github.com/clementchadebec/benchmark_VAE)\n\t- This library implements some of the most common (Variational) Autoencoder models\n\t- https://pythae.readthedocs.io/en/latest/\n\t- #PAPER [Pythae: Unifying Generative Autoencoders in Python -- A Benchmarking Use  Case (Chadebec 2022)](https://arxiv.org/pdf/2206.08309v1)\n\n\n## References\n- #PAPER [Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion (Vincent 2010)](https://www.jmlr.org/papers/v11/vincent10a.html)\n- #PAPER [Adversarial Autoencoders with Constant-Curvature Latent Manifolds (Grattarola 2018)](https://arxiv.org/abs/1812.04314)\n- #PAPER [Image-To-Image Translation Using a Cross-Domain Auto-Encoder and Decoder (Yoo 2019)](https://www.mdpi.com/2076-3417/9/22/4780/htm )\n\t- Early image-to-image translation methods used convolutional neural networks (CNN), which learn to minimize the loss of a pixel value between the source domain image and the target domain image but had the limitation of failing to produce more photorealistic images \n\t- Unlike other approaches… our method is not limited to a specific task, nor do we rely on predefined relationships between the source and target domains. Our method can be applied to make a general-domain solution for many image-to-image translation tasks. \n\n### Variational Autoencoders (VAE)\n- #PAPER [Auto-Encoding Variational Bayes (Kingma 2014)](https://arxiv.org/abs/1312.6114)\n- #PAPER [An Introduction to Variational Autoencoders (Kingma 2019)](https://arxiv.org/abs/1906.02691)\n- #PAPER [NVAE: A Deep Hierarchical Variational Autoencoder (Vahdat 2020)](https://arxiv.org/abs/2007.03898)\n\t- [Paper explained](https://www.youtube.com/watch?v=x6T1zMSE4Ts)\n- #PAPER [Deep Attentive Variational Inference (Apostolopoulou 2022)](https://blog.ml.cmu.edu/2022/05/27/deep-attentive-variational-inference/)\n\n### Masked Autoencoders (MAE)\n- #PAPER [Masked Autoencoders Are Scalable Vision Learners (He 2021)](https://arxiv.org/abs/2111.06377)\n\t- #CODE https://github.com/facebookresearch/mae\n\t- #CODE https://github.com/ariG23498/mae-scalable-vision-learners\n\t- https://keras.io/examples/vision/masked_image_modeling/\n\t- Masked autoencoder (MAE) is a simple autoencoding approach that reconstructs the original signal given its partial observation\n\t- [Paper explained](https://www.youtube.com/watch?v=Dp6iICL2dVI)\n\t- See [[AI/Deep learning/Transformers]]\n- #PAPER [Masked Autoencoders As Spatiotemporal Learners (Feichtenhofer 2022)](https://arxiv.org/pdf/2205.09113)\n- #PAPER [Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality (Li 2022)](https://arxiv.org/abs/2205.10063v1)\n\t- #CODE https://github.com/implus/um-mae\n- #PAPER [ConvMAE: Masked Convolution Meets Masked Autoencoders (Gao 2022)](https://arxiv.org/pdf/2205.03892v2)            \n\t- #CODE https://github.com/Alpha-VL/ConvMAE\n- #PAPER [Masked Autoencoders that Listen (Huang 2022)](https://arxiv.org/pdf/2207.06405v1)\n\t- #CODE https://github.com/facebookresearch/AudioMAE","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/CNNs":{"title":"Convolutional Neural Networks (CNNs)","content":"\u003e A convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks, based on their shared-weights architecture and translation invariance characteristics\n\n## Resources \n- https://github.com/kjw0612/awesome-deep-vision\n- https://en.wikipedia.org/wiki/Convolutional_neural_network\n- [CNNs chapter in d2l.ai](https://d2l.ai/chapter_convolutional-neural-networks/index.html)\n- [Convolutional Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)\n- http://cs231n.github.io/convolutional-networks/\n- http://cs231n.github.io/understanding-cnn/\n- https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/\n* [Best deep CNN architectures and their principles: from AlexNet to EfficientNet](https://theaisummer.com/cnn-architectures/)\n\n### Convolutions\n- [Understanding convolutions](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)\n- [An Introduction to different Types of Convolutions in DL](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d)\n- https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215\n- https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d\n- [Depthwise separable convolution](https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728)\n- https://stackoverflow.com/questions/42883547/intuitive-understanding-of-1d-2d-and-3d-convolutions-in-convolutional-neural-n \n- https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807\n- [Convolutions Over Volumes (channels)](https://www.youtube.com/watch?v=KTB_OFoAQcc )\n\n### 1x1 convolutions\n- 1x1 convolutions: https://d2l.ai/chapter_convolutional-neural-networks/channels.html#times-1-convolutional-layer\n- [1x1 convolutions](https://www.youtube.com/watch?v=qVP574skyuM)\n- [Networks in Networks and 1x1 Convolutions](https://www.youtube.com/watch?v=vcp0XvDAX68)\n- https://iamaaditya.github.io/2016/03/one-by-one-convolution/\n- https://towardsdatascience.com/1x1-convolution-5219bbc09027\n- https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578\n- https://machinelearningmastery.com/introduction-to-1x1-convolutions-to-reduce-the-complexity-of-convolutional-neural-networks/\n\t- A convolutional layer with a 1×1 filter is used at any point in a CNN to control the number of feature maps. It's often referred to as a projection operation or projection layer, or even a feature map or channel pooling layer\n\n### Human pose estimation and activity recognition\n- https://en.wikipedia.org/wiki/Activity_recognition\n- https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/\n- https://github.com/cbsudux/awesome-human-pose-estimation\n- https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/\n\n\n## Code \n- #CODE [Modern Convolutional Neural Network Architectures](https://github.com/Nyandwi/ModernConvNets)\n- #CODE [Keras Layers (for TensorFlow 2.x)](https://github.com/mvoelk/keras_layers)\n- #CODE [Model Zoo - Discover open source deep learning code and pretrained models](https://modelzoo.co/)\n- #CODE https://github.com/microsoft/computervision-recipes\n\n\n### Channel/visual attention\n- #CODE [Visual-attention-tf](https://github.com/vinayak19th/Visual_attention_tf) ^tfvisualattention\n\t- Pixel Attention\n\t- Channel Attention (CBAM)\n\t- Efficient Channel Attention\n- #CODE [Convolution Variants](https://github.com/JinLi711/Convolution_Variants) ^kerasconvvariants\n\t- Attention Augmented (AA) Convolution Layer\n\t- Mixed Depthwise Convolution Layer\n\t- Drop Block\n\t- Efficient Channel Attention (ECA) Layer\n\t- Convolutional Block Attention Module (CBAM) Layer\n\n\n## References\n- #PAPER [A guide to convolution arithmetic for deep learning (Dumoulin, 2016)](https://arxiv.org/abs/1603.07285)\n\t- #CODE https://github.com/vdumoulin/conv_arithmetic\n- #PAPER [Xception: Deep Learning with Depthwise Separable Convolutions (Chollet 2017)](https://arxiv.org/abs/1610.02357)\n- #PAPER [Deformable Convolutional Networks (Dai 2017)](https://arxiv.org/pdf/1703.06211)\n- #PAPER [Deformable ConvNets v2: More Deformable, Better Results (Zhu 2018)](https://arxiv.org/pdf/1811.11168)\n- #PAPER [3D Depthwise Convolution: Reducing Model Parameters in 3D Vision Tasks (Ye 2018)](https://arxiv.org/abs/1808.01556)\n- #PAPER [Making Convolutional Networks Shift-Invariant Again (Zhang 2019)](https://arxiv.org/pdf/1904.11486v2)\n- #PAPER [A Survey of the Recent Architectures of Deep Convolutional Neural Networks (Khan 2020)](https://arxiv.org/abs/1901.06032v7)\n- #PAPER [Revisiting Spatial Invariance with Low-Rank Local Connectivity (Elsayed 2020)](https://arxiv.org/abs/2002.02959)\n\t- #CODE https://github.com/google-research/google-research/tree/master/low_rank_local_connectivity\n- #THESIS/PHD [Multi-modal Medical Image Processing with Applications in HybridX-ray/Magnetic Resonance Imaging (Stimpel 2021)](https://opus4.kobv.de/opus4-fau/frontdoor/deliver/index/docId/15697/file/Dissertation_Bernhard_Stimpel.pdf)\n- #PAPER [Learning to Resize Images for Computer Vision Tasks (Talebi 2021)](https://arxiv.org/pdf/2103.09950v2)            \n\t- #CODE https://keras.io/examples/vision/learnable_resizer/\n- #PAPER [Non-deep Networks (Goyal 2021)](https://arxiv.org/abs/2110.07641)\n\t- #CODE https://paperswithcode.com/paper/non-deep-networks-1?from=n19\n\t- use parallel subnetworks instead of stacking one layer after another. This helps effectively reduce depth while maintaining high performance\n* #PAPER [ConvNext: A ConvNet for the 2020s (Liu 2022)](https://arxiv.org/abs/2201.03545) ^convnext\n\t* #CODE https://github.com/facebookresearch/ConvNeXt\n\t* #CODE https://github.com/bamps53/convnext-tf/\n\t* #CODE https://github.com/sayakpaul/ConvNeXt-TF\n\t* Paper explained: \n\t\t* https://www.youtube.com/watch?v=WvKsMI4Iemk\u0026t=330s\n\t\t* https://www.youtube.com/watch?v=idiIllIQOfU\u0026list=WL\u0026index=55\n\t\t* https://www.youtube.com/watch?v=QqejV0LNDHA\n\t* https://twitter.com/papers_daily/status/1481937771732566021\n\t* ConvNeXt essentially takes a ResNet and gradually \"modernizes\" it to discover components that contribute to performance gains. ConvNeXt applies several tricks like larger kernels, layer norm, fewer activation functions, separate downsampling layers to name a few. \n\t* These results show that hybrid models are promising and that different components can still be optimized further and composed more effectively to improve the overall model on a wide range of vision tasks.\n- #PAPER [Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs (Ding 2022)](https://arxiv.org/pdf/2203.06717v3)            \n\t- #CODE https://paperswithcode.com/paper/scaling-up-your-kernels-to-31x31-revisiting\n- #PAPER [More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using  Sparsity (Liu 2022)](https://arxiv.org/pdf/2207.03620v1)\n\t- #CODE https://github.com/vita-group/slak\n\t- explore the possibility of training extreme convolutions larger than 31×31 and test whether the performance gap can be eliminated by strategically enlarging convolutions\n\t- propose Sparse Large Kernel Network (SLaK), a pure CNN architecture equipped with 51×51 kernels that can perform on par with or better than state-of-the-art hierarchical Transformers and modern ConvNet architectures like ConvNeXt and RepLKNet, on ImageNet classification as well as typical downstream tasks\n\n### Sequence (time series) modelling\n- #PAPER [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling (Bai 2018)](https://arxiv.org/abs/1803.01271)\n  - Temporal convolutional networks (TCN)\n  - #CODE https://github.com/philipperemy/keras-tcn\n  - [Implementing Temporal Convolutional Networks](https://medium.com/the-artificial-impostor/notes-understanding-tensorflow-part-3-7f6633fcc7c7)\n\t  - The most important component of TCNs is dilated causal convolution. “Causal” simply means a filter at time step t can only see inputs that are no later than t. The point of using dilated convolution is to achieve larger receptive field with fewer parameters and fewer layers. \n\t  - A residual block stacks two dilated causal convolution layers together, and the results from the final convolution are added back to the inputs to obtain the outputs of the block. \n  - [Temporal convolutional networks for sequence modeling](https://dida.do/blog/temporal-convolutional-networks-for-sequence-modeling)\n- #PAPER [Convolutions Are All You Need (For Classifying Character Sequences) (Wood-doughty 2018)](https://www.aclweb.org/anthology/W18-6127/)\n- #PAPER [InceptionTime: Finding AlexNet for time series classification (Fawaz 2021)](https://link.springer.com/article/10.1007/s10618-020-00710-y)\n\t- #CODE https://github.com/hfawaz/InceptionTime\n\t- https://arxiv.org/abs/1909.04939\n\n### Object classification, image recognition\nSee [[AI/Computer Vision/Object classification, image recognition]]\n\n### Semantic segmentation\nSee [[AI/Computer Vision/Semantic segmentation]]\n\n### Object detection\nSee [[AI/Computer Vision/Object detection]]\n\n### Video segmentation and prediction\nSee [[AI/Computer Vision/Video segmentation and prediction]]\n\n### Image and video captioning\nSee [[AI/Computer Vision/Image and video captioning]]\n\n### Image-to-image translation\nSee [[AI/Computer Vision/Image-to-image translation]]\n\n### Super-resolution \nSee \"CNN-based\" section in [[AI/Computer Vision/Super-resolution]]\n\n### Inpainting\nSee \"CNN-based\" section in [[AI/Computer Vision/Inpainting and restoration]]\n\n### Background subtraction, foreground detection\nSee \"CNN-based\" section in [[AI/Computer Vision/Background subtraction]]\n\n### Edge detection\n- #PAPER [DeepEdge: A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection](http://arxiv.org/pdf/1412.1123)\n- #PAPER [DeepContour: A Deep Convolutional Feature Learned by Positive-Sharing Loss for Contour Detection](http://mc.eistar.net/UpLoadFiles/Papers/DeepContour_cvpr15.pdf)\n\n### Human pose estimation and activity recognition\n- #PAPER [Human activity recognition with smartphone sensors using deep learning neural networks (Ann Ronao 2016)](https://www.sciencedirect.com/science/article/abs/pii/S0957417416302056)\n- #PAPER [Convolutional pose machines (Wei 2016)](https://arxiv.org/abs/1602.00134)\n- #PAPER [Fast Human Pose Estimation (Zhang 2019)](https://arxiv.org/abs/1811.05419)\n\n### Motion detection, tracking\n- #PAPER [FlowNet: Learning Optical Flow with Convolutional Networks (Fischer 2015)](https://arxiv.org/abs/1504.06852)\n\n### Deconvolution\n- #PAPER [Deep Convolutional Neural Network for Image Deconvolution (Xu 2014)](http://lxu.me/projects/dcnn/)\n\n### Visual/Channel attention and Saliency\nSee \"Neural Networks explainability\" section in [[AI/XAI]]\n - #PAPER [Squeeze-and-Excitation Networks, SENets (Hu 2017)](https://arxiv.org/abs/1709.01507) ^senets\n\t- Features can incorporate global context\n\t- Since SENet only revolves around providing channel attention by using dedicated global feature descriptors, which in this case is Global Average Pooling (GAP), there is a loss of information and the attention provided is point-wise. This means that all pixels are mapped in the spatial domain of a feature map uniformly, and thus not discriminating between important or class-deterministic pixels versus those which are part of the background or not containing useful information.\n\t- Thus, the importance/need for spatial attention is justified to be coupled with channel attention. One of the prime examples of the same is CBAM (published at ECCV 2018) \n\t- #CODE https://github.com/hujie-frank/SENet\n\t- #CODE https://github.com/yoheikikuta/senet-keras\n\t- https://blog.paperspace.com/channel-attention-squeeze-and-excitation-networks/\n\t- https://programmerclick.com/article/4934219785/\n\t- https://pyimagesearch.com/2022/05/30/attending-to-channels-using-keras-and-tensorflow/\n - #PAPER [CBAM: Convolutional Block Attention Module (Woo 2018)](https://arxiv.org/abs/1807.06521) ^cbam\n\t - #CODE https://kobiso.github.io//research/research-CBAM/\n\t - https://medium.com/visionwizard/understanding-attention-modules-cbam-and-bam-a-quick-read-ca8678d1c671\n\t - https://blog.paperspace.com/attention-mechanisms-in-computer-vision-cbam/\n- #PAPER [ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks (Wang 2020)](https://arxiv.org/abs/1910.03151)\n\t- this paper proposes an Efficient Channel Attention (ECA) module, which only involves a handful of parameters while bringing clear performance gain\n\t- proposed a local cross-channel interaction strategy without dimensionality reduction, which can be efficiently implemented via 1D convolution\n- #PAPER See ^srwithpixelattention in [Super-resolution](AI/Computer%20Vision/Super-resolution.md)\n- #PAPER [Attention Mechanisms in Computer Vision: A Survey (Guo 2021)](https://arxiv.org/abs/2111.07624v1)\n\t- https://github.com/MenghaoGuo/Awesome-Vision-Attentions\n- #PAPER [Visual Attention Network (Guo 2022)](https://arxiv.org/abs/2202.09741)\n\t- #CODE https://paperswithcode.com/paper/visual-attention-network?from=n26\n\t- This work presents an approach that decomposes a large kernel convolution operation to capture long-range relationship. After obtaining long-range relationship, it estimates the importance of a point and generates attention map\n- #PAPER [Attention Map-Guided Visual Explanations for Deep Neural Networks (An 2022)](https://www.mdpi.com/2076-3417/12/8/3846/htm)\n\t- attention-map-guided visual explanations for deep neural networks, employing an attention mechanism to find the most important region of an input image\n\t- The Grad-CAM method is used to extract the feature map for deep neural networks, and then the attention mechanism is used to extract the high-level attention maps\n\t- Inspired in CBAM technique","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/CapsNets":{"title":"Capsule Neural networks (CapsNets)","content":"\u003e A Capsule Neural Network (CapsNet) is a machine learning system that is a type of artificial neural network (ANN) that can be used to better model hierarchical relationships. The approach is an attempt to more closely mimic biological neural organization\n\n## Resources\n- https://en.wikipedia.org/wiki/Capsule_neural_network.\n- The main failure of CNNs is that they do not carry any information about the relative relationships between features (CNNs since they are based on the convolution operation applied to scalar values).\n- Capsules introduce a new building block that can be used in deep learning to better model relationships inside the network. The key to this richer feature representation is the use of vectors rather than scalars.\n- A capsule is an abstract idea of having a group of neurons with an activity vector that contains more information about the object. There are many ways to implement this. Hinton et al chose one particular way to implement this, which allows using “dynamic routing”. \n- https://towardsdatascience.com/a-simple-and-intuitive-explanation-of-hintons-capsule-networks-b59792ad46b1\n- https://towardsdatascience.com/capsule-neural-networks-are-here-to-finally-recognize-spatial-relationships-693b7c99b12\n- https://towardsdatascience.com/capsule-neural-networks-part-2-what-is-a-capsule-846d5418929f\n- https://www.freecodecamp.org/news/understanding-capsule-networks-ais-alluring-new-architecture-bdb228173ddc/\n\n## References\n- #PAPER [Dynamic Routing Between Capsules (Sabour 2017)](https://arxiv.org/abs/1710.09829)\n\t- #CODE https://github.com/XifengGuo/CapsNet-Keras\n- #PAPER [Capsule Networks – A survey (Mensah 2019)](https://www.sciencedirect.com/science/article/pii/S1319157819309322)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/DL":{"title":"Deep Learning (DL)","content":"\u003e Deep learning (DL), also known as deep structured learning, is part of a broader family of [[AI/Machine Learning]] methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised. DL uses huge neural networks with many layers of processing units, taking advantage of advances in computing power and improved training techniques to learn complex patterns in large amounts of data\n\n## Resources\n- https://github.com/ChristosChristofidis/awesome-deep-learning\n- https://github.com/endymecy/awesome-deeplearning-resources\n- https://en.wikipedia.org/wiki/Deep_learning\n- [Deep Learning Curriculum](https://github.com/jacobhilton/deep_learning_curriculum)\n- https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/\n- [A Quick Introduction to Neural Networks](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)\n- [Deep Neural Nets: 33 years ago and 33 years from now (Andrej Karpathy)](http://karpathy.github.io/2022/03/14/lecun1989/)\n- [Deep learning's diminish returns (Thompson)](https://spectrum.ieee.org/deep-learning-computational-cost)\n\t- https://towardsdatascience.com/the-future-of-deep-learning-7e8574ad6ae3\n- [Deep Learning Is Hitting a Wall](https://nautil.us/deep-learning-is-hitting-a-wall-14467/)\n- [A Brief History of Neural Nets and Deep Learning (2020)](http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/)\n- [Time Benchmark of models](https://dawn.cs.stanford.edu/benchmark/)\n- [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)\n- [Computer Scientists Prove Why Bigger Neural Networks Do Better](https://www.quantamagazine.org/computer-scientists-prove-why-bigger-neural-networks-do-better-20220210/)\n- [No, We Don't Have to Choose Batch Sizes As Powers Of 2](https://sebastianraschka.com/blog/2022/batch-size-2.html)\n\t- https://www.youtube.com/watch?v=81ES7IguZo4\n\n### DL news aggregators\n- [DeepAI](https://deepai.org/)\n- [Papers with code](https://paperswithcode.com/)\n- [Deep learning monitor](https://deeplearn.org/)\n\n### Cheatsheets\n- https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/super-cheatsheet-deep-learning.pdf\n\n### When to use and not to use deep learning\n- [When and When Not to Use Deep Learning](https://blog.dataiku.com/when-and-when-not-to-use-deep-learning)\n- [You can probably use deep learning even if your data isn't that big](http://beamandrew.github.io/deeplearning/2017/06/04/deep_learning_works.html)\n- [When not to use deep learning](http://hyperparameter.space/blog/when-not-to-use-deep-learning/)\n- [Using ANNs on small data – Deep Learning vs. Xgboost](http://maxberggren.se/2017/06/18/deep-learning-vs-xgboost/)\n- [The limitations of deep learning](https://blog.keras.io/the-limitations-of-deep-learning.html)\n\n\n## Books\n- #BOOK [Deep Learning with R, 2nd Edition (Kalinowski 2022)](https://blogs.rstudio.com/ai/posts/2022-05-31-deep-learning-with-r-2e/)\n- #BOOK [Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI (Kashani 2022)](https://arxiv.org/abs/2201.00650)\n- #BOOK [Physics-based Deep Learning Book (Thuerey 2021)](https://physicsbaseddeeplearning.org/intro.html) ^PBDL\n- #BOOK [The Principles of DL Theory: An Effective Theory Approach to Understanding Neural Networks (Roberts 2022)](https://deeplearningtheory.com/PDLT.pdf)\n\t- https://ai.facebook.com/blog/advancing-ai-theory-with-a-first-principles-understanding-of-deep-neural-networks/\n\t- #PAPER [The Principles of Deep Learning Theory (Roberts 2021)](https://arxiv.org/abs/2106.10165)\n\t- [Paper explained](https://www.youtube.com/watch?v=m2bXL5Z5CBM)\n- #BOOK [Deep Learning Book (Goodfellow, 2016 MIT)](https://www.deeplearningbook.org/)\n\t- The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular\n- #BOOK [DL tutorial (LISA Lab, U Montreal)](http://deeplearning.net/tutorial/)\n- #BOOK [Deep Learning with Python (Chollet, 2021 MANNING)](https://www.manning.com/books/deep-learning-with-python-second-edition)\n\t- [1st edition](http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf)\n- #BOOK [Machine learning yearning (Andrew Ng, 2018)](https://freecomputerbooks.com/Machine-Learning-Yearning.html)\n\t- https://github.com/ajaymache/machine-learning-yearning\n- #BOOK [Dive into Deep Learning (Zhang)](https://d2l.ai/index.html)\n\t- An interactive deep learning book for students, engineers, and researchers. Uses MXNet/Gluon, Pytorch and Tensorflow\n\t- [Jupyter notebooks for each section](https://en.d2l.ai/d2l-en.zip)\n- #BOOK [Introduccion practica con Keras (Torres 2018)](https://torres.ai/deep-learning-inteligencia-artificial-keras/)\n- #BOOK [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html)\n\n\n## Talks\n- #TALK [The Future of Sparsity in Deep Learning (Trevor Gale, Phd student Stanford, 2021)](https://events.rainfocus.com/widget/nvidia/nvidiagtc/sessioncatalog/session/1631029840983001jvzq)\n- #TALK Deep Learning (Yoshua Bengio, MLSS 2020): \n\t- [Part I](https://www.youtube.com/watch?v=c_U4THknoHE)\n\t- [Part II](https://www.youtube.com/watch?v=PDPdIDihPvc)\n- #TALK [Deep Learning Hardware: Past, Present, and Future (Yann LeCun, ISSCC 2019)](https://www.youtube.com/watch?v=YzD7Z2yRL7Y)\n- #TALK [Keras, Deep Learning, and the Progress of AI (François Chollet, Lex Fridman Podcast, 2019)](https://www.youtube.com/watch?v=Bo8MY4JpiXE)\n- #TALK [Deep Learning and the Future of Artificial Intelligence (Yann LeCun, 2018)](https://www.youtube.com/watch?v=RM-Jtc2ryfM\u0026t=5s)\n- #TALK [AI Breakthroughs \u0026 Obstacles to Progress, Mathematical and Otherwise (Yann LeCun, 2018)](https://www.youtube.com/watch?v=1_KhJv0Em5Y)\n- #TALK [François Chollet at France is AI 2017: Deep Learning: current limits and future perspectives (Chollet 2017)](https://www.youtube.com/watch?v=MUF32XHqM34 )\n- #TALK [Power \u0026 Limits of Deep Learning (Yann Lecun, 2017)](https://www.youtube.com/watch?v=0tEhw5t6rhc)\n- #TALK [The Deep End of Deep Learning (Hugo Larochelle, TEDxBoston 2016)](https://www.youtube.com/watch?v=dz_jeuWx3j0)\n- #TALK [How deep neural networks work (Brandon Rohrer)](https://www.youtube.com/watch?v=ILsA4nyG7I0)\n\t- Simple explanations of DL basics and nice graphics\n\n\n## Courses\n- #COURSE [Introduction to Deep Learning (COMP0090, UCL)](https://github.com/YipengHu/COMP0090 )\n- #COURSE [Full Stack Deep Learning](https://fullstackdeeplearning.com/)\n\t- [Full Stack Deep Learning - Spring 2021](https://fullstackdeeplearning.com/spring2021/)\n\t\t- [Lecture 13: ML Teams and Startups](https://fullstackdeeplearning.com/spring2021/lecture-13/)\n\t- https://fall2019.fullstackdeeplearning.com/\n\t\t- https://github.com/full-stack-deep-learning/course-gitbook\n- #COURSE [Deep Learning (NYU)](https://atcold.github.io/pytorch-Deep-Learning/)\n\t- https://github.com/Atcold/pytorch-Deep-Learning (pytorch)\n- #COURSE [Deep Learning (CS230, Stanford)](http://cs230.stanford.edu/)\n\t- [Cheatsheets](https://github.com/afshinea/stanford-cs-230-deep-learning)\n- #COURSE [Tensorflow for Deep Learning Research (CS20SI, Stanford)](http://web.stanford.edu/class/cs20si/syllabus.html)\n- #COURSE [DeepMind x UCL | Deep Learning Lecture Series 2020](https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF)\n- #COURSE [Introduction to Deep Learning (6.S191, MIT)](http://introtodeeplearning.com/)\n\t- [MIT Introduction to Deep Learning | 6.S191 | 2022](https://www.youtube.com/watch?v=7sB052Pz0sQ)\n- #COURSE [MIT Deep Learning and Artificial Intelligence Lectures](https://deeplearning.mit.edu/)\n\t- [Youtube playlist](https://www.youtube.com/watch?v=0VH1Lim8gL8\u0026list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)\n\t- [Deep Learning State of the Art (2020)](https://www.youtube.com/watch?v=0VH1Lim8gL8)\n- #COURSE [Introduction to Deep Learning (MIT 6.S191)](http://introtodeeplearning.com/)\n- #COURSE [Intro to Neural Networks and Machine Learning (CSC 321, UToronto)](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/)\n- #COURSE [Deep Learning nanodegree (Udacity)](https://www.udacity.com/course/deep-learning-nanodegree--nd101)\n\t- https://github.com/udacity/deep-learning-v2-pytorch\n\t- https://www.udacity.com/course/deep-learning-pytorch--ud188\n- #COURSE [Deep Learning with PyTorch: Zero to GANs (Jovian)](https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans)\n- #COURSE [Fast AI - Practical Deep Learning For Coders](http://course.fast.ai/)\n\t- Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD - the book and the course\n\t- https://github.com/fastai/fastbook\n- #COURSE [CS 152: Neural Networks (Harvey Mudd college)](https://www.cs.hmc.edu/~rhodes/cs152/index.html)\n- #COURSE [Deep Learning course (U Paris-Saclay)](https://m2dsupsdlclass.github.io/lectures-labs/)\n- #COURSE [Introduction to Machine Learning and Neural Networks (Uniandes)](https://albahnsen.com/courses/applied-deep-learning/)\n\t- https://github.com/albahnsen/AppliedDeepLearningClass\n- #COURSE [Deep learning specialization (deeplearning.ai, Coursera, Andrew Ng)](https://www.coursera.org/specializations/deep-learning)\n\t- https://www.deeplearning.ai/deep-learning-specialization/\n- #COURSE [Neural Networks (U Sherbrooke)](http://info.usherbrooke.ca/hlarochelle/neural_networks/description.html)\n- #COURSE [The Neural Aesthetic (ITP-NYU)](http://ml4a.github.io/classes/itp-F18/)\n\n\n## Code\nState of ML frameworks: \n- https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/\n- https://towardsdatascience.com/tensorflow-or-pytorch-146f5397278a\n\n- #CODE [Tensorflow, keras](AI/DS%20and%20DataEng/Tensorflow,%20keras.md)\n- #CODE [Pytorch](AI/DS%20and%20DataEng/Pytorch.md)\n- #CODE [Ivy](https://github.com/unifyai/ivy)\n\t- The unified machine learning framework, enabling framework-agnostic functions, layers and libraries\n\t- [lets-unify.ai](https://lets-unify.ai/ \"https://lets-unify.ai\")\n\t- #PAPER [Ivy: Templated Deep Learning for Inter-Framework Portability (Lenton 2021)](https://arxiv.org/abs/2102.02886)\n\t- https://medium.com/@unifyai/why-unify-21b502f2015e\n\t- https://medium.com/@unifyai/standardization-7726c5113e4\n- #CODE [Huggingface](https://huggingface.co/)\n\t- Build, train and deploy state of the art models powered by the reference open source in ML\n\t- [Datasets](https://github.com/huggingface/datasets)\n\t- [Datasets-viewer](https://github.com/huggingface/datasets-viewer)\n\t\t- https://huggingface.co/datasets/viewer/\n\t- [Transformers](https://github.com/huggingface/transformers)\n- #CODE [Triton](https://github.com/openai/triton)\n\t- language and compiler for writing highly efficient custom Deep-Learning primitives\n\t- https://openai.com/blog/triton/\n\t- https://www.infoq.com/news/2021/08/openAI-triton/\n\t- Triton uses Python as its base. The developer writes code in Python using Triton’s libraries, which are then JIT-compiled to run on the GPU. This allows integration with the rest of the Python ecosystem, currently the biggest destination for developing machine-learning solutions\n- #CODE [Oneflow](https://github.com/Oneflow-Inc/oneflow)\n\t- OneFlow is a performance-centered and open-source deep learning framework\n\t- http://www.oneflow.org/\n- #CODE [MindSpore (Huawei)](https://github.com/mindspore-ai/mindspore) ^huaweimindpore\n\t- https://towardsdatascience.com/program-your-first-neural-network-with-huawei-mindspore-1fc50023e90d\n\t- https://towardsdatascience.com/huaweis-mindspore-a-new-competitor-for-tensorflow-and-pytorch-d319deff2aec\n\t- https://www.mindspore.cn/en\n- #CODE [Tensorlayer - Deep Learning and Reinforcement Learning Library for Scientists and Engineers](https://github.com/tensorlayer/tensorlayer)\n\t- http://tensorlayer.org/\n- #CODE [Elegy - Neural Networks framework based on Jax and inspired by Keras](https://github.com/poets-ai/elegy)\n\t- https://poets-ai.github.io/elegy/\n\t- See [Mathematical Optimization](AI/Math%20and%20Statistics/Mathematical%20Optimization.md) JAX\n- #CODE [Paddle (Baidu)](https://github.com/PaddlePaddle/Paddle)\n\t- http://www.paddlepaddle.org/\n\t- PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice\n- #CODE [Mxnet (Apache)](https://github.com/apache/incubator-mxnet)\n\t- http://mxnet.io/\n\t- [Towards Next Generation Deep Learning Framework](https://mli.github.io/cvpr17/)\n- #CODE [Microsoft Cognitive Toolkit (CNTK)](https://github.com/Microsoft/CNTK)\n\t- https://www.microsoft.com/en-us/research/product/cognitive-toolkit/\n\t- Microsoft Cognitive Toolkit: A free, easy-to-use, open-source, commercial-grade toolkit that trains deep learning algorithms to learn like the human brain.\n\t- #TALK https://www.youtube.com/watch?v=9gDDO5ldT-4\u0026feature=youtu.be\n- #CODE [Neupy - NeuPy is a Tensorflow based python library for prototyping and building neural networks](https://github.com/itdxer/neupy)\n\t- http://neupy.com/pages/home.html\n- #CODE Chainer - Chainer is a Python-based deep learning framework aiming at flexibility\n\t- https://github.com/chainer/chainer\n- #CODE [Neural Network Console (Sony)](https://dl.sony.com/)\n- #CODE [PySyft](https://github.com/OpenMined/PySyft)\n\t- PySyft is a Python library for secure and private Deep Learning. \n\t- PySyft decouples private data from model training, using Federated Learning, Differential Privacy, and Encrypted Computation (like Multi-Party Computation (MPC) and Homomorphic Encryption (HE)) within the main Deep Learning frameworks like PyTorch and TensorFlow.\n\t- #PAPER [A generic framework for privacy preserving deep learning](https://arxiv.org/abs/1811.04017)\n- #CODE [Deep cognition](https://deepcognition.ai/)\n\n### DL for science\n- #CODE [Gt4sd-core (IBM)](https://github.com/GT4SD/gt4sd-core) \n\t- GT4SD, an open-source library to accelerate hypothesis generation in the scientific discovery process \n\t- https://gt4sd.github.io/gt4sd-core/\n\t- https://research.ibm.com/blog/generative-models-toolkit-for-scientific-discovery\n\t- https://thenewstack.io/ibms-open-source-gt4sd-generates-ideas-for-scientists/\n- #CODE [Deep Search](https://github.com/DS4SD)\n\t- https://ds4sd.github.io/\n\t- Deep Search extracts and structures data from documents in four steps: Parse, Interpret, Index, and Integrate\n\t- [Handling Scientific Articles with Deep Search](https://opensource.science/handling-scientific-articles-with-deep-search-d3d7adebd3)\n\n\n## References\n- #PAPER [Deep learning in NNs: An overview (Schmidhuber 2015)](https://www.sciencedirect.com/science/article/pii/S0893608014002135)\n- #PAPER [Deep learning (LeCun 2015)](https://www.nature.com/articles/nature14539) ^dllecun15\n\t- https://www.researchgate.net/profile/Y_Bengio/publication/277411157_Deep_Learning/links/55e0cdf908ae2fac471ccf0f/Deep-Learning.pdf\n- #PAPER [Deep Neural Decision Forests (Kontschieder 2016)](https://www.ijcai.org/Proceedings/16/Papers/628.pdf)\n\t- #CODE https://keras.io/examples/structured_data/deep_neural_decision_forests/\n- #PAPER [On the Origin of Deep Learning (Wang 2017)](https://arxiv.org/abs/1702.07800v4 )\n- #PAPER [Representation Learning on Large and Small Data (Chou 2017)](https://arxiv.org/abs/1707.09873v1)\n- #PAPER [Deep Learning in Neural Networks: An Overview (Schmidhuber, 2018)](https://arxiv.org/abs/1404.7828)\n- #PAPER [Deep Learning as a Mixed Convex-Combinatorial Optimization Problem (Friesen 2018)](https://arxiv.org/abs/1710.11573)\n- #PAPER [Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods (Lucas, 2018)](https://ieeexplore.ieee.org/document/8253590)\n\t- http://decsai.ugr.es/vip/files/journals/08253590.pdf\n- #PAPER [Neural Tangent Kernel: Convergence and Generalization in Neural Networks (Jacot 2018)](https://arxiv.org/abs/1806.07572#)\n\t- https://www.quantamagazine.org/a-new-link-to-an-old-model-could-crack-the-mystery-of-deep-learning-20211011/\n- #PAPER [Neural circuit policies enabling auditable autonomy (Lechner 2020)](https://www.nature.com/articles/s42256-020-00237-3)\n\t- #CODE https://github.com/mlech26l/keras-ncp\n\t- https://www.csail.mit.edu/news/new-deep-learning-models-require-fewer-neurons\n\t- https://www.marktechpost.com/2021/10/19/mit-csail-tu-wien-and-ist-researchers-introduce-deep-learning-models-that-require-fewer-neurons/\n- #PAPER [Implicitly Defined Layers in Neural Networks (Zhang 2020)](https://arxiv.org/abs/2003.01822)\n- #PAPER [A Mathematical Principle of Deep Learning: Learn the Geodesic Curve in the Wasserstein Space (Gai 2021)](https://arxiv.org/abs/2102.09235)\n- #PAPER [Why is AI hard and Physics simple? (Roberts 2021)](https://arxiv.org/abs/2104.00008)\n- #PAPER [Deep Learning for AI (By Yoshua Bengio, Yann Lecun, Geoffrey Hinton, Turing lecture, 2021)](https://dl.acm.org/doi/10.1145/3448250)\n\t- https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltex\n- #PAPER [Self-Tuning for Data-Efficient Deep Learning (Wang 2021)](https://arxiv.org/abs/2102.12903)\n\t- #CODE https://github.com/thuml/Self-Tuning\n\t- #TALK https://recorder-v3.slideslive.com/#/share?share=40334\u0026s=f7988e61-bece-4a7a-a6ba-3e1a2b49b37b\n- #PAPER [Neural circuit policies enabling auditable autonomy (Lechner 2021)](https://www.nature.com/articles/s42256-020-00237-3)\n\t- #CODE https://github.com/mlech26l/keras-ncp\n- #PAPER [Controlling Neural Networks with Rule Representations (Seo 2021)](https://arxiv.org/abs/2106.07804)\n\t- https://ai.googleblog.com/2022/01/controlling-neural-networks-with-rule.html\n- #PAPER [Deep physical neural networks trained with backpropagation (Wrigth 2022)](https://www.nature.com/articles/s41586-021-04223-6)\n- #PAPER [Ensemble deep learning: A review (Ganaie 2022)](https://arxiv.org/pdf/2104.02395)            \n- #PAPER [projUNN: efficient method for training deep networks with unitary matrices (Kiani 2022)](https://arxiv.org/pdf/2203.05483)            \n\t- https://www.marktechpost.com/2022/04/09/researchers-including-yann-lecun-propose-projunn-an-efficient-method-for-training-deep-neural-networks-with-unitary-matrices/\n- #PAPER [LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification (Girish 2022)](https://arxiv.org/pdf/2204.02965)            \n\t- https://www.marktechpost.com/2022/04/12/researchers-propose-a-novel-framework-lilnetx-for-training-deep-neural-network-with-extreme-model-compression-and-structured-sparsification/\n\n### Generalization\n- http://www.inference.vc/everything-that-works-works-because-its-bayesian-2/\n\n- #PAPER [Understanding deep learning requires re-thinking generalization (Zhang 2016)](https://arxiv.org/abs/1611.03530)\n\t- https://blog.acolyer.org/2017/05/11/understanding-deep-learning-requires-re-thinking-generalization/\n\t- https://www.quora.com/Why-is-the-paper-%E2%80%9CUnderstanding-Deep-Learning-Requires-Rethinking-Generalization%E2%80%9D-important\n- #PAPER [A Closer Look at Memorization in Deep Networks (Arpit 2017)](https://arxiv.org/abs/1706.05394)\n- #PAPER [Deep nets don’t learn via memorization (Krueger 2017)](https://openreview.net/pdf?id=rJv6ZgHYg)\n- #PAPER [Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior (Martin 2017)](https://arxiv.org/abs/1710.09553)\n- #PAPER [Ablation Studies in Artificial Neural Networks (Meyes 2019)](https://arxiv.org/abs/1901.08644)\n- #PAPER [Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning (Allen-Zhu 2020)](https://arxiv.org/abs/2012.09816)\n\t- https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/\n- #PAPER [The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers (Nakkiran 2021)](https://arxiv.org/abs/2010.08127)\n\t- https://ai.googleblog.com/2021/03/a-new-lens-on-understanding.html\n- #PAPER [Predicting trends in the quality of state-of-the-art neural networks without access to training or testing data (Martin 2021)](https://www.nature.com/articles/s41467-021-24025-8)\n- #PAPER [Stochastic Training is Not Necessary for Generalization (Geiping 2021)](https://arxiv.org/abs/2109.14119)\n- #PAPER [Underspecification Presents Challenges for Credibility in Modern Machine Learning (D'Amour 2021)](https://arxiv.org/abs/2011.03395)\n\t- https://ai.googleblog.com/2021/10/how-underspecification-presents.html\n- #PAPER [Learning in High Dimension Always Amounts to Extrapolation (Balestriero 2021)](https://arxiv.org/abs/2110.09485)\n\t- In order for NNs to succeed at solving a task, they have to operate in the “extrapolation” regime! But not all of them generalise as well as others. So this opens up new questions about the relationship between this specific notion of extrapolation and generalisation more generally.\n- #PAPER [Incorporating Symmetry into Deep Dynamics Models for Improved Generalization (Wang 2021)](https://arxiv.org/abs/2002.03061)\n\t- #CODE https://github.com/Rose-STL-Lab/Equivariant-Net\n- #PAPER [Grokking - Generatlization beyond overfitting on small algorithmic datasets (Power 2022)](https://arxiv.org/abs/2201.02177v1)\n\t- [Paper explained](https://www.youtube.com/watch?v=dND-7llwrpw)\n\n\n### Regularization\n- In general, techniques aimed at reducing overfitting and improve generalization\n- [Overfit and underfit](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit)\n- [Regularization techniques for training deep neural networks](https://theaisummer.com/regularization/)\n- https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036\n- https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/\n- https://medium.com/intelligentmachines/convolutional-neural-network-and-regularization-techniques-with-tensorflow-and-keras-5a09e6e65dc7\n\n#### Data augmentation\n- https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n- https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n- #PAPER [A survey on Image Data Augmentation for Deep Learning (Shorten 2019)](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)\n- #PAPER [AutoAugment: Learning Augmentation Policies from Data (Cubuk 2019)](https://arxiv.org/pdf/1805.09501)\n\n#### Dropout\n- http://www.cs.toronto.edu/~hinton/absps/dropout.pdf\n- https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/\n- [12 Main Dropout Methods: Mathematical and Visual Explanation for DNNs, CNNs, and RNNs](https://towardsdatascience.com/12-main-dropout-methods-mathematical-and-visual-explanation-58cdc2112293)\n\n- #PAPER [Dropout: A Simple Way to Prevent Neural Networks from Overfitting (Srivastava 2014)](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n- #PAPER [Efficient Object Localization Using Convolutional Networks (Tompson 2015)](https://arxiv.org/abs/1411.4280v3)\n\t- Proposed spatial dropout\n- #PAPER [Analysis on the Dropout Effect in Convolutional Neural Networks (Park 2017)](https://link.springer.com/chapter/10.1007/978-3-319-54184-6_12)\n\t- http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf\n- #PAPER [Effective and Efficient Dropout for Deep Convolutional Neural Networks (Cai 2020)](https://arxiv.org/abs/1904.03392)\n\n### Stochastic depth\n- #PAPER [Deep Networks with Stochastic Depth (Huang 2016)](https://arxiv.org/pdf/1603.09382)\n\t- Stochastic depth is a regularization technique that randomly drops a set of layers. During inference, the layers are kept as they are. It is very much similar to Dropout but only that it operates on a block of layers rather than individual nodes present inside a layer\n\n#### Normalization\n- Normalization techniques also improve generalization error, providing some regularization\n- [Normalization Techniques in Deep Neural Networks](https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8)\n- [Different Types of Normalization in Tensorflow](https://towardsdatascience.com/different-types-of-normalization-in-tensorflow-dac60396efb0)\n- [Normalization in Deep Learning](https://arthurdouillard.com/post/normalization/)\n- https://sebastianraschka.com/faq/docs/scale-training-test.html \n- Data normalization/standardization can be used as an alternative (before training) to synch batchnorm (multi-gpu training)\n- [Spectral normalization](https://sthalles.github.io/advanced_gans/)\n\n- #PAPER [Normalization Techniques in Training DNNs: Methodology, Analysis and Application (Huang 2020)](https://arxiv.org/abs/2009.12836)\n\n##### BatchNorm\n- #PAPER [ Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (Ioffe 2015)](https://arxiv.org/abs/1502.03167)\n\t- #TALK https://www.youtube.com/watch?v=ZOabsYbmBRM\u0026feature=youtu.be\n\t- http://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras\n\t- Slower convergence w/o BN, BN can be applied on top of standardization \n\t- Synch BatchNorm appears in TF 2.2, for multi-gpu training \n\t\t- https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/SyncBatchNormalization \n- #PAPER [Rethinking the Usage of Batch Normalization and Dropout (Chen 2019)](https://arxiv.org/abs/1905.05928)\n\n### Activations\n- https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html\n- https://mlfromscratch.com/activation-functions-explained/\n- [RELU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))\n\t- https://www.quora.com/What-is-special-about-rectifier-neural-units-used-in-NN-learning\n- http://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-network\n- https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions\n\n### Loss/Cost functions\n- Cross entropy\n\t- http://neuralnetworksanddeeplearning.com/chap3.html\n\t- https://en.wikipedia.org/wiki/Cross_entropy\n\t- http://www.kdnuggets.com/2017/02/gentlest-introduction-tensorflow-part-4.html\n- Perceptual loss, image reconstruction\n\t- https://arxiv.org/pdf/1511.06409.pdf (Learning to Generate Images With Perceptual Similarity Metrics) \n\t- #PAPER [Loss Functions for Image Restoration with Neural Networks (Zhao 2018)](https://arxiv.org/abs/1511.08861)\n\t- https://medium.com/@sanari85/rediscovery-of-ssim-index-in-image-reconstruction-ssim-as-a-loss-function-a1ffef7d2be \n\t\t- We use three different metric for comparing each different methods such as DSSIM, MSE, and MAE. Structural dissimilarity(DSSIM) is an image distance metric, that corresponds better to the human perception than MAE or RMSE. Mean Squared Error (MSE) measures the average of the squares of the errors that is, the average squared difference between the estimated values and the actual value. Mean Absolute Error (MAE) is the average distance between each pixel point. https://arxiv.org/abs/2001.05372\n- [Deep learning image enhancement insights on loss function engineering](https://towardsdatascience.com/deep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7)\n- Mean squared logarithmic error \n\t- https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle) \n\t- https://medium.com/@olegrybkin_20684/the-reasonable-ineffectiveness-of-mse-pixel-loss-for-future-prediction-and-what-to-do-about-it-4dca8152355d \n\n### Optimizers and backpropagation\n- [How to use Learning Curves to Diagnose Machine Learning Model Performance](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)\n- https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent\n- [Keras optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/ )\n- [Adam](http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n- [An overview of gradient descent optimization algorithms (2016)](https://ruder.io/optimizing-gradient-descent/index.html#otherrecentoptimizers )\n- https://hackernoon.com/some-state-of-the-art-optimizers-in-neural-networks-a3c2ba5a5643 \n- https://www.jeremyjordan.me/neural-networks-training/\n- http://colah.github.io/posts/2015-08-Backprop/\n- [Back-propagation - Math Simplified](https://github.com/DebPanigrahi/Machine-Learning/blob/master/back_prop.ipynb)\n- https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n- https://venturebeat.com/2020/12/16/at-neurips-2020-researchers-proposed-faster-more-efficient-alternatives-to-backpropagation/amp/\n\n- #PAPER [On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima (Shirish Keshkar 2017)](https://arxiv.org/abs/1609.04836)\n- #PAPER [Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour (Goyal 2018)](https://arxiv.org/abs/1706.02677)\n- #PAPER [Decoupled Weight Decay Regularization (Loshchilov 2018)](https://arxiv.org/abs/1711.05101)\n\t- AdamW optimizer\n\t- #CODE https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/AdamW\n\t- https://www.fast.ai/2018/07/02/adam-weight-decay/\n- #PAPER [Deep Double Descent: Where Bigger Models and More Data Hurt (Nakkiran 2019)](https://arxiv.org/abs/1912.02292)\n\t- https://openai.com/blog/deep-double-descent/\n\t- https://medium.com/mlearning-ai/double-descent-8f92dfdc442f\n- #PAPER [Reconciling modern machine learning practice and the bias-variance trade-off (Belkin 2019)](https://arxiv.org/abs/1812.11118)\n\t- [Paper explained](https://www.youtube.com/watch?v=ZAW9EyNo2fw)\n- #PAPER [Deep Double Descent: Where Bigger Models and More Data Hurt (Nakkiran 2020)](https://arxiv.org/abs/1912.02292)\n\t- https://openai.com/blog/deep-double-descent/\n- #PAPER [Descending through a Crowded Valley -- Benchmarking Deep Learning Optimizers (Schmidt 2020)](https://arxiv.org/abs/2007.01547)\n\t- [Paper explained](https://www.youtube.com/watch?v=DiNzQP7kK-s)\n- #PAPER [Early Stopping in Deep Networks: Double Descent and How to Eliminate it (Heckel 2020)](https://arxiv.org/abs/2007.10099)\n\t- contrary to model-wise double descent, epoch-wise double descent is not a phenomena tied o over-parameterization\n\t- both under- and overparameterized models can have epoch-wise double descent \n\t- #CODE https://github.com/MLI-lab/early_stopping_double_descent\n\n\n### Efficiency and performance\n- #PAPER [Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better (Menghani 2021)](https://arxiv.org/abs/2106.08962)\n\t- https://analyticsindiamag.com/how-to-build-smaller-faster-better-deep-learning-models/\n\n### Scaling and distributed DL\nSee [[AI/DS and DataEng/Distributed DL]]\n\n### Attention\nSee \"For NLP\" section in [[AI/Deep learning/Transformers]] and \"Channel/Visual attention\" section in [[/AI/Deep learning/CNNs]]\n\n- #COURSE [Attention and Memory in Deep Learning (DeepMind x UCL | Deep Learning Lectures | 8/12)](https://www.youtube.com/watch?v=AIiwuClvH6k)\n\n\n### Explainability methods for Neural Networks\nSee [[AI/Deep learning/Explainability methods for NNs]]\n\n## Applications\n\n### Deep learning for multi-dimensional data\nSee [[AI/Computer Vision/Video segmentation and prediction]], [[AI/Deep learning/Encoder-decoder networks]], [[AI/Deep learning/Transformers]] and [[AI/Deep learning/Generative modelling]]\n- #PAPER [Demystifying Deep Learning in Predictive Spatio-Temporal Analytics: An Information-Theoretic Framework (Tan 2020)](https://arxiv.org/abs/2009.06304)\n\n### Deep learning for tabular data\n- [An Introduction to Deep Learning for Tabular Data](https://www.fast.ai/2018/04/29/categorical-embeddings/)\n- [Applying Deep Learning on Tabular Data Using TensorFlow 2.0](https://pdf.co/blog/deep-learning-on-tabular-data-using-tensorflow-20)\n- [A short chronology of deep learning for tabular data (Sebastian Rschka)](https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html)\n- #CODE See Pytorch tabular in [[AI/DS and DataEng/Pytorch]] \n- #PAPER [Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data (Popov 2019)](https://arxiv.org/abs/1909.06312)\n- #PAPER [TabNet: Attentive Interpretable Tabular Learning (Arik 2020)](https://arxiv.org/abs/1908.07442)\n- #PAPER [Converting tabular data into images for deep learning with convolutional neural networks (Zhu 2021)](https://www.nature.com/articles/s41598-021-90923-y)\n- #PAPER [Tabular Data: Deep Learning is Not All You Need (Shwartz-Ziv 2021)](https://arxiv.org/abs/2106.03253)\n- #PAPER [XBNet: An Extremely Boosted Neural Network (Sarkar 2021)](https://arxiv.org/abs/2106.05239)\n\t- #CODE [XBNet](https://github.com/tusharsarkar3/XBNet)\n\t- Boosted neural network for tabular data\n\t- https://analyticsindiamag.com/guide-to-xbnet-an-extremely-boosted-neural-network/\n- #PAPER [Revisiting Deep Learning Models for Tabular Data (Gorishniy 2021)](https://arxiv.org/abs/2106.11959)\n\t- #CODE [RDTL (Yandex)](https://github.com/yandex-research/rtdl)\n\t- https://yandex-research.github.io/rtdl/\n- #PAPER [TABBIE: Pretrained Representations of Tabular Data (Lida 2021)](https://arxiv.org/abs/2105.02584v1)\n\n### Deep learning for scientific discovery\nSee [[AI/AI#AI for scientific discovery]], [[AI/Machine Learning#Machine learning for scientific discovery]], [[AI/Deep learning/Neural ODEs]], and relevant code in [[AI/Deep learning/DL#DL for science]]\n- #PAPER [A Survey of Deep Learning for Scientific Discovery (Raghu \u0026 Schmidt, 2020)](https://arxiv.org/abs/2003.11755) ^dlscience20\n- #PAPER [DeepXDE: A deep learning library for solving differential equations (Lu 2020)](https://arxiv.org/abs/1907.04502)\n\t- #CODE https://github.com/lululxvi/deepxde\n\t- https://deepxde.readthedocs.io/en/latest/\n- #PAPER [SciANN: A Keras/Tensorflow wrapper for scientific computations and physics-informed deep learning using artificial neural networks (Haghighat 2020)](https://arxiv.org/abs/2202.07575)\n\t - #CODE https://github.com/sciann/sciann\n- #PAPER [Learning an Accurate Physics Simulator via Adversarial Reinforcement Learning (Jiang 2021)](http://ai.googleblog.com/2021/06/learning-accurate-physics-simulator-via.html \"Learning an Accurate Physics Simulator via Adversarial Reinforcement Learning\")\n- #PAPER [Data-driven discovery of Green’s functions with human-understandable deep learning (Boulle 2022)](https://www.nature.com/articles/s41598-022-08745-5)\n\t- https://phys.org/news/2022-04-rational-neural-network-advances-partial.html\n\n### Multimodal learning\nSee [[AI/Deep learning/Multimodal learning]]\n\n### DL for NLP, time series and sequence modelling\nSee [[AI/Time Series analysis]], [[AI/Forecasting]] and \"Deep learning approaches\" in [[AI/NLP]]\n\n\n## Architectures and model families\n- [The neural network zoo](http://www.asimovinstitute.org/neural-network-zoo/)\n- [Deep Learning Tips and Tricks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks)\n- [A Visual and Interactive Guide to the Basics of NNs](https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/)\n- [A Visual And Interactive Look at Basic Neural Network Math](https://jalammar.github.io/feedforward-neural-networks-visual-interactive/)\n- #CODE [Model Zoo](https://modelzoo.co/)\n- #CODE [Deep Learning Models (Raschka)](https://github.com/rasbt/deeplearning-models)\n\n### Geometric DL\nSee [[AI/Deep learning/Geometric deep learning]]\n\n### MLPs\nSee [[AI/Deep learning/MLPs]]\n\n### Deep belief network\nSee [[AI/Deep learning/Deep belief network]]\n\n### Autoencoders\nSee [[AI/Deep learning/Autoencoders]]\n\n### CNNs\nSee [[AI/Deep learning/CNNs]]\n\n### RNNs\nSee [[AI/Deep learning/RNNs]]\n\n### CapsNets\nSee [[AI/Deep learning/CapsNets]]\n\n### GANs\nSee [[AI/Deep learning/GANs]]\n\n### Diffusion models\nSee [[AI/Deep learning/Diffusion models]]\n\n### GNNs\nSee [[AI/Deep learning/GNNs]]\n\n### Residual and dense neural networks\nSee [[AI/Deep learning/Residual and dense neural networks]]\n\n### Neural ODEs\nSee [[AI/Deep learning/Neural ODEs]]\n\n### Fourier Neural Operators\nSee [[AI/Deep learning/Fourier Neural Operators]]\n\n### Transformers\nSee [[AI/Deep learning/Transformers]]\n\n### GFlowNets\nSee [[AI/Deep learning/GFlowNets]]\n\n### Neural Cellular Automata\nSee [[AI/Deep learning/Neural Cellular Automata]]\n\n### Neural processes\nSee [[AI/Deep learning/Neural processes]]\n\n### Bayesian/probabilistic DL\nSee [[AI/Deep learning/Probabilistic deep learning]]","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Deep-belief-network":{"title":"Deep belief network","content":"\u003e A deep belief network (DBN) is a generative graphical model, or alternatively a type of deep neural network, composed of multiple layers of latent variables(\"hidden units\"), with connections between the layers but not between units within each layer. DBNs can be viewed as a composition of simple, unsupervised networks such as restricted Boltzmann machines (RBMs) or autoencoders, where each sub-network's hidden layer serves as the visible layer for the next\n\n## Resources\n- #TALK [Deep Belief Nets (Hinton)](https://www.cs.toronto.edu/~hinton/nipstutorial/nipstut3.pdf)\n- [Deep-Belief Networks](https://wiki.pathmind.com/deep-belief-network)\n\t- A deep-belief network can be defined as a stack of restricted Boltzmann machines, in which each RBM layer communicates with both the previous and subsequent layers. The nodes of any single layer don’t communicate with each other laterally.\n\t- This stack of RBMs might end with a a Softmax layer to create a classifier, or it may simply help cluster unlabeled data in an unsupervised learning scenario.\n\t- With the exception of the first and final layers, each layer in a deep-belief network has a double role: it serves as the hidden layer to the nodes that come before it, and as the input (or “visible”) layer to the nodes that come after. It is a network built of single-layer networks.\n\t- Deep-belief networks are used to recognize, cluster and generate images, video sequences and motion-capture data. A continuous deep-belief network is simply an extension of a deep-belief network that accepts a continuum of decimals, rather than binary data. They were introduced by Geoff Hinton and his students in 2006.","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Diffusion-models":{"title":"Diffusion models","content":"\u003e Diffusion Models are generative models that work by destroying training data through the successive addition of Gaussian noise, and then learning to recover the data by reversing this noising process. After training, the Diffusion Model can be used to generate data by simply passing randomly sampled noise through the learned denoising process\n\n\n## Resources\n- [Diffusion models are autoencoders (Dieleman | Deepmind)](https://benanne.github.io/2022/01/31/diffusion.html \"Diffusion models are autoencoders\")\n- [High Fidelity Image Generation Using Diffusion Models](http://ai.googleblog.com/2021/07/high-fidelity-image-generation-using.html \"High Fidelity Image Generation Using Diffusion Models\")\n- [Introduction to deep generative modeling: Diffusion-based Deep Generative Models](https://jmtomczak.github.io/blog/10/10_ddgms_lvm_p2.html)\n- [Introduction to Diffusion Models for Machine Learning](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/)\n\n## Code\n- #CODE [diffusers](https://github.com/huggingface/diffusers) (huggingface)\n\t- Diffusers provides pretrained diffusion models across multiple modalities, such as vision and audio, and serves as a modular toolbox for inference and training of diffusion models\n\t- https://towardsdatascience.com/hugging-face-just-released-the-diffusers-library-846f32845e65\n\t- #TALK https://www.youtube.com/watch?v=UzkdOg7wWmI\n\n\n## References\n- #PAPER [Improved Denoising Diffusion Probabilistic Models (Nichol 2021)](https://arxiv.org/abs/2102.09672)\n- #PAPER [Cascaded Diffusion Models for High Fidelity Image Generation (Ho 2021)](https://cascaded-diffusion.github.io/)\n- #PAPER [Diffusion Models Beat GANs on Image Synthesis (Dhariwal 2021)](https://arxiv.org/abs/2105.05233v3)\n\t- #CODE https://github.com/openai/guided-diffusion\n\t- Diffusion models are a class of likelihood-based models that have shown to produce high-quality images with desired properties such as distribution coverage and easy scalability. These models generate samples by gradually removing noise from a signal. Previous research has shown that they improve reliably with increased compute. The proposed method brings improvements to diffusions models that have worked for GANs, such as improved model architecture and a scheme to trade off diversity for quality. The proposed diffusion model achieves several state-of-the-art results, surpassing GANs on several metrics and datasets\n\t- [Paper explained](https://www.youtube.com/watch?v=W-O7AZNzbzQ)\n- See Imagen in [[AI/Deep learning/Multimodal learning]]","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Encoder-decoder-networks":{"title":"Encoder-decoder networks","content":"\u003e [[AI/Deep learning/DL]] architectures composed of two paths, an encoding and a decoding one. [[AI/Deep learning/Autoencoders]] are similar but unsupervised (reconstructions loss). U-NETs are a type of encoder-decoder [[AI/Deep learning/CNNs]] model with skipped connections trained in a [[AI/Supervised Learning/Supervised learning]] context for image segmentation and related tasks. Very common models for semantic segmentation tasks\n\n## Resources\n- https://www.slideshare.net/PetteriTeikariPhD/multiphoton-vasculature-segmentation-5-unet\n\n## Code\n- #CODE [Keras-unet-collection](https://github.com/yingkaisha/keras-unet-collection)\n\n## References\n- #PAPER [U-Net: Convolutional Networks for Biomedical Image Segmentation (Ronneberger 2015)](https://arxiv.org/abs/1505.04597 )\n\t- https://towardsdatascience.com/review-u-net-biomedical-image-segmentation-d02bf06ca760 \n\t- https://github.com/karolzak/keras-unet \n\t- https://tuatini.me/practical-image-segmentation-with-unet/ \n\t- https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/unet.py \n\t- [diagram example](https://www.researchgate.net/publication/323302730/figure/fig1/AS:596310398881793@1519182886358/U-Net-architecture-consisted-with-convolutional-encoding-and-decoding-units-that-take.png )\n- #PAPER [3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation (Cicek 2016)](https://arxiv.org/abs/1606.06650)\n\t- https://towardsdatascience.com/review-3d-u-net-volumetric-segmentation-medical-image-segmentation-8b592560fac1 \n- #PAPER [V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation (Milletari 2016)](https://arxiv.org/abs/1606.04797)\n\t- https://towardsdatascience.com/review-v-net-volumetric-convolution-biomedical-image-segmentation-aa15dbaea974 \n- #PAPER [Volumetric ConvNets with Mixed Residual Connections for Automated Prostate Segmentation from 3D MR Images, 3D UNET+Resnet (Yu 2017)](https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14719)\n\t- https://towardsdatascience.com/review-3d-u-net-resnet-volumetric-convolutions-long-short-residual-connections-biomedical-3a7da3f98dae\n- #PAPER [Automatic 3D Cardiovascular MR Segmentation with Densely-Connected Volumetric ConvNets, DenseVoxNet (Yu 2017)](https://arxiv.org/abs/1708.00573 )\n\t- https://medium.com/@sh.tsang/review-densevoxnet-volumetric-brain-segmentation-biomedical-image-segmentation-9136bb6128dd \n- #PAPER [Road Extraction by Deep Residual U-Net, ResUNET (Zhang 2017)](https://arxiv.org/abs/1711.10684)\n\t- https://github.com/nikhilroxtomar/Deep-Residual-Unet\n- #PAPER [Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation (Alom 2018)](https://www.researchgate.net/publication/323302730_Recurrent_Residual_Convolutional_Neural_Network_based_on_U-Net_R2U-Net_for_Medical_Image_Segmentation)\n- #PAPER [UNet++: A Nested U-Net Architecture for Medical Image Segmentation (Zhou 2018)](https://arxiv.org/abs/1807.10165)\n\t- https://medium.com/@sh.tsang/review-unet-a-nested-u-net-architecture-biomedical-image-segmentation-57be56859b20 \n- #PAPER [H-DenseUNet: Hybrid Densely Connected UNet for Liver and Tumor Segmentation from CT Volumes (Li 2018)](https://arxiv.org/abs/1709.07330  )\n\t- https://medium.com/@sh.tsang/review-h-denseunet-2d-3d-denseunet-for-intra-inter-slice-features-biomedical-image-f3e526e81fe7 \n\t- #CODE https://github.com/xmengli999/H-DenseUNet/\n- #PAPER [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation, DeepLabv3+ (Chen 2018)](https://arxiv.org/abs/1802.02611)\n\t- #CODE https://github.com/ChoiDM/pytorch-deeplabv3plus-3D \n- #PAPER [ResUNet-a: a deep learning framework for semantic segmentation of remotely sensed data (Diakogiannis 2019)](https://arxiv.org/abs/1904.00592)\n- #PAPER [ResUNet++: An Advanced Architecture for Medical Image Segmentation (Jha 2019)](https://arxiv.org/abs/1911.07067)\n- #PAPER [M-Net: U-Net with Multi-stream Feature Fusion and Multi-scale Dilated Convolutions (Fu 2019)](https://ieeexplore.ieee.org/document/8864993 )\n\t- https://www.researchgate.net/publication/336455527_M-Net_A_Novel_U-Net_with_Multi-stream_Feature_Fusion_and_Multi-scale_Dilated_Convolutions_for_Bile_Ducts_and_Hepatolith_Segmentation_September_2019 \n- #PAPER [Channel-Unet: A Spatial Channel-Wise Convolutional Neural Network for Liver and Tumors Segmentation (Chen 2019)](https://www.frontiersin.org/articles/10.3389/fgene.2019.01110/full)\n- #PAPER [Bi-Directional ConvLSTM U-Net with Densely Connected Convolutions (Azad 2019)](https://arxiv.org/abs/1909.00166)\n    - #CODE https://github.com/rezazad68/BCDU-Net/blob/master/Retina%20Blood%20Vessel%20Segmentation/models.py\n- #PAPER [LSTM-UNET - Microscopy Cell Segmentation via Convolutional LSTM Networks (Arbelle 2019)](https://arxiv.org/abs/1805.11247)\n\t#CODE https://github.com/arbellea/LSTM-UNet\n- #PAPER [USE-Net: incorporating Squeeze-and-Excitation blocks into U-Net for prostate zonal segmentation of multi-institutional MRI datasets (Rundo 2019)](https://arxiv.org/abs/1904.08254)\n- #PAPER [Evaluation of Multi-Slice Inputs to Convolutional Neural Networks for Medical Image Segmentation (Vu 2019)](https://arxiv.org/abs/1912.09287)\n- #PAPER [Making a Case for 3D Convolutions for Object Segmentation in Videos (Mahadevan 2020)](https://arxiv.org/abs/2008.11516)\n\t- proposed a simple and fast network architecture consisting entirely of 3D  convolutions that is capable of effectively learning spatio-temporal features\n\t- used a 3D ResNet pretrained for video action classification as an encoder, and a novel decoder architecture inspired by existing 2D convolutional networks\n- #PAPER [nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation (Isensee 2020)](https://www.nature.com/articles/s41592-020-01008-z)\n\t- https://www.sciencedaily.com/releases/2020/12/201207112253.htm\n\t- #CODE https://github.com/MIC-DKFZ/nnUNet\n- #PAPER [MCNN, Multi-resolution convolutional neural networks for inverse problems (Wang 2020)](https://www.nature.com/articles/s41598-020-62484-z)\n\t- #CODE https://github.com/fengwang/MCNN\n\t- #CODE https://github.com/fengwang/mcnn-demo/tree/master/demo","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Explainability-methods-for-NNs":{"title":"Explainability methods for NNs","content":"## Resources \n- [Using ML to Explore Neural Network Architecture](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html)\n- [The Building Blocks of Interpretability](https://distill.pub/2018/building-blocks/)\n- [Feature Visualization](https://distill.pub/2017/feature-visualization/)\n- [Applying deep learning to real-world problems (labeled data, imbalance, black box models)](https://medium.com/merantix/applying-deep-learning-to-real-world-problems-ba2d86ac5837)\n- [Unblackboxing webinar (deepsense.io)](https://github.com/deepsense-io/unblackboxing_webinar)\n- [The Dark Secret at the Heart of AI](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/amp/)\n- [How AI detectives are cracking open the black box of deep learning](http://www.sciencemag.org/news/2017/07/how-ai-detectives-are-cracking-open-black-box-deep-learning)\n- [Visualization of activations and filters](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html) \n\t- https://github.com/jacobgil/keras-filter-visualization\n- https://towardsdatascience.com/understanding-your-convolution-network-with-visualizations-a4883441533b\n- https://imatge.upc.edu/web/publications/visual-saliency-prediction-using-deep-learning-techniques\n- [Attributing a deep network’s prediction to its input features](http://www.unofficialgoogledatascience.com/2017/03/attributing-deep-networks-prediction-to.html)\n\t- Integrated gradients method\n\t- It involves a few calls to a gradient operator yielding insightful results for a variety of deep networks\n\n### Saliency maps\n- https://en.wikipedia.org/wiki/Saliency_map\n- Saliency map is a broader term from the field of computer vision. The first reference of saliency maps applied to the predictions of DNNs is Morch et al 1995. Simonyan et al (2014) first proposed a method to produce saliency maps using back-propagation through a CNN, but note that you could compute \"saliency\" from an image in many ways that do not deal with back-propagating the prediction scores of DNNs. \n- [Pixel Attribution (Saliency Maps)](https://christophm.github.io/interpretable-ml-book/pixel-attribution.html)\n\n### Layer-wise Relevance Propagation (LRP)\n- LRP is an inverse method which calculates the contribution of a single pixel to the prediction made by a DNN in an image classification task\n- http://heatmapping.org/\n- [Interactive demo](https://lrpserver.hhi.fraunhofer.de/image-classification)\n- https://medium.com/@ODSC/layer-wise-relevance-propagation-means-more-interpretable-deep-learning-219ff5158914\n- https://towardsdatascience.com/indepth-layer-wise-relevance-propagation-340f95deb1ea\n- There are several approaches for calculating attributions by back-propagating the prediction score through each layer of the network, back to the input features /pixels (DeConvNet, SmoothGrad, GradCam, LRP, XRAI). LRP is just one of them. In the first LRP paper, they talk about heatmaps or relevance maps, probably to avoid confusion with older saliency map techniques\n\n\n## Courses\n- #COURSE [Interpretable Machine Learning for Computer Vision (CVPR 2020)](https://interpretablevision.github.io/index_cvpr2020.html)\n- #COURSE [Explainability Methods for Neural Networks (2021)](https://sites.google.com/view/emnn-ws-2020/home)\n\n\n## Code\n- #CODE [Quantus](https://github.com/understandable-machine-intelligence-lab/Quantus)\n\t- Quantus is an eXplainable AI toolkit for responsible evaluation of neural network explanations\n- #CODE [TruLens (tf.keras and pytorch): Explainability for Neural Networks](https://github.com/truera/trulens)\n\t- https://www.trulens.org/\n- #CODE [Captum (pytorch)](https://github.com/pytorch/captum)\n\t- Interpretability of models across modalities including vision, text, and more\n\t- https://captum.ai/\n\t- https://captum.ai/api/\n- #CODE [Explainable-cnn](https://github.com/ashutosh1919/explainable-cnn)\n\t- PyTorch based visualization package for generating layer-wise explanations for CNNs\n- #CODE [Saliency](https://github.com/PAIR-code/saliency)\n\t- XRAI, SmoothGrad, Vanilla Gradients, Guided Backpropogation, Integrated Gradients, Occlusion, Grad-CAM, Blur IG\n- #CODE [iNNvestigate](https://github.com/albermax/innvestigate) ^innvestigate\n\t- Vanilla gradient, SmoothGrad, DeConvNet, Guided BackProp, PatternNet, DeepTaylor, PatternAttribution, LRP, IntegratedGradients, DeepLIFT\n- #CODE [TF-explain](https://github.com/sicara/tf-explain)\n\t- implements interpretability methods as Tensorflow 2.x callbacks to ease neural network's understanding\n- #CODE [TensorSpace (Tensorflow.js)](https://github.com/tensorspace-team/tensorspace)\n\t- Neural network 3D visualization framework\n\t- https://tensorspace.org\n- #CODE [Lucid (Tensorflow 1) - A collection of infrastructure and tools for research in neural network interpretability](https://github.com/tensorflow/lucid)\n- #CODE [tf-keras-vis](https://github.com/keisen/tf-keras-vis)\n\t- Neural network visualization toolkit for tf.keras\n\t- Activation Maximization\n\t- Class Activation Maps (GradCAM, GradCAM++, ScoreCAM, Faster-ScoreCAM)\n\t- Saliency Maps (Vanilla Saliency, SmoothGrad)\n- #CODE [Keras-vis](https://github.com/raghakot/keras-vis)\n\t- https://raghakot.github.io/keras-vis/\n\t- Activation maximization, Saliency maps, Class activation maps\n- #CODE [DeepExplain (TensorFlow 1)](https://github.com/marcoancona/DeepExplain)\n\t- Saliency maps, Gradient * Input, Integrated Gradients, DeepLIFT, ε-LRP\n- #CODE [LRP toolbox](https://github.com/sebastian-lapuschkin/lrp_toolbox)\n\n## References\n- #PAPER [Visualization of neural networks using saliency maps (Morch 1995)](https://www.researchgate.net/publication/3623243_Visualization_of_neural_networks_using_saliency_maps)\n- #PAPER [Deep inside CNNs: Visualising Image Classification Models and Saliency Maps (Simonyan 2014)](https://arxiv.org/abs/1312.6034)\n\t- Presented two visualisation techniques for deep classification ConvNets\n\t\t- The first generates an artificial image, which is representative of a class of interest\n\t\t- The second computes an image-specific class saliency map, highlighting the areas of the given image, discriminative wrt the given class\n- #PAPER [Understanding Neural Networks Through Deep Visualization (Yosinski 2015)](https://arxiv.org/abs/1506.06579)\n\t- http://yosinski.com/deepvis\n- #PAPER [SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability (Raghu 2017)](https://arxiv.org/abs/1706.05806)\n\t- [Interpreting Deep Neural Networks with SVCCA](https://ai.googleblog.com/2017/11/interpreting-deep-neural-networks-with.html)\n- #PAPER [Axiomatic Attribution for Deep Networks (Sundararajan 2017)](https://arxiv.org/abs/1703.01365)\n- #PAPER [SmoothGrad: removing noise by adding noise (Smilkov 2017)](https://arxiv.org/abs/1706.03825)\n\t- https://pair-code.github.io/saliency/\n- #PAPER [iNNvestigate Neural Networks! (Alber 2018)](http://arxiv.org/abs/1808.04260)\n\t- #CODE See Code section\n- #PAPER [XRAI: Better Attributions Through Regions (Kapishnikov 2019)](https://arxiv.org/abs/1906.02825)\n- #PAPER [DeepLIFT - Learning Important Features Through Propagating Activation Differences (Shrikumar 2019)](https://arxiv.org/abs/1704.02685)\n - #PAPER [Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges (Borji 2019)](https://arxiv.org/abs/1810.03716)\n- #PAPER [DAX: Deep Argumentative eXplanation for Neural Networks (Albini 2020)](https://arxiv.org/abs/2012.05766)\n- #PAPER [Interpreting Deep Neural Networks Through Variable Importance (Ish-Horowicz 2020)](https://arxiv.org/abs/1901.09839)\n\t- Their strategy is specifically designed to leverage partial covariance structures and incorporate variable interactions into our proposed feature ranking.  \n\t- Extended the recently proposed “RelATive cEntrality” (RATE) measure (Crawford et al., 2019) to the Bayesian deep learning setting\n\t- Given a trained network, RATE applies an information theoretic criterion to the posterior distribution of effect sizes to assess feature significance\n- #PAPER [Determining the Relevance of Features for Deep Neural Networks (Reimers 2020)](https://link.springer.com/chapter/10.1007%2F978-3-030-58574-7_20)\n\t- Their approach builds upon concepts from causal inference\n\t- Interpret machine learning in a structural causal model and use Reichenbach’s common cause principle to infer whether a feature is relevant\n- #PAPER [Explainable Deep Learning Models in Medical Image Analysis (Singh 2020)](https://arxiv.org/abs/2005.13799)\n- #PAPER [Efficient Saliency Maps for Explainable AI (Mundhenk 2020)](https://arxiv.org/abs/1911.11293)\n- #PAPER [Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications (Samek 2021)](https://ieeexplore.ieee.org/document/9369420)\n- #PAPER [Logic Explained Networks (Ciravegna 2021)](https://arxiv.org/abs/2108.05149)\n\t- https://syncedreview.com/2021/08/18/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-85/\n- #PAPER [Toward Explainable AI for Regression Models (Letzgus 2021)](https://arxiv.org/abs/2112.11407)\n- #PAPER [Explaining in Style: Training a GAN to explain a classifier in StyleSpace (Lang 2021)](https://explaining-in-style.github.io/)\n\t- https://ai.googleblog.com/2022/01/introducing-stylex-new-approach-for.html\n- #PAPER [Variable selection with false discovery rate control in deep neural networks (Song 2021)](https://www.nature.com/articles/s42256-021-00308-z)\n\t- [SurvNet: A backward elimination procedure to enhance variable selection for deep neural networks](https://techxplore.com/news/2021-05-survnet-procedure-variable-deep-neural.html)\n \n### Layer-wise Relevance Propagation (LRP)\n- #PAPER [On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation (Bach 2015)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140)\n\t- #CODE [Tutorial: Implementing Layer-Wise Relevance Propagation](https://git.tu-berlin.de/gmontavon/lrp-tutorial)\n- #PAPER [Understanding Individual Decisions of CNNs via Contrastive Backpropagation (Gu 2019)](https://arxiv.org/abs/1812.02100)\n- #PAPER [Beyond saliency: understanding convolutional neural networks from saliency prediction on layer-wise relevance propagation (Li 2019)](https://arxiv.org/abs/1712.08268)\n\t- proposed a novel two-step understanding method, namely Salient Relevance (SR) map, which aims to shed light on how deep CNNs recognize images and learn features from attention areas\n\t- starts out with a layer-wise relevance propagation (LRP) step which estimates a pixel-wise relevance map over the input image. Following, we construct a context-aware saliency map, SR map, from the LRP-generated map which predicts areas close to the foci of attention instead of isolated pixels that LRP reveals\n- #PAPER [Towards Best Practice in Explaining Neural Network Decisions with LRP (Kohlbrenner 2020)](https://arxiv.org/abs/1910.09840)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Fourier-Neural-Operators":{"title":"Fourier Neural Operator (FNO)","content":"## Resources\n- [Neural Operator - Machine learning for scientific computing](https://zongyi-li.github.io/neural-operator/)\n\t- The classical development of neural networks has primarily focused on learning mappings between finite dimensional Euclidean spaces or finite sets. To better approximate the solution operators raised in PDEs, a generalization of neural networks to learn operators mapping between infinite dimensional function spaces is proposed\n\t- Formulate the approximation of operators by composition of a class of linear integral operators and nonlinear activation functions, so that the composed operator can approximate complex nonlinear operators\n\t- Such neural operators are resolution-invariant, and consequently more efficient compared to traditional neural networks\n\t- The FNO model has shown state-of-the-art performance with 1000x speedup in learning turbulent Navier-Stokes equation\n\n\n## Talks\n- #TALK [A crash course on Neural Operators (Kamyar Azizzadenesheli)](https://www.youtube.com/watch?v=KIGG-IA9awU)\n- #TALK [Zongyi Li's talk on solving PDEs from data](https://www.youtube.com/watch?v=0Ve9xwNJO2o\u0026t=1197s)\n- #TALK [Neural operator: A new paradigm for learning PDEs (Anima Anandkumar)](https://www.youtube.com/watch?v=Bd4KvlmGbY4\u0026t=0s)\n\n## References\n- #PAPER [Fourier Neural Operator for Parametric Partial Differential Equations (Li 2020)](https://arxiv.org/abs/2010.08895)\n\t- #CODE https://github.com/zongyi-li/fourier_neural_operator\n\t- #CODE https://github.com/astanziola/fourier-neural-operator-flax\n\t- https://zongyi-li.github.io/blog/2020/fourier-pde/\n\t- https://www.technologyreview.com/2020/10/30/1011435/ai-fourier-neural-network-cracks-navier-stokes-and-partial-differential-equations/\n\t- [Paper explained](https://www.youtube.com/watch?v=IaS72aHrJKE)\n\t- Function approximation in Fourier space instead of a the Euclidian (with conventional convolutions)\n\t- Fourier representation is more efficient than CNN, it's global and continuous\n\t- Convolution -\u003e pointwise multiplication (by matrix R, that is learned) in Fourier domain\n\t- Fourier layer. \n\t\t- Fourier transform. Filtering/truncating low frequency modes\n\t\t- Non-linearity (as in other DL models)\n\t\t- Linear transform/layer to track location information (just like a residual connection)\n\t- FNO captures energy spectrum\n\t- It can do zero-shot super-resolution: trained on a lower resolution directly evaluated on a higher resolution\n- #PAPER [MeshfreeFlowNet: A Physics-Constrained Deep Continuous Space-Time Super-Resolution Framework (Jiang 2020)](https://arxiv.org/abs/2005.01463)\n\t- #TALK [ML Cluster: Karthik Kashinath, Physics-informed Machine learning for weather and climate science](https://www.youtube.com/watch?v=B_4TONeY75U)\n\t- [[AI/Computer Vision/Super-resolution]]\n- #PAPER [Neural Operator: Learning Maps Between Function Spaces (Kovachki 2021)](https://arxiv.org/pdf/2108.08481)\n- #PAPER [Adaptive Fourier Neural Operators: Efficient Token Mixers for Transformers (Guibas 2022)](https://arxiv.org/pdf/2111.13587)            \n\t- #CODE https://github.com/NVlabs/AFNO-transformer\n\t- #CODE https://github.com/DarshanDeshpande/research-paper-implementations/tree/main/tensorflow/afno (not official)\n\t- Adaptive FNO (AFNO) - connection between transformers and FNOs\n\t- Transformers are a special case of neural operators\n\t- AFNO is efficient for that it splits the grid (efficient token mixing) \n- #PAPER FourCastNet (2022)\n\t- See [[AI4ES/Weather forecasting, nowcasting]]","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/GANs":{"title":"Generative Adversarial Networks (GANs)","content":"\u003e A GAN consists of two networks; a generator (G) and a discriminator (D), given a set of training examples, G will generate outputs and D will classify them as either being from the same distribution as the training examples or not. In doing so D is optimized so as to be able to discriminate between examples from the training example and from the generator network which in turn is optimized to fool D into classifying its output as being drawn from the training examples. After such training G can now generate samples with properties very similar to those of the training examples. GANs tend to be devilishly hard to train\n\n\u003e See [[AI/Deep learning/Generative modelling]]\n\n## Resources \n- [List of papers and other on Generative Adversarial Networks](https://github.com/pshams55/GAN-Case-Study)\n- [Generative Adversarial Networks](https://spectra.pub/ml/gans)\n- [Generative adversarial networks](https://deepgenerativemodels.github.io/notes/gan/ )\n- [Introduction to deep generative modeling: Generative Adversarial Networks (GANs)](https://jmtomczak.github.io/blog/12/12_gans.html)\n- [Generative adversarial networks for beginners](https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners)\n- [Intuitive explanation of GANs. Subtypes](https://tryolabs.com/blog/2016/12/06/major-advancements-deep-learning-2016/)\n- https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-1-Generative-Adversarial-Nets\n- http://www.openias.org/hybrid-generative-discriminative\n- http://edwardlib.org/tutorials/gan\n- [Play with GANs in your browser](https://poloclub.github.io/ganlab/)\n- [Do GANs actually do distribution learning?](http://www.offconvex.org/2017/07/06/GANs3/)\n- [The GAN Zoo - A list of all named GANs!](https://deephunt.in/the-gan-zoo-79597dc8c347)\n- [Advances in Generative Adversarial Networks](https://beyondminds.ai/advances-in-generative-adversarial-networks-gans/) ^advancesingans\n\t- Drawbacks of using GANs: Mode collapse, Convergence, Quality evaluation, Metrics\n\t- Techniques for Improving Performance:\n\t\t- Alternative Loss Functions: One of the most popular fixes to the shortcomings of GANs is the Wasserstein GAN. It essentially replaces the Jensen Shannon divergence of conventional GANs with the Earth Mover distance (Wasserstein-1 distance or EM distance)\n\t\t- Two Timescale Update Rule (TTUR): In this method, we use a different learning rate for the discriminator and the generator. Typically, a slower update rule is used for the generator and a faster update rule is used for the discriminator\n\t\t- Gradient Penalty: In the paper Wasserstein GAN GP, a simple gradient penalty was introduced which is added to the loss function to avoid exploding vanishing gradients and optimization issues (caused by weight clipping)\n\t\t- Spectral Normalization: weight normalization technique that is typically used on the Discriminator to enhance the training process\n\t\t- [Unrolling and Packing](http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/)\n\t\t- Stacking GANs: use multiple GANs placed consecutively, where each GAN solves an easier version of the problem.  For instance, FashionGAN used two GANs to perform localized image translation. Progressive GANs (ProGANs) can generate high quality images of excellent resolution.\n\t\t- Relativistic GANs: Conventional GANs measure the probability of the generated data being real. Relativistic GANs measure the probability of the generated data being “more realistic” than the real data. We can measure this “relative realism” using an appropriate distance measure, as mentioned in the RGAN paper\n\t\t- Self Attention Mechanism (SAGAN): The authors of Self Attention GANs claim that convolutions used for generating images look at information that are spread locally. That is, they miss out on relationships that span globally due to their restrictive receptive field. Self-Attention Generative Adversarial Network allows attention-driven, long-range dependency modeling for image generation tasks. \n\t\t- Miscellaneous Techniques: Feature Matching, Mini Batch Discrimination, Historical Averaging, One-sided Label Smoothing, Virtual Batch Normalization. \n\n## Courses\n- #COURSE [Generative Adversarial Networks ( DeepMind x UCL | Deep Learning Lectures | 9/12)](https://www.youtube.com/watch?v=wFsI2WqUfdA\u0026t=850s)\n\n\n## Talks\n- #TALK [GANs for Good - A Virtual Expert Panel by DeepLearning.AI](https://www.youtube.com/watch?v=9d4jmPmTWmc)\n- #TALK [A Friendly Introduction to Generative Adversarial Networks (GANs)](https://www.youtube.com/watch?v=8L11aMN5KY8)\n\n\n## Code\n- #CODE [Keras-GAN - Collection of Keras implementations of GANs](https://github.com/eriklindernoren/Keras-GAN)\n- #CODE [Pytorch-GAN - Collection of Pytorch implementations of GANs](https://github.com/eriklindernoren/PyTorch-GAN)\n- #CODE [Generative models in Tensorflow and Pytorch](https://github.com/wiseodd/generative-models)\n- #CODE [Tensorflow generative model collection](https://github.com/hwalsuklee/tensorflow-generative-model-collections)\n- #CODE [ydata-synthetic](https://github.com/ydataai/ydata-synthetic)\n\t- This repository contains material related with GANs for synthetic data generation, in particular regular tabular data and time-series\n\n\n## References\n- #PAPER [Generative Adversarial Networks (Goodfellow 2014)](http://arxiv.org/abs/1406.2661)\n\t- [Paper explained](https://www.youtube.com/watch?v=eyxmSmjmNS0)\n- #PAPER [GAN to convert text descriptions into images (Reed 2016)](https://arxiv.org/abs/1605.05396)\n- #PAPER [Unsupervised representation learning with GANs (Radford 2016)](https://arxiv.orga/abs/1511.06434v2)\n\t- Although GANs were already introduced in 2014 by Ian Goodfellow, it wasn't until the publication of this paper detailing a deep convolutional architecture (DCGAN) that GANs really took off \n\t- https://www.tensorflow.org/tutorials/generative/dcgan\n\t- https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8\n\t- #CODE https://github.com/tensorflow/models/blob/master/research/slim/nets/dcgan.py\n- #PAPER [Deconvolution and Checkerboard Artifacts (Odena 2016)](https://distill.pub/2016/deconv-checkerboard/)\n- #PAPER [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets (Chen 2016)](https://arxiv.org/abs/1606.03657)\n\t- https://wiseodd.github.io/techblog/2017/01/29/infogan/\n- #PAPER [Checkerboard artifact free sub-pixel convolution: A note on sub-pixel convolution, resize convolution and convolution resize (Aitken 2017)](https://arxiv.org/abs/1707.02937)\n- #PAPER [Wasserstein GAN (Arjovsky 2017)](https://arxiv.org/abs/1701.07875)\n\t- [From GAN to Wasserstein GAN](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html#wasserstein-gan-wgan )\n- #PAPER [Improved Training of Wasserstein GANs (Gulrajani 2017)](https://arxiv.org/abs/1704.00028) ^wgangp\n- #PAPER [Bayesian GAN (Saatchi 2017)](https://arxiv.org/abs/1705.09558)\n\t- #CODE https://github.com/andrewgordonwilson/bayesgan\n- #PAPER [WaterGAN: Unsupervised Generative Network to Enable Real-time Color Correction of Monocular Underwater Images (Li 2017)](https://arxiv.org/abs/1702.07392 )\n- #PAPER [A Style-Based Generator Architecture for Generative Adversarial Networks, StyleGAN (Karras 2018)](https://arxiv.org/abs/1812.04948 )\n\t- #TALK https://youtu.be/kSLJriaOumA \n\t- #CODE https://github.com/NVlabs/stylegan \n\t- [FFHQ](https://github.com/NVlabs/ffhq-dataset )\n- #PAPER [The relativistic discriminator: a key element missing from standard GAN (Jolicoeur-Martineau 2018)](https://arxiv.org/abs/1807.00734) ^190c58\n- #PAPER [From GAN to WGAN (Wenb 2019)](https://arxiv.org/abs/1904.08994)\n- #PAPER [Time Series Simulation by Conditional Generative Adversarial Net (Fu 2019)](https://arxiv.org/abs/1904.11419)\n- #PAPER [HoloGAN: Unsupervised learning of 3D representations from natural images (Nguyen-Phuoc 2019)](https://arxiv.org/abs/1904.01326 )\n\t- https://www.monkeyoverflow.com/#/hologan-unsupervised-learning-of-3d-representations-from-natural-images/ \n\t- #TALK https://www.youtube.com/watch?v=z2DnFOQNECM\n- #PAPER #REVIEW [A Survey on Generative Adversarial Networks: Variants, Applications,and Training (Jabbar 2020)](https://arxiv.org/abs/2006.05132)\n- #PAPER #REVIEW [A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications (Gui 2020)](https://arxiv.org/abs/2001.06937)\n- #PAPER [Implicit competitive regularization in GANs (Schafer 2020)](https://arxiv.org/abs/1910.05852)\n- #PAPER [Training Generative Adversarial Networks with Limited Data (Karras 2020)](https://arxiv.org/abs/2006.06676)\n- #PAPER [Gradient-Guided Dynamic Efficient Adversarial Training (Waag 2021)](https://arxiv.org/abs/2103.03076)\n\t- #CODE https://github.com/locuslab/fast_adversarial\n\t- The goal of DEAT is to improve adversarial training while maintaining effectiveness. It begins by training one batch replay and gradually increases it during training\n\t- This method reduces large amount of computation when doing backpropagation and consequently achieves a more efficient training paradigm\n- #PAPER [ExGAN: Adversarial Generation of Extreme Samples (Bathia 2021)](https://arxiv.org/abs/2009.08454)\n\t- #CODE https://github.com/Stream-AD/ExGAN\n\t- Existing approaches based on GANs excel at generating realistic samples, but seek to generate typical samples, rather than extreme samples\n\t- ExGAN is a GAN-based approach to generate realistic and extreme samples. To model the extremes of the training distribution in a principled way, our work draws from Extreme Value Theory (EVT), a probabilistic approach for modelling the extreme tails of distributions\n\n\n## Subtopics\n\n### GANs for super-resolution\nSee \"GAN-based\" section in [[AI/Computer Vision/Super-resolution]]\n\n\n### GANs for missing data, imputation and inpainting\nSee \"GAN-based\" section in [[AI/Computer Vision/Inpainting and restoration]]\n\n\n### Image-to-image translation. Conditional GANs\nSee \"GAN-based\" section in [[AI/Computer Vision/Image-to-image translation]]\n\n\n### GANs for spatio-temporal data generation\n- #PAPER [COT-GAN: Generating Sequential Data via Causal Optimal Transport (Xu 2020)](https://arxiv.org/abs/2006.08571)\n- #PAPER [SPATE-GAN: Improved Generative Modeling of Dynamic Spatio-Temporal Patterns with an Autoregressive Embedding Loss (Klemmer 2021)](https://arxiv.org/abs/2109.15044#) ^spate-gan\n\t- #CODE https://github.com/konstantinklemmer/spate-gan\n\n\n### GANs for representation learning and image synthesis \n- #PAPER [Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks, Laplacian GAN (Denton 2015)](https://arxiv.org/abs/1506.05751)\n- #PAPER [Adversarial feature learning, BiGAN (Donahue 2017)](https://arxiv.org/abs/1605.09782)\n- #PAPER [Large Scale Adversarial Representation Learning, BigBiGAN (Donahue 2019)](https://arxiv.org/abs/1907.02544)\n- #PAPER [Large Scale GAN Training for High Fidelity Natural Image Synthesis, BigGAN (Brock 2019)](https://arxiv.org/abs/1809.11096)\n- #PAPER [Self-Attention GANs, SAGAN (Zhang 2019)](https://arxiv.org/abs/1805.08318) ^sagan\n\t- #CODE https://github.com/brain-research/self-attention-gan\n- #PAPER [In-domain GAN Inversion for Real Image Editing (Zhu 2020)](https://genforce.github.io/idinvert/)\n\t- [Paper explained](https://www.youtube.com/watch?v=2qMw8sOsNg0)\n- #PAPER [High-Fidelity Generative Image Compression (Mentzer 2020)](https://arxiv.org/abs/2006.09965)\n\t- https://hific.github.io/\n- #PAPER [Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications (Liu 2020)](https://arxiv.org/abs/2008.02793)\n- #PAPER [Image Synthesis with Adversarial Networks: a Comprehensive Survey and Case Studies (Shamsolmoali 2020)](https://arxiv.org/abs/2012.13736)\n- #PAPER [Cross-Modal Contrastive Learning for Text-to-Image Generation (Zhang 2021)](https://arxiv.org/abs/2101.04702)\n\t- https://ai.googleblog.com/2021/05/cross-modal-contrastive-learning-for.html\n\t- text-to-image generation by learning to maximize the mutual information between image and text using inter-modal (image-text) and intra-modal (image-image) contrastive losses\n- #PAPER [TriGAN: image-to-image translation for multi-source domain adaptation (Roy 2021)](https://link.springer.com/article/10.1007/s00138-020-01164-4)\n\t- approach for multi-source domain adaptation (MSDA) based on generative adversarial networks\n- #PAPER [Sketch Your Own GAN (Wang 2021)](https://arxiv.org/abs/2108.02774)\n- #PAPER [Instance-Conditioned GAN (Casanova 2021)](https://arxiv.org/abs/2109.05070)\n\t- #CODE https://paperswithcode.com/paper/instance-conditioned-gan?from=n17\n\n\n### Semi-supervised GANs\n- #PAPER [Improved Techniques for Training GANs (Saliman 2016)](https://arxiv.org/abs/1606.03498) ^improvedgans\n\t- https://towardsdatascience.com/semi-supervised-learning-with-gans-9f3cb128c5e\n\t- https://hjweide.github.io/semi-supervised-dcgan\n- #PAPER [Semi-Supervised Learning with Generative Adversarial Networks (Odena 2016)](https://arxiv.org/abs/1606.01583)\n\t- #CODE https://github.com/tryambak2019/SGAN\n- #PAPER [Semi and Weakly Supervised Semantic Segmentation Using Generative Adversarial Network (Suoly 2017)](https://arxiv.org/abs/1703.09695)\n- #PAPER [Semi-supervised Learning in Generative Adversarial Networks, review (2018)](https://farzadab.github.io/assets/projects/pdf/Review__SSL_in_GANs.pdf)\n    - The GAN framework can be integrated with almost any available neural network classifier in order to make use of unlabeled data\n\n\n### Few/one-shot learning GANs \nSee \"Few one-shot learning GANs\" section in [[AI/One, few-shot learning]]\n\n\n### GANs for anomaly detection\n- #PAPER [A Survey on GANs for Anomaly Detection (Di Mattia 2019)](https://arxiv.org/abs/1906.11632 )\n- #PAPER [TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks (Geiger 2020)](https://arxiv.org/abs/2009.07769)\n\t- #CODE ^oriontfanomalies in [Anomaly and Outlier Detection](AI/Anomaly%20and%20Outlier%20Detection.md)\n\t- https://analyticsindiamag.com/hands-on-guide-to-tadgan-with-python-codes/","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/GFlowNets":{"title":"GFlowNets","content":"## Resources\n- [Generative Flow Networks (Bengio)](https://yoshuabengio.org/2022/03/05/generative-flow-networks/)\n\n## Talks\n- #TALK [GFlowNets for generative active learning | Amazon Science](https://www.youtube.com/watch?v=2s_GtmofbyU)\n- #TALK [Prof. YOSHUA BENGIO - GFlowNets, Consciousness \u0026 Causality (Podcast, discussion)](https://www.youtube.com/watch?v=M49TMqK5uCE)\n- #TALK [Confiance.ai Day 2021 - Yoshua Bengio, Director, Mila : GFlowNets for Generative Active Learning](https://www.youtube.com/watch?v=Ww9c9u_nTjQ)\n\n## References\n- #PAPER [Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation (Bengio 2021)](https://arxiv.org/abs/2106.04399)\n\t- #CODE https://github.com/GFNOrg/gflownet\n\t- http://folinoid.com/w/gflownet/\n- #PAPER [GFlowNet Foundations (Bengio 2021)](https://arxiv.org/abs/2111.09266)\n\t- Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function\n\t- https://syncedreview.com/2021/11/25/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-152/","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/GNNs":{"title":"Graph neural networks (GNNs)","content":"\u003e A GNN is an optimizable transformation on all attributes of the graph (nodes, edges, global-context) that preserves graph symmetries (permutation invariances). Graph Neural networks (GNNs) are being widely adopted for diverse applications and domains. This is in part due to their effectiveness on complex data structures, improved performance and scalability, and availability of approaches\n\n## Resources\n- [A Gentle Introduction to Graph Neural Networks](https://distill.pub/2021/gnn-intro/)\n- [Must read papers on GNNs](https://github.com/thunlp/GNNPapers)\n- [Graph Neural Networks beyond Weisfeiler-Lehman and vanilla Message Passing](https://towardsdatascience.com/graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing-bc8605fa59a)\n- [Time Series Forecasting with Graph Convolutional Neural Network](https://towardsdatascience.com/time-series-forecasting-with-graph-convolutional-neural-network-7ffb3b70afcf)\n- https://medium.com/dair-ai/an-illustrated-guide-to-graph-neural-networks-d5564a551783\n- [Graph Convolutional Networks](http://tkipf.github.io/graph-convolutional-networks/)\n\n## Talks\n- #TALK [Intro to graph neural networks (ML Tech Talks, Deepmind)](https://www.youtube.com/watch?v=8owQBFAHw7E)\n\n## Code\n- #CODE [TensorFlow GNN](https://github.com/tensorflow/gnn)\n\t- #PAPER [TF-GNN: Graph Neural Networks in TensorFlow (Ferludin 2022)](https://arxiv.org/pdf/2207.03522)\n\t- https://blog.tensorflow.org/2021/11/introducing-tensorflow-gnn.html\n\t- https://venturebeat.com/2021/11/18/google-releases-tf-gnn-for-creating-graph-neural-networks-in-tensorflow/\n- #CODE [DGL - Deep graph library](https://github.com/dmlc/dgl)\n\t- https://www.dgl.ai/\n- #CODE [Pytorch geometric](https://github.com/rusty1s/pytorch_geometric)\n- #CODE [Spektral - Graph Neural Networks with Keras and Tensorflow 2](https://github.com/danielegrattarola/spektral)\n- #CODE [Deep Graph Library (DGL)](https://github.com/dmlc/dgl) \n\t- http://dgl.ai\n\t- Python package built to ease deep learning on graph, on top of existing DL frameworks. \n\t- It makes implementing graph neural networks (including Graph Convolution Networks, TreeLSTM, and many others) easy while maintaining high computation efficiency.\n- #CODE [DIG: A Turnkey Library for Diving into Graph Deep Learning Research](https://github.com/divelab/DIG)\n- #CODE [PyTorch Geometric Temporal](https://github.com/benedekrozemberczki/pytorch_geometric_temporal)\n\t- A Temporal Extension Library for PyTorch Geometric\n- #CODE [PyNeuraLogic](https://github.com/LukasZahradnik/PyNeuraLogic)\n\t- https://pyneuralogic.readthedocs.io/\n\t- PyNeuraLogic lets you use Python to create Differentiable Logic Programs\n\t- https://towardsdatascience.com/beyond-graph-neural-networks-with-pyneuralogic-c1e6502c46f7\n\n## References\n- #PAPER [Dynamic Spatial-Temporal Graph Convolutional Neural Networks for Traffic Forecasting (Diao 2019)](https://www.aaai.org/ojs/index.php/AAAI/article/view/3877)\n- #PAPER [A Comprehensive Survey on Graph Neural Networks (Wu 2019)](https://arxiv.org/abs/1901.00596)\n- #PAPER #REVIEW [A Comprehensive Survey on Graph Neural Networks (Wu 2019)](https://arxiv.org/pdf/1901.00596)\n- #PAPER [Graph Neural Networks for Decentralized Controllers (Gama 2020)](https://arxiv.org/abs/2003.10280 )\n- #PAPER [Learning to Simulate Complex Physics with Graph Networks (Sanchez-Gonzalez 2020)](https://arxiv.org/abs/2002.09405)\n\t- [Two minute papers](https://www.youtube.com/watch?v=2Bw5f4vYL98)\n- #PAPER [DeepSphere: a graph-based spherical CNN (Defferrard 2020)](https://arxiv.org/abs/2012.15000) ^deepsphere\n\t- #CODE https://github.com/deepsphere\n- #PAPER #REVIEW [Graph neural networks: A review of methods and applications (Zhou 2020)](https://www.sciencedirect.com/science/article/pii/S2666651021000012)\n- #PAPER [VQ-GNN: A Universal Framework to Scale up Graph Neural Networks using Vector Quantization (Ding 2021)](https://arxiv.org/abs/2110.14363)\n- #PAPER [Nested Graph Neural Networks (Zhang 2021)](https://arxiv.org/abs/2110.13197)\n\t- #CODE https://paperswithcode.com/paper/nested-graph-neural-networks?from=n19\n- #PAPER [A Heterogeneous Graph Based Framework for Multimodal Neuroimaging Fusion Learning (Shi 2021)](https://arxiv.org/abs/2110.08465)\n\t- #CODE https://github.com/shigen97/hebraingnn\n\t- self-supervised pretraining contrastive strategy based on a heterogeneous brain network to address the potential overfitting problem caused by the conflict between a large parameter size and a small medical data sample size\n- #PAPER [Vision GNN: An Image is Worth Graph of Nodes (Han 2022)](https://arxiv.org/pdf/2206.00272v2)\n\t- #CODE https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/vig_pytorch\n\t- proposeD to represent the image as a graph structure and introduce a new Vision GNN (ViG) architecture to extract graph level feature for visual tasks\n\t- first split the image to a number of patches which are viewed as nodes, and construct a graph by connecting the nearest neighbors\n\t- the ViG model is built based on the graph representation of images to transform and exchange information among all the nodes\n\t- ViG consists of two basic modules: Grapher module with graph convolution for aggregating and updating graph information, and FFN module with two linear layers for node feature transformation\n\t- https://www.marktechpost.com/2022/06/08/researchers-from-china-introduce-vision-gnn-vig-a-graph-neural-network-for-computer-vision-systems/\n\n### Graph convolutional networks\n- #PAPER [Structured Sequence Modeling with Graph Convolutional Recurrent Networks (Seo 2016)](https://arxiv.org/abs/1612.07659)\n\t- Graph Convolutional Recurrent Network (GCRN)\n- #PAPER [Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting (Yu 2018)](https://arxiv.org/abs/1709.04875 )\n- #PAPER #REVIEW [Graph Neural Networks: A Review of Methods and Applications (Zhou 2019)](https://arxiv.org/abs/1812.08434)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/GRUs":{"title":"Gated Recurrent Units (GRUs)","content":"\u003e GRU (Gated Recurrent Unit) aims to solve the vanishing gradient problem which comes with a standard recurrent neural network. GRU can also be considered as a variation on the LSTM. GRU’s got rid of the cell state and used the hidden state to transfer information. It also only has two gates, a reset gate and update gate\n\n\n## Resources\n- https://en.wikipedia.org/wiki/Gated_recurrent_unit \n- https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be\n- The update gate acts similar to the forget and input gate of an LSTM. It decides what information to throw away and what new information to add.\n- The reset gate is another gate is used to decide how much past information to forget.\n\n## References\n- #PAPER [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation (Cho 2014)](https://arxiv.org/abs/1406.1078v3)\n- #PAPER [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches (Cho 2014)](https://arxiv.org/abs/1409.1259)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Generative-modelling":{"title":"Generative modeling","content":"## Resources\n- [Generative models](https://openai.com/blog/generative-models/ )\n- [Deep Generative Models](https://www.cs.toronto.edu/~slwang/generative_model.pdf)\n- [Taxonomy of Generative Models](https://christineai.blog/taxonomy/)\n- Jakub Tomczak [blog](https://jmtomczak.github.io/blog.html):\n\t- [Introduction to deep generative modeling: Why, Where and How](https://jmtomczak.github.io/blog/1/1_introduction.html)\n\t- [Introduction to deep generative modeling: Energy-based Models](https://jmtomczak.github.io/blog/11/11_energy_based_models.html)\n\n\n## Courses\n- #COURSE [Deep Generative Modeling: VAEs and GANs (MIT 6.S191)](https://www.youtube.com/watch?v=rZufA635dq4\u0026t=1062s)\n- #COURSE [Deep Generative Models (Stanford CS236 - Fall 2021)](https://deepgenerativemodels.github.io/)\n- #COURSE [Deep Generative Models lecture (Carnegie Mellon University)](https://www.youtube.com/watch?v=qEbYtPhG768)\n\n\n## Subtopics\n### Autoencoders\nSee \"VAEs\" section in [[AI/Deep learning/Autoencoders]]\n\n### GANs\nSee [[AI/Deep learning/GANs]]\n\n### Normalizing flows\nSee [[AI/Deep learning/Normalizing flows]]\n\n### Diffusion models\nSee [[AI/Deep learning/Diffusion models]]\n\n### Generative models for Image data\nSee: \n- [[AI/Computer Vision/Image-to-image translation]]\n- \"GAN-based\" section in [[AI/Computer Vision/Image-to-image translation]]\n- \"GANs for representation learning and image synthesis\" section in [[AI/Deep learning/GANs]]\n- \"For Computer Vision\" section in [[AI/Deep learning/Transformers]] \n- [[AI/Deep learning/Diffusion models]]\n- [[AI/Deep learning/Multimodal learning]]\n\n- #PAPER [Video Pixel Networks (Kalchbrenner 2016)](https://arxiv.org/abs/1610.00527)\n- #PAPER [Pixel RNNs - Pixel Recurrent Neural Networks (van den Oord 2016)](https://arxiv.org/abs/1601.06759)\n\t- Pixel-RNN presents a novel architecture with recurrent layers and residual connections that predicts pixels across the vertical and horizontal axes. The architecture models the joint distribution of pixels as a product of conditional distributions of horizontal and diagonal pixels. The model achieves state-of-the-art in the generation of natural images.\n\t- https://medium.com/a-paper-a-day-will-have-you-screaming-hurray/day-4-pixel-recurrent-neural-networks-1b3201d8932d\n\t- https://christineai.blog/pixelcnn-and-pixelrnn/\n- #PAPER [Conditional Image Generation with PixelCNN Decoders (van den Oord 2016)](https://arxiv.org/abs/1606.05328)\n\t-  https://medium.com/a-paper-a-day-will-have-you-screaming-hurray/day-5-conditional-image-generation-with-pixelcnn-decoders-a8fc68b103a2\n\t-  #CODE https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/PixelCNN\n\t-  #CODE https://keras.io/examples/generative/pixelcnn/\n- #PAPER [PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications (Salimans 2017)](https://arxiv.org/abs/1701.05517)\n\t- #CODE https://github.com/openai/pixel-cnn\n\t- https://openreview.net/forum?id=BJrFC6ceg\u0026noteId=Bkc_sOZ4l\n- #PAPER [FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models (Grathwohl 2018)](https://arxiv.org/abs/1810.01367 )\n- #PAPER [Generating Realistic Geology Conditioned on Physical Measurements with Generative Adversarial Networks (Dupont 2018)](http://arxiv.org/abs/1802.03065) ^dupont18\n\t- Using G and D we want to generate realistic images conditioned on a set of known pixels\n\t- Total loss is a combination of a Prior loss (high score of generated images from D) and a Context loss (generated image should match the known pxs)\n\t- For the Context loss, a mask is used with smoothing\n- #PAPER [Parametric generation of conditional geological realizations using generative neural networks (Chan 2019)](https://link.springer.com/article/10.1007%2Fs10596-019-09850-7) ^chan19\n- #PAPER [Parametrization of Stochastic Inputs Using Generative Adversarial Networks With Application in Geology (Chan 2020)](https://www.frontiersin.org/articles/10.3389/frwa.2020.00005/full) ^chan20\n- #PAPER [Generative Models as Distributions of Functions (Dupont 2021)](https://arxiv.org/abs/2102.04776)\n\t- Generative models are typically trained on grid-like data such as images (tied to the underlying grid resolution)\n\t- Instead of discretized grids, they parametrized individual data points by continuous functions over which they learned distributions --\u003e generative models\n\t- Coordinate and feature pairs are treated as point clouds (sets with underlying notion of distance). Leveraged the PointConv framekwork \n\t- Their model can learn rich distributions of functions independently of data type and resolution. Application to [[AI/Computer Vision/Super-resolution]]\n- #PAPER [Score-Based Generative Modeling through Stochastic Differential Equations (Song 2021)](https://arxiv.org/abs/2011.13456v2)\n\t- #CODE https://paperswithcode.com/paper/score-based-generative-modeling-through-1\n- #PAPER [Diverse Generation from a Single Video Made Possible (Haim 2021)](https://arxiv.org/abs/2109.08591)\n- #PAPER [Autoregressive Image Generation using Residual Quantization (Lee 2022)](https://arxiv.org/pdf/2203.01941v2)            \n\t- #CODE https://github.com/kakaobrain/rq-vae-transformer\n- #PAPER [High-Resolution Image Synthesis with Latent Diffusion Models (Rombach 2022)](https://arxiv.org/pdf/2112.10752)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Geometric-deep-learning":{"title":"Geometric deep learning","content":"\u003e Geometric Deep Learning is an attempt for geometric unification of a broad class of ML problems from the perspectives of symmetry and invariance\n\n## References\n- [Geometric foundations of Deep Learning](https://towardsdatascience.com/geometric-foundations-of-deep-learning-94cdd45b451d)\n\n## Talks and courses\n- #TALK [Geometric Deep Learning: The Erlangen Programme of ML (M Bronstein, ICLR 2021 Keynote)](https://www.youtube.com/watch?v=w6Pw4MOzMuo)\n- #COURSE [Geometric Deep Learning](https://geometricdeeplearning.com/lectures/)\n\n## References\n- #PAPER #REVIEW [Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges (Bronstein 2021)](https://arxiv.org/abs/2104.13478)\n\t- https://geometricdeeplearning.com/\n\t- #TALK [ICLR 2021 Keynote](https://www.youtube.com/watch?v=w6Pw4MOzMuo) - \"Geometric Deep Learning: The Erlangen Programme of ML\" - M Bronstein\n\t- [ICLR Invited Talk on Geometric Deep Learning](https://blog.twitter.com/engineering/en_us/topics/insights/2021/iclr-invited-talk-on-geometric-deep-learning)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/LSTMs":{"title":"Long Short-Term Memory networks (LSTMs)","content":"\u003e One of the most innovative works in the NLP space is LSTMs, which can remember information from the way past and also selectively forget stuff that is not required. There are several architectures of LSTM units. A common architecture is composed of a cell (the memory part of the LSTM unit) and three \"regulators\", usually called gates, of the flow of information inside the LSTM unit: an input gate, an output gate and a forget gate. Some variations of the LSTM unit do not have one or more of these gates or maybe have other gates (for instance, GRUs do not have an output gate). The Forget gate decides what is relevant to keep from prior steps. The input gate decides what information is relevant to add from the current step. The output gate determines what the next hidden state should be\n\n## Resources\n- https://en.wikipedia.org/wiki/Long_short-term_memory\n- With a basic RNN cell, we see a massive drop in performance when it comes to long sequences and the network needs to remember patterns which have occurred way at the beginning to infer things correctly at a current time step. And this is because of exploding and vanishing gradients.\n- Then came Sepp Hochreiter and Jürgen Schmidhuber and invented LSTMs, which can remember information from the way past and also selectively forget stuff that is not required.\n- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n- http://machinelearningmastery.com/tune-lstm-hyperparameters-keras-time-series-forecasting/\n- http://machinelearningmastery.com/use-features-lstm-networks-time-series-forecasting/\n- http://blog.echen.me/2017/05/30/exploring-lstms/\n- https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4\n- https://rubikscode.net/2018/03/19/understanding-long-short-term-memory-networks-lstms/\n- https://eli.thegreenplace.net/2018/minimal-character-based-lstm-implementation/\n\n\n## References\n- #PAPER [Long Short-Term Memory (Hochreiter 1997)](https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735)\n- #PAPER [IndyLSTMs: Independently Recurrent LSTMs (Gonnet 2019)](https://arxiv.org/abs/1903.08023)\n\t- Independently Recurrent Long Short-term Memory cells (IndyLSTMs) differ from regular LSTM cells in that the recurrent weights are not modeled as a full matrix, but as a diagonal matrix, i.e.\\ the output and state of each LSTM cell depends on the inputs and its own output/state, as opposed to the input and the outputs/states of all the cells in the layer. The number of parameters per IndyLSTM layer, and thus the number of FLOPS per evaluation, is linear in the number of nodes in the layer, as opposed to quadratic for regular LSTM layers, resulting in potentially both smaller and faster models. IndyLSTMs, despite their smaller size, consistently outperform regular LSTMs both in terms of accuracy per parameter, and in best accuracy overall. We attribute this improved performance to the IndyLSTMs being less prone to overfitting.\n- #PAPER [Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks (Staudemeyer 2019)](https://arxiv.org/abs/1909.09586)\n- #PAPER [Sequencer: Deep LSTM for Image Classification (Tatsunami 2022)](https://arxiv.org/abs/2205.01972v2)            \n\t- #CODE https://github.com/okojoalg/sequencer","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/MLPs":{"title":"Multilayer perceptrons (MLPs)","content":"\u003e A multilayer perceptron (MLP) is a feed forward artificial neural network model that maps sets of input data onto a set of appropriate outputs. An MLP consists of multiple layers of nodes in a directed graph, with each layer fully connected to the next one. Except for the input nodes, each node is a neuron (or processing element) with a non linear activation function\n\n## Resources\n- MLP utilizes a supervised learning technique called back propagation for training the network\n- MLP is a modification of the standard linear perceptron and can distinguish data that is not linearly separable\n- [Multilayer Perceptron (MLP) vs Convolutional Neural Network in Deep Learning](https://medium.com/data-science-bootcamp/multilayer-perceptron-mlp-vs-convolutional-neural-network-in-deep-learning-c890f487a8f1)\n\n## Code\n- #CODE [MLP for MNIST](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py)\n- #CODE Sklearn MLP implementation: \n\t- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n\t- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\n\n\n## Perceptron\n- [History of the Perceptron](https://medium.com/@Jaconda/a-concise-history-of-neural-networks-2070655d3fec)\n- https://www.neuraldesigner.com/blog/perceptron-the-main-component-of-neural-networks\n- https://fr.mathworks.com/help/nnet/ug/perceptron-neural-networks.html\n- http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/\n- http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html\n\n\n## MLPs for vision and language\n- #PAPER [MLP-Mixer: An all-MLP Architecture for Vision (Tolstikhin 2021)](https://arxiv.org/abs/2105.01601v2)\n\t- #CODE https://paperswithcode.com/paper/mlp-mixer-an-all-mlp-architecture-for-vision?from=n9\n\t- CNNs are widely regarded as the go-to model for dealing with computer vision tasks. Attention-based architectures have also emerged as promising approaches that produce good performance on a variety of vision tasks. Despite this trend and the successes of attention and CNN architectures, this paper proposes a simple alternative architecture, MLP-Mixer, based on multi-layer perceptions, that produces competitive results on image classification benchmarks\n\t- MLP-Mixer contains two types of layers. One layer of MLPs applied independently to image patches and another layer of MLPs applied across patches. These layers achieve the effect of mixing per-location features and mixing spatial information, respectively \n\t- MLP-Mixer achieves competitive results on the ImageNet benchmark\n- #PAPER [RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition (Ding 2021)](https://arxiv.org/abs/2105.01883v1)\n\t- #CODE https://github.com/DingXiaoH/RepMLP\n- #PAPER [ResMLP: Feedforward networks for image classification with data-efficient training (Touvron 2021)](https://arxiv.org/abs/2105.03404)\n- #PAPER [Pay Attention to MLPs (Liu 2021)](https://arxiv.org/abs/2105.08050v2)\n\t- #CODE https://paperswithcode.com/paper/pay-attention-to-mlps?from=n10\n\t- https://www.infoq.com/news/2021/10/google-mlp-vision-language/\n\t- Researchers at Google Brain have announced Gated Multi-Layer Perceptron (gMLP), a deep-learning model that contains only basic multi-layer perceptrons\n\t- gMLP aims to show that these simplified architectures can perform as well as Transformers on key vision and language applications. According to the authors, the results and comparisons show that attention is not critical for Vision Transformers\n\t- In fine-tuning tasks, gMLP can close the gap on Transformers by simply making the model substantially larger\n\t- gMLP can scale as well as Transformers over increased data and compute\n- #PAPER [MAXIM: Multi-Axis MLP for Image Processing (Tu 2022)](https://arxiv.org/abs/2201.02973v1)\n\t- #CODE https://paperswithcode.com/paper/maxim-multi-axis-mlp-for-image-processing?from=n23","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Multimodal-learning":{"title":"Multimodal learning, Foundation models","content":"\u003e General-purpose neural networks capable of handling diverse inputs and output tasks\n\n## Resources\n- [Multimodal Deep Learning](https://multimodal-dl.mpi-inf.mpg.de/)\n- https://paperswithcode.com/methods/category/vision-and-language-pre-trained-models\n- [Vision Language models: towards multi-modal deep learning](https://theaisummer.com/vision-language-models/)\n- [AI Image Generators Compared Side-By-Side Reveals Stark Differences](https://petapixel.com/2022/08/22/ai-image-generators-compared-side-by-side-reveals-stark-differences/)\n\n### Models\n- [Midjourney](https://www.midjourney.com/home/)\n- [DALLE-2](https://openai.com/dall-e-2/)\n- [IMAGEN](https://imagen.research.google/)\n- [Stable Diffusion](https://github.com/CompVis/stable-diffusion)\n\t- https://stability.ai/blog/stable-diffusion-announcement\n\t- [DreamStudio](https://beta.dreamstudio.ai) \n\n\n## Code\n- #CODE [Pykale (in pytorch)](https://github.com/pykale/pykale)\n\n## Courses\n- #COURSE [Multimodal Machine Learning (Carnegie Mellon University)](https://www.youtube.com/watch?v=VIq5r7mCAyw\u0026list=PL-Fhd_vrvisNup9YQs_TdLW7DQz-lda0G)\n\t- https://cmu-multicomp-lab.github.io/mmml-course/fall2020/\n\n\n## References\n- #PAPER [Multi-modal Transformer for Video Retrieval (Gabeur 2020)](https://arxiv.org/abs/2007.10639)\n- #PAPER #REVIEW [Recent Advances and Trends in Multimodal Deep Learning: A Review (Summaira 2021)](https://arxiv.org/abs/2105.11087)\n- #PAPER [Perceiver: General Perception with Iterative Attention (Jaegle 2021)](https://arxiv.org/abs/2103.03206)\n\t- https://www.zdnet.com/article/googles-supermodel-deepmind-perceiver-is-a-step-on-the-road-to-an-ai-machine-that-could-process-everything/\n\t- Multi-model with image, audio, video, 3d point clouds\n- #PAPER [PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python (Lu 2021)](https://arxiv.org/abs/2106.09756v1) ^pykale\n- #PAPER [Perceiver IO: A General Architecture for Structured Inputs \u0026 Outputs (Jaegle 2021)](https://arxiv.org/abs/2107.14795v2)\n\t- #CODE https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for\n- #PAPER [VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text (Akbari 2021)](https://arxiv.org/abs/2104.11178v2)\n\t- #CODE https://paperswithcode.com/paper/vatt-transformers-for-multimodal-self\n\t- VATT is trained to learn multimodal representations from unlabeled data using Transformer architectures\n- #PAPER [NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion (Wu 2021)](https://arxiv.org/abs/2111.12417v1)\n\t- #CODE https://paperswithcode.com/paper/nuwa-visual-synthesis-pre-training-for-neural\n\t- [Paper explained](https://www.youtube.com/watch?v=InhMx1h0N40\u0026list=WL\u0026index=50)\n\t- NÜWA consists of an adaptive encoder that takes either text or visual input, and a pre-trained decoder shared by 8 visual tasks\n\t- 3D Nearby Attention mechanism (3DNA) is proposed to reduce computational complexity and improve visual quality of results, by considering the locality characteristics for both spatial and temporal axes to better deal with the nature of the visual data\n- #PAPER [data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language (Baevski 2022)](https://arxiv.org/abs/2202.03555)\n\t- #CODE https://github.com/pytorch/fairseq/tree/main/examples/data2vec\n\t- https://ai.facebook.com/blog/the-first-high-performance-self-supervised-algorithm-that-works-for-speech-vision-and-text/\n- #PAPER [A Generalist Agent (Reed 2022)](https://arxiv.org/abs/2205.06175v1)\n\t- [Paper explained](https://www.youtube.com/watch?v=wSQJZHfAg18)\n\t- New approach, inspired by large-scale language models, that acts a single generalist agent. The agent, called Gato, is built to work as a multi-modal, multi-task, multi-embodiment generalist policy\n- #PAPER [Language Models are General-Purpose Interfaces (Hao 2022)](https://arxiv.org/pdf/2206.06336v1)\n\t- #CODE https://github.com/microsoft/unilm\n- #PAPER [NUWA-Infinity: Autoregressive over Autoregressive Generation for Infinite Visual Synthesis (Wu 2022)](https://arxiv.org/pdf/2207.09814)\n\t- #CODE https://github.com/microsoft/NUWA\n\t- https://nuwa-infinity.microsoft.com/#/\n\n### Vision and language models\n- #PAPER [DALL-E - Creating Images from Text (Ramesh 2021)](https://openai.com/blog/dall-e/)\n\t- https://www.technologyreview.com/2021/01/05/1015754/avocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense/\n\t- [Blogpost explained](https://www.youtube.com/watch?v=j4xgkjWlfL4)\n\t- #CODE https://github.com/EleutherAI/DALLE-mtf\n\t- Multi-modal text and vision\n\t- [DALL-E mini](https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA)\n- #PAPER [Learning Transferable Visual Models From Natural Language Supervision (Radford 2021)](https://arxiv.org/pdf/2103.00020v1)            \n\t- #CODE https://paperswithcode.com/paper/learning-transferable-visual-models-from#code\n\t- #CODE https://github.com/openai/CLIP\n- #PAPER [SimVLM: Simple Visual Language Model Pretraining with Weak Supervision (Wang 2022)](https://arxiv.org/pdf/2108.10904v2)            \n- #PAPER [Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework (Wang 2022)](https://arxiv.org/pdf/2202.03052v1)            \n- #PAPER [Flamingo: a Visual Language Model for Few-Shot Learning (Alayrac 2022)](https://arxiv.org/abs/2204.14198v1)\n\t- #CODE https://github.com/lucidrains/flamingo-pytorch\n- #PAPER [LViT: Language meets Vision Transformer in Medical Image Segmentation (Li 2022)](https://arxiv.org/abs/2206.14718v1) ^lvit\n\t- #CODE https://github.com/HUANGLIZI/LViT\n- #PAPER [Scaling Autoregressive Models for Content-Rich Text-to-Image Generation (Yu 2022)](https://arxiv.org/pdf/2206.10789v1)\n\t- #CODE https://github.com/google-research/parti\n\t- https://parti.research.google/\n\t- Pathways Autoregressive Text-to-Image model (Parti), an autoregressive text-to-image generation model that achieves high-fidelity photorealistic image generation and supports content-rich synthesis involving complex compositions and world knowledge\n- #PAPER [CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers (Ding 2022)](https://arxiv.org/pdf/2204.14217)\n\t- #CODE https://github.com/THUDM/CogView2\n- #PAPER [Imagen - Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding (Saharia 2022)](https://arxiv.org/pdf/2205.11487v1)            \n\t- https://imagen.research.google/\n\t- Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation\n\t- #CODE https://paperswithcode.com/paper/photorealistic-text-to-image-diffusion-models\n- #PAPER [Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks (Lu 2022)](https://arxiv.org/pdf/2206.08916)\n\t- https://unified-io.allenai.org/\n- #PAPER #REVIEW [A Survey of Vision-Language Pre-Trained Models (Du 2022)](https://arxiv.org/pdf/2202.10936)            \n- #PAPER #REVIEW [The Creativity of Text-to-Image Generation (Oppenlaender 2022)](https://arxiv.org/pdf/2206.02904)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Neural-Cellular-Automata":{"title":"Neural Cellular Automata","content":"## References\n- #PAPER [Growing Neural Cellular Automata (Mordvintsev 2020)](https://distill.pub/2020/growing-ca/)\n\t- [Paper explained](https://www.youtube.com/watch?v=9Kec_7WFyp0)\n\t- #CODE https://github.com/chenmingxiang110/Growing-Neural-Cellular-Automata\n- #PAPER [Self-Organising Textures (Niklasson 2021)](https://distill.pub/selforg/2021/textures/)\n- #PAPER [Variational Neural Cellular Automata](https://arxiv.org/pdf/2201.12360)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Neural-ODEs":{"title":"Neural Ordinary Differential Equations","content":"## Resources\n- https://github.com/Zymrael/awesome-neural-ode\n- [Understanding Neural ODE's](https://jontysinai.github.io/jekyll/update/2019/01/18/understanding-neural-odes.html)\n- [Neural Ordinary Differential Equations and Dynamics Models](https://medium.com/@ml.at.berkeley/neural-ordinary-differential-equations-and-dynamics-models-1a4277fbb80)\n\t- ODEs are often used to describe the time derivatives of a physical situation, referred to as the dynamics. Knowing the dynamics allows us to model the change of an environment, like a physics simulation, unlocking the ability to take any starting condition and model how it will change. With Neural ODEs, we don’t define explicit ODEs to document the dynamics, but learn them via ML.\n\t- Strong connection with [[AI/Deep learning/Residual and dense neural networks]]. Why do residual layers help networks achieve higher accuracies and grow deeper? Firstly, skip connections help information flow through the network by sending the hidden state, h(t), along with the transformation by the layer, f(h(t)), to layer t+1, preventing important information from being discarded by f. Secondly, residual layers can be stacked, forming very deep networks.\n\t- However, ResNets still employ many layers of weights and biases requiring much time and data to train. On top of this, the backpropagation algorithm on such a deep network incurs a high memory cost to store intermediate values.\n\t- Continuous depth ODENets are evaluated using black box ODE solvers, but first the parameters of the model must be optimized via gradient descent. To do this, we need to know the gradient of the loss with respect to the parameters, or how the loss function depends on the parameters in the ODENet.\n\t- In deep learning, backpropagation is the workhorse for finding this gradient, but this algorithm incurs a high memory costs to store the intermediate values of the network. On top of this, the sheer number of chain rule applications produces numerical error. Since an ODENet models a differential equation, these issues can be circumvented using sensitivity analysis methods developed for calculating gradients of a loss function with respect to the parameters of the system producing its input.\n\n\n## References\n- #PAPER [Neural Ordinary Differential Equations (TQ Chen 2018)](https://arxiv.org/abs/1806.07366)\n\t- #CODE https://github.com/JSeam2/Neural-Ordinary-Differential-Equations\n\t- #CODE https://github.com/jason71995/Keras_ODENet\n\t- [Neural Ordinary Differential Equations - Best Paper Awards NeurIPS 2018](https://www.youtube.com/watch?v=V6nGT0Gakyg)\n\t- https://towardsdatascience.com/paper-summary-neural-ordinary-differential-equations-37c4e52df128\n\t- https://braindump.jethro.dev/posts/neural_ode/\n\t- https://msurtsukov.github.io/Neural-ODE/\n\t- https://github.com/msurtsukov/neural-ode/blob/master/Neural%20ODEs.ipynb\n\t- https://www.youtube.com/watch?v=jltgNGt8Lpg\n- #PAPER [Augmented Neural ODEs (Dupont 2019)](https://arxiv.org/abs/1904.01681)\n- #PAPER [Differential Bayesian Neural Nets (Look 2020)](https://arxiv.org/abs/1912.00796)\n\t- Neural Ordinary Differential Equations (N-ODEs) are a powerful building block for learning systems, which extend residual networks to a continuous-time dynamical system. Propose a Bayesian version of N-ODEs that enables well-calibrated quantification of prediction uncertainty, while maintaining the expressive power of their deterministic counterpart.\n- #THESIS/MSC [Generative Modeling with Neural Ordinary Differential Equations (2019)](https://uwspace.uwaterloo.ca/bitstream/handle/10012/15354/Dockhorn_Tim.pdf)\n- #PAPER [Universal Differential Equations for Scientific Machine Learning (Rackauckas 2020)](https://arxiv.org/abs/2001.04385)\n\t- https://www.stochasticlifestyle.com/how-to-train-interpretable-neural-networks-that-accurately-extrapolate-from-small-data/\n- #PAPER [Neural Differential Equations for Single Image Super-Resolution (Le Scao 2020)](https://arxiv.org/pdf/2005.00865)\n- #PAPER [Liquid Time-constant Networks (Hasani 2020)](https://arxiv.org/abs/2006.04439)\n\t- #TALK https://www.youtube.com/watch?v=IlliqYiRhMU\n\t- #CODE https://github.com/raminmh/liquid_time_constant_networks\n\t- https://news.mit.edu/2021/machine-learning-adapts-0128\n- #PAPER [On Neural Differential Equations (Kidger 2022)](https://arxiv.org/abs/2202.02435)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Neural-processes":{"title":"Neural processes","content":"\u003e A Neural Process (NP) is a map from a set of observed input-output pairs to a predictive distribution over functions, which is designed to mimic other stochastic processes' inference mechanisms. NPs define distributions over functions, are capable of rapid adaptation to new observations, and can estimate the uncertainty in their predictions\n\n## Resources\n- [The Neural Process Family](https://yanndubs.github.io/Neural-Process-Family/text/Intro.html)\n- [Conditional Neural Process](https://yanndubs.github.io/Neural-Process-Family/reproducibility/CNP.html)\n\n## References\n- #PAPER [Neural Processes (Garnelo 2018)](https://arxiv.org/pdf/1807.01622)            \n- #PAPER [Conditional Neural Processes (Garnelo 2018)](https://arxiv.org/abs/1807.01613)\n- #PAPER [Residual Neural Processes (Lee 2020)](https://ojs.aaai.org//index.php/AAAI/article/view/5883)\n- #PAPER [Convolutional Conditional Neural Processes (Gordon 2020)](https://arxiv.org/abs/1910.13556)\n\t- #CODE https://github.com/cambridge-mlg/convcnp\n\t- https://yanndubs.github.io/Neural-Process-Family/reproducibility/ConvCNP.html\n\t- See [[AI/Deep learning/CNNs]]\n- #PAPER [The Gaussian Neural Process (Bruinsma 2021)](https://arxiv.org/pdf/2101.03606)            \n- #PAPER [GP-ConvCNP: Better Generalization for Convolutional Conditional Neural Processes on Time Series Data (Petersen 2021)](https://arxiv.org/pdf/2106.04967)            \n\t- #CODE https://github.com/MIC-DKFZ/gpconvcnp\n- #PAPER [Conditional Temporal Neural Processes with Covariance Loss (Yoo 2021)](http://proceedings.mlr.press/v139/yoo21b.html)\n- #PAPER [Contrastive Conditional Neural Processes (Ye 2022)](https://arxiv.org/abs/2203.03978)\n\t- Conditional Neural Processes (CNPs) bridge neural networks with probabilistic inference to approximate functions of Stochastic Processes under meta-learning settings\n\t- Proposed to equip CNPs by 1) aligning prediction with encoded ground-truth observation, and 2) decoupling metarepresentation adaptation from generative reconstruction","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Normalizing-flows":{"title":"Normalizing flows","content":"\u003e Normalizing flow models are generative models, i.e. they infer the underlying probability distribution of an observed dataset. With that distribution we can do a number of interesting things, namely sample new realistic points and query probability densities\n\n## Resources\n- https://github.com/janosh/awesome-normalizing-flows\n- [Flow-based Deep Generative Models](https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html)\n- [Normalizing flow models](https://deepgenerativemodels.github.io/notes/flow/)\n- http://akosiorek.github.io/ml/2018/04/03/norm_flows.html \n\n\n## Talks\n- #TALK [Introduction to Normalizing Flows (ECCV2020 Tutorial)](https://www.youtube.com/watch?v=u3vVyFVU_lI)\n\n\n## Code\n- #CODE [Normalizing Flows in JAX](https://github.com/ChrisWaites/jax-flows)\n- #CODE [NuX - Normalizing Flows using JAX](https://github.com/Information-Fusion-Lab-Umass/NuX)\n\n\n## References\n- #PAPER [NICE: Non-linear Independent Components Estimation (Dinh 2015)](https://arxiv.org/abs/1410.8516)\n- #PAPER [Glow: Generative Flow with Invertible 1x1 Convolutions (Kingma 2018)](https://arxiv.org/abs/1807.03039)\n\t- https://openai.com/blog/glow/\n\t- #CODE https://github.com/openai/glow\n- #PAPER #REVIEW [Normalizing Flows: An Introduction and Review of Current Methods (Kobyzev 2020)](https://arxiv.org/abs/1908.09257)\n\n### Image-to-image translation\nSee [[AI/Computer Vision/Image-to-image translation#Flow-based]]","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Probabilistic-deep-learning":{"title":"Probabilistic deep learning","content":"\u003e See: \n\u003e - [[AI/Bayesian modelling]] \n\u003e - [[AI/Deep learning/GFlowNets]]\n\n## Resources\n- [A Comprehensive Introduction to Bayesian Deep Learning](https://jorisbaan.nl/2021/03/02/introduction-to-bayesian-deep-learning.html)\n- [Bayesian Neural Network tutorial](http://edwardlib.org/tutorials/bayesian-neural-network)\n- [Bayesian Deep Learning - NeurIPS Workshop](http://bayesiandeeplearning.org/ )\n- [Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe AI](https://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai/)\n- [Making Your Neural Network Say “I Don’t Know” — Bayesian NNs using Pyro and PyTorch](https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd)\n- [Building a Bayesian deep learning classifier](https://towardsdatascience.com/building-a-bayesian-deep-learning-classifier-ece1845bc09)\n- [Physics - a Gateway to Bayesian Deep Learning](https://github.com/henripal/sgld)\n- [Bayesian deep learning with Fastai : how not to be uncertain about your uncertainty!](https://towardsdatascience.com/bayesian-deep-learning-with-fastai-how-not-to-be-uncertain-about-your-uncertainty-6a99d1aa686e)\n\t- BNNs are a way to add uncertainty handling in our models. The idea is simple, instead of having deterministic weights that we learn, we instead learn the parameters of a random variable which we will use to sample our weights during forward propagation. Then, to learn the parameters, we will use backpropagation, sometimes with a little trick to make our parameters differentiable.\n\t- Dropout is a way to make your Neural Networks Bayesian almost for free, and to use it during inference you just have to keep the Dropout, and sample several models, this is called MC Dropout.\n\n ### Monte Carlo Dropout\n- [Monte Carlo Dropout](https://towardsdatascience.com/monte-carlo-dropout-7fd52f8b6571)\n- [What is MC Dropout](https://datascience.stackexchange.com/questions/44065/what-is-monte-carlo-dropout)\n- normal dropout (only at training time) serves as a regularization to avoid overfitting. During test time, dropout is not applied; instead, all nodes/connections are present, but the weights are adjusted accordingly (e.g. multiplied by the keep ratio, which is 1 - dropout_ratio). Such a model during test time can be understood as a *average* of an ensemble of neural networks.\n- Notice that for normal dropout, at test time the prediction is *deterministic*. Without other source of randomness, given one test data point, the model will always predict the same label or value.\n- For *Monte Carlo dropout*, the dropout is applied at both training and test time. At test time, the prediction is no longer deterministic, but depending on which nodes/links you randomly choose to keep. Therefore, given a same datapoint, your model could predict different values each time.\n- The primary goal of MC dropout is to generate random predictions and interpret them as samples from a probabilistic distribution. \n- #TALK [Estimacion de la Incertidumbre en Redes Neuronales (Valdenegro)](https://mvaldenegro.github.io/files/DSRP-meetup-NeurIPS-2020-incertidumbre-redes-neuronales.pdf)\n\n\n## Code\n- #CODE [Pyro (Uber) - Deep universal probabilistic programming with Python and PyTorch](https://github.com/uber/pyro  )\n\t- http://pyro.ai\n\t- http://eng.uber.com/pyro\n- #CODE [Blitz - Bayesian Layers in Torch Zoo](https://github.com/piEsposito/blitz-bayesian-deep-learning)\n- #CODE [Bean machine (Meta/Facebook)](https://github.com/facebookresearch/beanmachine)\n\t- https://research.facebook.com/blog/2021/12/introducing-bean-machine-a-probabilistic-programming-platform-built-on-pytorch/\n- #CODE [Edwardlib](http://edwardlib.org/)\n\t- Edward is a Python library for probabilistic modeling, inference, and criticism\n\t- https://theintelligenceofinformation.wordpress.com/2017/06/02/pydata-london-2017-bayesian-deep-learning-talk-by-andrew-rowan/\n\t- #TALK https://www.youtube.com/watch?v=I09QVNrUS3Q\n\t- http://willwolf.io/2017/06/15/random-effects-neural-networks/\n- #CODE [TensorFlow Probability](https://www.tensorflow.org/probability/)\n\t- https://towardsdatascience.com/bayesian-neural-networks-with-tensorflow-probability-fbce27d6ef6\n- #CODE [keras-uncertainty](https://github.com/mvaldenegro/keras-uncertainty)\n\t- Monte Carlo Dropout (MC-Dropout)\n\t- Deep Ensembles\n\n## Books\n- #BOOK [Probabilistic Graphical Models: Principles and Techniques (Koller, 2009 MIT)](http://pgm.stanford.edu/ )\n- #BOOK [Probabilistic Deep Learning - With Python, Keras and TensorFlow Probability (Durr, MANNING 2020)](https://www.manning.com/books/probabilistic-deep-learning)\n\t- https://tensorchiefs.github.io/dl_book/\n\n\n## Talks\n- #TALK [Uncertainty in deep learning (Olof Mogren)](https://www.youtube.com/watch?v=L8S5B6ojbwY)\n\n\n## Courses\n- #COURSE [Introductory course on probabilistic graphical models](https://ermongroup.github.io/cs228-notes/)\n\n## References\n- #PAPER [Probabilistic machine learning and artificial intelligence (Ghahramani 2015)](https://www.nature.com/articles/nature14541)\n- #PAPER [Dropout as a Bayesian Approximation:Representing Model Uncertainty in Deep Learning (Gal 2016)](https://arxiv.org/abs/1506.02142)\n- #PAPER [Bayesian Neural Networks (Mullachery, 2018)](https://arxiv.org/abs/1801.07710)\n- #PAPER [Deep Sub-Ensembles for Fast Uncertainty Estimation in Image Classification (Valdenegro-Toro 2019)](https://arxiv.org/abs/1910.08168)\n- #PAPER [Bayesian Recurrent Neural Networks (Fortunato 2019)](https://arxiv.org/abs/1704.02798)\n- #PAPER [Bayesian Deep Learning and a Probabilistic Perspective of Generalization (Gordon Wilson, 2020)](https://arxiv.org/abs/2002.08791)\n\t- https://github.com/izmailovpavel/understandingbdl\n- #PAPER [Hands-on Bayesian Neural Networks - a Tutorial for Deep Learning Users (Jospin 2020)](https://arxiv.org/abs/2007.06823)\n- #PAPER [DropConnect is effective in modeling uncertainty of Bayesian deep networks (Mobiny 2021)](https://www.nature.com/articles/s41598-021-84854-x)\n\t- #CODE https://github.com/hula-ai/mc_dropconnect\n- #PAPER [Epistemic Neural Networks (Osband 2021)](https://arxiv.org/abs/2107.08924)\n\t- #CODE https://github.com/deepmind/enn\n\t- https://syncedreview.com/2021/07/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-69/\n- #PAPER [Uncertainty Baselines: Benchmarks for Uncertainty \u0026 Robustness in Deep Learning (Nado 2021)](https://arxiv.org/abs/2106.04015)\n\t- https://ai.googleblog.com/2021/10/baselines-for-uncertainty-and.html\n\t- #CODE https://github.com/google/uncertainty-baselines\n- #PAPER [Probabilistic Deep Learning with Probabilistic Neural Networks and Deep Probabilistic Models (Chang 2021)](https://arxiv.org/abs/2106.00120)\n- #PAPER #REVIEW [A Survey of Uncertainty in Deep Neural Networks (Gawlikowski 2022)](https://arxiv.org/abs/2107.03342)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/RNNs":{"title":"Recurrent Neural Networks (RNNs)","content":"\u003e See:\n\u003e - [[AI/Deep learning/LSTMs]]\n\u003e - [[AI/Deep learning/GRUs]]\n\u003e - [[AI/Deep learning/Reservoir computing]] \n\u003e - [[AI/Deep learning/Transformers]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Recurrent_neural_network\n- https://github.com/kjw0612/awesome-rnn\n- [Recurrent Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)\n- [Tensorflow, DL and RNNs without a PhD](https://docs.google.com/presentation/d/e/2PACX-1vRouwj_3cYsmLrNNI3Uq5gv5-hYp_QFdeoan2GlxKgIZRSejozruAbVV0IMXBoPsINB7Jw92vJo2EAM/pub?slide=id.p)\n- http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html\n- http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n- https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0\n- https://www.kaggle.com/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru\n- https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n- [4 Sequence Encoding Blocks You Must Know Besides RNN/LSTM in Tensorflow](https://hanxiao.github.io/2018/06/24/4-Encoding-Blocks-You-Need-to-Know-Besides-LSTM-RNN-in-Tensorflow/)\n- [When Recurrent Models Don't Need to be Recurrent (recurrent vs feed-forward models)](http://www.offconvex.org/2018/07/27/approximating-recurrent/)\n- [Deep Learning: No, LSTMs Are Not Dead!](https://towardsdatascience.com/deep-learning-no-lstms-are-not-dead-20217553b87a)\n\n## References\n- #PAPER [Neural Turing Machines (Graves 2014)](http://arxiv.org/abs/1410.5401)\n- #PAPER [Attention and Augmented Recurrent Neural Networks (Olah 2016)](http://distill.pub/2016/augmented-rnns/)\n- #PAPER [Engineering Extreme Event Forecasting at Uber with Recurrent Neural Networks (Laptev 2017)](https://eng.uber.com/neural-networks/)\n- #PAPER [Deep and Confident Prediction for Time Series at Uber (Zhu 2017)](https://arxiv.org/abs/1709.01907)\n\t- https://eng.uber.com/neural-networks-uncertainty-estimation/ \n\t- introduced a new end-to-end Bayesian neural network (BNN) architecture that more accurately forecasts time series predictions and uncertainty estimations at scale\n- #PAPER [Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau 2016)](https://arxiv.org/abs/1409.0473)\n\t- https://medium.com/datadriveninvestor/attention-in-rnns-321fbcd64f05\n- #PAPER [DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks (Salinas 2019)](https://arxiv.org/abs/1704.04110)            \n\n### LSTMs\nSee [[AI/Deep learning/LSTMs]]\n\n### GRUs\nSee [[AI/Deep learning/GRUs]]\n\n### Reservoir computing\nSee [[AI/Deep learning/Reservoir computing]]","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Reservoir-computing":{"title":"Reservoir computing","content":"\u003e Reservoir computing is a framework for computation derived from recurrent neural network theory that maps input signals into higher dimensional computational spaces through the dynamics of a fixed, non-linear system called a reservoir. After the input signal is fed into the reservoir, which is treated as a \"black box,\" a simple readout mechanism is trained to read the state of the reservoir and map it to the desired output\n\n## Resources\n- https://en.wikipedia.org/wiki/Reservoir_computing\n\n#### Echo state networks (ESN)\n- https://en.wikipedia.org/wiki/Echo_state_network\n- The ESN is a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity)\n\n\n## References\n- #PAPER [Next generation reservoir computing (Gauthier 2021)](https://www.nature.com/articles/s41467-021-25801-2)\n\n#### Echo state networks (ESN)\n- https://en.wikipedia.org/wiki/Echo_state_network\n- The ESN is a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity)\n\n- #PAPER [Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication (Jaeger 2004)](https://pubmed.ncbi.nlm.nih.gov/15064413/)\n\t- #CODE https://github.com/cknd/pyESN\n- #PAPER [Design of deep echo state networks (Gallicchio 2018)](https://www.sciencedirect.com/science/article/pii/S0893608018302223)\n\t- #CODE https://github.com/lucapedrelli/DeepESN\n- #PAPER [Using Machine Learning to Replicate Chaotic Attractors and Calculate Lyapunov Exponents from Data (Pathak 2017)](https://arxiv.org/abs/1710.07313)\n- #PAPER [Model-Free Prediction of Large Spatiotemporally Chaotic Systems from Data: A Reservoir Computing Approach (Pathak 2018)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.024102)\n- #PAPER [Wind Power Forecasting Based on Echo State Networks and Long Short-Term Memory (Lopez 2018)](https://www.mdpi.com/1996-1073/11/3/526/htm)\n\t- ESN + LSTM\n- #PAPER [Comparison between DeepESNs and gatedRNNs on multivariate time-series prediction (Gallicchio 2019)](https://arxiv.org/abs/1812.11527)\n- #PAPER [Deep Echo State Network (DeepESN): A Brief Survey (Gallicchio 2020)](https://arxiv.org/abs/1812.11527\t)\n- #PAPER [Comparison of Recurrent Neural Networks for Wind Power Forecasting (Lopez 2020)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7297597/#CR12)\n\t- ESN + LSTM","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Residual-and-dense-neural-networks":{"title":"Residual and dense neural networks","content":"## Resources\n- https://en.wikipedia.org/wiki/Residual_neural_network\n- [Training and investigating Residual Nets](http://torch.ch/blog/2016/02/04/resnets.html)\n\n\n## References\n- #PAPER [Deep Residual Learning for Image Recognition, Resnet-50 (He 2015)](http://arxiv.org/abs/1512.03385) ^resnet\n\t- #CODE https://github.com/raghakot/keras-resnet\n\t- https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\n\t- [Explained paper](https://www.youtube.com/watch?v=GWt6Fu05voI)\n\t- Deep convolutional neural networks have led to a series of breakthroughs for image classification. Many other visual recognition tasks have also greatly benefited from very deep models. So, over the years there is a trend to go more deeper, to solve more complex tasks and to also increase /improve the classification/recognition accuracy. But, as we go deeper; the training of neural network becomes difficult and also the accuracy starts saturating and then degrades also. Residual Learning tries to solve both these problems.\n\t- What is Residual Learning?\n\t\t- In general, in a deep convolutional neural network, several layers are stacked and are trained to the task at hand. The network learns several low/mid/high level features at the end of its layers. In residual learning, instead of trying to learn some features, we try to learn some residual. Residual can be simply understood as subtraction of feature learned from input of that layer. ResNet does this using shortcut connections (directly connecting input of nth layer to some (n+x)th layer. It has proved that training this form of networks is easier than training simple deep convolutional neural networks and also the problem of degrading accuracy is resolved.\n\t\t- The architecture is similar to the VGGNet consisting mostly of 3X3 filters. From the VGGNet, shortcut connection as described above is inserted to form a residual network.\n- #PAPER [Aggregated Residual Transformations for Deep Neural Networks, ResNeXt (Xie 2016)](https://arxiv.org/abs/1611.05431) ^resnext\n- #PAPER [Densely Connected Convolutional Networks, DenseNet (Huang 2016)](https://arxiv.org/abs/1608.06993) ^densenet\n\t- #CODE https://github.com/liuzhuang13/DenseNet\n\t- #BOOK [DenseNet](https://d2l.ai/chapter_convolutional-modern/densenet.html)\n\t- For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages such as alleviating the vanishing-gradient problem, strengthening the feature propagation, encouraging feature reuse, and substantially reducing the number of parameters. DenseNets outperformed ResNets whilst requiring less memory and computation to achieve high performance.\n\t- https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803\n\t- In DenseNet, each layer obtains additional inputs from all preceding layers and passes on its own feature-maps to all subsequent layers. Concatenation is used (while element-wise addition for ResNets). Each layer is receiving a “collective knowledge” from all preceding layers. \n\t- https://arthurdouillard.com/post/densenet/\n- #PAPER [Wide Residual Networks (Zagoruyko 2016)](https://arxiv.org/abs/1605.07146)\n\t- #CODE https://github.com/szagoruyko/wide-residual-networks\n- #PAPER [Residual Attention Network for Image Classification (Wang 2017)](https://arxiv.org/abs/1704.06904)\n\t- Residual Attention Network, a convolutional neural network using attention mechanism which can incorporate with state-of-art feed forward network architecture in an end-to-end training fashion. The attention residual learning is used to train very deep Residual Attention Networks which can be easily scaled up to hundreds of layers.\n- #PAPER [ResNet strikes back: An improved training procedure in timm (Wightman 2021)](https://arxiv.org/abs/2110.00476)\n\t- [Paper explained](https://www.youtube.com/watch?v=Gl0s0GDqN3c)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Deep-learning/Transformers":{"title":"Transformers","content":"## Resources\n- https://github.com/IDEACVR/awesome-detection-transformer\n- https://github.com/Yangzhangcst/Transformer-in-Computer-Vision\n- https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/ (from RNNs with attention to Transformers)\n- https://analyticsindiamag.com/a-complete-learning-path-to-transformers/\n- https://analyticsindiamag.com/transformers-for-vision-7-works-that-indicate-fusion-is-the-future-of-ai/\n- [Investigating Vision Transformer representations](https://keras.io/examples/vision/probing_vits/)\n\t- #CODE https://github.com/sayakpaul/probing-vits\n- [Self-Supervised Learning in Vision Transformers](https://towardsdatascience.com/self-supervised-learning-in-vision-transformers-30ff9be928c)\n\n\n## Courses\n- #COURSE [CS25: Transformers United (Stanford)](https://web.stanford.edu/class/cs25/)\n\t- [Videos](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM)\n\n\n## Code\n- #CODE [Transformers](https://github.com/huggingface/transformers)\n\t- thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio\n\t- JAX, PyTorch and TensorFlow\n- #CODE [Xformers](https://github.com/facebookresearch/xformers)\n- #CODE [Transformers: from NLP to CV](https://github.com/IbrahimSobh/Transformers)\n- #CODE [Big vision](https://github.com/google-research/big_vision)\n\t- This codebase is designed for training large-scale vision models on Cloud TPU VMs. It is based on Jax/Flax libraries, and uses tf.data and TensorFlow Datasets for scalable input pipelines in the Cloud\n\n\n## For NLP\n- #PAPER [Attention is all you need (Vaswani 2017)](https://arxiv.org/abs/1706.03762)\n\t- https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\n\t- [Paper explained](https://www.youtube.com/watch?v=iDulhoQ2pro)\n\t- The Transformer is a novel neural network architecture based on a self-attention mechanism that is well suited for language understanding. \n\t- It outperforms both recurrent and convolutional models on academic English to German and English to French translation benchmarks. On top of higher translation quality, the Transformer requires less computation to train and is a much better fit for modern machine learning hardware, speeding up training by up to an order of magnitude.\n\t- Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing. If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. \n\t- The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n\t- http://jalammar.github.io/illustrated-transformer/\n\t- [Attention is all you need, attentional neural network models (Łukasz Kaiser)](https://www.youtube.com/watch?v=rBCqOTEfxvg)\n\t- [LSTM is dead, long live Transformers](https://sea-adl.org/2019/12/03/lstm-is-dead-long-live-transformers/)\n- #PAPER [Tensor2tensor (Vaswani 2018)](https://arxiv.org/abs/1803.07416)\n\t- Tensor2Tensor, or T2T for short, is a library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research. T2T is actively used and maintained by researchers and engineers within the Google Brain team and a community of users. We're eager to collaborate with you too, so feel free to open an issue on GitHub or send along a pull request (see our contribution doc). You can chat with us on Gitter and join the T2T Google Group.\n\t- It includes the reference implementation of the state-of-the-art Transformer model.\n- #PAPER [Improving Language Understanding by Generative Pre-Training, GPT (Radford 2018)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n\t- https://openai.com/blog/language-unsupervised/\n- #PAPER [Language Models are Unsupervised Multitask Learners, GPT-2 (Radford 2018)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n\t- #CODE https://github.com/openai/gpt-2\n\t- https://openai.com/blog/better-language-models/\n\t- Paper explained\n\t\t- https://www.youtube.com/watch?v=u1_qMdb0kYU\n\t\t- https://www.youtube.com/watch?v=UULqu7LQoHs\n\t\t- https://www.youtube.com/watch?v=8ypnLjwpzK8\n- #PAPER [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin 2019)](https://arxiv.org/abs/1810.04805)\n\t- #CODE [TensorFlow code and pre-trained models for BERT](https://github.com/google-research/bert)\n\t- [Paper explained](https://www.youtube.com/watch?v=-9evrZnBorM)\n\t- [BERT as a service](https://github.com/hanxiao/bert-as-service)\n- #PAPER [Language Models are Few-Shot Learners, GPT-3 (Brown 2020)](https://arxiv.org/abs/2005.14165)\n\t- Paper explained: \n\t\t- https://www.youtube.com/watch?v=SY5PvZrJhLE\n\t\t-  https://www.youtube.com/watch?v=_x9AwxfjxvE\n- #PAPER [It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners (Schick 2020)](https://arxiv.org/abs/2009.07118)\n\t- #CODE https://github.com/timoschick/pet\n\t- https://www.infoq.com/news/2020/10/training-exceeds-gpt3/\n- #PAPER [Rethinking Attention with Performers (Choromanski 2020)](https://arxiv.org/abs/2009.14794)\n\t- https://syncedreview.com/2020/10/02/google-cambridge-deepmind-alan-turing-institutes-performer-transformer-slashes-compute-costs/\n\t- https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html\n\t- #CODE https://github.com/google-research/google-research/tree/master/performer/fast_self_attention\n\t- [Paper explained](https://www.youtube.com/watch?v=xJrKIPwVwGM)\n- #PAPER [SqueezeBERT: What can computer vision teach NLP about efficient neural networks? (Iandola 2020)](https://arxiv.org/abs/2006.11316)\n\t- #TALK [From SqueezeNet to SqueezeBERT: Developing Efficient Deep Neural Networks](https://www.youtube.com/watch?v=kPMaEYSywdI)\n\t- https://www.microsoft.com/en-us/research/video/from-squeezenet-to-squeezebert-developing-efficient-deep-neural-networks/\n- #PAPER [FNet: Mixing Tokens with Fourier Transforms (Lee-Thorp 2021)](https://arxiv.org/abs/2105.03824)\n\t- https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/\n\t- #CODE https://paperswithcode.com/paper/fnet-mixing-tokens-with-fourier-transforms?from=n10\n\t- Transformer architectures can be massively sped up, with limited accuracy costs, by replacing self-attention sublayers with linear transformations that \"mix\" input tokens\n- #PAPER [Optimizing Deeper Transformers on Small Datasets (Xu 2021)](https://arxiv.org/abs/2012.15355)\n- #PAPER [Infinity-former: Infinite Memory Transformer (Martins 2022)](https://arxiv.org/abs/2109.00301)\n\t- [Paper explained](https://www.youtube.com/watch?v=0JlB9gufTw8)\n- #PAPER [Scaling Language Models: Methods, Analysis \u0026 Insights from Training Gopher (Rae 2022)](https://arxiv.org/abs/2112.11446)\n\t- [Paper explained](https://www.youtube.com/watch?v=aPiHhJjN3hI)\n- #PAPER [LaMDA: Language Models for Dialog Applications (Thoppilan 2022)](https://arxiv.org/pdf/2201.08239)\n\n## For Computer Vision\n- #PAPER [Spatial Transformer Networks (Jaderberg 2016)](https://arxiv.org/abs/1506.02025)\n\t-  the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, result-ing in state-of-the-art performance on several benchmarks, and for a number of classes of transformations\n\t-  https://www.youtube.com/watch?v=6NnearestOQC_fl1hQ\n\t-  #CODE https://github.com/oarriaga/paz/tree/master/examples/spatial_transfomer_networks\n- #PAPER [Image Transformer (Parmar 2018)](https://arxiv.org/abs/1802.05751)\n- #PAPER [Generative Pretraining from Pixels (Chen 2020)](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf) ^imagegpt\n\t- https://openai.com/blog/image-gpt/ \n\t- #CODE https://github.com/openai/image-gpt\n\t- [Paper explained](https://www.youtube.com/watch?v=YBlNQK0Ao6g)\n\t- https://www.youtube.com/watch?v=7rFLnQdl22c\n- #PAPER [DETR - End-to-End Object Detection with Transformers (Carion 2020)](https://arxiv.org/abs/2005.12872 )\n\t- #CODE https://paperswithcode.com/paper/end-to-end-object-detection-with-transformers\n- #PAPER [Taming Transformers for High-Resolution Image Synthesis (Esser 2020)](https://arxiv.org/abs/2012.09841v1) ^tamingtransformers\n\t- https://compvis.github.io/taming-transformers/\n\t- https://github.com/CompVis/taming-transformers\n\t- https://www.marktechpost.com/2020/12/28/a-new-method-to-code-inductive-image-biases-into-models-using-cnn-and-transformers/\n- #PAPER [ViT - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (2020)](https://openreview.net/forum?id=YicbFdNTTy)\n\t- While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer can perform very well on image classification tasks when applied directly to sequences of image patches\n\t- [Paper explained](https://www.youtube.com/watch?v=TrdevFK_am4)\n\t- #CODE https://github.com/google-research/vision_transformer\n\t- #CODE https://keras.io/examples/vision/image_classification_with_vision_transformer/\n\t- #CODE https://github.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples\n- #PAPER [Training data-efficient image transformers \u0026 distillation through attention (Touvron 2021)](https://arxiv.org/abs/2012.12877)\n\t- #CODE https://github.com/facebookresearch/deit\n\t- Propose a competitive convolution-free transformer by training on Imagenet only\n\t- Introduced a teacher-student strategy specific to transformers. It relies on a distillation token ensuring that the student learns from the teacher through attention\n\t- https://ai.facebook.com/blog/data-efficient-image-transformers-a-promising-new-technique-for-image-classification/\n- #PAPER [PVT - Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions (Wang 2021)](https://arxiv.org/abs/2102.12122) ^pvt\n\t- #CODE https://paperswithcode.com/paper/pyramid-vision-transformer-a-versatile\n\t- #CODE https://github.com/wangermeng2021/PVT-tensorflow2\n\t- PVT inherits the advantages from both CNN and Transformer, making it a unified backbone in various vision tasks without convolutions by simply replacing CNN backbones\n- #PAPER [Vision Transformers for Dense Prediction (Ranftl 2021)](https://arxiv.org/abs/2103.13413v1)\n\t- #CODE https://paperswithcode.com/paper/vision-transformers-for-dense-prediction\n\t- Model with an encoder-decoder design, leveraging the vision transformer (ViT) as the building block of the encoder\n\t- The representations produced by the transformer are reassembled into image-like feature representations at various resolutions and are progressively combined into the final dense prediction using a convolutional decoder \n\t- The transformer downsamples operations and keeps a representation with a constant dimensionality throughout the processing stages while keeping a global receptive field at every stage\n\t- These properties allows DPT to provide fine-grained and globally coherent predictions as compared to fully-convolutional networks\n- #PAPER [Understanding Robustness of Transformers for Image Classification (Bhojanapalli 2021)](https://arxiv.org/abs/2103.14586v1)\n- #PAPER [Medical Transformer: Gated Axial-Attention for Medical Image Segmentation (Valanarasu 2021)](https://arxiv.org/abs/2102.10662)\n\t- #CODE https://github.com/jeya-maria-jose/Medical-Transformer\n\t- https://analyticsindiamag.com/guide-to-medical-transformer-attention-for-medical-image-segmentation/\n\t- Trains with less data thanks to the Gated Axial-Attention model which extends the existing architectures by introducing an additional control mechanism in the self-attention module\n\t- To train the model effectively on medical images, we propose a Local-Global training strategy (LoGo) which further improves the performance. Specifically, we operate on the whole image and patches to learn global and local features, respectively\n- #PAPER [TransGAN: Two Transformers Can Make One Strong GAN (Jiang 2021)](https://arxiv.org/abs/2102.07074v2)\n\t- #CODE https://paperswithcode.com/paper/transgan-two-transformers-can-make-one-strong\n\t-  first pilot study in building a GAN completely free of convolutions, using only pure transformer-based architectures\n- #PAPER [Gansformer - Generative Adversarial Transformers (Hudson 2021)](https://arxiv.org/abs/2103.01209v2)\n\t- #CODE https://paperswithcode.com/paper/generative-adversarial-transformers\n- #PAPER [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Liu 2021)](https://arxiv.org/abs/2103.14030)\n\t- #CODE https://github.com/microsoft/Swin-Transformer\n\t- #CODE https://github.com/rishigami/Swin-Transformer-TF\n\t- #CODE https://github.com/yingkaisha/keras-vision-transformer\n\t- Swin Transformer serves as a general-purpose backbone for computer vision. Works for tasks such as image classification, object detection and semantic segmentation\n\t- involves a hierarchical Transformer whose representation is computed through a shifted windowing mechanism which limits the self-attention computation to non-overlapping local windows while still allowing for cross-window connection\n\t- the benefits of this hierarchical architecture are greater efficiency and flexibility to model at various scales. In addition, this model has linear computational complexity with respect to image size\n- #PAPER [How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers (Steiner 2021)](https://arxiv.org/abs/2106.10270v1)\n\t- Results show that models using a combination of AugReg (model regularization) and increased compute can attain similar performance as models trained on an order of magnitude more training data\n\t- ViT models of various sizes, trained on ImageNet-21k, match or outperform counterparts trained on a larger dataset (JFT-300M)\n\t- #CODE https://paperswithcode.com/paper/how-to-train-your-vit-data-augmentation-and\n- #PAPER [Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning (Kossen 2021)](https://arxiv.org/abs/2106.02584v1)\n\t- #CODE https://paperswithcode.com/paper/self-attention-between-datapoints-going?from=n11\n\t- Authors challenge a common assumption underlying most supervised deep learning: that a model makes a prediction depending only on its parameters and the features of a single input\n\t- Introduced a general-purpose deep learning architecture that takes as input the entire dataset instead of processing one datapoint at a time\n\t- The approach uses self-attention to reason about relationships between datapoints explicitly, which can be seen as realizing non-parametric models using parametric attention mechanisms\n- #PAPER [Segmenter: Transformer for Semantic Segmentation (Strudel 2021)](https://arxiv.org/abs/2105.05633)\n- #PAPER [Focal Self-attention for Local-Global Interactions in Vision Transformers (Yang 2021)](https://arxiv.org/abs/2107.00641)\n\t- https://www.marktechpost.com/2021/08/24/microsoft-ai-open-source-the-code-for-its-focal-transformer/\n- #PAPER [Do Vision Transformers See Like Convolutional Neural Networks (Raghu 2021)](https://arxiv.org/abs/2108.08810)\n\t- [Paper explained](https://www.youtube.com/watch?v=rk9bhIRInC0)\n- #PAPER [DECIMER 1.0: deep learning for chemical image recognition using transformers (Rajan 2021)](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-021-00538-8)\n- #PAPER [Multiscale Vision Transformers (Fan 2021)](https://arxiv.org/abs/2104.11227)\n\t- #CODE  https://github.com/facebookresearch/SlowFast\n\t- https://ai.facebook.com/blog/multiscale-vision-transformers-an-architecture-for-modeling-visual-data/\n- #PAPER [Swin Transformer V2: Scaling Up Capacity and Resolution (Liu 2021)](https://arxiv.org/abs/2111.09883v1)\n\t- #CODE https://paperswithcode.com/paper/swin-transformer-v2-scaling-up-capacity-and\n- #PAPER [Transformers in Medical Imaging: A Survey (Shamshad 2022)](https://arxiv.org/abs/2201.09873v1)\n\t- #CODE https://paperswithcode.com/paper/transformers-in-medical-imaging-a-survey?from=n24\n\t- https://github.com/fahadshamshad/awesome-transformers-in-medical-imaging\n- #PAPER [How Do Vision Transformers Work? (Park 2022)](https://arxiv.org/abs/2202.06709v2)\n\t- #CODE https://paperswithcode.com/paper/how-do-vision-transformers-work-1?from=n26\n- #PAPER [EfficientFormer: Vision Transformers at MobileNet Speed (Li 2022)](https://arxiv.org/pdf/2206.01191v3)\n\t- #CODE https://github.com/snap-research/efficientformer\n- #PAPER [Vision Transformers for Dense Prediction (Ranftl 2022)](https://arxiv.org/pdf/2103.13413) ^dpt\n\t- #CODE https://github.com/isl-org/DPT\n\t- DPT is a dense prediction architecture that is based on an encoder-decoder design that leverages a transformer as the basic computational building block of the encoder\n\t- used the recently proposed VIT as a backbone architecture reassembling the bag-of-words representation that is provided by ViT into image-like feature representations at various resolutions and progressively combine the feature representations into the final dense prediction using a convolutional decoder\n\t- it has a global receptive field at every stage\n- #PAPER [HRFormer: High-Resolution Vision Transformer for Dense Predict (Yuan 2021)](https://proceedings.neurips.cc/paper/2021/hash/3bbfdde8842a5c44a0323518eec97cbe-Abstract.html)\n\t- #CODE https://github.com/HRNet/HRFormer\n- #PAPER [ITTR: Unpaired Image-to-Image Translation with Transformers (Zheng 2022)](https://arxiv.org/pdf/2203.16015)\n\n### Self-supervised vision transformers\n- #PAPER [SiT: Self-supervised vIsion Transformer (Atito 2021)](https://arxiv.org/abs/2104.03602)\n- #PAPER [DINO - Emerging Properties in Self-Supervised Vision Transformers (Caron 2021)](https://arxiv.org/abs/2104.14294)\n\t- https://towardsdatascience.com/on-dino-self-distillation-with-no-labels-c29e9365e382\n- #PAPER [ConvMAE: Masked Convolution Meets Masked Autoencoders (Gao 2022)](https://arxiv.org/abs/2205.03892v2)\n\t- #CODE https://github.com/Alpha-VL/ConvMAE\n\n### Vision transformers with convolutions\n- #PAPER [CeiT - Incorporating Convolution Designs into Visual Transformers (Yan 2021)](https://arxiv.org/abs/2103.11816v1)\n\t- #CODE https://paperswithcode.com/paper/incorporating-convolution-designs-into-visual\n\t- CeiT combines the advantages of CNNs in extracting low-level features, strengthening locality, and the advantages of Transformers in establishing long-range dependencies\n- #PAPER [TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation (Chen 2021)](https://arxiv.org/abs/2102.04306v1)\n\t- #CODE https://paperswithcode.com/paper/transunet-transformers-make-strong-encoders\n\t- due to the intrinsic locality of convolution operations, U-Net generally demonstrates limitations in explicitly modeling long-range dependency\n\t- TransUNet merits both Transformers and U-Net, as a strong alternative for medical image segmentation\n\t- transformer encodes tokenized image patches from a convolution neural network (CNN) feature map as the input sequence for extracting global contexts\n\t- on the other hand, the decoder upsamples the encoded features which are then combined with the high-resolution CNN feature maps to enable precise localization\n\t- #TALK [Paper explained](https://www.youtube.com/watch?v=jKBJITQ8xJY)\n- #PAPER [Escaping the Big Data Paradigm with Compact Transformers (Hassani 2021)](https://arxiv.org/abs/2104.05704) ^cctransformer\n\t- Compact Convolutional Transformer (CCT)\n\t- #CODE https://github.com/SHI-Labs/Compact-Transformers\n\t- #CODE https://keras.io/examples/vision/cct/\n\t- ViTs (or a typical Transformer-based architecture) do not have well-informed inductive biases (such as convolutions for processing images)\n\t- Attempt to combine the benefits of convolution and the benefits of Transformers in a single network architecture\n\t- These benefits include parameter-efficiency, and self-attention to process long-range and global dependencies (interactions between different regions in an image)\n\t- Patching (VIT-like) and embedding is already a convolution in itself, albeit non-overlapping. This is replaced with overlapping (regular) convolutions\n\t- Better performance on CIFAR-10 than VIT, so it's efficient on smaller datasets, comparable with SOTA CNNs\n\t- #TALK [Escaping the Big Data Paradigm with Compact Transformers (Humphrey Shi)](https://www.youtube.com/watch?v=AEWhf_hMBgs)\n- #PAPER [CvT: Introducing Convolutions to Vision Transformers (Wu 2021)](https://arxiv.org/abs/2103.15808)\n\t- #CODE https://github.com/leoxiaobin/CvT\n\t- Convolutional vision Transformers (CvT) improves ViT in performance and efficienty by introducing convolutions into ViT to yield the best of both disignes\n\t- This is accomplished through two primary modifications: a hierarchy of Transformers containing a new convolutional token embedding, and a convolutional Transformer block leveraging a convolutional projection\n\t- These changes introduce desirable properties of CNNs to the ViT architecture (e.g. shift, scale, and distortion invariance) while maintaining the merits of Transformers (e.g. dynamic attention, global context, and better generalization)\n- #PAPER [Combining EfficientNet and Vision Transformers for Video Deepfake Detection (Coccomini 2021)](https://arxiv.org/abs/2107.02612)\n\t- [Vision Transformers or Convolutional Neural Networks? Both!](https://towardsdatascience.com/vision-transformers-or-convolutional-neural-networks-both-de1a2c3c62e4)\n- #PAPER [Early Convolutions Help Transformers See Better (Xiao 2021)](https://arxiv.org/abs/2106.14881)\n\t- https://syncedreview.com/2021/07/06/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-55/\n\t- replacing the ViT patchify stem with a standard convolutional stem in early visual processing results in marked improvements in terms of optimizer stability and final model accuracy\n- #PAPER [ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases (d'ascoli 2021)](https://arxiv.org/abs/2103.10697)\n\t- #CODE https://github.com/facebookresearch/convit\n\t- https://ai.facebook.com/blog/computer-vision-combining-transformers-and-convolutional-neural-networks/\n- #PAPER [CMT: Convolutional Neural Networks Meet Vision Transformers (Guo 2021)](https://arxiv.org/abs/2107.06263)\n- #PAPER [CoAtNet: Marrying Convolution and Attention for All Data Sizes (Dai 2021)](https://arxiv.org/abs/2106.04803)\n\t- https://ai.googleblog.com/2021/09/toward-fast-and-accurate-neural.html\n- #PAPER [UniFormer: Unifying Convolution and Self-attention for Visual Recognition (Li 2022)](https://arxiv.org/abs/2201.09450v1)\n\t- #CODE https://paperswithcode.com/paper/uniformer-unifying-convolution-and-self?from=n24\n- #PAPER [Convolutional Xformers for Vision (Jeevan 2022)](https://arxiv.org/abs/2201.10271v1)\n\t- #CODE https://github.com/pranavphoenix/CXV\n- #PAPER [Patches Are All You Need? (Trockman 2022)](https://arxiv.org/pdf/2201.09792)            \n\t- #CODE https://github.com/locuslab/convmixer\n\t- https://scoste.fr/posts/convmixer/index.html\n\t- https://medium.com/codex/an-overview-on-convmixer-patches-are-all-you-need-8502a8d87011\n\n## Multi-modal transformers\nSee [[AI/Deep learning/Multimodal learning]]\n\n## For RL\nSee ^decisiontransformer in [[AI/Reinforcement learning]]","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/FairAI":{"title":"Fair AI","content":"\u003e The term ‘‘fair AI’’ refers to probabilistic decision support that prevents disparate harm (or benefit) to different subgroups\n\n## Resources\n- [Timnit Gebru Launches Independent AI Research Institute On Anniversary of Ouster from Google](https://www.dair-institute.org/press-release)\n- [Socially acceptable and fair AI](https://fair-ai.ch/)\n\n## References\n- #PAPER [Fair AI : Challenges and Opportunities (Feuerriegel 2020)](https://www.zora.uzh.ch/id/eprint/188091/)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Feature-learning":{"title":"Feature learning","content":"\u003e In ML, feature learning or representation learning is a set of techniques that allows a system to automatically discover the representations needed for feature detection or classification from raw data. This replaces manual feature engineering and allows a machine to both learn the features and use them to perform a specific task.\n\n## Resources\n- https://en.wikipedia.org/wiki/Feature_learning\n- [Feature Engineering for Machine Learning](https://towardsdatascience.com/feature-engineering-for-machine-learning-434c9b4912c6)\n\n### Unsupervised case\n- Dictionary learning\n- Autoencoders\n- ICA\n- Matrix factorization\n\n### Supervised case\n- Representational Learning (RL) refers to learning latent representations using non-parametric (i.e. non-statistical) methods to _extract features_\n- Deep supervised models (Multilayer perceptron, Supervised neural networks) are able to learn automatically features from data","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Federated-learning":{"title":"Federated learning","content":"\u003e Federated learning (also known as collaborative learning) is a machine learning technique that trains an algorithm across multiple decentralized edge devices or servers holding local data samples, without exchanging them\n\n## Resources\n- https://en.wikipedia.org/wiki/Federated_learning\n- [Federated Learning: Collaborative Machine Learning without Centralized Training Data](http://ai.googleblog.com/2017/04/federated-learning-collaborative.html \"Federated Learning: Collaborative Machine Learning without Centralized Training Data\")\n\n\n## Talks\n- #TALK [What is Federated Learning?](https://www.youtube.com/watch?v=X8YYWunttOY)\n- #TALK [Federated Learning: Machine Learning on Decentralized Data (Google I/O'19)](https://www.youtube.com/watch?v=89BGjQYA0uE)\n\n## Code\n- #CODE [TF federated](https://github.com/tensorflow/federated)\n\t- https://www.tensorflow.org/federated?hl=es-419\n\n## References\n- #PAPER [Federated learning challenges and opportunities: An outlook (Ding 2022)](https://www.amazon.science/publications/federated-learning-challenges-and-opportunities-an-outlook)\n\t- https://www.marktechpost.com/2022/04/17/latest-paper-from-amazon-ai-research-analyzes-and-explains-the-challenges-and-developments-in-the-field-of-federated-learning/","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Forecasting":{"title":"Forecasting","content":"\u003e See: \n\u003e - [[AI/Time Series analysis]]\n\u003e - [[AI/Supervised Learning/Regression]]\n\u003e - [[AI/Deep learning/RNNs]]\n\u003e - \"Sequence time series modelling\" section in [[AI/Deep learning/CNNs]]\n\u003e - \"For NLP\" section in [[AI/Deep learning/Transformers]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Forecasting\n- [Microsoft - Time Series Forecasting Best Practices \u0026 Examples](https://github.com/microsoft/forecasting)\n- Forecasting with a Time Series Model using Python: \n\t- https://www.bounteous.com/insights/2020/09/15/forecasting-time-series-model-using-python-part-one/\n\t- https://www.bounteous.com/insights/2020/09/15/forecasting-time-series-model-using-python-part-two/\n- https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775\n- https://towardsdatascience.com/automl-for-time-series-advanced-approaches-with-fedot-framework-4f9d8ea3382c\n\n## Code\n- #CODE [Darts](https://github.com/unit8co/darts)\n\t- https://unit8co.github.io/darts/\n\t- Python library for easy manipulation and forecasting of time series. It contains a variety of models, from classics such as ARIMA, Prophet,  deep neural networks (NBEATS, RNNs, Transformers)\n\t- https://towardsdatascience.com/darts-swiss-knife-for-time-series-forecasting-in-python-f37bb74c126\n- #CODE [Neuralforecast](https://github.com/Nixtla/neuralforecast)\n\t- NeuralForecast is a Python library for time series forecasting with deep learning models. It includes benchmark datasets, data-loading utilities, evaluation functions, statistical tests, univariate model benchmarks and SOTA models implemented in PyTorch and PyTorchLightning\n\t- https://nixtla.github.io/neuralforecast\n- #CODE [Prophet (Facebook)](https://github.com/facebook/prophet)\n\t- https://facebook.github.io/prophet/\n\t- Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data.\n\t- https://research.fb.com/prophet-forecasting-at-scale/\n\t- http://blog.fastforwardlabs.com/2017/03/22/prophet.html\t\n- #CODE [NeuralProphet](https://github.com/ourownstory/neural_prophet)\n\t- https://ourownstory.github.io/neural_prophet/\n\t- A simple forecasting model based on Neural Networks in PyTorch\n- #CODE [Hcrystalball](https://github.com/heidelbergcement/hcrystalball)\n\t- Library that unifies the API for most commonly used libraries and modeling techniques for time-series forecasting in Python\n- #CODE [AtsPy: Automated Time Series Forecasting in Python](https://github.com/firmai/atspy)\n- #CODE [Greykite (Linkedin)](https://github.com/linkedin/greykite)\n\t- https://linkedin.github.io/greykite/\n\t- A flexible, intuitive and fast forecasting library\n- #CODE [Scalecast](https://github.com/mikekeith52/scalecast)\n\t- https://towardsdatascience.com/introducing-scalecast-a-forecasting-library-pt-1-33b556d9b019\n- #CODE [Skforecast](https://github.com/JoaquinAmatRodrigo/skforecast)\n- #CODE [Deep_XF](https://github.com/ajayarunachalam/Deep_XF)\n\t- Package towards building Explainable Forecasting and Nowcasting Models with State-of-the-art Deep Neural Networks and Dynamic Factor Model on Time Series data sets with single line of code\n\t- https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html\n\t\n\n## Talks\n- #TALK [Feature Engineering for Time Series Forecasting | PyData London 2022](https://www.youtube.com/watch?v=9QtL7m3YS9I)\n\n\n## Books\n- #BOOK [Forescasting: principles and practice (Hyndman 2018, R)](https://otexts.com/fpp2/)\n\n\n## References\n- #PAPER [Time Series Forecasting With Deep Learning: A Survey (Lim 2020)](https://arxiv.org/abs/2004.13408)\n- #PAPER [N-BEATS: Neural basis expansion analysis for interpretable time series forecasting (Oreshkin 2020)](https://arxiv.org/abs/1905.10437)\n- #PAPER [A flexible forecasting model for production systems (Hosseini 2021)](https://arxiv.org/abs/2105.01098)\n- #PAPER [An Experimental Review on Deep Learning Architectures for Time Series Forecasting (Lara-Benitez 2021)](https://arxiv.org/abs/2103.12057)\n- #PAPER [Temporal Fusion Transformers for interpretable multi-horizon time series forecasting (Lim 2021)](https://www.sciencedirect.com/science/article/pii/S0169207021000637)\n\t- https://ai.googleblog.com/2021/12/interpretable-deep-learning-for-time.html\n\t- [[AI/Deep learning/Transformers]]","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Learning-to-rank":{"title":"Learning to rank","content":"\u003e Learning to rank or machine-learned ranking (MLR) is the application of machine learning, typically supervised, semi-supervised or reinforcement learning, in the construction of ranking models for information retrieval systems\n\n## Resources\n- https://en.wikipedia.org/wiki/Learning_to_rank\n- Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model's purpose is to rank, i.e. produce a permutation of items in new, unseen lists in a way which is \"similar\" to rankings in the training data in some sense.\n\n### Ordinal regression (classification)\n- https://en.wikipedia.org/wiki/Ordinal_regression\n- OR (also called \"ordinal classification\" or “ranking learning”) is a type of [AI/Supervised Learning/Regression](AI/Supervised%20Learning/Regression.md) analysis used for predicting an ordinal variable, i.e. a variable whose value exists on an arbitrary scale where only the relative ordering between different values is significant. It can be considered an intermediate problem between regression and classification.\n- http://stackoverflow.com/questions/3495157/ordinal-classification-packages-and-algorithms\n- http://stats.idre.ucla.edu/r/dae/ordinal-logistic-regression/\n\n## Code\n- #CODE [RAX](https://github.com/google/rax)\n\t- #PAPER [Rax: Composable Learning-to-Rank using JAX (Jagerman 2022)](https://research.google/pubs/pub51453/#:~:text=Rax%20is%20a%20library%20for,rest%20of%20the%20JAX%20ecosystem.)\n\t- https://www.marktechpost.com/2022/08/16/google-ai-open-sources-rax-a-python-library-for-ltr-learning-to-rank-in-the-jax-ecosystem/\n- #CODE [Adarank](https://github.com/rueycheng/AdaRank)\n- #CODE [Pyltr - LambdaMART](https://github.com/jma127/pyltr)\n- #CODE [Mord - Ordinal Regression in Python](https://github.com/fabianp/mord)\n\t- https://pythonhosted.org/mord/\n\t- http://fa.bianp.net/blog/2013/logistic-ordinal-regression/\n\n## References\n### DL-based ranking\n- #PAPER [TF-Ranking: Scalable TensorFlow Library for Learning-to-Rank (Kumar Pasumarthi 2019)](https://research.google/pubs/pub48160/)\n\t- #CODE https://github.com/tensorflow/ranking\n\t- [New Keras-based TF-Ranking version](https://ai.googleblog.com/2021/07/advances-in-tf-ranking.html)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Machine-Learning":{"title":"Machine Learning (ML)","content":"\u003e Machine learning identifies patterns using statistical learning and computers by unearthing boundaries in data sets. \n\n## Resources\n- [Awesome ML](https://github.com/josephmisiti/awesome-machine-learning)\n- [Machine Learning Research Articles](https://deepai.org/publications/statistics-machine-learning/1)\n- [Rules of ML (Google)](https://developers.google.com/machine-learning/rules-of-ml/)\n- [Jason's Machine Learning 101 (Google)](https://www.youtube.com/watch?v=JpTYbmpoHT0)\n\t- https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/preview\n- [Machine Learning Glossary (Google)](https://developers.google.com/machine-learning/glossary/)\n- [ML Resources (MIT student)](https://sgfin.github.io/learning-resources/)\n- [Machine Learning \u0026 Deep Learning Tutorials](https://github.com/ujjwalkarn/Machine-Learning-Tutorials/)\n- [A visual introduction to machine learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n- [ML Algorithms: Strengths and Weaknesses](https://elitedatascience.com/machine-learning-algorithms)\n- [A friendly introduction to linear algebra for ML (ML Tech Talks)](https://www.youtube.com/watch?v=LlKAna21fLE)\n- [Best practices for ML engineering (Google)](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf)\n- [Recommendation System Algorithms](https://blog.statsbot.co/recommendation-system-algorithms-ba67f39ac9a3)\n- [Training Machine Learning Models More Efficiently with Dataset Distillation](http://ai.googleblog.com/2021/12/training-machine-learning-models-more.html \"Training Machine Learning Models More Efficiently with Dataset Distillation\")\n\n### Cheatsheets and notes\n- https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/super-cheatsheet-machine-learning.pdf\n- https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks\n- [ML-AI guide](https://csinva.io/blog/compiled_notes/_build/html//intro.html)\n\n### Naive/homemade implementations\n- https://github.com/trekhleb/homemade-machine-learning\n- https://github.com/anhquan0412/basic_model_scratch\n- https://github.com/rushter/MLAlgorithms\n- https://github.com/ahmedbesbes/Neural-Network-from-scratch\n- https://github.com/eriklindernoren/ML-From-Scratch\n\n### Open datasets (for ML, DL and DS)\nSee [[AI/DS and DataEng/Open ML data]]\n\n\n## Books\n- #BOOK [An Introduction to Statistical Learning (James 2013, SPRINGER)](http://www-bcf.usc.edu/~gareth/ISL/)\n\t- https://github.com/JWarmenhoven/ISLR-python\n- #BOOK [The elements of statistical learning (Hastie 2015, SPRINGER)](https://web.stanford.edu/~hastie/ElemStatLearn/)\n-  #BOOK [Recommender Systems - The Textbook (Aggarwal, 2016 SPRINGER)](http://charuaggarwal.net/Recommender-Systems.pdf)\n-  #BOOK [Mathematics for ML (Deisenroth, 2020 CAMBRIDGE)](https://mml-book.github.io/)\n-  #BOOK [Introduction to Machine Learning with Python - A Guide for Data Scientists (Muller, 2016 O'REILLY)](\u003chttps://www.nrigroupindia.com/e-book/Introduction%20to%20Machine%20Learning%20with%20Python%20(%20PDFDrive.com%20)-min.pdf\u003e)\n\t\t- https://github.com/amueller/introduction_to_ml_with_python\n- #BOOK [Machine Learning for Dummies (Hurwitz, 2018 WILEY-IBM)](https://www-01.ibm.com/common/ssi/cgi-bin/ssialias?htmlfid=IMM14209USEN)\n- #BOOK [Python Machine Learning (Raschka 2019, PACKT)](https://github.com/rasbt/python-machine-learning-book-3rd-edition)\n- #BOOK [Mastering Machine Learning with scikit-learn (Hackeling 2014, PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/mastering-machine-learning-scikit-learn)\n- #BOOK [Designing Machine Learning Systems with Python (Julian 2016, PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/designing-machine-learning-systems-python)\n- #BOOK [Evaluating Machine Learning Models (Zheng 2015, OREILLY)](https://www.oreilly.com/ideas/evaluating-machine-learning-models)\n- #BOOK [Introduction to Machine Learning Interviews Book](https://huyenchip.com/ml-interviews-book/)\n\n## Courses\n- #COURSE [Machine Learning (CS229, Stanford)](http://cs229.stanford.edu/)\n\t- [Lecture notes](https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf)\n\t- [Cheat sheets](https://github.com/afshinea/stanford-cs-229-machine-learning)\n- #COURSE [Machine Learning (Coursera-Stanford)](https://www.coursera.org/learn/machine-learning)\n- #COURSE [Machine Learning Crash Course with TensorFlow APIs (Google)](https://developers.google.com/machine-learning/crash-course/)\n- #COURSE [Data Mining and Machine Learning (STAT 365/665, Yale)](http://euler.stat.yale.edu/~tba3/stat665/)\n- #COURSE [Applied machine learning (U Columbia)](https://github.com/amueller/applied_ml_spring_2017)\n- #COURSE [L'apprentissage face à la malédiction de la grande dimension (College de France)](https://www.college-de-france.fr/site/stephane-mallat/course-2017-2018.htm)\n- #COURSE [The Machine Learning Summer School, MLSS Tubingen 2020 (virtual)](http://mlss.tuebingen.mpg.de/2020/)\n\t- https://www.youtube.com/channel/UCBOgpkDhQuYeVVjuzS5Wtxw/videos\n\n## Code \n- #CODE [Benchmarks of ML libraries](https://github.com/szilard/benchm-ml)\n- #CODE [Scikit-learn](https://github.com/scikit-learn/scikit-learn)\n\t- http://scikit-learn.org/stable/\n\t- [Contrib packages](https://github.com/scikit-learn-contrib)\n\t- #TALK [PyData tutorial by Sebastian Raschka](https://www.youtube.com/watch?v=9fOWryQq9J8)\n\t- #CODE [scikit-plot](http://scikit-plot.readthedocs.io/en/stable/Quickstart.html)\n\t- #CODE [Lightning](http://contrib.scikit-learn.org/lightning/)\n\t\t- Large-scale linear classification, [[AI/Supervised Learning/Regression]] and ranking ([[AI/Learning to rank]]] in Python\n\t- #CODE [MAPIE](https://github.com/scikit-learn-contrib/mapie)\n\t\t- #PAPER [MAPIE: an open-source library for distribution-free uncertainty quantification](https://arxiv.org/pdf/2207.12274v1)\n\t\t- A scikit-learn-compatible module for estimating prediction intervals for single-output regression or multi-class classification settings\n- #CODE [mlinsights](https://github.com/sdpython/mlinsights/)\n\t- http://www.xavierdupre.fr/app/mlinsights/helpsphinx/notebooks/piecewise_linear_regression.html\n- #CODE [PyCaret](https://github.com/pycaret/pycaret)\n\t- https://pycaret.org/\n\t- PyCaret is an open-source, low-code machine learning library in Python that automates machine learning workflows\n\t- PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, LightGBM, CatBoost, spaCy, Optuna, Hyperopt, Ray, and many more\n\t- PyCaret \u003e= 2.2 provides the option to use GPU for select model training and hyperparameter tuning\n- #CODE [Hypertools](https://github.com/ContextLab/hypertools)\n\t-  A python toolbox for visualizing and manipulating high-dimensional data\n\t- http://hypertools.readthedocs.io/en/latest/\n\t- https://github.com/ContextLab/hypertools-paper-notebooks\n\t- http://blog.kaggle.com/2017/04/10/exploring-the-structure-of-high-dimensional-data-with-hypertools-in-kaggle-kernels/\n- #CODE [PySAL: Python Spatial Analysis Library Meta-Package](https://github.com/pysal/pysal)\n\t- http://pysal.org/pysal/\n- #CODE [MLxtend](http://rasbt.github.io/mlxtend/)\n\t- A library of extension and helper modules for Python's data analysis and machine learning libraries\n- #CODE [H2O](https://github.com/h2oai/)\n\t- http://www.h2o.ai/\n\t- https://github.com/h2oai/h2o-3\n\t- https://github.com/h2oai/h2o4gpu\n\t- https://github.com/h2oai/h2o-tutorials\n\t- #TALK [Getting started with H2O on Python (pydata)](https://www.youtube.com/watch?v=OYJYl8egLQs)\n\t- http://www.jowanza.com/post/156015716294/why-h2o-sparkling-water\n\t- https://github.com/h2oai/h2o-3/tree/master/h2o-py/demos\n- #CODE [Dlib (C++ with python interface)](http://dlib.net/)\n- #CODE [Shogun](http://shogun-toolbox.org/)\n- #CODE [Vowpal Wabbit](https://github.com/VowpalWabbit/vowpal_wabbit)\n\t- ML system which pushes the frontier of machine learning with techniques such as online, hashing, allreduce, reductions, learning2search, active, and interactive learning\n\t- http://hunch.net/~vw/\n\t- https://github.com/JohnLangford/vowpal_wabbit/wiki\n- #CODE [DMTK (Microsoft)](https://github.com/Microsoft/DMTK)\n\t- http://www.dmtk.io/\n\t- [Light LDA - Scalable, fast, and lightweight system for large-scale topic modeling](http://www.dmtk.io)\n- #CODE [RAPIDS - GPU data science](https://github.com/rapidsai, https://rapids.ai/)\n\t- #CODE [cuML - RAPIDS Machine Learning Library](https://github.com/rapidsai/cuml)\n\t- #CODE [cuspatial - CUDA-accelerated GIS and spatiotemporal algorithms](https://github.com/rapidsai/cuspatial)\n\t- #CODE [cuSignal - RAPIDS Signal Processing Library](https://github.com/rapidsai/cusignal)\n\t- #CODE [cuGraph - RAPIDS Graph Analytics Library](https://github.com/rapidsai/cugraph)\n\t- #CODE [cuDF - GPU DataFrame Library](https://github.com/rapidsai/cudf)\n- #CODE [scikit-learn-intelex](https://github.com/intel/scikit-learn-intelex)\n\t- Intel(R) Extension for Scikit-learn is a seamless way to speed up your Scikit-learn application\n\t- https://intel.github.io/scikit-learn-intelex/\n- #CODE [CuPy - NumPy-like API accelerated with CUDA](https://github.com/cupy/cupy)\n\t- https://cupy.chainer.org/\n\t- https://docs-cupy.chainer.org/en/stable/\n\t- https://docs-cupy.chainer.org/en/stable/tutorial/\n- #CODE [ArrayFire](https://github.com/arrayfire/arrayfire-python)\n\t- ArrayFire is a high performance library for parallel computing with an easy-to-use API. It enables users to write scientific computing code that is portable across CUDA, OpenCL and CPU devices. This project provides Python bindings for the ArrayFire library.\n\t- https://arrayfire.com/\n- #CODE [TuriCreate (Apple)](https://github.com/apple/turicreate)\n\t- TuriCreate simplifies the development of custom machine learning models. You don't have to be a machine learning expert to add recommendations, object detection, image classification, image similarity or activity classification to your app\n\t- https://developer.apple.com/videos/play/wwdc2018/712/\n- #CODE [ThunderSVM - A Fast SVM Library on GPUs and CPUs](https://github.com/zeyiwen/thundersvm)\n- #CODE [PyGAM](https://github.com/dswah/pyGAM) - Generalized Additive Models in Python\n\t- https://pygam.readthedocs.io\n- #CODE [SurPRISE - A Python scikit for building and analyzing recommender systems](http://surpriselib.com)\n- #CODE [Facets](https://github.com/PAIR-code/facets)\n\t- visualizations for understanding and analyzing machine learning datasets: Facets Overview and Facets Dive. The visualizations are implemented as Polymer web components, backed by Typescript code and can be easily embedded into Jupyter notebooks or webpages\n\t- https://pair-code.github.io/facets/\n- #CODE [PyCM](https://github.com/sepandhaghighi/pycm)\n\t- PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters\n\t- http://www.pycm.ir/\n\n### ML platforms\n- #CODE [Azure (Microsoft)](https://azure.microsoft.com/en-gb/)\n\t- [Azure ML Studio](https://azure.microsoft.com/en-us/services/machine-learning/)\n\t- [Microsoft Cognitive Services](https://azure.microsoft.com/en-in/services/cognitive-services/)\n- #CODE [Google Cloud Platform](https://cloud.google.com/)\n\t- [Pick your AI/ML Path on Google Cloud](https://cloud.google.com/blog/topics/developers-practitioners/pick-your-aiml-path-google-cloud)\n\t- https://codelabs.developers.google.com/\n\t- https://cloud.google.com/products/ai/\n\t- https://medium.com/google-cloud/jupyter-tensorflow-nvidia-gpu-docker-google-compute-engine-4a146f085f17\n\t- [Cloud AI building blocks](https://cloud.google.com/products/ai/building-blocks/)\n\t- [Cloud ML Engine](https://cloud.google.com/ml/)\n\t\t- [Google Cloud Machine Learning platform](https://cloud.google.com/ml-engine/docs/)\n\t\t- #TALK [Machine Intelligence at Google Scale: Vision/Speech API (Guillaume Laforge)](https://www.youtube.com/watch?v=zqWt8oI4gEw)\n\t\t- https://www.slideshare.net/matthiasfeys/machine-learning-at-scale-with-google-cloud-platform\n\t\t- https://github.com/Fematich/mlengine-boilerplate\n\t- [AI Hub](https://cloud.google.com/ai-hub/)\n\t- [Cloud AutoML](https://cloud.google.com/automl/)\n- #CODE [Amazon web services (AWS)](https://aws.amazon.com/)\n\t- https://github.com/donnemartin/awesome-aws\n\t- [ML on AWS](https://aws.amazon.com/machine-learning/)\n\t- [SageMaker](https://aws.amazon.com/sagemaker/)\n\t- [AI on AWS](https://aws.amazon.com/lex/) \n\t\t- https://aws.amazon.com/polly\n\t\t- https://aws.amazon.com/rekognition\n- #CODE [Watson (IBM)](http://www.ibm.com/watson/)\n\t- [IBM Watson APIs](https://www.ibm.com/watson/developer/)\n\t- http://www.datasciencecentral.com/profiles/blogs/ibm-watson-does-your-taxes-question-answering-machine-versus-expe\n\t- https://www.codecademy.com/learn/ibm-watson\n\t- https://www.ibm.com/cloud/watson-studio\n\t- https://www.ibm.com/watson/services/knowledge-studio/\n- #CODE [Dataiku DSS](https://www.dataiku.com/)\n- #CODE [Domino DataLab](https://www.dominodatalab.com/)\n- #CODE [RapidMiner](https://rapidminer.com/)\n- #CODE [Knime](https://www.knime.org/knime-analytics-platform)\n\n\n## References\n- #PAPER [Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence (Raschka 2020)](https://arxiv.org/abs/2002.04803)\n- #PAPER [How to avoid machine learning pitfalls: a guide for academic researchers (Lones 2021)](https://arxiv.org/abs/2108.02497)\n\t- https://venturebeat.com/2021/08/23/the-dos-and-donts-of-machine-learning-research/\n- #PAPER [Pen and Paper Exercises in Machine Learning (Gutmann 2022)](https://arxiv.org/pdf/2206.13446)\n\n### Machine learning for scientific discovery\nSee [[AI/Deep learning/DL#Deep learning for scientific discovery]] and [[AI/AI#AI for scientific discovery]]\n- [NeurIPS - Machine Learning and the Physical Sciences](https://neurips.cc/Conferences/2021/Schedule?showEvent=21862)\n- #PAPER [Machine learning and the physical sciences (Carleo 2019)](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.91.045002)\n- #PAPER [Machine Learning for Scientific Discovery (Surana 2021)](https://arxiv.org/abs/2102.12712)\n- #PAPER [Machine Intelligence for Scientific Discovery and Engineering Invention (Daniels 2021)](https://cset.georgetown.edu/publication/machine-intelligence-for-scientific-discovery-and-engineering-invention/). White paper\n- #PAPER [Optimizing the synergy between physics and machine learning (2021)](https://www.nature.com/articles/s42256-021-00416-w). Editorial\n- #PAPER [Leakage and the Reproducibility Crisis in ML-based Science (Kapoor 2022)](https://arxiv.org/abs/2207.07048)\n\t- [Could machine learning fuel a reproducibility crisis in science?](https://www.nature.com/articles/d41586-022-02035-w)\n\n\n## Subtopics\n\n### Feature selection\nSee [[AI/Supervised Learning/Feature selection]]\n\n### Feature learning\nSee [[AI/Feature learning]]\n\n### Anomaly and Outlier Detection\nSee [[AI/Anomaly and Outlier Detection]]\n\n### Time Series analysis and forecasting\nSee [[AI/Time Series analysis]] and [[AI/Forecasting]]\n\n### AutoML\nSee [[AI/AutoML]]\n\n### Deep Learning\nSee [[AI/Deep learning/DL]]\n\n### Reinforcement learning\nSee [[AI/Reinforcement learning]]\n\n### Unsupervised learning\nSee [[AI/Unsupervised learning/Unsupervised learning]]\n\n### Supervised learning\nSee [[AI/Supervised Learning/Supervised learning]]\n\n### Weakly-supervised learning\nSee [[AI/Weakly-supervised learning]]. It includes these topics: [[AI/Semi-supervised learning]], [[AI/Active learning]] and [[AI/Transfer learning]]\n\n### One, few-shot learning\nSee [[AI/One, few-shot learning]]\n\n### Self-supervised learning\nSee [[AI/Self-supervised learning]]\n\n### Learning to rank and ordinal regression\nSee [[AI/Learning to rank]]\n\n### Multi task learning\nSee [[AI/Multi-task learning]]\n\n### Generative modelling\nSee [[AI/Deep learning/Generative modelling]]\n\n### Explainable AI\nSee [[AI/XAI]]\n\n### Federated learning\nSee [[Federated learning]]\n\n## Quantum ML\nSee [[QML]]","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Math-and-Statistics/Distances":{"title":"Distances","content":"## Resources\n- [Anscombe dataset](http://datascienceplus.com/the-importance-of-data-visualization/)\n- Distance = 1 - Similarity \n- Having a set of points (space), a distance d is a function d(x,y) that takes 2 point in the space and produces a real number. It must satisfy 4 axioms:\n\t1. d(x,y)\u003e=0, no negative distances\n\t2. d(x,y)=0 if and only if x=y, positive distances except the from a point to itself\n\t3. d(x,y) = d(y,x), distance is symmetric \n\t4. d(x,y) \u003c= d(x,z)+d(z,y), the triangle inequality says that to travel from x to y, we cannot obtain any benefit if we are forced to travel via some particular third point z. \n- http://www.benfrederickson.com/distance-metrics/ (notebook kind of post using pandas, d3)\n- https://github.com/andrecosta90/distance-similarity-measures\n\n### Minkowski\n- The Minkowski distance is the generalized Lp -norm of the difference. \n- Lp-norm is the distance d defined as: d = (sum|x_i - y_i|^p)^1/p \n\n### Euclidean\n- Same as L2-norm (Lp-norm when p=2)\n- Most familiar distance measure, defined as the square root of the sum of the square distances: d = sqrt(sum((x_i - y_i)^2)\n- An equivalent to the L2-norm is the Squared Euclidean distance or sum of squared difference (SSD). This is the fundamental metric in least squares problems and linear algebra. It’s very sensitive to outliers (because of the square). The Mean Squared Error (MSE) is the normalized version of the SSD. \n\n### Manhattan\n- https://en.wikipedia.org/wiki/Taxicab_geometry\n- Same as L1-norm (Lp-norm when p=1)\n- Also known as Taxicab norm and SAD\n- Distance defined as the sum of the absolute differences of the coordinates: d = sum(|x_i - y_i|)\n- In solving an underdetermined system of linear equations, the regularisation term for the parameter vector is expressed in terms of the-norm (taxicab geometry) of the vector. This approach appears in the signal recovery framework called compressed sensing.\n- The Mean-Absolute Error (MAE) is a normalized version of the SAD: d_MAE(x,y) = d_SAD(x,y)/n = 1/n sum(|x_i - y_i|)\n\n### Cosine\n- The cosine distance contains the dot product scaled by the product of the Euclidean distances from the origin. It represents the angular distance of two vectors while ignoring their scale. \n\n### Jaccard\n- The Jaccard distance, is a measure of how _dissimilar_ two sets are. It is the complement of the Jaccard index and can be found by subtracting the Jaccard Index from 100%\n- https://en.wikipedia.org/wiki/Jaccard_index\n\n### Hamming\n- The hamming distance represents the number of entries in the two sample vectors which are different. It is a fundamental distance measure in information theory but less relevant in non-integer numerical problems. \n\n### Pearson\n- The Pearson distance is a correlation distance based on Pearson's product-momentum correlation coefficient of the two sample vectors. Since the correlation coefficient falls between [-1, 1], the Pearson distance lies in [0, 2] and measures the linear relationship between the two vectors. \nd_pearson(x,y) = 1 - Correlation(x,y)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Math-and-Statistics/Genetic-algorithms":{"title":"Genetic algorithms","content":"\u003e Metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms. Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on bio-inspired operators such as mutation, crossover and selection\n\n## Resources\n- https://en.wikipedia.org/wiki/Genetic_algorithm\n- [What Is the Genetic Algorithm?](https://www.mathworks.com/help/gads/what-is-the-genetic-algorithm.html)\n- [Introduction to Genetic Algorithms — Including Example Code](https://towardsdatascience.com/introduction-to-genetic-algorithms-including-example-code-e396e98d8bf3)\n\n## Code\n- #CODE [DEAP](https://github.com/DEAP/deap)\n\t- Distributed Evolutionary Algorithms in Python\n\t- [deap.readthedocs.org/](http://deap.readthedocs.org/ \"http://deap.readthedocs.org/\")\n- #CODE [geneticalgorithm](https://github.com/rmsolgi/geneticalgorithm)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Math-and-Statistics/Linear-Algebra":{"title":"Linear Algebra","content":"\u003e Mathematical discipline that deals with vectors and matrices and, more generally, with vector spaces and linear transformations\n\n## Resources\n- https://en.wikipedia.org/wiki/Linear_algebra\n- https://www.britannica.com/science/linear-algebra\n- [The Matrix Cookbook (Brandt 2012)](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)\n- [Stanford, Linear algebra refresher](https://stanford.edu/~shervine/teaching/cme-102/linear-algebra)\n- Stanford CS229, algebra and calculus refresher: \n\t- https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf\n\t- http://cs229.stanford.edu/section/cs229-linalg.pdf\n- http://people.duke.edu/~ccc14/sta-663/LinearAlgebraReview.html\n- https://www.khanacademy.org/math/linear-algebra\n- http://nbviewer.jupyter.org/github/relopezbriega/relopezbriega.github.io/blob/master/downloads/LinearAlgebraPython.ipynb\n\n### Matrix decompositions\n- See [[AI/Unsupervised learning/Dimensionality reduction and low rank modeling]]\n- See [[AI/Math and Statistics/SVD]]\n- https://en.wikipedia.org/wiki/Matrix_decomposition\n- http://people.duke.edu/~ccc14/sta-663/LinearAlgebraMatrixDecompWithSolutions.html\n- http://hameddaily.blogspot.be/2016/12/simple-matrix-factorization-with.html\n- https://sites.google.com/site/igorcarron2/matrixfactorizations\n- http://blog.ethanrosenthal.com/2017/06/20/matrix-factorization-in-pytorch/\n- https://tryolabs.com/blog/introduction-to-recommender-systems/\n- Alternating Least-squares\n\t- [Fast Python Collaborative Filtering for Implicit Datasets](https://github.com/benfred/implicit)\n\t- [Recommender system using matrix factorization (SVD, ALS)](http://www.benfrederickson.com/matrix-factorization/)\n- Eigen decomposition: \n\t- https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix\n\t- http://setosa.io/ev/eigenvectors-and-eigenvalues/\n- [LU decomposition](https://en.wikipedia.org/wiki/LU_decomposition)\n- [QR decomposition](https://en.wikipedia.org/wiki/QR_decomposition)\n\n\n## Code\n- #CODE [Tensorly](https://github.com/tensorly/tensorly)\n\t- http://tensorly.org\n\t- TensorLy is a Python library that aims at making tensor learning simple and accessible. It allows to easily perform tensor decomposition, tensor learning and tensor algebra. Its backend system allows to seamlessly perform computation with NumPy, PyTorch, JAX, MXNet, TensorFlow or CuPy, and run methods at scale on CPU or GPU\n\t- https://github.com/JeanKossaifi/tensorly-notebooks/\n\t- http://tensorly.org/stable/modules/api.html#module-tensorly.decomposition\n- #CODE [Eigen - Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms](http://eigen.tuxfamily.org/index.php?title=Main_Page)\n- #CODE https://github.com/rballester/tntorch\n\n## Books\n- #BOOK [Templates for the Solution of Algebraic Eigenvalue Problems (Bai, Demmel 2000)](https://www.cs.ucdavis.edu/~bai/ET/contents.html)\n- #BOOK [High Dimensional Data Analysis 2020 (HDA2020)](https://statomics.github.io/HDA2020/index.html)\n\n\n## References\n- #PAPER [tntorch: Tensor Network Learning with PyTorch (Usvyatsov 2022)](https://arxiv.org/pdf/2206.11128)\n\t- https://www.marktechpost.com/2022/06/30/eth-zurich-ai-researchers-introduce-tntorch-a-pytorch-powered-tensor-learning-python-library-that-supports-multiple-decompositions-under-a-unified-interface/","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Math-and-Statistics/Math-and-Statistics":{"title":"Math and Statistics","content":"## Resources\n- https://en.wikipedia.org/wiki/Portal:Mathematics\n- https://en.wikipedia.org/wiki/Mathematics\n- [Statistics cheatsheet](https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-statistics)\n- [Mathematics for Machine Learning](https://github.com/dair-ai/Mathematics-for-ML)\n- https://github.com/rouseguy/intro2stats\n- [Stanford-cs-229 ML, probability and stats refresher](https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-probabilities-statistics.pdf)\n- https://www.khanacademy.org/math/statistics-probability\n- http://christopherroach.com/articles/statistics-for-hackers/\n- [Trigonometry refresher](https://stanford.edu/~shervine/teaching/cme-102/trigonometry)\n\n## Books\n- #BOOK [Essential Mathematics and Statistics for Science (Currell 2009, WILEY)](https://www.wiley.com/en-us/Essential+Mathematics+and+Statistics+for+Science%2C+2nd+Edition-p-9780470694480)\n\t- http://www.stewartschultz.com/statistics/books/Essential%20Mathematics.pdf\n- #BOOK [Think Stats - Exploratory Data Analysis in Python (Downey 2014)](https://greenteapress.com/wp/think-stats-2e/)\n\t- Think Stats is an introduction to Probability and Statistics for Python programmers\n- #BOOK [An Introduction to Statistics with Python (Haslwanter, 2015 6 SPRINGER)](https://www.springer.com/fr/book/9783319283159)\n\t- Applications in the life sciences\n\t- https://es.scribd.com/document/338198132/An-Introduction-to-Statistics-With-Python-With-Applications-in-the-Life-Sciences\n- #BOOK [Statistical Thinking for the 21st Century (Poldrack 2018)](http://statsthinking21.org/index.html)\n\t- R language\n- #BOOK [Jupyter Guide to Linear Algebra](https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/intro.html)\n\n## Courses\n- #COURSE [Statistical inference for data science](https://www.coursera.org/learn/statistical-inference)\n\t- https://leanpub.com/LittleInferenceBook\n\t- [Coursera Inference Version 3](https://www.youtube.com/playlist?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ)\n- #COURSE [Probability and Statistics (Stanford online)](https://lagunita.stanford.edu/courses/course-v1:OLI+ProbStat+Open_Jan2017/about)\n- #COURSE [Modern Applied Statistics: Elements of Statistical Learning (Statistics 315a, Stanford)](http://statweb.stanford.edu/~tibs/stat315a/)\n- #COURSE [Calculus introductory courses (MIT)](https://ocw.mit.edu/high-school/mathematics/)\n\t- [Single Variable Calculus (18.01SC)](https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010)\n\t- [Multivariable Calculus (18.02SC)](https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010)\n\t- [Highlights of calculus (Strang)](https://ocw.mit.edu/resources/res-18-005-highlights-of-calculus-spring-2010)\n- #TALK [Statistics in Python (Varoquaux 2015 Euroscipy)](https://www.youtube.com/watch?v=yaSgoGLXKOg)\n\n## Code\n- #CODE [Numpy](https://numpy.org/)\n\t- #PAPER [Array programming with NumPy (Harris 2020)](https://www.nature.com/articles/s41586-020-2649-2)\n- #CODE [Scipy](https://www.scipy.org/)\n- #CODE [Nums](https://github.com/nums-project/nums)\n\t- A library that translates Python and NumPy to optimized distributed systems code\n- #CODE [Statsmodels](http://www.statsmodels.org/)\n- #CODE [PyLops](https://github.com/PyLops/pylops)\n\t- https://pylops.readthedocs.io/en/latest/index.html\n\t- Python library is inspired by the MATLAB Spot – A Linear-Operator Toolbox project\n- #CODE [Bayesian bootstrap](https://github.com/lmc2179/bayesian_bootstrap)\n\n\n### A/B testing\n- #CODE [Sixpack](https://github.com/sixpack/sixpack)\n- #CODE [Expan (Zalando)](https://github.com/zalando/expan)\n\t- A Python library for statistical analysis of randomised control trials (A/B tests)\n\t- #TALK https://www.youtube.com/watch?v=furJxiZlo6w\n- #CODE Proctor (Indeed): \n\t- https://github.com/indeedeng/proctor\n\t- http://opensource.indeedeng.io/proctor/\n\n\n## Subtopics\n### Calculus\n- [Calculus refresher](https://stanford.edu/~shervine/teaching/cme-102/calculus)\n- Ordinary Differential Equations\n\t- https://stanford.edu/~shervine/teaching/cme-102/cheatsheet-first-ode\n\t- https://stanford.edu/~shervine/teaching/cme-102/cheatsheet-second-ode\n\t- https://stanford.edu/~shervine/teaching/cme-102/cheatsheet-applications\n- [Stanford-cs-229 ML, algebra and calculus refresher](https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf)\n- https://scipy-latinamerica.github.io/revista.io/blog/2018/10/20/introduccion-al-calculo-con-python/\n- https://www.khanacademy.org/math/multivariable-calculus\n\n### Linear Algebra\nSee [[AI/Math and Statistics/Linear Algebra]]\n\n\n### Distances\nSee [[AI/Math and Statistics/Distances]]\n\n\n### Descriptive stats\n- https://en.wikipedia.org/wiki/Descriptive_statistics\n- http://debrouwere.org/2017/02/01/unlearning-descriptive-statistics/\n\n#### Correlation and dependance\n- https://www.datascience.com/blog/introduction-to-correlation-learn-data-science-tutorials\n- https://en.wikipedia.org/wiki/Correlation_and_dependence\n- Correlation is a statistical measure that describes the association between random variables. Why is correlation a useful metric?\n\t- Correlation can help in predicting one quantity from another\n\t- Correlation can (but often does not, as we will see in some examples below) indicate the presence of a causal relationship\n\t- Correlation is used as a basic quantity and foundation for many other modeling techniques\n- Types:\n\t- Pearson’s Correlation: \n\t\t- Pearson is the most widely used correlation coefficient. Pearson correlation measures the linear association between continuous variables. In other words, this coefficient quantifies the degree to which a relationship between two variables can be described by a line. Raw observations are centered by subtracting their means and re-scaled by a measure of standard deviations.\n\t\t- `Ro_X,Y = E[(X - mu_X)(Y - mu_Y)] / simga_X sigma_Y `\n\t\t- numerator  -\u003e covariance\n\t\t- Dividing the covariance between two variables by the product of standard deviations ensures that correlation will always fall between -1 and 1 (much easier to interpret)\n\t- Spearman's Correlation:\n\t\t- Spearman's rank correlation coefficient can be defined as a special case of Pearson ρapplied to ranked (sorted) variables. Rather than comparing means and variances, Spearman's coefficient looks at the relative order of values for each variable. The formula for Spearman's coefficient looks very similar to that of Pearson, with the distinction of being computed on ranks instead of raw scores. \n\t- Kendall's Tau:\n\t\t- Also based on variable ranks, however, unlike Spearman's coefficient, Kendall’s tau does not take into account the difference between ranks— only directional agreement.\n- Covariance (matrix)\n\t- https://en.wikipedia.org/wiki/Covariance\n\t- In probability theory and statistics, covariance is a measure of the joint variability of two random variables. The sign of the covariance therefore shows the tendency in the linear relationship between the variables. The magnitude of the covariance is not easy to interpret. The normalized version of the covariance, the correlation coefficient, however, shows by its magnitude the strength of the linear relation. \n\t- [In multidimensional case: covariance matrix](https://en.wikipedia.org/wiki/Covariance_matrix)\n- Correlation \u0026 Causation \n\t- https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation\n\t- \"Correlation does not imply causation\" is a phrase used in statistics to emphasize that a correlation between two variables does not imply that one causes the other. Spurious statistical associations can be found in a multitude of quantities, simply due to chance.\n\t- Often, a relationship may appear to be causal through high correlation due to some unobserved variables. For example, the number of grocery stores in a city can be strongly correlated with the number of ice cream creameries. However, there is an obvious hidden variable here— the population size of the city.\n\t- https://medium.com/@akelleh/a-technical-primer-on-causality-181db2575e41#.4csn3na8j\n\t- https://www.khanacademy.org/math/probability/scatterplots-a1/creating-interpreting-scatterplots/v/correlation-and-causality\n\t- Also, weak or no correlation does not imply lack of association. Correlation is only one data summary statistic that by no means tells the complete story of relationships in the data.\n\n\n### Experimental design\nSee [[AI/Active learning]]\n- [Coursera - data scientist's toolbox](https://www.youtube.com/watch?v=vSXOJnGNtM4)\n- Good experiment: replication, measure variability, generalise to the problem, transparent\n- Confounding variable - strategies: randomization, stratifying \n- Prediction is not and inference. Both are important and depend on the problem. Prediction is more challenging that inference. For prediction there are key quantities (metrics): sensitivity, specificity, positive predictive value, negative predictive value, accuracy\n\n#### A/B testing\n- https://en.wikipedia.org/wiki/A/B_testing\n- In marketing and business intelligence, A/B testing is a term for a randomized experiment with two variants, A and B, which are the control and variation in the controlled experiment. A/B testing is a form of statistical hypothesis testing with two variants leading to the technical term, two-sample hypothesis testing, used in the field of statistics. Other terms used for this method include bucket tests and split-run testing.\n- https://www.optimizely.com/ab-testing/\n- https://www.wired.com/2012/04/ff_abtesting/\n- http://data36.com/ab-testing-5-rules/\n- https://www.udacity.com/course/ab-testing--ud257\n- https://tech.okcupid.com/the-pitfalls-of-a-b-testing-in-social-networks/\n- https://www.quora.com/What-kind-of-A-B-testing-questions-should-I-expect-in-a-data-scientist-interview-and-how-should-I-prepare-for-such-questions\n- http://www.kdnuggets.com/2017/05/must-know-key-issues-problems-ab-testing.html\n\n#### Multi-armed bandit\n- http://blog.actblue.com/2015/04/29/the-multi-armed-bandit-new-and-much-improved-ab-testing-tools-2/\n- https://conversionxl.com/bandit-tests/\n- https://support.google.com/analytics/answer/2844870?hl=en\n- https://vwo.com/blog/multi-armed-bandit-algorithm/\n\n### Statistical Inference\n- https://en.wikipedia.org/wiki/Statistical_inference\n- https://www.youtube.com/watch?v=WkOinijQmPU\u0026feature=youtu.be\u0026list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/\n- Statistical inference : the process of generating conclusions about a population from a noisy sample. Without statistical inference we’re simply living within our data. With statistical inference, we’re trying to generate new knowledge. The use of probability models as the connection between our data and a populations represents the most effective way to obtain inference.\n- Question to answer: Are the statistics calculated on a small sample representative of the ones of the whole population?\n- http://www.datasciencecentral.com/profiles/blogs/the-death-of-the-statistical-test-of-hypothesis\n\n#### Frequentist inference\n- https://en.wikipedia.org/wiki/Frequentist_inference\n- https://en.wikipedia.org/wiki/Nonparametric_statistics\n- Statistical Hypothesis testing\n\t- http://youtu.be/Wqvx6_12ZMs?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-hypothesis-testing\n\t- Hypothesis testing is concerned with making decisions using data. \n\t- To make decisions using data, we need to characterize the kinds of conclusions we can make. Classical hypothesis testing is concerned with deciding between two decisions (things get much harder if there’s more than two). The first, a null hypothesis is specified that represents the status quo. This hypothesis is usually labeled, H_0. This is what we assume by default. The alternative or research hypothesis is what we require evidence to conclude. This hypothesis is usually labeled H_a, or sometimes H_1 (or some other number other than 0). So to reiterate, the null hypothesis is assumed true and statistical evidence is required to reject it in favor of a research or alternative hypothesis\t\n\t- [t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)\n\t\t- http://www.cs.cornell.edu/~asampson/blog/statsmistakes.html\n\t\t- https://www.quora.com/What-is-an-intuitive-explanation-of-the-t-test-in-hypothesis-testing\n\t\t- https://medium.freecodecamp.org/the-t-distribution-a-key-statistical-concept-discovered-by-a-beer-brewery-dbfdc693184\n\t\t- Good for small samples? \n\t\t\t- Historically, the very first demonstration of the t-test (in \"Student\"'s 1908 paper) was in an application to sample sizes of size four. Indeed, obtaining improved results for smallsamples is the test's claim to fame: once the sample size reaches 40 or so, the t-test is not substantially different from the z-tests researchers had been applying throughout the 19th century.  \n\t\t\t- There is no minimum sample size for the t test to be valid. Validity requires that the assumptions for the test statistic hold approximately. Those assumptions are in the one sample case that the data are iid normal (or approximately normal) with mean 0 under the null hypothesis and a variance that is unknown but estimated from the sample. In the two sample case it is that both samples are independent of each other and each sample consists of iid normal variables with the two samples having the same mean and a common unknown variance under the null hypothesis. A pooled estimate of variance is used for the statistic. \n\t\t\t- The problem with low sample size is with regard to the power of the test. \n\t\t\t- Using the Student’s t-test with extremely small sample sizes (Winter 2013). It is concluded that there are no principal objections to using a t-test with Ns as small as 2. This study showed that there are no objections to using a t-test with extremely small samples, as long as the effect size is large.  \n\t- [z-test](https://en.wikipedia.org/wiki/Z-test)\n\t- [f-test](https://en.wikipedia.org/wiki/F-test)\n\t- [Mann–Whitney U test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)\n\t- [Welch's t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test)\n\t- [Anderson–Darling test](https://en.wikipedia.org/wiki/Anderson%E2%80%93Darling_test)\n\t- [Kolmogorov–Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)\n\t\t- In essence, the test answers the question \"What is the probability that this collection of samples could have been drawn from that probability distribution?\" or, in the second case, \"What is the probability that these two sets of samples were drawn from the same (but unknown) probability distribution?\"\n\t\t- https://asaip.psu.edu/Articles/beware-the-kolmogorov-smirnov-test/\n- Confidence intervals\n\t- http://youtu.be/u85aQ0mtiZ8?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-confidence-intervals\n\t- Confidence intervals are methods for quantifying uncertainty in our estimates. The fact that the interval has width characterizes that there is randomness that prevents us from getting a perfect estimate.\n\t- t-confidence intervals\n\t\t- http://youtu.be/pHXrDMjzyYg?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-t-confidence-intervals\n- Null hypothesis\n\t- https://en.wikipedia.org/wiki/Null_hypothesis\n\t- The term \"null hypothesis\" is a general statement or default position that there is no relationship between two measured phenomena, or no association among groups.\n\t- H_0 is generally assumed to be true until evidence indicates otherwise.\n- P-value\n\t- https://en.wikipedia.org/wiki/P-value\n\t- A p-value is the probability that, using a given statistical model, the statistical summary (such as the sample mean difference between two compared groups) would be the same as or more extreme than the actual observed results, when the null hypothesis is true.\n\t- After choosing the models H_0, H_1 and a threshold value alpha for p (the significance level of the test, traditionally 5% or 1%), if the p-value is less than or equal to alpha, the test suggests that the observed data is inconsistent with the null hypothesis, so the null hypothesis must be rejected. However, that does not prove that the tested hypothesis is true. When the p-value is calculated correctly, this test guarantees that the Type I error rate is at most alpha. For typical analysis, using the standard alpha= 0.05 cutoff, the null hypothesis is rejected when p\u003c .05 and not rejected when p\u003e .05. \n\t- The p-value does not, in itself, support reasoning about the probabilities of hypotheses but is only a tool for deciding whether to reject the null hypothesis (it can only provide evidence against a hypothesis).\n\t- http://youtu.be/Ky68x_7iK6c?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-p-values\n\t- P-values are the most common measure of statistical significance. Their ubiquity, along with concern over their interpretation and use makes them controversial among statisticians.\n\t- http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values\n\t- A P value is the probability of obtaining an effect at least as extreme as the one in your sample data, assuming the truth of the null hypothesis.\n\t- For example, suppose that a vaccine study produced a P value of 0.04. This P value indicates that if the vaccine had no effect, you’d obtain the observed difference or more in 4% of studies due to random sampling error. \n\t- P values address only one question: how likely are your data, assuming a true null hypothesis? It does not measure support for the alternative hypothesis.\n\t- http://machinelearningmastery.com/use-statistical-significance-tests-interpret-machine-learning-results/\n\t- https://www.nature.com/news/big-names-in-statistics-want-to-shake-up-much-maligned-p-value-1.22375\n- Statistical Power\n\t- https://en.wikipedia.org/wiki/Statistical_power\n\t- #TALK Statistical power:\n\t\t- http://youtu.be/-TsBOLiW4rQ?list=PLpl-gQkQivXiB1mGyzLrUjzsblmQsLtkzJ\n\t\t- http://youtu.be/GRS2b1aedmk?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-power\n\t- Power is the probability of rejecting the null hypothesis when it is false. Ergo, power (as its name would suggest) is a good thing; you want more power. A type II error (a bad thing, as its name would suggest) is failing to reject the null hypothesis when it’s false; the probability of a type II error is usually called Beta. Note Power = 1 - Beta.\n- [Effect size](https://en.wikipedia.org/wiki/Effect_size)\n- [Goodness of fit](https://en.wikipedia.org/wiki/Goodness_of_fit)\n\t- [Chi squared](https://en.wikipedia.org/wiki/Chi-squared_test)\n\n### Bootstrap and permutation tests\n- http://youtu.be/0hNQx9nagq4?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-bootstrap-and-resampling\n- The bootstrap is a tremendously useful tool for constructing confidence intervals and calculating standard errors for difficult statistics. That’s the bootstrap principle: investigate the sampling distribution of a statistic by simulating repeated realizations from the observed distribution.\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-permutation-tests\n- Consider comparing means between the group. However, let’s use the calculate the distribution of our statistic under a null hypothesis that the labels are irrelevant (exchangeable). This is a handy way to create a null distribution for our test statistic by simply permuting the labels over and over and seeing how extreme our data are with respect to this permuted distribution. \n- The procedure would be as follows: \n\t- consider a data from with count and spray,\n\t- permute the spray (group) labels,\n\t- recalculate the statistic (such as the difference in means),\n\t- calculate the percentage of simulations where the simulated statistic was more extreme (toward the alternative) than the observed.\n\n#### Bayesian bootstrap\n- http://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/\n\n### Probability theory\nSee [[AI/Math and Statistics/Probability Theory]]\n\n### Bayesian modelling\nSee [[AI/Bayesian modelling]]\n\n### Monte Carlo methods\nSee [[AI/Math and Statistics/Monte Carlo methods]]\n\n### Mathematical Optimization\nSee [[AI/Math and Statistics/Mathematical Optimization]]\n\n### Time series analysis\nSee [[Time Series analysis]]\n\n### Regression analysis\nSee [[AI/Supervised Learning/Regression]]\n- https://en.wikipedia.org/wiki/Regression_analysis\n- Regression analysis is widely used for prediction and forecasting, where its use has substantial overlap with the field of [[AI/Machine Learning]]\n\n### Compressed sensing\nSee [[AI/Unsupervised learning/Sparse dictionary learning]]\n- https://en.wikipedia.org/wiki/Compressed_sensing\n- Compressed sensing(also known as compressive sensing, compressive sampling, or sparse sampling) is a signal processing technique for efficiently acquiring and reconstructing a signal, by finding solutions to underdetermined linear systems. This is based on the principle that, through optimization, the sparsity of a signal can be exploited to recover it from far fewer samples than required by the Shannon-Nyquist sampling theorem.\n- There are two conditions under which recovery is possible: \n\t- Sparsity, which requires the signal to be sparse in some domain. \n\t- Incoherence, which is applied through the isometric property which is sufficient for sparse signals\n- https://calculatedcontent.com/2012/12/28/foundations-theory-of-compressed-sensing/amp/\n\n#### Nyquist theorem\n- https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem\n- In the field of digital signal processing, the sampling theorem is a fundamental bridge between continuous-time signals(often called \"analog signals\") and discrete-time signals(often called \"digital signals\"). It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.\n\n#### Matching pursuit\n- https://en.wikipedia.org/wiki/Matching_pursuit\n- Matching pursuit (MP) is asparse approximation algorithm which involves finding the \"best matching\" projections of multidimensional data onto the span of an over-complete (i.e., redundant) dictionary D.\n- Orthogonal Matching Pursuit\n\t- Extension of MP: after every step, all the coefficients extracted so far are updated, by computing the orthogonal projection of the signal onto the set of atoms selected so far. This can lead to better results than standard MP, but requires more computation.\n\t- http://scikit-learn.org/stable/auto_examples/linear_model/plot_omp.html","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Math-and-Statistics/Mathematical-Optimization":{"title":"Mathematical Optimization","content":"## Resources\n- https://en.wikipedia.org/wiki/Mathematical_optimization\n- [A birds-eye view of optimization algorithms (Pedregosa)](http://fa.bianp.net/teaching/2018/eecs227at/)\n- http://people.duke.edu/~ccc14/sta-663/BlackBoxOptimization.html\n- http://www.benfrederickson.com/numerical-optimization/ (notebook kind of post with python, d3)\n- http://www.kdnuggets.com/2016/12/hard-thing-about-deep-learning.html\n- https://www.neuraldesigner.com/blog/5_algorithms_to_train_a_neural_network\n- [Why Momentum works](http://distill.pub/2017/momentum/)\n\n### Heuristics\n- A heuristic is any algorithm which is not guaranteed (mathematically) to find the solution, but which is nevertheless useful in certain practical situations.\n- [[Genetic algorithms]]\n- [Nelder–Mead method](https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method)\n\t- The Nelder–Mead method or downhill simplex method or amoeba method is a commonly applied numerical method used to find the minimum or maximum of an objective function in a multidimensional space. It is applied to nonlinear optimization problems for which derivatives may not be known. However, the Nelder–Mead technique is a heuristic search method that can converge to non-stationary points on problems that can be solved by alternative methods.\n\t- The method uses the concept of a simplex, which is a special polytope of n+ 1 vertices in n dimensions. Examples of simplices include a line segment on a line, a triangle on a plane, a tetrahedron in three-dimensional space and so forth. The method approximates a local optimum of a problem with n variables when the objective function varies smoothly and is unimodal.\n\t- Nelder–Mead in n dimensions maintains a set of n+1test points arranged as a simplex. It then extrapolates the behavior of the objective function measured at each test point, in order to find a new test point and to replace one of the old test points with the new one, and so the technique progresses. The simplest approach is to replace the worst point with a point reflected through the centroid of the remaining n points. If this point is better than the best current point, then we can try stretching exponentially out along this line. On the other hand, if this new point isn't much better than the previous value, then we are stepping across a valley, so we shrink the simplex towards a better point.\n\t- [The Nelder–Mead algorithm](https://pyfssa.readthedocs.io/en/stable/nelder-mead.html)\n\t- https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin.html\n\n### Iterative methods\n- Iterative methods used to solve problems of nonlinear programming differ according to whether they evaluate Hessians, gradients, or only function values.\n- Gradient descent\n\t- https://en.wikipedia.org/wiki/Gradient_descent\n\t- Gradient descent is a first-order iterative optimization algorithm. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or of the approximate gradient) of the function at the current point. Gradient descent is also known as steepest descent, or the method of steepest descent.\n\t- [An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/index.html)\n\t- https://towardsdatascience.com/gradient-descent-demystified-bc30b26e432a\n\t- https://www.jeremyjordan.me/gradient-descent/\n- [Conjugate gradient method](https://en.wikipedia.org/wiki/Conjugate_gradient_method)\n- [Interior point method](https://en.wikipedia.org/wiki/Interior_point_method)\n\n\n## Code\n- #CODE [Nevergrad (Facebook)](https://code.fb.com/ai-research/nevergrad/)\n\t- A Python toolbox for performing gradient-free optimization\n- #CODE [Theseus (Facebook)](https://github.com/facebookresearch/theseus)\n\t- A library for differentiable nonlinear optimization\n\t- https://sites.google.com/view/theseus-ai\n- #CODE [scikit-optimize](https://scikit-optimize.github.io/)\n- #CODE [GPflowOpt - library for Bayesian Optimization with GPflow](https://gpflowopt.readthedocs.io/en/latest/index.html )\n- #CODE [PyBrain - Black-box Optimization Algorithms](http://pybrain.org/docs/api/optimization/optimization.html)\n- #CODE [JAX](https://github.com/google/jax) ^jax\n\t- JAX is Autograd and XLA, brought together for high-performance machine learning research. It can automatically differentiate native Python and NumPy functions\n\t- #TALK [JAX: Accelerated Machine Learning Research | SciPy 2020 | VanderPlas](https://www.youtube.com/watch?v=z-WSrQDXkuM)\n\t- https://towardsdatascience.com/deep-learning-with-jax-and-elegy-c0765e3ec31a\n\t- #TALK [Machine Learning with JAX - From Zero to Hero](https://www.youtube.com/watch?v=SstuvS-tVc0)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Math-and-Statistics/Monte-Carlo-methods":{"title":"Monte Carlo methods","content":"## Resources\n- https://en.wikipedia.org/wiki/Monte_Carlo_method\n\n### Sequential Monte Carlo (SMC or particle filter)\n- Particle filters or Sequential Monte Carlo (SMC) methods are a set of Monte Carlo algorithms used to solve filtering problems arising in signal processing and Bayesian statistical inference. The filtering problem consists of estimating the internal states in dynamical systems when partial observations are made, and random perturbations are present in the sensors as well as in the dynamical system. The objective is to compute the posterior distributions of the states of some Markov process, given some noisy and partial observations.\n\n### Markov Process\n- https://en.wikipedia.org/wiki/Markov_chain\n- https://en.wikipedia.org/wiki/Markov_property\n- A stochastic process has the Markov property if the conditional probability distribution of future states of the process (conditional on both past and present states) depends only upon the present state, not on the sequence of events that preceded it. A process with this property is called a Markov process.\n- [Markov Chains Explained Visually](http://setosa.io/ev/markov-chains/)\n\n#### Hidden Markov Model (HMM)\n- https://en.wikipedia.org/wiki/Hidden_Markov_model\n- Hidden Markov Model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (i.e. hidden) states.\n- HMM is a Markov chain for which the state is only partially observable. In other words, observations are related to the state of the system, but they are typically insufficient to precisely determine the state. Several well-known algorithms for hidden Markov models exist. \n- https://www.quora.com/What-is-a-hidden-Markov-Model-HMM-and-how-can-it-be-used-in-speech-recognition\n- https://www.quora.com/Why-do-we-use-Hidden-Markov-Models-for-speech-recognition\n- http://scikit-learn.sourceforge.net/stable/modules/hmm.html\n- https://github.com/hmmlearn/hmmlearn\n- http://hmmlearn.readthedocs.io/en/latest/tutorial.html#available-models\n\n### MCMC\n- MCMC methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by recording states from the chain\n- https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo\n\n### Nested Sampling\n- https://en.wikipedia.org/wiki/Nested_sampling_algorithm\n- The nested sampling algorithm is a computational approach to the problem of comparing models in Bayesian statistics. \n\n\n## Code\n- [A list of Python-based MCMC packages. Also here’s a nice list of MCMC algorithms](https://gabriel-p.github.io/pythonMCMC/)\n- #CODE [Sampyl - MCMC samplers for Bayesian estimation in Python, including Metropolis-Hastings, NUTS, and Slice](http://mcleonard.github.io/sampyl/)\n- #CODE [emcee](http://dan.iel.fm/emcee/current/)\n- #CODE UltraNest - A Pythonic implementation of the Nested Sampling integration algorithm for Bayesian model comparison and parameter estimation\n\t- https://johannesbuchner.github.io/UltraNest/\n\t- https://johannesbuchner.github.io/UltraNest/testsuite/","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Math-and-Statistics/Probability-Theory":{"title":"Probability Theory","content":"## Resources\n- https://en.wikipedia.org/wiki/Probability_theory\n- https://stanford.edu/~shervine/teaching/cme-106/key-concepts\n- [A visual introduction to probability and statistics](http://students.brown.edu/seeing-theory/)\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-probability\n- Probability forms the foundation for almost all treatments of statistical inference. Probability is a law that assigns numbers to the long run occurrence of random phenomena after repeated unrelated realizations\n- http://nbviewer.jupyter.org/url/norvig.com/ipython/Probability.ipynb\n- https://en.wikipedia.org/wiki/Probability_interpretations\n- https://en.wikipedia.org/wiki/Bayesian_probability\n- [The Coursera Statistical Inference class](http://youtu.be/oTERv_vrmJM?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ)\n- [Monty Hall problem](https://en.wikipedia.org/wiki/Monty_Hall_problem)\n- [Coded in Python](https://github.com/cs109/2015lab1/blob/master/hw0.ipynb)\n- Cheatsheets:\n\t- https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-probability\n\t- Probability Cheatsheet (Chen): \n\t\t- http://www.wzchen.com/probability-cheatsheet/\n\t\t- This is an 10-page probability cheatsheet compiled from Harvard's Introduction to Probability course, taught by Joe Blitzstein (@stat110). The probability formula sheet summarizes important probability probability concepts, formulas, and distributions, with figures, examples, and stories.\n\t- Review of Probability Theory (CS229 Stanford)\n\t\t- http://cs229.stanford.edu/section/cs229-prob.pdf\t\n\t\t- http://cs229.stanford.edu/section/cs229-prob-slide.pdf\n\n#### Random variables\n- http://youtu.be/Shzt9uZ8BII?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-random-variables\n- Random variable is a numerical outcome of an experiment. The random variables that we study will come in two varieties, discrete or continuous. Discrete random variables are random variables that take on only a countable number of possibilities. Mass functions will assign probabilities that they take specific values. Continuous random variable can conceptually take any value on the real line or some subset of the real line and we talk about the probability that they lie within some range. Densities will characterize these probabilities.\n- For all of these kinds of random variables, we need convenient mathematical functions to model the probabilities of collections of realizations. These functions, called mass functions and densities, take possible values of the random variables, and assign the associated probabilities. These entities describe the population of interest.\n- PDF - probability density function\n\t- https://en.wikipedia.org/wiki/Probability_density_function\n\t- http://youtu.be/mPe0Us4VYDM?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-probability-density-functions\n\t- A probability density function (pdf), is a function associated with a continuous random variable. Because of the peculiarities of treating measurements as having been recorded to infinite decimal expansions, we need a different set of rules. This leads us to the central dogma of probability density functions: Areas under PDFs correspond to probabilities for that random variable. \n\t- A PDF, or density of a continuous random variable, is a function, whose value at any given sample (or point) in the sample space(the set of possible values taken by the random variable) can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample.\n\t- The PDF is used to specify the probability of the random variable falling within a particular range of values, as opposed to taking on any one value.\n\n#### Conditional probability\n- http://youtu.be/u6AH6qsSVA4?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-conditional-probability\n- Conditioning is a central subject in statistics. If we are given information about a random variable, it changes the probabilities associated with it. For example, the probability of getting a one when rolling a (standard) die is usually assumed to be one sixth. If you were given the extra information that the die roll was an odd number (hence 1, 3 or 5) then conditional on this new information, the probability of a one is now one third.\n- http://setosa.io/ev/conditional-probability/\n\n#### Independance\n- https://en.wikipedia.org/wiki/Independence_(probability_theory)\n- http://youtu.be/MY1EfrR1ZUs?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-independence\n- Statistical independence of events is the idea that the events are unrelated. Consider successive coin flips. Knowledge of the result of the first coin flip tells us nothing about the second.\n- The important principle is that probabilities of independent things multiply! This has numerous consequences, including the idea that we shouldn’t multiply non-independent probabilities.\n- [IID samples ](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)\n\t- IID - Independent and identically distributed \n\t- In probability theory and statistics, a sequence or other collection of random variables is independent and identically distributed(i.i.d.) if each random variable has the same probability distribution as the others and all are mutually independent.\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-iid-random-variables\n\t- Random variables are said to be independent and identically distributed (iid) if they are independent and all are drawn from the same population. The reason iid samples are so important is that they are a model for random samples. This is a default starting point for most statistical inferences.\n  \n#### Common distributions\n- https://stanford.edu/~shervine/teaching/cme-106/distribution-tables\n- https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-some-common-distributions\n- [Normal distribution](http://efavdb.com/normal-distributions/)\n- Bernoulli\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-bernoulli-distribution\n\t- TheBernoulli distribution arises as the result of a binary outcome, such as a coin flip.\n- Normal\n\t- http://youtu.be/dUTWvKa0Leo?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-normal-distribution\n\t- The normal distribution is easily the handiest distribution in all of statistics. It can be used in an endless variety of settings. Moreover, as we’ll see later on in the course, sample means follow normal distributions for large sample sizes.\n\t- The normal distribution only requires two numbers to characterize it, mean and variance.\n- Poisson\n\t- http://youtu.be/ZPLZg7qz4xE?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-poisson-distribution\n\t- The Poisson distribution is used to model counts. It is perhaps only second to the normal distribution usefulness. In fact, the Bernoulli, binomial and multinomial distributions can all be modeled by clever uses of the Poisson.\n\t- The Poisson distribution is especially useful for modeling unbounded counts or counts per unit of time (rates). Like the number of clicks on advertisements, or the number of people who show up at a bus stop. There is also a deep connection between the Poisson distribution and popular models for so-called event-time data.\n\n#### Expected value\n- https://en.wikipedia.org/wiki/Expected_value\n- In probability theory, the expected value of a random variable, intuitively, is the long-run average value of repetitions of the experiment it represents.\n- Less roughly, the law of large numbers states that the arithmetic mean of the values almost surely converges to the expected value as the number of repetitions approaches infinity. The expected value is also known as the expectation, mathematical expectation, EV, average, mean value, mean, or first moment.\n- [Expected values](http://youtu.be/zljxRbu6jyc?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ)\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-expected-values\n- Expected values characterize a distribution. The most useful expected value, the mean, characterizes the center of a density or mass function. Another expected value summary, the variance, characterizes how spread out a density is. Yet another expected value calculation is the skewness, which considers how much a density is pulled toward high or low values.\n\n#### Central limit theorem\n- https://en.wikipedia.org/wiki/Central_limit_theorem\n- http://youtu.be/FAIyVHmniK0?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-central-limit-theorem\n- CLT is one of the most important theorems in statistics. For our purposes, the CLT states that the distribution of averages of iid variables becomes that of a standard normal as the sample size increases.\n\n#### Kullback-Leibler Divergence\n- https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n- https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained\n\n\n## Books\n- #COURSE [Introduction to Probability and Statistics (MIT)](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Math-and-Statistics/SVD":{"title":"Singular Value Decomposition (SVD)","content":"\u003e The singular value decomposition (SVD) is a factorization of a real or complex matrix. It generalizes the eigendecomposition of a square normal matrix with an orthonormal eigenbasis to any `m x n` matrix\n\n\u003e See [[AI/Unsupervised learning/PCA#PCA and SVD]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Singular_value_decomposition\n- https://mathworld.wolfram.com/SingularValueDecomposition.html\n- [Geometric explanation of SVD and applications](http://www.ams.org/publicoutreach/feature-column/fcarc-svd)\n- [Cool Linear Algebra: Singular Value Decomposition](https://andrew.gibiansky.com/blog/mathematics/cool-linear-algebra-singular-value-decomposition/)\n- [Singular Value Decomposition as Simply as Possible](https://gregorygundersen.com/blog/2018/12/10/svd/)\n- https://jeremykun.com/2016/04/18/singular-value-decomposition-part-1-perspectives-on-linear-algebra/\n- Implementations:\n\t- https://fa.bianp.net/blog/2012/singular-value-decomposition-in-scipy/\n\t- http://scicomp.stackexchange.com/questions/1861/understanding-how-numpy-does-svd\n\t- http://scicomp.stackexchange.com/questions/6979/how-is-the-svd-of-a-matrix-computed-in-practice\n\t- https://software.intel.com/sites/products/documentation/doclib/mkl_sa/11/mkl_lapack_examples/sgesdd.htm \n\t- http://www.alglib.net/matrixops/general/svd.php \n\t- LAPACK implements a divide and conquer algorithm SGESDD or DGESDD (not the “highly accurate” Golub-Kahan-Reinsch algorithm, SGESVD or DGESVD) \n\t- [Truncated SVD by implicitly restarted Lanczos bidiagonalization for Python Numpy](https://github.com/bwlewis/irlbpy)\n\t- https://stackoverflow.com/questions/15414027/multiprocessing-pool-makes-numpy-matrix-multiplication-slower\n\n### Randomized SVD\n- https://gregorygundersen.com/blog/2019/01/17/randomized-svd/\n- [Fast Randomized SVD (Meta/Facebook research)](https://research.facebook.com/blog/2014/09/fast-randomized-svd/)\n\n## Talks\n- #TALK [SVD (MIT, Gilbert Strang)](https://www.youtube.com/watch?v=mBcLRGuAFUk)\n- #TALK [Singular Value Decomposition (SVD): Mathematical Overview](https://www.youtube.com/watch?v=nbBvuuNVfco)\n- #TALK [Randomized Singular Value Decomposition (SVD)](https://www.youtube.com/watch?v=fJ2EyvR85ro)\n\n## References\n- #PAPER [Singular value decomposition and least squares solutions (Golub \u0026 Reinsch 1970)](https://link.springer.com/article/10.1007/BF02163027)\n\t- http://people.duke.edu/~hpgavin/SystemID/References/Golub+Reinsch-NM-1970.pdf\n- #PAPER [Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions (Halko 2010)](https://arxiv.org/pdf/0909.4061)","lastmodified":"2022-09-05T14:10:31.886035744Z","tags":null},"/AI/Multi-task-learning":{"title":"Multi-task learning","content":"\u003e Multi-task learning is a subfield of machine learning in which multiple learning tasks are solved at the same time, while exploiting commonalities and differences across tasks\n\n\u003e See: \n\u003e - [[AI/Transfer learning]] \n\u003e - [[AI/Deep learning/Multimodal learning]]\n\n\n## Resources\n- https://en.wikipedia.org/wiki/Multi-task_learning\n\t- Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better\n\t- Multi-task learning works because regularization induced by requiring an algorithm to perform well on a related task can be superior to regularization that prevents overfitting by penalizing all complexity uniformly\n- [An Overview of Multi-Task Learning in Deep Neural Networks](https://ruder.io/multi-task/)\n\n## Courses\n- #COURSE [CS 330](https://cs330.stanford.edu/): Deep Multi-Task and Meta Learning (Stanford)\n\t- [Videos](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)\n- #COURSE Multi task learning [lecture](https://www.youtube.com/watch?v=Tjtzml4PQWE) (CS 152 Neural Networks, Harvey Mudd college)\n- #COURSE Multi task Learning [lecture](https://www.youtube.com/watch?v=UdXfsAr4Gjw) (DeepLearningAI, Andrew Ng)\n\n\n## References\n- #PAPER [Multitask Learning (Caruana 1997)](https://link.springer.com/article/10.1023/A:1007379606734)\n\t- http://www.cs.cornell.edu/~caruana/mlj97.pdf\n- #PAPER [Multi-Task Learning with Deep Neural Networks: A Survey (Crawshaw 2020)](https://arxiv.org/abs/2009.09796)\n- #PAPER [Which Tasks Should Be Learned Together in Multi-task Learning? (Standley 2020)](https://arxiv.org/pdf/1905.07553)\n\t- #TALK https://www.youtube.com/watch?v=qCRdrczbqUo\n- #PAPER [Multi-task UNet: Jointly Boosting Saliency Prediction and Disease  Classification on Chest X-ray Images (Zhu 2022)](https://arxiv.org/pdf/2202.07118)\n\t- #CODE https://github.com/hz-zhu/MT-UNet","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/NLP":{"title":"Natural Language Processing (NLP)","content":"---\n\n\u003e A Computer Science field connected to Artificial Intelligence and Computational Linguistics which focuses on interactions between computers and human language and a machine’s ability to understand, or mimic the understanding of human language\n\n## Resources\n- https://en.wikipedia.org/wiki/Natural_language_processing\n- NLP is a branch of data science that consists of systematic processes for analyzing, understanding, and deriving information from the text data in a smart and efficient manner. By utilizing NLP and its components, one can organize the massive chunks of text data, perform numerous automated tasks and solve a wide range of problems such as – automatic summarization, machine translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation etc.\n- https://github.com/keon/awesome-nlp\n- [The most important NLP highlights of 2018](https://github.com/omarsar/nlp_highlights)\n- [NLP - Udemy ML](https://github.com/jmportilla/Udemy","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Neuro-symbolic-AI":{"title":"Neuro-symbolic AI","content":"\u003e Neuro-Symbolic AI uses deep learning neural network architectures and combines them with symbolic reasoning techniques\n\n## Resources\n- https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence\n- [Neuro-symbolic AI](https://research.ibm.com/topics/neuro-symbolic-ai)\n- [What Is Neuro-Symbolic AI And Why Are Researchers Gushing Over It](https://analyticsindiamag.com/what-is-neuro-symbolic-ai-and-why-are-researchers-gushing-over-it/)\n- [Neuro-Symbolic Artificial Intelligence](https://people.cs.ksu.edu/~hitzler/nesy/)\n\n## Course\n- #COURSE [NeuroSymbolic Artificial Intelligence Course (U at Buffalo)](https://cedar.buffalo.edu/~srihari/CSE701/index.html)\n- #COURSE [MIT 6.S191 (2020): Neurosymbolic AI](https://www.youtube.com/watch?v=4PuuziOgSU4)\n\n## References\n- #PAPER [Neurosymbolic AI: The 3rd Wave (d'Avila Garcez 2020)](https://arxiv.org/pdf/2012.05876)\n- #PAPER [The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence (Marcus 2020)](https://arxiv.org/abs/2002.06177v3)\n\t- https://www.zdnet.com/article/rebooting-ai-deep-learning-meet-knowledge-graphs/\n\t- #TALK [AI debate: Yoshua Bengio | Gary Marcus](https://www.youtube.com/watch?v=EeqwFjqFvJA)\n- #PAPER [Neuro-Symbolic AI: An Emerging Class of AI Workloads and their  Characterization (Susskind 2021)](https://arxiv.org/pdf/2109.06133)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/One-few-shot-learning":{"title":"One, few-shot learning","content":"\u003e One-shot learning is an object categorization problem, found mostly in computer vision. Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of samples/images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training samples/images.\n\n## Resources\n- https://en.wikipedia.org/wiki/One-shot_learning\n- https://medium.com/sap-machine-learning-research/deep-few-shot-learning-a1caa289f18\n- https://sorenbouma.github.io/blog/oneshot/\n- https://github.com/Goldesel23/Siamese-Networks-for-One-Shot-Learning\n- [Zero-Shot Visual Imitation](https://pathak22.github.io/zeroshot-imitation/)\n- #TALK [Neural Networks - One Shot Learning](https://www.youtube.com/watch?v=r8LLorRACPM)\n\n\n## Code\n- #CODE [LibFewShot](https://github.com/rl-vig/libfewshot)\n\t- #PAPER [LibFewShot: A Comprehensive Library for Few-shot Learning (Li 2021)](https://arxiv.org/abs/2109.04898)\n\t- LibFewShot: A Comprehensive Library for Few-shot Learning (pytorch)\n\n## References\n- #PAPER [Siamese Neural Networks for One-shot Image Recognition (Koch 2015)](http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\n\t- Few-Shot learning has seen great progress over the last years. A classic approach is based on metric learning using Siamese neural networks.\n\t- #CODE https://sorenbouma.github.io/blog/oneshot/\n- #PAPER [One-Shot Imitation Learning (Duan 2017)](https://arxiv.org/abs/1703.07326)\n- #PAPER [One-shot texture segmentation (Ustyuzhaninov 2018)](https://arxiv.org/abs/1807.02654)\n\t- We solve the task of one-shot texture segmentation in three steps. First, we compute embeddings of an input image and a reference patch; second, we search for the reference texture in the embedding space to produce a rough segmentation mask; and, finally, we employ a decoding network to produce the output segmentation.\n- #PAPER [One-shot instance segmentation (Michaelis 2018)](https://arxiv.org/abs/1811.11507 )\n\t- We tackle one-shot visual search by example for arbitrary object categories: Given an example image of a novel reference object, find and segment all object instances of the same category within a scene. To address this problem, we propose Siamese Mask R-CNN. \n\t- It extends Mask R-CNN by a Siamese backbone encoding both reference image and scene, allowing it to target detection and segmentation towards the reference category.\n- #PAPER [FIGR: Few-shot Image Generation with Reptile (Clouatre 2019)](https://arxiv.org/abs/1901.02199)\n- #PAPER [Generalizing from a Few Examples: A Survey on Few-Shot Learning (Wang 2020)](https://arxiv.org/abs/1904.05046)\n- #PAPER ['Less Than One'-Shot Learning: Learning N Classes From M \u003c N Samples (Sucholutsky 2020)](https://arxiv.org/abs/2009.08449)\n\t- https://www.technologyreview.com/2020/10/16/1010566/ai-machine-learning-with-tiny-data/\n\t- AI model able to accurately recognize more objects than the number of examples it was trained on\n\t- The trick, was to create images that blend multiple digits together and then feed them into an AI model with hybrid, or “soft,” labels\n\n\n### Few/one-shot learning GANs \n- #PAPER [MetaGAN: An Adversarial Approach to Few-Shot Learning (Zhang 2018)](https://papers.nips.cc/paper/7504-metagan-an-adversarial-approach-to-few-shot-learning)\n- #PAPER [SinGAN: Learning a Generative Model from a Single Natural Image, SinGAN (Rott Shaham, ICCV 2019 Best Paper)](https://arxiv.org/abs/1905.01164 )\n\t- [ Paper explained](https://www.youtube.com/watch?v=-f8sz8AExdc )\n\t- [ Paper explained](https://www.youtube.com/watch?v=Xc9Rkbg6IZA)\n- #PAPER [DAWSON: A Domain Adaptive Few Shot Generation Framework (Liang 2020)](https://arxiv.org/abs/2001.00576)\n- #PAPER [LARGE: Latent-Based Regression through GAN Semantics (Nitzan 2021)](https://arxiv.org/abs/2107.11186)\n\t- #CODE https://github.com/YotamNitzan/LARGE","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Problem-Solving-and-Search":{"title":"Problem Solving and Search","content":"## Resources\n- [Solving problems by searching](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture2.md)\n- [Problem solving and search](https://www.emse.fr/~picard/cours/ai/chapter03.pdf)\n- Constraint satisfaction problems:\n\t- Constraint satisfaction problems (CSPs) are mathematical questions defined as a set of objects whose state must satisfy a number of constraints or limitations. CSPs represent the entities in a problem as a homogeneous collection of finite constraints over variables, which is solved by constraint satisfaction methods. CSPs are the subject of intense research in both artificial intelligence and operations research, since the regularity in their formulation provides a common basis to analyze and solve problems of many seemingly unrelated families. \n\t- [Constraint satisfaction problems](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture3.md)\n\t- [Constraint satisfaction problems](https://www.emse.fr/~picard/cours/ai/chapter06.pdf)\n- Adversarial Search\n\t- [Games and adversarial search](https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture4.md)\n\t- [Adversarial search](https://www.emse.fr/~picard/cours/ai/chapter05.pdf)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/QML":{"title":"Quantum Machine Learning (QML)","content":"\u003e Quantum machine learning is the integration of quantum algorithms within machine learning programs\n\n## Resources\n- https://github.com/Christophe-pere/Roadmap-to-QML\n- https://en.wikipedia.org/wiki/Quantum_machine_learning\n\n## Talks\n- #TALK [An introduction to Quantum Machine Learning](https://www.youtube.com/watch?v=-DWng3jyBIM) - Webinar (27-04-2020)\n\n## References\n- #PAPER [Modern applications of machine learning in quantum sciences (Dawid 2022)](https://arxiv.org/pdf/2204.04198)\n- #PAPER [Systematic Literature Review: Quantum Machine Learning and its  applications (Peral Garcia 2022)](https://arxiv.org/pdf/2201.04093)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Reinforcement-learning":{"title":"Reinforcement learning (RL)","content":"\u003e Reinforcement learning (RL) is an area of [[AI/Machine Learning]] concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward\n\n## Resources\n- https://en.wikipedia.org/wiki/Reinforcement_learning\n- Reinforcement learning is the task of learning what actions to take, given a certain situation/environment, so as to maximize a reward signal. The interesting difference between supervised and reinforcement learning is that this reward signal simply tells you whether the action (or input) that the agent takes is good or bad. It doesn’t tell you anything about what the best action is. Contrast this to CNNs where the corresponding label for each image input is a definite instruction of what the output should be for each input. Another unique component of RL is that an agent’s actions will affect the subsequent data it receives. For example, an agent’s action of moving left instead of right means that the agent will receive different input from the environment at the next time step.\n- [Curriculum for Reinforcement Learning](https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html)\n- [Andrej Karpathy's introduction to RL](http://karpathy.github.io/2016/05/31/rl/)\n- [Spinning Up as a Deep RL Researcher](https://spinningup.openai.com/en/latest/spinningup/spinningup.html)\n- [Evolution strategies vs RL](https://blog.openai.com/evolution-strategies/)\n\t- https://github.com/openai/evolution-strategies-starter\n- [Reinforcement learning derivations (math)](http://www.alexirpan.com/rl-derivations/)\n- [Introduction to various RL algos](https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287)\n- [Q-learning](https://en.wikipedia.org/wiki/Q-learning)\n- Temporal differencing (TD) learning  is a prediction-based machine learning method. \n\t- It has primarily been used for the reinforcement learning problem, and is said to be \"a combination ofMonte Carlo ideas and dynamic programming (DP) ideas.\" \n\t- TD resembles a Monte Carlo method because it learns by sampling the environment according to some policy, and is related to dynamic programming techniques as it approximates its current estimate based on previously learned estimates (a process known as bootstrapping). The TD learning algorithm is related to the temporal difference model of animal learning. As a prediction method, TD learning considers that subsequent predictions are often correlated in some sense.\n\t- TD-Lambda: This algorithm was famously applied by Gerald Tesauro to createTD-Gammon, a program that learned to play the game of backgammon at the level of expert human players. The lambda parameter refers to the trace decay parameter, with 0\u003c= lambda \u003c=1. Higher settings lead to longer lasting traces; that is, a larger proportion of credit from a reward can be given to more distant states and actions when lambda is higher, with lambda=1 producing parallel learning to Monte Carlo RL algorithms.\n- [SARSA](https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action)\n\n\n## Courses, talks and books\n- #COURSE [Reinforcement Learning (UCL)](https://www.davidsilver.uk/teaching/)\n\t- [Videos](https://www.youtube.com/watch?v=2pWv7GOvuf0\u0026list=PLzuuYNsE1EZAXYR4FJ75jcJseBmo4KQ9-)\n- #COURSE [CS294-112 Deep Reinforcement Learning Sp17](https://www.youtube.com/playlist?list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX)\n- #COURSE [Practical Reinforcement Learning (Yandex)](https://github.com/yandexdataschool/Practical_RL)\n- #COURSE [Tutorial: Introduction to Reinforcement Learning](https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W3D2_BasicReinforcementLearning/student/W3D2_Tutorial1.ipynb)\n- #TALK [Deep Learning and Reinforcement Learning Summer School, Toronto 2018](http://videolectures.net/DLRLsummerschool2018_toronto/)\n- #TALK [Deep RL Bootcamp](https://sites.google.com/view/deep-rl-bootcamp/lectures\t  )\n- #BOOK [Deep Reinforcement Learning (2020 SPRINGER)](https://www.springer.com/gp/book/9789811540943)\n\t- https://deepreinforcementlearningbook.org/\n\n\n## Code\n- #CODE [Acme: a research framework for reinforcement learning](https://github.com/deepmind/acme)\n- #CODE [Deep Reinforcement Learning Model ZOO](https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement_learning)\n- #CODE [Open.ai Gym - A toolkit for developing and comparing reinforcement learning algorithms](https://github.com/openai/gym)\n\t- https://gym.openai.com/\n\t- #PAPER http://arxiv.org/abs/1606.01540\n- #CODE [Horizon (Facebook) - The first open source reinforcement learning platform for large-scale products and services](https://github.com/facebookresearch/Horizon)\n- #CODE [Keras-rl - Deep Reinforcement Learning for Keras](https://github.com/keras-rl/keras-rl)\n- #CODE [TRFL (pronounced \"truffle\") is a library built on top of TensorFlow that exposes several useful building blocks for implementing Reinforcement Learning agents](https://github.com/deepmind/trfl/)\n- #CODE [Surreal - Open-Source Distributed Reinforcement Learning Framework by Stanford Vision and Learning Lab](https://github.com/SurrealAI/surreal)\n\t- https://surreal.stanford.edu\n- #CODE Tensorforce - Tensorforce is an open-source deep reinforcement learning framework, with an emphasis on modularized flexible library design and straightforward usability for applications in research and practice. \n\t- https://github.com/tensorforce/tensorforce\n\t- https://reinforce.io/blog/introduction-to-tensorforce/\n- #CODE [Tensorlayer](https://github.com/tensorlayer/tensorlayer)\n\t- Deep Learning and Reinforcement Learning Library for Scientists and Engineers\n\t- https://tensorlayer.readthedocs.io/en/latest/index.html\n\n\n## References\n- #PAPER [DQN: Human-level control through Deep Reinforcement Learning (Mnih 2015)](https://deepmind.com/research/dqn/)\n\t- https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf\n- #PAPER [Learning to Optimize (Li 2016)](https://arxiv.org/abs/1606.01885)\n\t- [Learning to Optimize with Reinforcement Learning](https://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/)\n- #PAPER [Deep Recurrent Q-Learning for Partially Observable MDPs (Hausknecht 2017)](https://arxiv.org/abs/1507.06527)\n- #PAPER [Neural Episodic Control (Pritzel 2017)](https://arxiv.org/abs/1703.01988)\n\t- Deep reinforcement learning methods attain super-human performance in a wide range of environments. Such methods are grossly inefficient, often taking orders of magnitudes more data than humans to achieve reasonable performance\n\t- Neural Episodic Control: a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them. \n\t- The agent uses a semi-tabular representation of the value function: a buffer of past experience containing slowly changing state representations and rapidly updated estimates of the value function\n\t- https://www.technologyreview.es/s/6656/olvidese-del-aprendizaje-profundo-el-nuevo-enfoque-de-google-funciona-mucho-mejor\n\t- [Explanation of Neural Episodic Control](https://rylanschaeffer.github.io/content/research/neural_episodic_control/main.html)\n- #PAPER #REVIEW [A Brief Survey of Deep Reinforcement Learning (Arulkumaran 2017)](https://arxiv.org/abs/1708.05866)\n\t- Many of the successes in DRL have been based on scaling up prior work in RL to high-dimensional problems. This is due to the learning of low-dimensional feature representations and the powerful function approximation properties of neural networks. By means of representation learning, DRL can deal efficiently with the curse of dimensionality, unlike tabular and traditional non-parametric methods.\n\t- https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-2-Reinforcement-Learning\n- #PAPER #REVIEW [An Introduction to Deep Reinforcement Learning (Fancois-Lavet 2018)](https://arxiv.org/abs/1811.12560)\n- #PAPER [Supervising strong learners by amplifying weak experts (Christiano 2018)](https://arxiv.org/abs/1810.08575)\n\t- [Learning Complex Goals with Iterated Amplification](https://blog.openai.com/amplifying-ai-training/)\n- #PAPER [MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model (Schrittwieser 2019)](https://deepmind.com/research/publications/MasterinModel)\n\t- https://medium.com/dataseries/deepminds-muzero-is-one-of-the-most-important-deep-learning-systems-ever-created-347442a6793g-Atari-Go-Chess-and-Shogi-by-Planning-with-a-Learned-\n- #PAPER #REVIEW [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems (Levine 2020)](https://arxiv.org/abs/2005.01643)\n- #PAPER [Decision Transformer: Reinforcement Learning via Sequence Modeling (Chen 2021)](https://arxiv.org/abs/2106.01345v1) ^decisiontransformer\n\t- #CODE https://paperswithcode.com/paper/decision-transformer-reinforcement-learning\n\t- [Paper explained](https://www.youtube.com/watch?v=-buULmf7dec)\n- #PAPER [Reward is enough (Silver 2021)](https://www.sciencedirect.com/science/article/pii/S0004370221000862)\n\t- https://towardsdatascience.com/reward-is-enough-ml-paper-review-e448ee0a6092\n\t- From the authors of “Attention is all you need”, this paper proposes an intriguing hypothesis that incentivizing AI agents with reward is enough to achieve General Artificial Intelligence\n\t- \"General intelligence, of the sort possessed by humans and perhaps also other animals, may be defined as the ability to flexibly achieve a variety of goals in different contexts. According to our hypothesis, general intelligence can instead be understood as, and implemented by, maximising a singular reward in a single, complex environment4\"","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Self-supervised-learning":{"title":"Self-supervised learning","content":"\u003e Self-supervised learning deals with learning from unlabeled sample data. It can be regarded as an intermediate form between [[AI/Supervised Learning/Supervised learning]] and [[AI/Unsupervised learning/Unsupervised learning]]\n\n\u003e See \"Self-supervised vision transformers\" subsection in [[AI/Deep learning/Transformers]]\n\n## Resources\n- https://github.com/jason718/awesome-self-supervised-learning\n- https://en.wikipedia.org/wiki/Self-supervised_learning\n- https://hackernoon.com/self-supervised-learning-gets-us-closer-to-autonomous-learning-be77e6c86b5a\n- [Self-Supervised Representation Learning](https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html)\n- [Self-Supervised Vision Models (2021, Dr. Ishan Misra - FAIR)](https://www.youtube.com/watch?v=EXJmodhu4_4)\n- [Self-supervised learning: The dark matter of intelligence](https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/)\n\t- The general technique of self-supervised learning is to predict any unobserved or hidden part (or property) of the input from any observed or unhidden part of the input\n\t- [Blog post explained](https://www.youtube.com/watch?v=Ag1bw8MfHGQ\u0026t=6s)\n\t\n \n## Code\n- #CODE [VISSL](https://github.com/facebookresearch/vissl)\n\t- FAIR's library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images\n- #CODE [Solo-learn](https://github.com/vturrisi/solo-learn)\n\t- A library of self-supervised methods for unsupervised visual representation learning powered by PyTorch Lightning\n\t- Methods available: Barlow Twins, BYOL, DeepCluster V2, DINO, MoCo V2+, NNCLR, ReSSL, SimCLR + Supervised Contrastive Learning, SimSiam, Swav, VICReg, W-MSE\n\t- https://arxiv.org/abs/2108.01775v2\n- #CODE [Lightly](https://github.com/lightly-ai/lightly)\n\t- A python library for self-supervised learning on images\n- #CODE [OpenSelfSup](https://github.com/open-mmlab/OpenSelfSup)\n\t- Self-Supervised Learning Toolbox and Benchmark\n- #CODE [Curator](https://github.com/spaceml-org/Self-Supervised-Learner)\n\t- A No-Code, Self-Supervised Learning and Active Labeling Tool to Create Labeled Image Datasets from Petabyte-Scale Imagery\n\n\n## References\n- #PAPER [Self-Supervised Learning of Pretext-Invariant Representations (Misra 2019)](https://arxiv.org/abs/1912.01991)\n- #PAPER [A Framework For Contrastive Self-Supervised Learning And Designing A New Approach (Falcon 2020)](https://arxiv.org/abs/2009.00104)\n\t- https://towardsdatascience.com/a-framework-for-contrastive-self-supervised-learning-and-designing-a-new-approach-3caab5d29619\n- #PAPER [RegNet - Designing Network Design Spaces (Radosavovic 2020)](https://arxiv.org/abs/2003.13678v1)\n- #PAPER [Transferable Visual Words: Exploiting the Semantics of Anatomical Patterns for Self-supervised Learning (Haghighi 2021)](https://arxiv.org/abs/2102.10680)\n- #PAPER [Instance Localization for Self-supervised Detection Pretraining (Yang 2021)](https://arxiv.org/abs/2102.08318)\n- #PAPER [Supervised Contrastive Learning (Khosla 2021)](https://arxiv.org/abs/2004.11362)\n\t- #CODE https://github.com/google-research/google-research/tree/master/supcon\n\t- #CODE https://keras.io/examples/vision/supervised-contrastive-learning/\n\t- extended the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information\n\t- clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Semi-supervised-learning":{"title":"Semi-supervised learning","content":"\u003e  Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data)\n\n## Resources\n- https://en.wikipedia.org/wiki/Semi-supervised_learning\n- In contrast (to active learning), semi-supervised learning attempts to automatically exploit unlabeled data in addition to labeled data to improve learning performance, where no human intervention is assumed. \n- https://deepai.org/machine-learning-glossary-and-terms/semi-supervised-learning\n- https://scikit-learn.org/stable/modules/label_propagation.html\n\n## Code\n- #CODE [TorchSSL](https://github.com/TorchSSL/TorchSSL)\n\t- A PyTorch-based Toolbox for Semi-Supervised Learning\n\n## References\n- #PAPER [Semi-Supervised Learning Literature Survey (2008)](http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf)\n- #PAPER [Learning Loss Functions for Semi-supervised Learning via Discriminative Adversarial Networks (Nogueira Dos Santos 2017)](https://arxiv.org/abs/1707.02198)\n- #PAPER [Semi-Supervised Learning with Normalizing Flows (Izmailov, 2019)](https://arxiv.org/abs/1912.13025)\n\t- #CODE https://github.com/izmailovpavel/flowgmm\n- #PAPER [Self-training with Noisy Student improves ImageNet classification (Xie 2020)](https://arxiv.org/abs/1911.04252)\n\t- [Paper explained](https://www.youtube.com/watch?v=q7PjrmGNx5A)\n\t- Noisy Student Training, a semi-supervised learning approach that works well even when labeled data is abundant. Noisy Student Training extends the idea of self-training and distillation with the use of equal-or-larger student models and noise added to the student during learning. On ImageNet, we first train an EfficientNet model on labeled images and use it as a teacher to generate pseudo labels for 300M unlabeled images. We then train a larger EfficientNet as a student model on the combination of labeled and pseudo labeled images. We iterate this process by putting back the student as the teacher. During the learning of the student, we inject noise such as dropout, stochastic depth, and data augmentation via RandAugment to the student so that the student generalizes better than the teacher.\n\t- #CODE https://github.com/google-research/noisystudent\n- #PAPER [Big Transfer (BiT):General Visual Representation Learning (Kolesnikov 2020)](https://arxiv.org/abs/1912.11370)\n\t- [Paper explained](https://www.youtube.com/watch?v=k1GOF2jmX7c)\n- #PAPER [Towards a Deeper Understanding of Adversarial Losses (Dong 2020)](https://arxiv.org/abs/1901.08753)\n- #PAPER [DoubleMatch: Improving Semi-Supervised Learning with Self-Supervision (Wallin 2022)](https://arxiv.org/pdf/2205.05575v1)            \n\t- #CODE https://paperswithcode.com/paper/doublematch-improving-semi-supervised\n\t- DoubleMatch combines the pseudo-labeling technique with a self-supervised loss, enabling the model to utilize all unlabeled data in the training process. We show that this method achieves state-of-the-art accuracies on multiple benchmark datasets while also reducing training times compared to existing SSL methods","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Class-imbalance":{"title":"Class imbalance","content":"## Resources\n- https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis\n- http://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation\n- http://www.alfredo.motta.name/cross-validation-done-wrong/\n- http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/\n- http://www.chioka.in/class-imbalance-problem/\n- http://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html\n- https://svds.com/learning-imbalanced-classes/\n\t- Conventional algorithms are often biased towards the majority class because their loss functions attempt to optimize quantities such as error rate, not taking the data distribution into consideration. Result: a trivial classifier that classifies every example as the majority class.\n\n## Code\n- #CODE [Imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn )\n\t- https://imbalanced-learn.readthedocs.io/en/stable/\n\t- https://imbalanced-learn.readthedocs.io/en/stable/api.html\n- #CODE [Smote_variants](https://github.com/analyticalmindsltd/smote_variants)\n\t- http://smote-variants.readthedocs.io/\n\t-  The package implements 85 variants of the Synthetic Minority Oversampling Technique (SMOTE). Besides the implementations, an easy to use model selection framework is supplied to enable the rapid evaluation of oversampling techniques on unseen datasets. \n\n## Approaches\n### Resampling\n- Balance the training dataset\n- #PAPER [Survey of resampling techniques for improving classification performance in unbalanced datasets (More 2016)](https://arxiv.org/abs/1608.06048)\n\n#### Oversampling\n- #PAPER [SMOTE: Synthetic Minority Over-sampling Technique (Chaula 2002)](https://jair.org/index.php/jair/article/view/10302)\n\t- There are a number of methods available to oversample a dataset used in a typical classification problem (using a classification algorithm to classify a set of images, given a labelled training set of images). The most common technique is known as SMOTE. \n\t- https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n- #PAPER [ADASYN: Adaptive synthetic sampling approach for imbalanced learning (He 2008)](https://ieeexplore.ieee.org/document/4633969)\n\t- https://sci2s.ugr.es/keel/pdf/algorithm/congreso/2008-He-ieee.pdf\n\t- ADASYN builds on the methodology of SMOTE, by shifting the importance of the classification boundary to those minority classes which are difficult. ADASYN uses a weighted distribution for different minority class examples according to their level of difficulty in learning, where more synthetic data is generated for minority class examples that are harder to learn.\n\n#### Undersampling\n- Down-sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm. The most common heuristic for doing so is resampling without replacement.\n- https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n- Cluster. Cluster centroids is a method that replaces cluster of samples by the cluster centroid of a K-means algorithm, where the number of clusters is set by the level of undersampling.\n- Tomek links. Tomek links remove unwanted overlap between classes where majority class links are removed until all minimally distanced nearest neighbor pairs are of the same class. Tomek links are pairs of instances of opposite classes who are their own nearest neighbors. Tomek’s algorithm looks for such pairs and removes the majority instance of the pair.\n\t- [Classification of Imbalance Data using Tomek Link (T-Link) Combined with Random Under-sampling (RUS) as a Data Reduction Method](https://pdfs.semanticscholar.org/6ec4/18f9071f3a96d5548e87e34be3665703119e.pdf)\n- Throw away minority examples and switch to an anomaly detection framework\n\n### Adjust the class importance or the metric\n- At the algorithm level, or after: Adjust the class weight (misclassification costs), adjust the decision threshold. Many machine learning toolkits have ways to adjust the “importance” of classes (classifiers that take an optional class_weight). \n- Change the metric. \n\t- Evaluating the classifier: Accuracy is not a good metric for imbalanced classes!!\n\t- Use a ROC curve\n\t- Don’t get hard classifications (labels) from your classifier (via score or predict). Instead, get probability estimates via proba or predict_proba\n\t- No matter what you do for training, always test on the natural (stratified) distribution your classifier is going to operate upon. Seesklearn.cross_validation.StratifiedKFold\n\t- For a singe metric (value): AUC, F1 (harmonic mean of precision and recall), Cohen’s Kappa (evaluation statistic that takes into account how much agreement would be expected by chance)\n\t- https://medium.com/towards-data-science/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba\n\t- http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\n\t- The following performance measures that can give more insight into the accuracy of the model than traditional classification accuracy:\n\t\t- Confusion Matrix: A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned).\n\t\t- Precision: A measure of a classifiers exactness.\n\t\t- Recall: A measure of a classifiers completeness\n\t\t- F1 Score (or F-score): A weighted average of precision and recall.\n\t\t- Kappa (or Cohen’s kappa): Classification accuracy normalized by the imbalance of the classes in the data.\n\t\t- ROC Curves: Like precision and recall, accuracy is divided into sensitivity and specificity and models can be chosen based on the balance thresholds of these values.\n\n### Cost-sensitive training\n- Cost-Sensitive Training. For this tactic we use penalized learning algorithms that increase the cost of classification mistakes on the minority class. A popular algorithm for this technique is Penalized-SVM. During training, we can use the argument class_weight='balanced'  to penalize mistakes on the minority class by an amount proportional to how under-represented it is.\n\n### Select or create a suitable algorithm\n- Create new algorithm for the imbalanced classes situation, or use one which handles the data imbalance\n- #PAPER [Boosting/bagging. Comparing Boosting and Bagging Techniques With Noisy and Imbalanced Data (Khoshgoftaar 2010)](https://ieeexplore.ieee.org/document/5645694?arnumber=5645694)\n\t- The experiments show that the bagging techniques generally outperform boosting, and hence in noisy data environments, bagging is the preferred method for handling class imbalance.","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Classification":{"title":"Classification","content":"---\n\n## Resources\n- https://github.com/jmportilla/Udemy","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Ensemble-learning":{"title":"Ensemble learning","content":"\u003e In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. In general, ensembling is a technique of combining two or more algorithms of similar or dissimilar types called base learners. This is done to make a more robust system (improving generalizability / robustness over a single estimator) which incorporates the predictions from all the base learners\n\n## Resources\n- https://en.wikipedia.org/wiki/Ensemble_learning\n- By analogy, ensemble techniques have been used also in [[AI/Unsupervised learning/Unsupervised learning]] scenarios, for example in consensus clustering or in anomaly or [[AI/Anomaly and Outlier Detection]]\n- http://scikit-learn.org/stable/modules/ensemble.html\n- http://mlwave.com/kaggle-ensembling-guide/\n- https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n- http://www.datasciencecentral.com/profiles/blogs/improving-predictions-with-ensemble-model\n- http://www.kdnuggets.com/2016/11/data-science-basics-intro-ensemble-learners.html\n- https://medium.com/diogo-menezes-borges/ensemble-learning-when-everybody-takes-a-guess-i-guess-ec35f6cb4600\n- https://blog.statsbot.co/ensemble-learning-d1dcd548e936\n- [How to Reduce Variance in the Final DL Model With a Horizontal Voting Ensemble](https://machinelearningmastery.com/horizontal-voting-ensemble/)\n\n### Bagging\n- With bootstrap aggregating (Bagging) we build models of smaller datasets by sampling with replacement. The results of these bootstrap samples are then aggregated, using majority voting (equal weighting of models)\n- See [[AI/Supervised Learning/Random forest]]\n\n### Boosting\nSee [[AI/Supervised Learning/Gradient boosting]]\n- Same as bagging but operates via weighted voting. Algorithm proceeds iteratively (one tries to reduce the bias of the combined estimator); new models are influenced by previous ones. E.g. AdaBoost (Adaptive Boosting) and LogitBoost\n- https://en.wikipedia.org/wiki/AdaBoost\n\n### Stacking\n- uses a meta learner (as opposed to bagging/boosting which use voting schemes)\n- It consists in training multiple learners/algorithms (as opposed to bagging/boosting which train a single learner).  Each learner uses a subset of data. \n- A \"combiner\" is trained on a validation set. This combiner can be any ensemble technique, but logistic regression is often found to be an adequate and simple algorithm to perform this combining.\n- http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/\n- https://machinelearningmastery.com/ensemble-methods-for-deep-learning-neural-networks/","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Feature-selection":{"title":"Feature selection","content":"\u003e See:\n\u003e - [[AI/Supervised Learning/Regularized regression]]\n\u003e - [[AI/Feature learning]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Feature_selection\n- http://machinelearningmastery.com/an-introduction-to-feature-selection/\n- http://scikit-learn.org/stable/modules/feature_selection.html\n- [Removing features with low variance](http://scikit-learn.org/stable/modules/feature_selection.html#removing-features-with-low-variance)\n- [Univariate feature selection](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)\n- [Recursive feature elimination](http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination)\n \n### Regularization\nSee [[AI/Supervised Learning/Regularized regression]]\n- http://scikit-learn.org/stable/modules/feature_selection.html#l1-based-feature-selection\n\n### Tree-based methods\n- https://scikit-learn.org/stable/modules/feature_selection.html#tree-based-feature-selection\n- [Random forest, extra trees. Feature importances with forests of trees](http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)\n- XGBoost, Feature importance and why it’s important: \n\t- http://datawhatnow.com/feature-importance/\n\t- http://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/\n\t- Importance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity (Gini index) used to select the split points or another more specific error function. The feature importances are then averaged across all of the the decision trees within the model.\n\n## Books\n- #BOOK [Feature Engineering and Selection: A Practical Approach for Predictive Models (Kuhn 2018)](http://www.feat.engineering/index.html)\n\n## Code \n- #CODE [Scikit-feature](https://github.com/jundongl/scikit-feature)\n\t- http://featureselection.asu.edu/\n- #CODE Feature-selector - Feature selector is a tool for dimensionality reduction of machine learning datasets.\n\t- Methods: Missing Values, Single Unique Values, Collinear Features, Zero Importance Features, Low Importance Features\n    - https://github.com/WillKoehrsen/feature-selector/blob/master/Feature%20Selector%20Usage.ipynb\n    - https://towardsdatascience.com/a-feature-selection-tool-for-machine-learning-in-python-b64dd23710f0\n- #CODE [ITMO_FS](https://github.com/ctlab/ITMO_FS)\n\t- Feature selection library in python\n\t- https://itmo-fs.readthedocs.io/en/latest/\n\n## References\n- #PAPER [A Guided Hybrid Genetic Algorithm for Feature Selection with Expensive Cost Functions (Jung 2013)](https://www.sciencedirect.com/science/article/pii/S1877050913005486)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Gaussian-Process":{"title":"Gaussian Process","content":"\u003e In probability theory and statistics, a Gaussian process (GP) is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i.e. every finite linear combination of them is normally distributed. The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space. A machine-learning algorithm that involves a Gaussian process uses lazy learning and a measure of the similarity between points (the kernel function) to predict the value for an unseen point from training data. The prediction is not just an estimate for that point, but also has uncertainty information - it is a one-dimensional Gaussian distribution (which is the marginal distribution at that point).\n\n## Resources\n- https://en.wikipedia.org/wiki/Gaussian_process\n- http://scikit-learn.org/stable/modules/gaussian_process.html\n- [A Practical Guide to Gaussian Processes](https://drafts.distill.pub/gp/ )\n- A Visual Exploration of Gaussian Processes\n\t- https://www.jgoertler.com/visual-exploration-gaussian-processes/\n\t- https://blog.dominodatalab.com/fitting-gaussian-process-models-python/\n- [Gaussian processes](http://krasserm.github.io/2018/03/19/gaussian-processes/)\n- [Deep Neural Networks and Gaussian Processes: Similarities, Differences, and Trade-Offs](https://towardsdatascience.com/deep-neural-networks-vs-gaussian-processes-similarities-differences-and-trade-offs-18647376d799)\n\n## Code\n- #CODE [GPy](https://github.com/SheffieldML/GPy)\n- #CODE [GPyTorch](https://github.com/cornellius-gp/gpytorch)\n\t- https://gpytorch.ai/\n- #CODE [GPFlow](https://github.com/GPflow/GPflow)\n\t- https://gpflow.readthedocs.io/en/master/intro.html\n- #CODE [GPflux](https://github.com/secondmind-labs/GPflux)\n\t- GPflux uses the mathematical building blocks from GPflow and marries these with the powerful layered deep learning API provided by Keras. \n\t- https://secondmind-labs.github.io/GPflux/tutorials.html\n\n\n## Books\n- #BOOK [Bayesian Optimization Book (Garnett 2021)](https://bayesoptbook.com/)\n\n\n## References\n- #PAPER [Gaussian Processes for Machine Learning (Rasmussen and Williams 2006)](http://www.gaussianprocess.org/gpml/)\n\t- http://www.gaussianprocess.org/gpml/chapters/RW.pdf\n- #PAPER [Convolutional Gaussian Processes (van der Wilk 2017)](https://arxiv.org/abs/1709.01894)\n\t- #CODE https://gpflow.readthedocs.io/en/master/notebooks/advanced/convolutional.html\n- #PAPER [Deep convolutional Gaussian processes (Blomqvist 2018)](https://arxiv.org/abs/1810.03052)\n\t- #CODE https://github.com/kekeblom/DeepCGP\n\t- https://github.com/kekeblom/DeepCGP/blob/master/notebooks/Inspect.ipynb\n- #PAPER [Gaussian processes meet NeuralODEs: A Bayesian framework for learning the dynamics of partially observed systems from scarce and noisy data (Aziz Bhouri 2021)](https://arxiv.org/abs/2103.03385)\n\t- #CODE https://github.com/PredictiveIntelligenceLab/GP-NODEs\n- #PAPER #REVIEW [An Intuitive Tutorial to Gaussian Processes Regression (Wang 2021)](https://arxiv.org/abs/2009.10862)\n- #PAPER #REVIEW [Deep Gaussian Processes: A Survey (Jakkala 2021)](https://arxiv.org/abs/2106.12135)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Gradient-boosting":{"title":"Gradient boosting","content":"\u003e See  [[AI/Supervised Learning/Ensemble learning]]\n\n## Resources\n- Outperforms Random Forests and AdaBoost. RF is easier to tune and less prone to overfitting\n- http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html\n- http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html\n- https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/\n- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n\n## Code\n- #CODE [Xgboost](https://github.com/dmlc/xgboost)\n\t- Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library, for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Flink and DataFlow\n\t- https://xgboost.readthedocs.org/\n\t- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n- #CODE [Light GBM](https://github.com/microsoft/LightGBM)\n\t- a very high-performance gradient boosting tree framework (supporting GBDT, GBRT, GBM, and MART), and its distributed implementation. Part of DMTK (Microsoft)\n\t- https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/\n\t- https://www.techleer.com/articles/489-lightgbm-a-light-gradient-boosting-machine/\n- #CODE [CatBoost](https://github.com/catboost/catboost/)\n\t- https://catboost.ai/\n\t- https://catboost.ai/docs/\n\t- A fast, scalable, high performance Gradient Boosting on Decision Trees library, used for ranking, classification, regression and other machine learning tasks for Python, R, Java, C++. Supports computation on CPU and GPU\n\t- [CatBoost vs. Light GBM vs. XGBoost](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db)\n- #CODE https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n\n\n## References\n- #PAPER [Probabilistic Gradient Boosting Machines for Large-Scale Probabilistic Regression (Sprangers 2021)](https://arxiv.org/abs/2106.01682v2)\n\t- #CODE https://paperswithcode.com/paper/probabilistic-gradient-boosting-machines-for?from=n11","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Model-selection-and-tuning":{"title":"Model selection and tuning","content":"\u003e See: \n\u003e - [[AI/AutoML]] \n\u003e - [[AI/DS and DataEng/Data engineering and computer science]]\n\n\n## Resources\n- [Model selection and evaluation](https://scikit-learn.org/stable/model_selection.html)\n\n## Code\nSee [[AI/DS and DataEng/ML Ops]]\n- #CODE [Optuna - A hyperparameter optimization framework](https://github.com/optuna/optuna)\n\t- https://optuna.org/\n- #CODE [Yellowbrick. Visual analysis and diagnostic tools to facilitate machine learning model selection](http://www.scikit-yb.org/en/latest/)\n- #CODE [Tune-sklearn](https://github.com/ray-project/tune-sklearn)\n\t- Tune-sklearn is a drop-in replacement for Scikit-Learn’s model selection module (GridSearchCV, RandomizedSearchCV) with cutting edge hyperparameter tuning techniques\n- #CODE [Talos. Hyperparameter Optimization for Keras Models](https://autonomio.github.io/docs_talos/#introduction)\n- #CODE [Hyperopt. Distributed Asynchronous Hyperparameter Optimization in Python](http://hyperopt.github.io/hyperopt)\n\t- [Hyperparameter optimization for neural networks](https://github.com/hyperopt/hyperopt-nnet)\n\t- [Hyperopt-sklearn](http://hyperopt.github.io/hyperopt-sklearn/)\n\t- #CODE [Hyperas- Keras + Hyperopt: A very simple wrapper for convenient hyperparameter optimization](https://github.com/maxpumperla/hyperas)\n\t\t- http://maxpumperla.github.io/hyperas/\n- #CODE [Hyperband - A Novel Bandit-Based Approach to Hyperparameter Optimization](https://github.com/zygmuntz/hyperband)\n\t- #PAPER https://arxiv.org/abs/1603.06560\n\t- http://fastml.com/tuning-hyperparams-fast-with-hyperband/\n\n## Bias-variance trade-off\n- Problem of minimizing two sources of errors that prevent a supervised learning algorithm from generalizing beyond the training set:\n\t- High bias  -\u003e  underfitting\n\t- High variance  -\u003e  overfitting\n- [Validation curves: plotting scores to evaluate models](https://scikit-learn.org/stable/modules/learning_curve.html)\n- https://www.quora.com/How-would-you-explain-the-bias-variance-tradeoff-to-a-five-year-old\n- http://scott.fortmann-roe.com/docs/BiasVariance.html\n- http://scott.fortmann-roe.com/docs/MeasuringError.html\n- https://elitedatascience.com/bias-variance-tradeoff\n- [Overfitting](https://en.wikipedia.org/wiki/Overfitting)\n\t- https://www.quora.com/What-is-an-intuitive-explanation-of-overfitting\n\t- https://www.quora.com/How-can-I-avoid-overfitting\n\t- https://www.quora.com/How-do-we-detect-overfitting-and-under-fitting-in-Machine-Learning\n\n## Cross-validation\n- [Train, test and validation](https://machinelearningmastery.com/difference-test-validation-datasets/)\n- [Train, test, validation split and cross-validation (scikit-learn documentation)](http://scikit-learn.org/stable/modules/cross_validation.html)\n- http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n- https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html\n- https://blog.dataiku.com/model-sucks-evaluating-models-validation-set-infographic\n- [Making Predictive Models Robust: Holdout vs Cross-Validation](https://www.kdnuggets.com/2017/08/dataiku-predictive-model-holdout-cross-validation.html)\n- [How to Train a Final ML Model](http://machinelearningmastery.com/train-final-machine-learning-model/)\n- http://nbviewer.jupyter.org/github/cs109/content/blob/master/lec_10_cross_val.ipynb\n- [Hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning))\n- [Tuning the hyper-parameters of an estimator (scikit-learn documentation)](https://scikit-learn.org/stable/modules/grid_search.html)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Random-forest":{"title":"Random forest","content":"\u003e Bagging and random forests are “bagging” algorithms that aim to reduce the complexity of models that overfit the training data. In contrast, boosting is an approach to increase the complexity of models that suffer from high bias, that is, models that underfit the training data\n\n\u003e See [[AI/Supervised Learning/Ensemble learning]]\n\n## Resources\n- https://github.com/kjw0612/awesome-random-forest\n- https://sebastianraschka.com/faq/docs/bagging-boosting-rf.html\n- https://scikit-learn.org/stable/modules/ensemble.html#random-forests\n- http://www.listendata.com/2014/11/random-forest-with-r.html\n- https://medium.com/rants-on-machine-learning/the-unreasonable-effectiveness-of-random-forests-f33c3ce28883\n- In particular, trees that are grown very deep tend to learn highly irregular patterns: they overfit their training set or have low bias, but very high variance. Random forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance. This comes at the expense of a small increase in the bias and some loss of interpretability, but generally greatly boosts the performance of the final model.\n\n\n## References\n- #THESIS/PHD [Understanding Random Forests: From Theory to Practice (Louppe 2014)](https://arxiv.org/abs/1407.7502)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Regression":{"title":"Regression","content":"---\n\n\u003e In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships between a dependent variable (often called the 'outcome' or 'response' variable) and one or more independent variables (often called 'predictors', 'covariates', 'explanatory variables' or 'features')\n\n\u003e See: \n\u003e - [[AI/Supervised Learning/Regularized regression]]\n\u003e - [[AI/Time Series analysis]]\n\u003e - [[AI/Forecasting]]\n\u003e - [[AI/Deep learning/RNNs]]\n\u003e - \"Sequence time series modelling\" section in [[AI/Deep learning/CNNs]]\n\n\n## Resources\n- https://en.wikipedia.org/wiki/Regression_analysis\n- https://www.analytics. idhya.com/blog/2015/08/comprehensive-guide-regression/\n- https://towardsdatascience.com/a-beginners-guide-to-regression-analysis-in-machine-learning-8a828b491bbf\n- http://www.datasciencecentral.com/profiles/blogs/10-types-of-regressions-which-one-to-use\n- http://www.datasciencecentral.com/profiles/blogs/23-types-of-regression\n- [Curve fitting vs regression](https://blog.datazar.com/curve-fitting-vs-regression-752ce295b0b1)\n- Goodness of fit:\n\t- [Coefficient of determination (The R-squared measure of goodness of fit)](http://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)\n\t- Reduced chi-squared\n- [Linear models](http://scikit-learn.org/stable/modules/linear_model.html)\n- Multicollinearity:\n\t- [Dealing With Multicollinearity: A Brief Overview and Introduction to Tolerant Methods](https://waterprogramming.wordpress.com/2017/02/22/dealing-with-multicollinearity-a-brief-overview-and-introduction-to-tolerant-methods/)\n\t- https://stackoverflow.com/questions/42904211/lasso-or-ridge-for-correlated-variables\n\t- [Permutation Importance with Multicollinear or Correlated Features (scikit-learn)](https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html)\n1\n### Linear Regression\n- https://en.wikipedia.org/wiki/Linear_regression\n- In statistics, linear regression is an approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression.\n- http://www.datasciencecentral.com/profiles/blogs/linear-regression-geometry\n- https://github.com/jmportilla/Udemy","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Regularized-regression":{"title":"Regularized regression","content":"\u003e Regularization, in mathematics and statistics and particularly in the field of machine learning, refers to a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting\n\n\u003e See [[AI/Supervised Learning/Feature selection]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Regularization_(mathematics)\n- #TALK [Linear Regression, Logistic Regression, SVM](https://www.youtube.com/watch?v=_5lsmWpA5IU)\n- [Regularización Lasso L1, Ridge L2 y ElasticNet](https://www.iartificial.net/regularizacion-lasso-l1-ridge-l2-y-elasticnet/)\n- https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/\n- http://www.astroml.org/book_figures/chapter8/fig_lasso_ridge.html\n- https://chaoticsenses.wordpress.com/2016/01/20/taming-the-beast-with-regularization-3/\n- https://www.cienciadedatos.net/documentos/py14-ridge-lasso-elastic-net-python.html\n- [LARS (Least angle regression)](https://en.wikipedia.org/wiki/Least-angle_regression)\n- Penalized regression techniques don’t always create confidence intervals, t-statistics, or p-values for regression parameters. These types of measures are typically only available through iterative methods or bootstrapping that can require extra computing time.\n- https://www.quora.com/What-is-regularization-in-machine-learning\n- The loss function is penalized by adding an L1 or L2 norm of the weights vector W (the vector of the learned parameters in the linear regression):\n\t- L(X,Y) + lambda N(W), where N is either the L1, L2 or any other norm.\n\t- This helps avoiding overfitting and performs feature selection for the case of the L1 regularization. Lambda can be chosen by cross-validation. \n\n### Ridge regression\n- [Ridge regression](https://en.wikipedia.org/wiki/Tikhonov_regularization)\n- Tikhonov/L2/ridge penalties help preserve parameter estimate stability, even when many correlated variables exist in a wide data set or important predictor variables are correlated\n\n### Elastic net\n- https://en.wikipedia.org/wiki/Elastic_net_regularization\n- In the fitting linear or logistic regression models, the elastic net is a regularized regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods.\n- http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n\n### LASSO\n- [LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics))\n- Least absolute shrinkage and selection operator\n- L1/LASSO penalties drive unnecessary regression parameters to zero, selecting a small, representative subset of regression parameters for the regression model while avoiding potential multiple comparison problems that arise in forward, backward, and stepwise variable selection.\n- https://www.kirenz.com/post/2019-08-12-python-lasso-regression-auto/\n- https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b\n\n\n## Code\n- #CODE [Glmnet_py. Glmnet Vignette (for python)](https://github.com/bbalasub1/glmnet_python) ^glmnetpy","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Supervised-Learning/Supervised-learning":{"title":"Supervised Learning","content":"\u003e Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs\n\n## Resources\n- https://en.wikipedia.org/wiki/Supervised_learning\n- [Supervised Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning)\n- http://scikit-learn.org/stable/supervised_learning.html\n- Metrics:\n\t- http://docs.aws.amazon.com/machine-learning/latest/dg/binary-model-insights.html\n\t- ROC curves, AUC\n\t\t- http://www.dataschool.io/roc-curves-and-auc-explained/\n\t\t- http://corysimon.github.io/articles/what-is-an-roc-curve/\n\n\n### Classification\nSee [[AI/Supervised Learning/Classification]]\n\n### Regression\nSee [[AI/Supervised Learning/Regression]]\n\n### Structured learning\n- https://en.wikipedia.org/wiki/Structured_prediction\n\n### Ensemble learning\nSee [[AI/Supervised Learning/Ensemble learning]]\n\n### Class imbalance\nSee [[AI/Supervised Learning/Class imbalance]]\n\n### Model selection and tuning\nSee [[AI/Supervised Learning/Model selection and tuning]]\n\n### Probability calibration\n- https://en.wikipedia.org/wiki/Calibration_(statistics)\n- https://scikit-learn.org/stable/modules/calibration.html\n- When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction. \n- Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class.\n- https://scikit-learn.org/stable/auto_examples/calibration/plot_compare_calibration.html\n- Isotonic regression: \n\t- https://scikit-learn.org/stable/modules/isotonic.html\n\t- Isotonic regression is a probability calibration technique which can calibrate classifier scores to approximate probability values by fitting a stepwise non-decreasing function along the scores returned by the classifier.","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Time-Series-analysis":{"title":"Time series analysis","content":"\u003e See: \n\u003e - [[AI/Forecasting]]\n\u003e - [[AI/Deep learning/RNNs]]\n\u003e - \"Sequence (time series) modelling\" section in [[AI/Deep learning/CNNs]]\n\u003e - \"Deep learning for tabular data\" section in [[AI/Deep learning/DL]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Time_series\n- https://github.com/MaxBenChrist/awesome_time_series_in_python\n- https://github.com/frutik/awesome-timeseries\n- https://github.com/cuge1995/awesome-time-series\n- http://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n- [Python to work with time series data](https://github.com/MaxBenChrist/awesome_time_series_in_python)\n- [timeseriesAI](https://github.com/timeseriesAI)\n\n## Code\nSee code in [[AI/Forecasting]]\n- #PAPER [A systematic review of Python packages for time series analysis (Siebert 2021)](https://arxiv.org/pdf/2104.07406)            \n\n- #CODE [Sktime](https://github.com/alan-turing-institute/sktime)\n\t- https://towardsdatascience.com/sktime-a-unified-python-library-for-time-series-machine-learning-3c103c139a55\n- #CODE [Stumpy](https://github.com/TDAmeritrade/stumpy)\n\t- STUMPY is a powerful and scalable Python library for modern time series analysis\n- #CODE [Orbit](https://github.com/uber/orbit)\n\t- A Python package for Bayesian forecasting with object-oriented design and probabilistic models under the hood.\n\t- https://eng.uber.com/the-new-version-of-orbit-v1-1-is-released/\n- #CODE [TSflex](https://github.com/predict-idlab/tsflex)\n\t- https://predict-idlab.github.io/tsflex/\n- #CODE [Merlion](https://github.com/salesforce/merlion)\n\t- #PAPER [Merlion: A Machine Learning Library for Time Series (Bhatnagar 2021)](https://arxiv.org/abs/2109.09265)\n\t- Merlion is a Python library for time series intelligence\n- #CODE [Kats](https://github.com/facebookresearch/Kats) ^kats\n\t- Kats, a kit to analyze time series data, a lightweight, easy-to-use, generalizable, and extendable framework to perform time series analysis, from understanding the key statistics and characteristics, detecting change points and anomalies, to forecasting future trends\n\t- https://facebookresearch.github.io/Kats/\n\t- https://engineering.fb.com/2021/06/21/open-source/kats/\n\t- https://towardsdatascience.com/kats-a-generalizable-framework-to-analyze-time-series-data-in-python-3c8d21efe057\n- #CODE [Tsfresh - Time Series Feature extraction based on scalable hypothesis tests](https://github.com/blue-yonder/tsfresh)\n\t- [Automatic extraction of relevant features from time series](http://tsfresh.readthedocs.io)\n- #CODE [TSFEL](https://github.com/fraunhoferportugal/tsfel)\n\t- #PAPER [TSFEL: Time Series Feature Extraction Library (Barandas 2020)](https://www.sciencedirect.com/science/article/pii/S2352711020300017)\n- #CODE [Tslearn - A machine learning toolkit dedicated to time-series data](https://github.com/rtavenar/tslearn)\n- #CODE [Pmdarima](https://github.com/alkaline-ml/pmdarima)\n\t- Pyramid bridges one more gap between R and Python by bringing R's auto.arima to Python. Pyramid wraps statsmodels' well-tested ARIMA and SARIMAX estimators.\n- #CODE [Tick](https://github.com/X-DataInitiative/tick)\n- #CODE [Feature engine](https://feature-engine.readthedocs.io/en/1.3.x/user_guide/timeseries/index.html)\n\n## Subtopics\n### Time Series Forecasting\nSee [[AI/Forecasting]]\n\n### Anomaly and Outlier Detection\nSee [[AI/Anomaly and Outlier Detection]]\n\n### TS models\n- [Autoregressive](https://en.wikipedia.org/wiki/Autoregressive)\n- [Moving average](https://en.wikipedia.org/wiki/Moving_average_model)\n- [Autoregressive moving average (ARMA)](https://en.wikipedia.org/wiki/Autoregressive_moving_average)\n- [Autoregressive integrated moving average (ARIMA)](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average)\n- [Generalized additive model (GAM)](https://en.wikipedia.org/wiki/Generalized_additive_model)\n\t- http://www.kdnuggets.com/2017/04/time-series-analysis-generalized-additive-models.html\n\n### TS classification\n- [UEA \u0026 UCR Time Series Classification Repository](http://www.timeseriesclassification.com/)\n\t- [Datasets](http://www.timeseriesclassification.com/dataset.php)\n- [Dynamic time warping](https://en.wikipedia.org/wiki/Dynamic_time_warping)\n\t- DTW is one of the algorithms for measuring similarity between two temporal sequences, which may vary in speed\n- https://medium.com/@hassanismailfawaz/deep-learning-for-time-series-classification-a-brief-overview-73b58767ed0f\n\n- #PAPER [ROCKET: Exceptionally fast and accurate time series classification using random convolutional kernels (Dempster 2019)](https://arxiv.org/abs/1910.13051)\n- #PAPER [InceptionTime: Finding AlexNet for Time Series Classification (Ismail Fawaz 2019)](https://arxiv.org/abs/1909.04939)\n- #PAPER [Deep learning for time series classification: a review (Ismail Fawaz 2019)](https://arxiv.org/abs/1809.04356)\n\t- #CODE https://github.com/hfawaz/dl-4-tsc\n\t- https://medium.com/@hassanismailfawaz/deep-learning-for-time-series-classification-a-brief-overview-73b58767ed0f\n- #PAPER [TS-CHIEF: A Scalable and Accurate Forest Algorithm for Time Series Classification (Shifaz 2020)](https://arxiv.org/abs/1906.10329)\n\n\n### Time-frequency analysis\n- [Continuous wavelet transform](https://en.wikipedia.org/wiki/Continuous_wavelet_transform)\n\n#### Fourier Analysis\n- [Fourier analysis](https://en.wikipedia.org/wiki/Fourier_analysis)\n\t- [Fast Fourier transform](https://en.wikipedia.org/wiki/Fast_Fourier_transform)\n\t\t- A fast Fourier transform (FFT) is an algorithm that computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IDFT).\n\t- [Fourier Transform for Time Series](https://towardsdatascience.com/fourier-transform-for-time-series-292eb887b101)\n\t- [Understanding FFTs and Windowing](https://download.ni.com/evaluation/pxi/Understanding%20FFTs%20and%20Windowing.pdf)\n\n  \n### Causality\nSee [[AI/Causality]]","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Transfer-learning":{"title":"Transfer learning","content":"\u003e Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem\n\n\u003e See [[AI/Multi-task learning]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Transfer_learning\n- https://github.com/artix41/awesome-transfer-learning\n- [Transfer Learning - Machine Learning's Next Frontier](https://ruder.io/transfer-learning/index.html#usingpretrainedcnnfeatures)\n- [Domain adaptation](https://en.wikipedia.org/wiki/Domain_adaptation)\n\t- Domain adaptation is a field associated with machine learning and transfer learning. This scenario arises when we aim at learning from a source data distribution a well performing model on a different (but related) target data distribution\n\n## Courses\n- #COURSE [Transfer Learning | Kaggle](https://www.youtube.com/watch?v=mPFq5KMxKVw)\n\n## Code\n- #CODE [pytorch-adapt](https://github.com/KevinMusgrave/pytorch-adapt)\n\t- Domain adaptation made easy. Fully featured, modular, and customizable\n\t- https://kevinmusgrave.github.io/pytorch-adapt/\n- #CODE [TLlib](https://github.com/thuml/Transfer-Learning-Library)\n\t- open-source and well-documented library for Transfer Learning. It is based on pure PyTorch with high performance and friendly API\n- #code [Salad](https://github.com/domainadaptation/salad)\n\t- https://domainadaptation.org/\n- #code [Robustness](https://github.com/bethgelab/robustness)\n\t- https://domainadaptation.org/robusta/\n\n\n## References\n- #PAPER [A Brief Review of Domain Adaptation (Farahani 2020)](https://arxiv.org/abs/2010.03978)\n- #PAPER [On the Opportunities and Risks of Foundation Models (Bommasani 2021)](https://arxiv.org/abs/2108.07258)\n\t- A foundation model is any model that is trained on broad data at scale and can be adapted (e.g., fine-tuned) to a wide range of downstream tasks; current examples include BERT, GPT-3, and CLIP\n\t- Foundation models are based on deep neural networks and self-supervised learning\n\t- On a technical level, foundation models are enabled by transfer learning and scale\n\t- The idea of transfer learning is to take the “knowledge” learned from one task (e.g., object recognition in images) and apply it to another task (e.g., activity recognition in videos).\n\t- Within deep learning, pretraining is the dominant approach to transfer learning: a model is trained on a surrogate task (often just as a means to an end) and then adapted to the downstream task of interest via fine-tuning\n\t- Transfer learning is what makes foundation models possible, but scale is what makes them powerful. Scale required three ingredients: improvements in computer hardware, the development of the Transformer model architecture that leverages the parallelism of the hardware to train much more expressive models than before and the availability of much more training data","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Unsupervised-learning/Clustering":{"title":"Clustering","content":"\u003e Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters)\n\n## Resources\n- http://scikit-learn.org/stable/modules/clustering.html\n- Hierarhical clustering: Method of cluster analysis which seeks to build a hierarchy of clusters. Strategies for hierarchical clustering generally fall into two types:\n\t- Agglomerative: This is a \"bottom up\" approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.\n\t- Divisive: This is a \"top down\" approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.\n\t- The results of hierarchical clustering are usually presented in a dendrogram. The complexity of agglomerative clustering is O(n^2log(n)), slow for large data. Divisive clustering with an exhaustive search is O(2^n), which is even worse.\n\t- https://blog.alookanalytics.com/2017/04/11/intuition-vs-unsupervised-learning-agglomerative-clustering-in-practice/\n\t- Single linkage: Single-linkage clustering is one of several methods of hierarchical clustering. It is based on grouping clusters in bottom-up fashion (agglomerative clustering), at each step combining two clusters that contain the closest pair of elements not yet belonging to the same cluster as each other. A drawback of this method is that it tends to produce long thin clusters in which nearby elements of the same cluster have small distances, but elements at opposite ends of a cluster may be much farther from each other than to elements of other clusters. The naive version has a time complexity of O(n^3). There are improvements: SLINK and Kruskal's algo, with time complexity O(n^2).\n\t- Mean linkage\n\t\t- [Unweighted Pair Group Method with Arithmetic Mean](https://en.wikipedia.org/wiki/UPGMA)\n\t    - [Weighted Pair Group Method with Arithmetic Mean](https://en.wikipedia.org/wiki/WPGMA)\n\t- Ward’s method: Ward's minimum variance criterion minimizes the total within-cluster variance.\n\t  To implement this method, at each step find the pair of clusters that leads to minimum increase in total within-cluster variance after merging. This increase is a weighted squared distance between cluster centers. At the initial step, all clusters are singletons (clusters containing a single point).\n\t- Complete linkage: The method is also known as farthest neighbour clustering. At the beginning of the process, each element is in a cluster of its own. The clusters are then sequentially combined into larger clusters until all elements end up being in the same cluster. At each step, the two clusters separated by the shortest distance are combined. \n\t  The definition of 'shortest distance' is what differentiates between the different agglomerative clustering methods. \n\t  In complete-linkage clustering, the link between two clusters contains all element pairs, and the distance between clusters equals the distance between those two elements (one in each cluster) that are farthest away from each other. Complexity O(n^3), CLINK version with O(n^2).\n- [K-means](https://en.wikipedia.org/wiki/K-means_clustering)\n\t- k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. The standard k-means algorithm is called Lloyd's algorithm:\n\t\t- Initialization: Forgy method (taking k random observations from the data set), random partitioning or k-means++ methods \n\t\t- 2 steps: assignment and update (the \"assignment\" step is also referred to as expectation step, the \"update step\" as maximization step, making this algorithm a variant of the generalized expectation-maximization algorithm):\n\t\t\t- Assignment: Assign each observation to the cluster whose mean yields the least within-cluster sum of squares (WCSS). Also called “Expectation step” because it involves updating our expectation of which cluster each point belongs to\n\t\t\t- Update step: Calculate the new means to be the centroids of the observations in the new clusters. This also minimizes the within-cluster sum of squares (WCSS) objective. Also called “Maximization step” because it involves maximizing some fitness function that defines the location of the cluster centers — in this case, that maximization is accomplished by taking a simple mean of the data in each cluster\n\t  - http://stanford.edu/~cpiech/cs221/handouts/kmeans.html  \n\t  - [Five Minutes With Ingo - K Means Clustering](https://www.youtube.com/watch?v=wGzumILN5ww)\n- DBSCAN \n\t- [Density-based spatial clustering of applications with noise](https://en.wikipedia.org/wiki/DBSCAN)\n- [HDBSCAN](http://hdbscan.readthedocs.io/en/latest/soft_clustering_explanation.html)\n- Embeddings\n\t- http://projector.tensorflow.org\n\t- https://www.tensorflow.org/versions/master/how_tos/embedding_viz/index.html\n\n### Spatial clustering\n- [Introduction to hierarchical clustering (Spatial clustering)](https://towardsdatascience.com/introduction-to-hierarchical-clustering-part-3-spatial-clustering-1f8cbd451173)\n\n## References\n- #PAPER [k-means++: the advantages of careful seeding (Arthur 2007)](https://dl.acm.org/doi/10.5555/1283383.1283494)\n- #PAPER [A Comparative Study of Efficient Initialization Methods for the K-Means Clustering Algorithm (Celebi 2012)](https://arxiv.org/abs/1209.1960)\n- #PAPER [SCAN: Learning to Classify Images without Labels (Van Gansbeke 2020)](https://arxiv.org/abs/2005.12320)\n\t- #CODE https://github.com/wvangansbeke/Unsupervised-Classification\n\t- [Paper explained](https://www.youtube.com/watch?v=hQEnzdLkPj4)\n\t- grouping images into semantically meaningful clusters when ground-truth annotations. This is tackling the task of unsupervised image classification in [Computer vision](AI/Computer%20Vision/Computer%20vision.md)\n\t- advocate a two-step approach where feature learning and clustering are decoupled. First, a self-supervised task from representation learning is employed to obtain semantically meaningful features.Second, we use the obtained features as a prior in a learnable clustering  approach.  In  doing  so,  we  remove  the  ability  for  cluster  learning to depend on low-level features, which is present in current end-to-end learning approaches\n- #PAPER [Deep Robust Clustering by Contrastive Learning (Zhong 2020)](https://arxiv.org/abs/2008.03030)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Unsupervised-learning/Dimensionality-reduction-and-low-rank-modeling":{"title":"Dimensionality reduction and low-rank modeling","content":"## Resources and references\n- [The Beginner's Guide to Dimensionality Reduction](https://idyll.pub/post/visxai-dimensionality-reduction-1dbad0a67a092b007c526a45/)\n- [Distances, Neighborhoods, or Dimensions? Projection Literacy for the Analysis of Multivariate Data](https://visxprojections.dbvis.de/client/index.html)\n- [Matrix Factorization: A Simple Tutorial and Implementation in Python](http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/)\n- [Sklearn - Decomposing signals in components (matrix factorization problems)](https://scikit-learn.org/stable/modules/decomposition.html)\n- Projection techniques transform high-dimensional data to a lower-dimensional space while preserving its main structure. Often, the data is transformed to two-dimensional space and visualized as a scatter plot as a means to analyze and understand the data\n- Two categories: linear and non-linear projection techniques. \n\n### Linear methods\n- Linear projection techniques produce a linear transformation of data dimensions in lower-dimensional space. Proximity between data points indicates similarity. The more similar data points are, the closer they are located to each other and vice versa. This is why linear projection techniques are also known as global techniques.\n\n#### Principal component analysis (PCA)\nSee [[PCA]]\n\n#### Non-negative matrix factorization (NMF)\n- Non-negative matrix factorization (NNMF, or NMF) is a method for factorizing a matrix into two lower rank matrices with strictly non-negative elements.\n- https://en.wikipedia.org/wiki/Non-negative_matrix_factorization\n- https://yliapis.github.io/Non-Negative-Matrix-Factorization/\n- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\n- https://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py\n\n#### Generalized Low Rank Models\n- Extension of the idea of PCA to handle arbitrary data sets consisting of numerical, Boolean, categorical, ordinal, and other data types. This framework encompasses many well known techniques in data analysis, such as nonnegative matrix factorization, matrix completion, sparse and robust PCA,-means,-SVD, and maximum margin matrix factorization. The method handles heterogeneous data sets, and leads to coherent schemes for compressing, denoising, and imputing missing entries across all data types simultaneously. It also admits a number of interesting interpretations of the low rank factors, which allow clustering of examples or of features.\n\t- https://github.com/cehorn/GLRM\n\t- #TALK [Generalized Low Rank Models - Madeleine Udell](https://www.youtube.com/watch?v=zwvzGuS82MA)\n\t- #TALK Introduction to generalized low-rank models and missing values (OREILLY): \n\t  - https://conferences.oreilly.com/strata/strata-eu-2016/public/schedule/detail/49771\n\t  - http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glrm.html\n\n#### Dynamic mode decomposition\n- https://en.wikipedia.org/wiki/Dynamic_mode_decomposition\n- linear dimensionality reduction technique for high-dimensional time-series originating from fluid dynamics. DMD combines the best of two worlds: PCA and Fourier transform. Mathematically, it is related to a fundamental operator in dynamical system theory known as the Koopman operator\n- [A case against PCA for time-series analysis](https://towardsdatascience.com/a-case-against-pca-for-time-series-analysis-ac66b47629e0)\n\t- Recent studies have shown that DMD behaves as a source separation algorithm (e.g. ICA), although this framework can be more flexible\n\t- For a similar computational cost, it moreover provides a far more interpretable model than PCA\n\n### Non-linear methods\n- Non-linear projection techniques, also known as local projection techniques, aim at preserving the local neighborhoods across the features in the data. Hereby, proximity highlights differences and coherences between observations and is not to put on the same level as similarity\n\n#### Multidimensional scaling (MDS)\n- Multidimensional scaling (MDS) is a means of visualizing the level of similarity of individual cases of a dataset. It refers to a set of related ordination techniques used in information visualization, in particular to display the information contained in a distance matrix. It is a form of non-linear dimensionality reduction.\n\n#### Self organizing maps (SOM)\n- https://en.wikipedia.org/wiki/Self-organizing_map\n- unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while preserving the topological structure of the data\n- https://stackabuse.com/self-organizing-maps-theory-and-implementation-in-python-with-numpy/\n\n#### T-distributed Stochastic Neighbor Embedding (t-SNE)\n- http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n- t-SNE is a tool to visualize high-dimensional data. It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with different initializations we can get different results.\n- t-SNE is a technique for nonlinear dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. The technique can be implemented via Barnes-Hut approximations, allowing it to be applied on large real-world datasets. It is particularly well-suited for embedding high-dimensional data into a space of two or three dimensions, which can then be visualized in a scatter plot. Specifically, it models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points.\n- https://mark-borg.github.io/blog/2016/tsne/\n- https://blog.alookanalytics.com/2017/02/28/analytical-market-segmentation-with-t-sne-and-clustering-pipeline/\n- [How to Use t-SNE Effectively (Interactive)](http://distill.pub/2016/misread-tsne/)\n\n#### Uniform Manifold Approximation and Projection (UMAP)\n- #PAPER [UMAP - Uniform Manifold Approximation and Projection for Dimension Reduction (McInnes 2020)](https://arxiv.org/abs/1802.03426)\n\t- Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also for general non-linear dimension reduction\n\t- #CODE [Umap](https://github.com/lmcinnes/umap)\n\t- https://umap-learn.readthedocs.io/en/latest/\n- [Understanding UMAP](https://pair-code.github.io/understanding-umap/)\n\t- Nice interactive visualizations\n\n## Code\n- #CODE [Nimfa](https://github.com/marinkaz/nimfa)\n- #CODE [Pymf](https://github.com/cthurau/pymf)\n- #CODE [HyperSpy](https://github.com/hyperspy/hyperspy)\n\t- https://hyperspy.readthedocs.io/en/stable/user_guide/mva.html\n\t- HyperSpy provides easy access to several “machine learning” algorithms that can be useful when analysing multi-dimensional data. In particular, decomposition algorithms, such as principal component analysis (PCA), or blind source separation (BSS) algorithms, such as independent component analysis (ICA), are available","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Unsupervised-learning/PCA":{"title":"Principal component analysis (PCA)","content":"\u003e Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. The number of principal components is less than or equal to the number of original variables. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors are an uncorrelated orthogonal basis set\n\n## Resources\n- https://en.wikipedia.org/wiki/Principal_component_analysis\n\n- http://setosa.io/ev/principal-component-analysis/\n- https://www.neuraldesigner.com/blog/principal-components-analysis\n- http://stats.stackexchange.com/questions/110508/questions-on-pca-when-are-pcs-independent-why-is-pca-sensitive-to-scaling-why \n- Explained variance ratio:\n\t- http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html#explained-variance \n\t- http://jotterbach.github.io/2016/03/24/Principal_Component_Analysis/ \n\n### PCA and SVD\n- Link between [[AI/Math and Statistics/SVD]] and [[AI/Unsupervised learning/PCA]]: the eigenvectors of DDT are simply the left singular vectors of D. SVD gives us also the eigenvectors of DTD, useful for rows  instead of columns notation (python notation)\n- http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues \n- https://www.quora.com/What-is-an-intuitive-explanation-of-singular-value-decomposition-SVD\n- https://stats.stackexchange.com/questions/10251/what-is-the-objective-function-of-pca\n\n### Incremental PCA\n- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.IncrementalPCA.html\n- This algorithm has constant memory complexity, on the order of `batch_size * n_features`, enabling use of np.memmap files without loading the entire file into memory. For sparse matrices, the input is converted to dense in batches (in order to be able to subtract the mean) which avoids storing the entire dense matrix at any one time.\n\n### Robust PCA\nSee [[AI/Unsupervised learning/Robust PCA]]\n\n### Multilinear PCA\n- https://en.wikipedia.org/wiki/Multilinear_principal_component_analysis\n- [http://alumni.media.mit.edu/~maov/tensorfaces/eccv02_corrected.pdf](http://alumni.media.mit.edu/~maov/tensorfaces/eccv02_corrected.pdf) \n- [http://www.comp.hkbu.edu.hk/~haiping/MSL.html](http://www.comp.hkbu.edu.hk/~haiping/MSL.html) \n- [http://www.mathworks.com/matlabcentral/fileexchange/26168-multilinear-principal-component-analysis--mpca](http://www.mathworks.com/matlabcentral/fileexchange/26168-multilinear-principal-component-analysis--mpca)- \n- [http://www.comm.toronto.edu/~kostas/Publications2008/pub/102.pdf](http://www.comm.toronto.edu/~kostas/Publications2008/pub/102.pdf)\n\n\n## Code\n- #CODE https://github.com/jakevdp/wpca\n\n## References\n- #PAPER [Principal Component Analysis with Noisy and/or Missing Data (Bailey 2012)](https://arxiv.org/pdf/1208.4122)            \n- #PAPER [Weighted principal component analysis: a weighted covariance eigendecomposition approach (Delchambre 2014)](https://arxiv.org/pdf/1412.4533)            \n- #PAPER [A Tutorial on Principal Component Analysis (Shlens 2014)](https://arxiv.org/pdf/1404.1100)            \n- #PAPER [EigenGame: PCA as a Nash Equilibrium (Gemp 2021)](https://openreview.net/forum?id=NzTU59SYbNq)\n\t- https://pub.towardsai.net/deepmind-wants-to-reimagine-one-of-the-most-important-algorithms-in-machine-learning-381884d42de","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Unsupervised-learning/Robust-PCA":{"title":"Robust PCA","content":"## Resources\n- https://en.wikipedia.org/wiki/Robust_principal_component_analysis\n- IALM, GoDec \n\t- [http://kastnerkyle.github.io/blog/2014/03/05/matrix-decomposition/](http://kastnerkyle.github.io/blog/2014/03/05/matrix-decomposition/)  \n\t- [http://blog.shriphani.com/2013/12/18/robust-principal-component-pursuit-background-matrix-recovery/](http://blog.shriphani.com/2013/12/18/robust-principal-component-pursuit-background-matrix-recovery/) \n- Robust PCA missing in scikit-learn \n\t- [https://github.com/scikit-learn/scikit-learn/issues/5851](https://github.com/scikit-learn/scikit-learn/issues/5851) \n- [Robust Principal Component Analysis via ADMM in Python](https://jeremykarnowski.wordpress.com/2015/08/31/robust-principal-component-analysis-via-admm-in-python/)\n\n### Godec\n- https://sites.google.com/site/godecomposition/home\n- https://github.com/niam/godec \n- The most interesting aspect of GoDec is that it builds an extremely simple model and develops an fast, randomized algorithm to produce an approximated low-rank + sparse decomposition when rank and cardinality are constrained, and the extra noise exists. This is always the case in real applications, where the model complexity needs to be pre-determined, and neither the low-rank nor sparse part is the noise. \n- It is worthy to note the difference between GoDec and Robust PCA with its extension stable principal component pursuit (SPCP). They have intersections on their application tasks. But their assumptions to data, their models and optimization algorithms are extirely different, thus they works for different situations. \n- https://tianyizhou.wordpress.com/2011/04/20/learn-low-rank-sparse-structures-via-randomized-alternating-projections/ \n- https://tianyizhou.wordpress.com/2011/11/14/semi-soft-godec-4-times-faster-auto-determined-k/ \n- https://tianyizhou.wordpress.com/2011/08/30/news-about-godec-code-and-icml-2011-paper/ \n- GREB: https://tianyizhou.wordpress.com/2013/02/11/greedy-bilateral-greb-paradigm-for-large-scale-matrix-completion-robust-pca-and-low-rank-approximation/ \n\n\n## Code\n- https://github.com/jkarnows/rpcaADMM\n- [https://github.com/nwbirnie/rpca](https://github.com/nwbirnie/rpca) \n- [https://github.com/dganguli/robust-pca](https://github.com/dganguli/robust-pca) \n\t- A Python implementation of R-PCA using principle component pursuit by alternating directions. \n- [https://github.com/dfm/pcp](https://github.com/dfm/pcp) \n\t- A Python implementation of the Principal Component Pursuit algorithm\n- [https://github.com/apapanico/RPCA](https://github.com/apapanico/RPCA) \n\t- Python Implementation of RPCA \n- [https://github.com/kuantkid/PyRPCA/blob/master/](https://github.com/kuantkid/PyRPCA/blob/master/robustpca.py) \n\t- Various algorithms for RPCA \n- [https://jeankossaifi.github.io/tensorly/rpca.html](https://jeankossaifi.github.io/tensorly/rpca.html) \n\t- Robust Tensor PCA with TensorLy\n\n\n## References\n- #PAPER [Robust Kernel Principal Component Analysis (Nguyen 2008)](https://proceedings.neurips.cc/paper/2008/file/8f53295a73878494e9bc8dd6c3c7104f-Paper.pdf)\n- #PAPER [Robust principal component analysis? (Candes 2011)](https://dl.acm.org/doi/10.1145/1970392.1970395)\n- #PAPER [Proximal algorithms. Foundations and Trends in optimization (Parikh \u0026 Boyd, S, 2013)](http://web.stanford.edu/~boyd/papers/prox_algs.html)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Unsupervised-learning/Sparse-dictionary-learning":{"title":"Sparse dictionary learning","content":"\u003e Sparse coding is a representation learning method which aims at finding a sparse representation of the input data (also known as sparse coding) in the form of a linear combination of basic elements as well as those basic elements themselves. These elements are called atoms and they compose a dictionary. Atoms in the dictionary are not required to be orthogonal, and they may be an over-complete spanning set\n\n## Resources\n- https://en.wikipedia.org/wiki/Sparse_dictionary_learning\n- https://en.wikipedia.org/wiki/Compressed_sensing\n- As the era of big data dawns upon us, we are now faced with problems where not only the number of records is massive, but also the number of features per record can be massive too. The problems that arise relating to data that is “too wide” is referred to as the curse of dimensionality. It can therefore be vital to take some measures to reduce the dimensionality of the data set while still preserving the (majority of the) information it holds. \n- Sparse coding is a technique for discovering a small number of “representatives” that can be used to reconstruct the original high-dimensional signal. In the linear generative model of sparse coding, given a set of k-dimensional vectors in a (possibly high-dimensional) real space, the goal of sparse coding is to find some number of basis vectors in addition to a sparse weight vector such that the linear combination of the basis vectors and the weight vector closely approximate the input vectors. (Note: there are other techniques for performing sparse coding) \n- A distinguishing feature of sparse coding from other dimensionality reduction procedures (e.g. principal components analysis, singular value decomposition, etc.) is that the number of bases can exceed the input dimension. It is argued in the literature that this may make sparse coding more biologically realistic, as there is some evidence that the primary visual cortex acts in this manner (see e.g. Honglak Lee et al’s 2006 Advances in neural information processing systems paper titled “Efﬁcient sparse coding algorithms”)\n- https://paperswithcode.com/task/dictionary-learning/codeless\n- Optimizing Orthogonal Matching Pursuit code in Numpy\n\t- http://vene.ro/blog/optimizing-orthogonal-matching-pursuit-code-in-numpy-part-1.html\n\t- http://vene.ro/blog/optimizing-orthogonal-matching-pursuit-code-in-numpy-part-2.html\n\t- https://gist.github.com/vene/996771\n- https://earlbellinger.wordpress.com/2013/12/15/sparse-coding/\n- https://www.quora.com/Sparse-Coding-what-is-the-step-by-step-implementation-for-sparse-coding-What-does-the-l0-norm-l1-norm-regularization-represent\n\n## Code\n- #CODE [Mini-batch dictionary learning (sklearn)](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.html)\n- #CODE [modl](https://github.com/arthurmensch/modl)\n\t- MODL: Massive Online Dictionary Learning\n\t- This python package allows to perform sparse / dense matrix factorization on fully-observed/missing data very efficiently, by leveraging random subsampling with online learning. It is able to factorize matrices of terabyte scale with hundreds of components in the latent space in a few hours\n- #CODE [sparselandtools](https://github.com/fubel/sparselandtools)\n\t- A Python package for sparse representations and dictionary learning, including matching pursuit, K-SVD and applications\n- #CODE [dictlearn](https://github.com/permfl/dictlearn)\n\t- Dictionary Learning for image processing\n- #CODE [mdla](https://github.com/sylvchev/mdla)\n\t- Multivariate Dictionary Learning Algorithm, for time series\n- #CODE [pytorch-lasso](https://github.com/rfeinman/pytorch-lasso)\n- #CODE [PyMP](http://mmoussallam.github.io/PyMP/doc.html)\n\n\n## References\n- #PAPER [Online Dictionary Learning for Sparse Coding (Mairal 2009)](https://www.di.ens.fr/~fbach/mairal_icml09.pdf)\n- #PAPER [Online Learning for Matrix Factorization and Sparse Coding (Mairal 2010)](https://arxiv.org/abs/0908.0050)\n- #PAPER [Sparse Modeling for Image and Vision Processing (Mairal 2014)](https://arxiv.org/pdf/1411.3230)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Unsupervised-learning/Unsupervised-learning":{"title":"Unsupervised learning","content":"\u003e Unsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from \"unlabeled\" data (a classification or categorization is not included in the observations)\n\n## Resources\n- https://en.wikipedia.org/wiki/Unsupervised_learning\n- [Unsupervised Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-unsupervised-learning)\n\n## Sub-topics\n### Kernel density estimation\n- https://en.wikipedia.org/wiki/Kernel_density_estimation\n- kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable\n- [Kernel Density Estimation in Python](https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/)\n- [Histograms and kernel density estimation KDE 2](https://mglerner.github.io/posts/histograms-and-kernel-density-estimation-kde-2.html?p=28)\n- https://scikit-learn.org/stable/modules/density.html\n- https://stackabuse.com/kernel-density-estimation-in-python-using-scikit-learn/\n\n### Dimensionality reduction and low rank modeling\nSee [[AI/Unsupervised learning/Dimensionality reduction and low rank modeling]]\n\n### Clustering \nSee [[AI/Unsupervised learning/Clustering]]\n\n### Blind source separation\n- Blind signal separation (BSS), also known as blind source separation, is the separation of a set of source signals from a set of mixed signals, without the aid of information (or with very little information) about the source signals or the mixing process.\n\n#### Independent component analysis (ICA)\n- https://en.wikipedia.org/wiki/Independent_component_analysis\n- In signal processing, independent component analysis (ICA) is a computational method for separating a multivariate signal into additive subcomponents. This is done by assuming that the subcomponents are non-Gaussian signals and that they are statistically independent from each other.\n- https://scikit-learn.org/stable/modules/decomposition.html#ica\n- https://scikit-learn.org/stable/auto_examples/decomposition/plot_ica_blind_source_separation.html\n- https://mne.tools/stable/generated/mne.preprocessing.ICA.html\n\n### Anomaly and Outlier Detection\nSee [[AI/Anomaly and Outlier Detection]]\n\n### Sparse dictionary learning\nSee [[Sparse dictionary learning]]","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/Weakly-supervised-learning":{"title":"Weakly supervised learning","content":"\u003e Weak supervision is a branch of machine learning where noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts of training data in a supervised learning setting. This approach alleviates the burden of obtaining hand-labeled data sets, which can be costly or impractical. Instead, inexpensive weak labels are employed with the understanding that they are imperfect, but can nonetheless be used to create a strong predictive model.\n\n\u003e See [[AI/Transfer learning]], [[AI/Active learning]] and [[AI/Semi-supervised learning]]\n\n## Resources\n- Other areas of machine learning exist that are likewise motivated by the demand for increased quantity and quality of labeled training data but employ different high-level techniques to approach this demand. These other approaches include [[AI/Active learning]], [[AI/Semi-supervised learning]], and [[AI/Transfer learning]].\n- Related to [[AI/One, few-shot learning]]. The most relevant problem to few-shot learning is weakly supervised learning with incomplete supervision where only a small amount of samples have supervised. By definition, weakly supervised learning with incomplete supervision includes only classification and regression, while few-shot learning also includes reinforcement learning problems. Moreover, weakly supervised learning with incomplete supervision mainly uses unlabeled data as additional information in E, while few-shot learning leverages various kinds of prior knowledge such as pretrained models, supervised data from other domains or modalities and does not restrict to using unlabeled data. Therefore, few-shot learning becomes weakly supervised learning problem only when prior knowledge is unlabeled data and the task is classification or regression.information.\n- [Weakly Supervised Learning: Introduction and Best Practices](https://datasciencemilan.medium.com/weakly-supervised-learning-introduction-and-best-practices-c65f490d4a0a)\n\n\n## References\n- #PAPER [A brief introduction to weakly supervised learning (2018)](https://academic.oup.com/nsr/article/5/1/44/4093912 )\n- #PAPER [A Graph-Based Method for Active Outlier Detection With Limited Expert Feedback (2019)](https://ieeexplore.ieee.org/document/8871105)\n\n### Incomplete supervision\n- In this case, only a (usually small) subset of training data is given with labels while the other data remain unlabeled (e.g., in image categorization the ground-truth labels are given by human annotators, and only a small subset of images can be annotated due to the human cost)\n- #PAPER [Learning from Incomplete and Inaccurate Supervision (Zhang 2021)](https://ieeexplore.ieee.org/document/9361098)\n\n### Inexact supervision\n- In this case, only coarse-grained labels are given. Consider the image categorization task again. It is desirable to have every object in the images annotated; however, usually we only have image-level labels rather than object-level labels. \n- #PAPER [Labeled Data Generation with Inexact Supervision (Dai 2021)](https://arxiv.org/abs/2106.04716)\n\n### Inaccurate supervision\n- The given labels are not always ground-truth (e.g., the image annotator is careless, or some images are difficult to categorize)\n - #PAPER [Auxiliary Image Regularization for Deep CNNs with Noisy Labels (2016)](https://arxiv.org/abs/1511.07069v2)\n - #PAPER [Anomaly detection with inexact labels (2019)](https://arxiv.org/abs/1909.04807)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI/XAI":{"title":"XAI","content":"\u003e Explainable AI (XAI), or Interpretable AI, is artificial intelligence (AI) in which the results of the solution can be understood by humans\n\n## Resources\n- https://en.wikipedia.org/wiki/Explainable_artificial_intelligence\n- https://github.com/anguyen8/XAI-papers\n- [Ideas on interpreting machine learning](https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning)\n- [Explainable AI demos](https://lrpserver.hhi.fraunhofer.de/)\n- [Why you need to care about Explainable Machine Learning](https://medium.com/james-blogs/why-you-need-to-care-about-explainable-machine-learning-d01196a6af76)\n- [Interpreting machine learning models](https://towardsdatascience.com/interpretability-in-machine-learning-70c30694a05f)\n- [I.am.ai. Explaining artificial intelligence](https://www.i-am.ai/)\n- [Baking recipes made by AI](https://cloud.google.com/blog/topics/developers-practitioners/baking-recipes-made-ai)\n- [Breaking into the black box of artificial intelligence](https://www.nature.com/articles/d41586-022-00858-1)\n- A Review of Different Interpretation Methods:\n\t- https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-1-saliency-map-cam-grad-cam-3a34476bc24d\n\t- https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-2-input-gradient-layerwise-e077609b6377\n\t- https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-3-shap-integrated-gradients-918fc9fedd9b\n\n\n## Events, talks\n- [Workshop on Visualization for AI Explainability](http://visxai.io/)\n- [ACM Conference on Fairness, Accountability, and Transparency](https://facctconference.org/)\n- [Explainable AI xAI 2020](https://human-centered.ai/explainable-ai-2020/)\n- #TALK [Synthesizing Explainable and Deceptive Behavior for Human-AI Interaction (AAAI 2020 Tutorial)](https://yochan-lab.github.io/tutorial/AAAI-2020/)\n\t- https://www.youtube.com/watch?v=r6KhJ3ORYnc\n- #TALK [Explainable AI in Industry (Tutorial)](https://sites.google.com/view/explainable-ai-tutorial)\n\t- https://www.youtube.com/watch?list=PLewjn-vrZ7d3x0M4Uu_57oaJPRXkiS221\u0026v=rcUw7PXHWF4\n- #TALK [Explainable AI: Foundations, Industrial Applications, Practical Challenges, and Lessons Learned (AAAI 2020)](https://xaitutorial2020.github.io/)\n\t- https://xaitutorial2020.github.io/raw/master/slides/aaai_2020_xai_tutorial.pdf\n\n\n## Books\n- #BOOK [ Interpretable Machine Learning (Molnar 2021)](https://christophm.github.io/interpretable-ml-book/)\n\n## Code\nSee \"Code\" section in [[AI/Deep learning/Explainability methods for NNs]]\n- https://towardsdatascience.com/explainable-ai-xai-a-guide-to-7-packages-in-python-to-explain-your-models-932967f0634b\n\n- #CODE [Xplique](https://github.com/deel-ai/xplique)\n\t- Python toolkit dedicated to explainability, currently based on Tensorflow\n\t- https://deel-ai.github.io/xplique/\n\t- #PAPER [Xplique: A Deep Learning Explainability Toolbox (Fel 2022)](https://arxiv.org/pdf/2206.04394v1)\n- #CODE [CARLA](https://github.com/carla-recourse/CARLA)\n\t- CARLA is a python library to benchmark counterfactual explanation and recourse models\n\t- #PAPER [CARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms (Pawelczyk 2021)](https://arxiv.org/abs/2108.00783)\n\t- https://www.marktechpost.com/2021/08/22/university-of-tubingen-researchers-open-source-carla-a-python-library-for-benchmarking-counterfactual-explanation-methods-across-data-sets-and-machine-learning-models/\n- #CODE [Shapash](https://github.com/MAIF/shapash)\n\t- https://shapash.readthedocs.io/en/latest/\n- #CODE [ExplainerDashboard](https://github.com/oegedijk/explainerdashboard)\n\t- https://explainerdashboard.readthedocs.io/en/latest/index.html#\n\t- library for quickly building interactive dashboards for analyzing and explaining the predictions and workings of (scikit-learn compatible) machine learning models, including xgboost, catboost and lightgbm\n\t- #TALK https://www.youtube.com/watch?v=1nMlfrDvwc8\n- #CODE [AIX360](https://github.com/Trusted-AI/AIX360) ^aix360\n\t- Interpretability and explainability of data and machine learning models\n\t- http://aix360.mybluemix.net/\n- #CODE [LIME: Local Interpretable Model-agnostic Explanations](https://github.com/marcotcr/lime) ^limegithub\n- #CODE [Skater](https://github.com/datascienceinc/Skater)\n\t- Skater is a python package for model agnostic interpretation of predictive models. With Skater, you can unpack the internal mechanics of arbitrary models; as long as you can obtain inputs, and use a function to obtain outputs, you can use Skater to learn about the models internal decision policies.\n\t- https://datascienceinc.github.io/Skater/overview.html\n\t- Understanding How and Why Your Model Works:  https://www.datascience.com/learn-data-science/fundamentals/model-interpretation-algorithms\n\t- https://www.datascience.com/resources/tools/skater\n- #CODE [FairML - Auditing Black-Box Predictive Models](https://github.com/adebayoj/fairml)\n\t- FairML is a python toolbox auditing the machine learning models for bias. \n\t- http://blog.fastforwardlabs.com/2017/03/09/fairml-auditing-black-box-predictive-models.html\n- #CODE [ELI5](https://github.com/TeamHG-Memex/eli5)\n\t- ELI5 is a Python library which allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides a way to explain black-box models.\n\t- http://eli5.readthedocs.io/en/latest/\n- #CODE [BlackBox Auditing](https://github.com/algofairness/BlackBoxAuditing)\n- #CODE [SHAP](https://github.com/slundberg/shap) ^shapgithub\n\t- Unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations.\n- #CODE [FastTreeSHAP](https://github.com/linkedin/FastTreeSHAP)\n\t- Fast SHAP value computation for interpreting tree-based models\n\t- [LinkedIn Researchers Open-Source FastTreeSHAP](https://www.marktechpost.com/2022/03/20/linkedin-researchers-open-source-fasttreeshap-a-python-package-that-enables-an-efficient-interpretation-of-tree-based-machine-learning-models/)\n- #CODE [InterpretML](https://github.com/interpretml/interpret). Microsoft open-source package that incorporates state-of-the-art machine learning interpretability techniques under one roof\n- #CODE [imodels](https://github.com/csinva/imodels)\n\t- Python package for concise, transparent, and accurate predictive modeling. All sklearn-compatible and easy to use\n\t- [UC Berkeley Researchers Introduce ‘imodels: A Python Package For Fitting Interpretable Machine Learning Models](https://www.marktechpost.com/2022/02/10/uc-berkeley-researchers-introduce-imodels-a-python-package-for-fitting-interpretable-machine-learning-models/)\n\n\n## References\n- #PAPER [The Mythos of Model Interpretability (Lipton 2017)](https://arxiv.org/abs/1606.03490)\n- #PAPER [A Survey of Methods for Explaining Black Box Models (Guidotti, 2018)](https://dl.acm.org/doi/10.1145/3236009)\n- #PAPER [Making the Black Box More Transparent: Understanding the Physical Implications of Machine Learning (McGovern et al. 2019)](https://journals.ametsoc.org/bams/article/100/11/2175/343787/Making-the-Black-Box-More-Transparent)\n- #PAPER [Towards Explainable Artificial Intelligence (Samek \u0026 Muller 2019)](https://arxiv.org/abs/1909.12072)\n- #PAPER [Explaining Explanations: An Overview of Interpretability of Machine Learning (Gilpin et al. 2019)](https://arxiv.org/abs/1806.00069)\n- #PAPER [One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques (Arya 2019)](https://arxiv.org/abs/1909.03012)\n\t- #CODE See Code section\n- #PAPER [Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead (Rudin 2019)](https://www.nature.com/articles/s42256-019-0048-x)\n\t- https://arxiv.org/abs/1811.10154\n- #PAPER [Explainable Machine Learning for Scientific Insights and Discoveries (Roscher 2020)](https://arxiv.org/abs/1905.08883)\n- #PAPER [Review Study of Interpretation Methods for Future Interpretable Machine Learning (Jian-Xun 2020)](https://ieeexplore.ieee.org/document/9234594)\n- #PAPER [Explainable neural networks that simulate reasoning (Blazek 2021)](https://www.nature.com/articles/s43588-021-00132-w)\n- #PAPER [Turning biases into hypotheses through method: A logic of scientific discovery for machine learning (Aagaard Enni 2021)](https://journals.sagepub.com/doi/full/10.1177/20539517211020775)\n\t- bridging the gap in the understanding of ML models and their reasonableness requires a focus on developing an improved methodology for their creation\n\t- this process has been likened to “alchemy” and criticized for involving a large degree of “black art,” owing to its reliance on poorly understood “best practices”\n\t- authors soften this critique and argue that the seeming arbitrariness often is the result of a lack of explicit hypothesizing stemming from an empiricist and myopic focus on optimizing for predictive performance rather than from an occult or mystical process\n\n\n### Model-agnostic methods\n- https://christophm.github.io/interpretable-ml-book/agnostic.html\n\t- The great advantage of model-agnostic interpretation methods over model-specific ones is their flexibility\n\t- An alternative to model-agnostic interpretation methods is to use only interpretable models, which often has the big disadvantage that predictive performance is lost compared to other machine learning models and you limit yourself to one type of model\n\n- #PAPER [Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation (Goldstein 2014)](https://arxiv.org/abs/1309.6392)\n- #PAPER [Model-Agnostic Interpretability of Machine Learning (Tulio Ribeiro 2016)](https://arxiv.org/abs/1606.05386)\n- #PAPER [SHAP - A Unified Approach to Interpreting Model Predictions (Lundberg 2017)](https://arxiv.org/abs/1705.07874)\n\t- SHAP (SHapley Additive exPlanations)\n\t- #CODE See Code section\n\t- Can be used for computer vision tasks\n- #PAPER [Fast TreeSHAP: Accelerating SHAP Value Computation for Trees (Yang 2021)](https://arxiv.org/abs/2109.09847)\n\n#### Partial Dependence Plot\n- The partial dependence plot (short PDP or PD plot) shows the marginal effect one or two features have on the predicted outcome of a machine learning model\n- https://christophm.github.io/interpretable-ml-book/pdp.html\n- https://scikit-learn.org/stable/modules/partial_dependence.html\n\n#### Individual Conditional Expectation\n- Individual Conditional Expectation (ICE) plots display one line per instance that shows how the instance's prediction changes when a feature changes\n- https://christophm.github.io/interpretable-ml-book/ice.html\n- https://scikit-learn.org/stable/modules/partial_dependence.html\n\n#### Permutation Feature Importance\n- Permutation feature importance measures the increase in the prediction error of the model after we permuted the feature's values, which breaks the relationship between the feature and the true outcome\n- https://christophm.github.io/interpretable-ml-book/feature-importance.html\n- https://scikit-learn.org/stable/modules/permutation_importance.html\n\t- The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled\n\t- Tree-based models provide an alternative measure of feature importances based on the mean decrease in impurity (MDI). Impurity is quantified by the splitting criterion of the decision trees (Gini, Entropy or Mean Squared Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data\n\n#### Surrogate models\n- A surrogate model is a simple model that is used to explain a complex model. Surrogate models are usually created by training a linear regression or decision tree on the original inputs and predictions of a complex model. Coefficients, variable importance, trends, and interactions displayed in the surrogate model are then assumed to be indicative of the internal mechanisms of the complex model. There are few, possibly no, theoretical guarantees that the simple surrogate model is highly representative of the more complex model.\n- The globally interpretable attributes of a simple model are used to explain global attributes of a more complex model. However, there is nothing to preclude fitting surrogate models to more local regions of a complex model's conditional distribution, such as clusters of input records and their corresponding predictions and their corresponding input rows. Because small sections of the conditional distribution are more likely to be linear, monotonic, or otherwise well-behaved, local surrogate models can be more accurate than global surrogate models.\n- #PAPER [LIME - \"Why Should I Trust You?\": Explaining the Predictions of Any Classifier (2016)](https://arxiv.org/abs/1602.04938) ^lime\n\t- #CODE See Code section\n\t- Formalized approach for local surrogate models. It is meant to shed light on how decisions are made for specific observations. LIME requires that a set of explainable records be found, simulated, or created.\n\t- https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime\n\t- https://github.com/albahnsen/Talk_Demystifying_Machine_Learning\n\t- [Interpreting ML models prediction power](http://www.datasciencecentral.com/profiles/blogs/deep-learning-epic-fail-right-answer-wrong-reason)\n\t- https://medium.com/@ageitgey/natural-language-processing-is-fun-part-3-explaining-model-predictions-486d8616813c\n\t- https://www.slideshare.net/albahnsen/demystifying-machine-learning-using-lime\n\t- https://github.com/albahnsen/Talk_Demystifying_Machine_Learning\n\n\n### Maximum activation analysis\n- See [[AI/Deep learning/Explainability methods for NNs]]\n- In maximum activation analysis, examples are found or simulated that maximally activate certain neurons, layers, or filters in a neural network or certain trees in decision tree ensembles. For the purposes of maximum activation analysis, low residuals for a certain tree are analogous to high-magnitude neuron output in a neural network.\n- Maximum activation analysis elucidates internal mechanisms of complex models by determining the parts of the response function that specific observations or groups of similar observations excite to the highest degree, either by high-magnitude output from neurons or by low residual output from trees.\n\n\n### Sensitivity analysis\n- Sensitivity analysis investigates whether model behavior and outputs remain stable when data is intentionally perturbed or other changes are simulated in data. \n- Beyond traditional assessment practices, sensitivity analysis of machine learning model predictions is perhaps the most important validation technique for machine learning models. \n- Machine learning models can make drastically differing predictions from minor changes in input variable values. In practice, many linear model validation techniques focus on the numerical instability of regression parameters due to correlation between input variables or between input variables and the dependent variable\n- Sensitivity analysis can also test model behavior and outputs when interesting situations or known corner cases are simulated. Output distributions, error measurements, plots, and interpretation techniques can be used to explore the way models behave in important scenarios, how they change over time, or if models remain stable when data is subtly and intentionally corrupted\n\n\n### Variable importance measures\n- Variable importance measures are typically seen in tree-based models but are sometimes also reported for other models.\n- A simple heuristic rule for variable importance in a decision tree is related to the depth and frequency at which a variable is split on in a tree, where variables used higher in the tree and more frequently in the tree are more important. \n- For a single decision tree, a variable's importance is quantitatively determined by the cumulative change in the splitting criterion for every node in which that variable was chosen as the best splitting candidate. \n- For a gradient boosted tree ensemble, variable importance is calculated as it is for a single tree but aggregated for the ensemble. \n- For random forests:\n\t- Variable importance is also calculated as it is for a single tree and aggregated, but an additional measure of variable importance is provided by the change in out-of-bag accuracy caused by shuffling the independent variable of interest, where larger decreases in accuracy are taken as larger indications of importance\n\t- The default method to compute variable importance is the mean decrease in impurity (or gini importance) mechanism: At each split in each tree, the improvement in the split-criterion is the importance measure attributed to the splitting variable, and is accumulated over all the trees in the forest separately for each variable. Note that this measure is quite like the R^2 in regression on the training set\n\t- [This example highlights the limitations of impurity-based feature importance in contrast to permutation-based feature importance](https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html)\n\t- #PAPER [Understanding variable importances in forests of randomized trees (Louppe 2013)](https://papers.nips.cc/paper/4928-understanding-variable-importances-in-forests-of-randomized-trees.pdf)\n\t\t- #POSTER https://orbi.uliege.be/bitstream/2268/155642/3/poster.pdf\n\t- #PAPER [Trees, forests, and impurity-based variable importance (Scornet 2020)](https://arxiv.org/abs/2001.04295)\n- For neural networks, variable importance measures are typically associated with the aggregated, absolute magnitude of model parameters for a given variable of interest. \n- Global variable importance techniques are typically model specific, and practitioners should be aware that unsophisticated measures of variable importance can be biased toward larger scale variables or variables with a high number of categories.\n\n\n### Explainability methods for Neural Networks\nSee [[AI/Deep learning/Explainability methods for NNs]]","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/AC-AQ":{"title":"Atmospheric composition and air quality (AC, AQ)","content":"## Resources\n- [Atmospheric composition data products](https://iasi.aeris-data.fr/)\n- [Chemical transport model (CTM)](https://en.wikipedia.org/wiki/Chemical_transport_model)\n\t- type of computer numerical model which typically simulates atmospheric chemistry and may give air pollution forecasting\n\t- CTM focuses on the stocks and flows of one or more chemical species\n\t- CTM is expected to accurately represent the entire cycle for the species of interest, including fluxes (e.g. advection), chemical production/loss, and deposition\n- [Gaussian process regression (GPR) on Mauna Loa CO2 data. — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_co2.html)\n- [Air Quality e-Reporting](https://www.eea.europa.eu/data-and-maps/data/aqereporting-9)\n\n### Methane emission sources\n- [The MEthane Tracking Emissions Reference (METER) database](https://meterplatform.web.app/)\n\t- The METER database combines public data set aggregation, crowdsourcing, and artificial intelligence to create a freely available, global repository of methane-emitting infrastructure\n- [GHGsat](https://www.bloomberg.com/news/articles/2021-02-12/new-climate-satellite-spotted-giant-methane-leak-as-it-happened)\n- Methane tracker: \n\t- https://www.iea.org/articles/global-methane-emissions-from-oil-and-gas\n\t- https://www.iea.org/articles/methane-tracker-database\n\t- [Mapping methane emissions on a global scale](https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-5P/Mapping_methane_emissions_on_a_global_scale)\n\t- [Monitoring methane emissions from gas pipelines](https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-5P/Monitoring_methane_emissions_from_gas_pipelines)\n\n### TROPOMI\n- [AI4EO challenge](https://platform.ai4eo.eu/air-quality-and-health)\n\n\n## References\n- #PAPER [Forecasting CO2 Emission with Machine Learning Methods (Garip 2018)](https://ieeexplore.ieee.org/document/8620767)\n\t- https://www.researchgate.net/publication/331426320_Forecasting_CO2_Emission_with_Machine_Learning_Methods\n- #PAPER [Forecasting CO2 Emissions from Energy, Manufacturing and Transport Sectors in Pakistan: Statistical Vs. Machine Learning Methods (Ur Rehman 2018)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3292279 )\n- #PAPER [A novel method for carbon dioxide emission forecasting based on improved Gaussian processes regression (Fang 2018)](https://www.sciencedirect.com/science/article/abs/pii/S0959652617310429)\n- #PAPER [A Neural Attention Model for Urban Air Quality Inference: Learning the Weights of Monitoring Stations (Cheng, 2018)](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16607)\n\t- Existing approaches to inferring spatially fine-grained air quality information mainly fall into two categories:physical methods and data-driven approaches\n\t- Proposed a generic neural attention model based on deep neural networks for urban air quality inference. We leverage both records from monitoring stations and various urban data (e.g., meteorology, road networks, POIs), and extract important features that are correlated with air quality\n- [#THESIS/MSC Mid-term air quality forecasts using remote sensing data and machine learning (van Linschoten, 2017)](https://staff.fnwi.uva.nl/a.s.z.belloum/MSctheses/MScthesis_Boris_van_linschoten.pdf)\n- #PAPER [Estimation of ground-level particulate matter concentrations through the synergistic use of satellite observations and process-based models over South Korea (Park 2019)](https://www.atmos-chem-phys.net/19/1097/2019/)\n- #PAPER [Air Quality Forecast through Integrated Data Assimilation and Machine Learning (Lin 2019)](https://www.researchgate.net/publication/330451387_Air_Quality_Forecast_through_Integrated_Data_Assimilation_and_Machine_Learning)\n- #PAPER [Machine learning for Inferring CO2 Fluxes: The New Metaphysics of Neural Nets (Nguyen 2019)](https://eartharxiv.org/284f5/)\n- #PAPER [California’s methane super-emitters (Duren 2019)](https://www.nature.com/articles/s41586-019-1720-3)\n\t- Identifying point sources of emissions with HiRes EO. No ML though\n- #PAPER [Machine learning for observation bias correction with application to dust storm data assimilation (Jin 2019)](https://www.atmos-chem-phys.net/19/10009/2019/)\n\t- Two methods have been implemented to remove the non-dust part of the PM10 observations during the dust event in order to use them as a dust proxy in a dust assimilation system\n\t- The first method uses a conventional regional chemistry transport model, LOTOS-EUROS/non-dust, which simulates the emission, transport, chemistry, and deposition of aerosols mainly related to anthropogenic activities\n\t- The second method uses a machine learning model (LSTM) that statistically describes the relations between regular PM10 concentrations (outside dust events) and available air quality and meteorological data\n\t- The best results are obtained when using a LSTM model to remove the non-dust part of the PM10 observations, with a posteriori concentrations in good agreement with the measurements\n- #PAPER [MapLUR: Exploring a New Paradigm for Estimating Air Pollution Using Deep Learning on Map Images (Steininger 2020)](https://dl.acm.org/doi/fullHtml/10.1145/3380973)\n\t- https://arxiv.org/pdf/2002.07493.pdf\n- #PAPER [A scientific algorithm to simultaneously retrieve carbon monoxide and methane from TROPOMI onboard Sentinel-5 Precursor (Schneising 2019)](https://www.researchgate.net/publication/333785409)\n- #PAPER [TROPOMI NO2 Tropospheric Column Data: Regridding to 1 km Grid-Resolution and Assessment of their Consistency with In Situ Surface Observations (Cersosimo 2020)](https://www.mdpi.com/2072-4292/12/14/2212/htm)\n\t- Kriging\n- #PAPER [Copernicus Atmosphere Monitoring Service TEMPOral profiles (CAMS-TEMPO): global and European emission temporal profile maps for atmospheric chemistry modelling (Guevara 2020)](https://essd.copernicus.org/articles/13/367/2021/)\n- #PAPER [Comparison of Machine Learning and Land Use Regression for fine scale spatiotemporal estimation of ambient air pollution: Modeling ozone concentrations across the contiguous United States (Ren 2020)](https://www.sciencedirect.com/science/article/pii/S0160412020317827#bb0130)\n- #PAPER [Importance of satellite observations for high-resolution mapping of near-surface NO2 by machine learning (Kim 2021)](https://www.sciencedirect.com/science/article/pii/S0034425721002935#f0035)\n\t- https://www.empa.ch/web/s503/maps-of-air-pollutants\n\t- XGBoost per grid-point\n\t- 100 m resolution\n- #PAPER [Exploring Deep Learning for Air Pollutant Emission Estimation (Huang 2021)](https://gmd.copernicus.org/preprints/gmd-2021-80/)\n\t- #CODE https://zenodo.org/record/4607127#.YGTqgnX7RtM\n- #PAPER [The UrbEm Hybrid Method to Derive High-Resolution Emissions for City-Scale Air Quality Modeling (Ramacher 2021)](https://www.mdpi.com/2073-4433/12/11/1404/htm)\n\t- See [[AI4ES/Statistical downscaling]]\n\t- non ML but the methodology is useful\n\t- In addition to a better spatial representation of emission sources and especially hotspots, the air quality modeling results show that UrbEm outputs, when compared to a uniform spatial disaggregation, have an impact on NO2 predictions up to 70% for urban regions with complex topographies, which corresponds to a big improvement of model accuracy (FAC2 \u003e 0.5), especially at the source-impacted sites \n- #PAPER [MethaNet – An AI-driven approach to quantifying methane point-source emission from high-resolution 2-D plume imagery (Jongaramrungruang 2022)](https://www.sciencedirect.com/science/article/abs/pii/S0034425721005290?casa_token=Rr8iWs71uhYAAAAA:D4PWThLU5hKi7khAv3yk23pR76hR81P5dTDSUjLJrF5SPL2r76hZE3YkHOGPzapU64pAzzHuAgU#!)\n- #PAPER [Single-blind validation of space-based point-source methane emissions detection and quantification (Sherwin 2022)](https://eartharxiv.org/repository/view/3465/)\n- #PAPER [METER-ML: A Multi-sensor Earth Observation Benchmark for Automated Methane Source Mapping (Zhu 2022)](https://stanfordmlgroup.github.io/projects/meter-ml/)\n\t- multi-sensor Earth observation dataset containing georeferenced images in the U.S. labeled for the presence or absence of six methane source facilities","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/AI4ES":{"title":"AI4ES","content":"\u003e Applications of [[AI/Machine Learning]] and [[AI/AI]] to Earth Sciences\n\n\u003e See:\n\u003e - [[AI4ES/EO]]\n\u003e - [[AI4ES/Geospatial science]]\n\n## Resources\n- [Earth system science](https://en.wikipedia.org/wiki/Earth_system_science)\n- [Accelerating progress in Climate Science (Schneider 2021, Physics today)](https://digital.physicstoday.org/physicstoday/june_2021/MobilePagedReplica.action?utm_source=newsletter\u0026utm_medium=email\u0026utm_campaign=TXPHYS210602002\u0026utm_content=gtxcel\u0026pm=2\u0026folio=44#pg47)\n- https://www.scientificamerican.com/article/how-machine-learning-could-help-to-improve-climate-forecasts/\n- https://e360.yale.edu/features/can-artificial-intelligence-help-build-better-smarter-climate-models\n- [Artificial Intelligence—A Game Changer for Climate Change and the Environment ](https://blogs.ei.columbia.edu/2018/06/05/artificial-intelligence-climate-environment/)\n- [Ten Ways to Apply Machine Learning in Earth and Space Sciences](https://eos.org/opinions/ten-ways-to-apply-machine-learning-in-earth-and-space-sciences)\n- [Supercomputers, Climate Models and 40 Years of the World Climate Research Programme](https://insideclimatenews.org/news/06122019/climate-models-supercomputer-world-research-program-agu-100-anniversary-cheyenne-wyoming)\n- [Thoughtfully Using Artificial Intelligence in Earth Science](https://eos.org/opinions/thoughtfully-using-artificial-intelligence-in-earth-science)\n- [Advancing AI for Earth Science: A Data Systems Perspective](https://eos.org/science-updates/advancing-ai-for-earth-science-a-data-systems-perspective)\n\t- high-priority challenges include:\n\t\t- a lack of publicly available benchmark training data sets across all science disciplines\n\t\t- a lack of interoperability among data sources, types, and formats (e.g., standard data formats for computer vision algorithms may be different from the standard formats for commonly used Earth science models)\n\t\t- limited availability of baseline pretrained models that can be customized for various types or modes of Earth observations\n\t\t- label or target values that are not usually structured, such as oceanic measurements from drifting buoys that cannot be adapted easily to the grid systems commonly used in ML algorithms\n- [Weathering Environmental Change Through Advances in AI](https://eos.org/opinions/weathering-environmental-change-through-advances-in-ai)\n- [Tackling 21st Century Geoscience Problems with Machine Learning](https://eos.org/editors-vox/tackling-21st-century-geoscience-problems-with-machine-learning)\n- [Advancing Application of Machine Learning Tools for NASA’s Earth Observation Data (NASA)](https://cdn.earthdata.nasa.gov/conduit/upload/14287/NASA_ML_Workshop_Report.pdf) ^7b7470\n- [Training the Next Generation of Physical Data Scientists](https://eos.org/opinions/training-the-next-generation-of-physical-data-scientists)\n- [Guest post (CarbonBrief): How artificial intelligence is fast becoming a key tool for climate science](https://www.carbonbrief.org/guest-post-how-artificial-intelligence-is-fast-becoming-a-key-tool-for-climate-science/)\n\n## Talks\n- #TALK [Deep Learning for Climate (Gallinari)](https://ai4climate.lip6.fr/wp-content/uploads/2018/10/2018-05-25-Deep-Learning-Climate-Gallinari-2.pdf)\n- #TALK [A collective agenda for AI on the Earth sciences (Camps-Valls)](https://www.youtube.com/watch?v=ts5XSYgcsiE)\n- #TALK [Destination Earth and AI (Peter Dueben)](https://www.youtube.com/watch?v=qcYbHkgTrvM)\n\n## Books\n- #BOOK [Introduction to Climate Science (Schmittner 2017)](https://open.umn.edu/opentextbooks/textbooks/introduction-to-climate-science-1st-edition-schmittner)\n- #BOOK [Introduction to Oceanography (Webb 2019)](https://open.umn.edu/opentextbooks/textbooks/introduction-to-oceanography)\n- #BOOK [Introduction to Environmental Science - 2nd Edition (2018)](https://open.umn.edu/opentextbooks/textbooks/introduction-to-environmental-science-2nd-edition)\n- #BOOK [Introduction to Physical Oceanography (Stewart 2008)](https://open.umn.edu/opentextbooks/textbooks/introduction-to-physical-oceanography)\n- #BOOK [Deep Learning for the Earth Sciences: A Comprehensive Approach to Remote Sensing, Climate Science and Geosciences (Camps-Valls 2021)](https://www.amazon.com/-/es/Gustau-Camps-Valls-dp-1119646146/dp/1119646146/ref=mt_other?_encoding=UTF8\u0026me=\u0026qid=)\n\n## Courses\n- #COURSE [Applied Machine Learning Tutorial for Earth Scientists](https://github.com/eabarnes1010/ml_tutorial_csu)\n\t- Machine Learning Tutorial for Earth Scientists created by members of the Atmospheric Science Department at Colorado State University\n\t- [Google Slides](https://docs.google.com/presentation/d/1Fa9SuyK9DIpd-MkJJjGqjCbAa-sHtr3qufC9MhmewDQ/edit?usp=sharing)\n- #COURSE [An Introduction to Earth and Environmental Data Science (Ryan Abernathey, Columbia UIniversity, 2021)](https://earth-env-data-science.github.io/intro.html)\n- #COURSE [Research computing in ES (Ryan Abernathey, Columbia UIniversity)](https://rabernat.github.io/research_computing_2018/)\n- #COURSE [Introduction to Environmental Data Science (Jerry Davis, SFSU Institute for Geographic Information Science_, 2022)](https://bookdown.org/igisc/EnvDataSci/)\n\n## References\n- #PAPER [Earth System Modeling 2.0: A Blueprint for Models That Learn From Observations and Targeted High‐Resolution Simulations (Schneider 2017)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017GL076101)\n\t- http://climate-dynamics.org/earth-system-modeling-2-0/\n\t- ESM with subgrid-scale (SGS) process models that learn automatically from two sources of information\n\t\t- Global observations. ESMs can learn directly from space-based global data, augmented and validated with more detailed local observations where available\n\t\t- Local high-resolution simulations. Some SGS processes in ESMs are in principle computable, only the globally achievable resolution precludes their explicit computation\n\t- The automated learning from observations and high-resolution simulations will use statistics accumulated in time (e.g., over seasons) to:\n\t\t- Minimize model biases, especially biases that are known to correlate with the climate response of models. This amounts to minimizing mismatches between time averages of ESM-simulated quantities and data\n\t\t- Minimize model-data mismatches in higher-order Earth system statistics\n- #PAPER [Machine learning for data-driven discovery in solid Earth geoscience (Bergen 2019)](https://science.sciencemag.org/content/363/6433/eaau0323)\n- #PAPER [Machine learning and artificial intelligence to aid climate change research and preparedness (Huntingford et al., 2019)](https://iopscience.iop.org/article/10.1088/1748-9326/ab4e55)\n\t- Nine basic dimensions of climate modelling (there include geographical location, the many configurations of ESMs, and alternative future trajectories in emissions policy) : Longitude direction, altitude direction, Vertical direction, Time, Different climate models, Climate model ensembles, Different initial state, Perturbed physics runs, Different future emissions\n\t- Examples of existing AI applications to climate: Earth System modelling, Teleconnections, Weather forecasting, Future climate scenarios, Climate impacts, Climate datasets, Climate extremes\n- #PAPER [Leveraging Modern Artificial Intelligence for Remote Sensing and NWP: Benefits and Challenges (Boukabara 2019)](https://journals.ametsoc.org/bams/article/100/12/ES473/344464/Leveraging-Modern-Artificial-Intelligence-for)\n- #PAPER [Deep learning and process understanding for data-driven Earth system science (Reichstein, 2019)](https://doodle.com/poll/r5fwu4rne37hzkgh?utm_source=poll\u0026utm_medium=link)\n\t- http://www.ccpo.odu.edu/~klinck/Reprints/PDF/reichsteinNature2019.pdf\n\t- ML approaches are increasingly used to extract patterns and insights from the ever-increasing stream of geospatial data, but current approaches may not be optimal when system behaviour is dominated by spatial or temporal context\n\t- Earth system data are exemplary of all four of the ‘four Vs’ of ‘big data’: volume, velocity, variety and veracity\n\t- One key challenge is to extract interpretable information and knowledge from this big data, possibly almost in real time and integrating between disciplines\n\t- Two major tasks in the coming years: (1) extracting knowledge from the data deluge, and (2) deriving models that learn much more from data than traditional data assimilation approaches can, while still respecting our evolving understanding of nature’s laws\n\t- #TALK [Machine-learning-model-data-integration for a better understanding of the Earth System (Markus Reichstein)](https://events.ecmwf.int/event/227/ ) ^ea6338\n- #PAPER [Machine Learning for Clouds and Climate (Beucler 2020)](https://www.semanticscholar.org/paper/Machine-Learning-for-Clouds-and-Climate-Beucler-Ebert%E2%80%90Uphoff/ea0ccde42b1f4517e87ee2e3f77fb6c06671666b)\n- #PAPER [What is next for National Meteorological Services? (Arribas 2020)](https://arxiv.org/abs/2005.01425)\n\t- Head of informatics lab at Met  office, Prof. U. Exeter, Turing fellow\n\t- #TALK [[AI]], a change in science/technology ... or culture? \n\t\t- https://vimeo.com/438176732\n\t\t- https://www.ecmwf.int/sites/default/files/medialibrary/2020-07/14_July_Arribas.pdf\n- #PAPER [A digital twin of Earth for the green transition (Bauer 2021)](https://www.nature.com/articles/s41558-021-00986-y)\n\t- A digital twin of Earth is an information system that exposes users to a digital replication of the state and temporal evolution of the Earth system constrained by available observations and the laws of physics\n\t- Digital twins must focus exactly on how best to realize this convergence of the modelling and observation worlds\n\t- A methodological framework for the twin’s architecture already exists in the form of data assimilation, which numerical weather prediction has developed with success over decades\n- #PAPER [Machine learning for weather and climate are worlds apart (Watson-Parris 2021)](https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0098)\n- #PAPER [Artificial Intelligence Revolutionises Weather Forecast, Climate Monitoring and Decadal Prediction (Dewitte 2021)](https://www.mdpi.com/2072-4292/13/16/3209/htm#B66-remotesensing-13-03209)\n- #PAPER [Towards neural Earth system modelling by integrating artificial intelligence in Earth system science (Irrgang 2021)](https://www.nature.com/articles/s42256-021-00374-3#citeas)\n- #PAPER [Evolution of machine learning in environmental science—A perspective (Hsieh 2022)](https://www.cambridge.org/core/journals/environmental-data-science/article/evolution-of-machine-learning-in-environmental-sciencea-perspective/C21F19C66FA387BC25F43C3C6B95E866)\n- #PAPER [Machine Learning in Weather Prediction and Climate Analyses—Applications and Perspectives (Bochenek 2022)](https://www.mdpi.com/2073-4433/13/2/180/htm)\n\n### AI for pattern recognition and spatio-temporal modelling\n- See [[AI/Computer Vision/Video segmentation and prediction]]\n- Extreme events identification. See [[AI4ES/Extremes events]]\n\n### Climate models\nSee [[AI4ES/ESMs, GCMs]], [[AI4ES/Ensembles, multi-models]] and [[AI4ES/Weather forecasting, nowcasting]], [[AI/Computer Vision/Image-to-image translation]], [[AI/Computer Vision/Video segmentation and prediction]] (next frame prediction) using the temporal dimension\n\n### Filling observational gaps\nSee [[AI4ES/Filling observational gaps]]\n\n### S2S2D\nSee [[AI4ES/S2S]], [[AI4ES/S2D]]\n\n### Parameterizations\nSee [[AI4ES/Parameterizations]]\n\n### Atmospheric composition and air quality\nSee [[AI4ES/AC, AQ]]\n\n### Statistical downscaling\nSee [[AI4ES/Statistical downscaling]]\n\n### Bias correction and adjustment\nSee [[AI4ES/Bias correction, adjustment]]\n\n### HPC and distributed DL/ML\nSee [[AI/DS and DataEng/Distributed DL]] and [[AI4ES/HPC-AI convergence]]\n\n### ML interpretability and causal modelling in ES\nSee [[AI4ES/ML interpretability in ES]] and [[AI4ES/Causal modeling in ES]]\n\n### Digital twins\nSee [[AI4ES/Emulators]]\n- [NVIDIA Construirá la Supercomputadora Earth-2 para Ver Nuestro Futuro](https://la.blogs.nvidia.com/2021/11/16/supercomputadora-earth-2/)\n- [Climate Science Sessions at GTC Highlight How Digital Twins Powered by HPC and AI Can Help Earth](https://blogs.nvidia.com/blog/2022/03/08/climate-science-sessions-gtc/)\n- #PAPER [How to tell the difference between a model and a digital twin (Wright 2020)](https://amses-journal.springeropen.com/articles/10.1186/s40323-020-00147-4)\n\n### Other applications\n#### Agriculture\n- #PAPER [Deep learning in agriculture: A survey (Kamilaris 2018)](http://arxiv.org/abs/1807.11809)\n- #PAPER [Machine Learning in Agriculture: A Review (Liakos 2018)](https://www.mdpi.com/1424-8220/18/8/2674/htm)\n- #PAPER [Crop yield prediction using machine learning: A systematic literature review (van Klompenburg 2020)](https://www.sciencedirect.com/science/article/pii/S0168169920302301?dgcid=rss_sd_all)\n\n#### Smart buildings\n- #PAPER [Leveraging Machine Learning and Big Data for Smart Buildings: A Comprehensive Survey (Qolomany 2019)](https://www.researchgate.net/publication/332170623_Leveraging_Machine_Learning_and_Big_Data_for_Smart_Buildings_A_Comprehensive_Survey )\n- #PAPER [Physics-constrained deep learning of multi-zone building thermal dynamics (Drgona 2021)](https://www.sciencedirect.com/science/article/pii/S0378778821002760#f0010)\n\n#### Compression of Climate model outputs\n- #PAPER [Evaluating lossy data compression on climate simulation data within a large ensemble (Baker 2016)](https://gmd.copernicus.org/articles/9/4381/2016/)\n- #PAPER [A statistical analysis of lossily compressed climate model data (Poppick 2020)](https://www.sciencedirect.com/science/article/pii/S009830042030580X)\n- #PAPER [Compressing atmospheric data into its real information content (Kloewer 2022)](https://www.researchsquare.com/article/rs-590601/v1)\n\t- #CODE https://github.com/esowc/Elefridge.jl\n\n#### Energy optimization and renewable energy\n- #PAPER [Surrogate modelling for sustainable building design – A review (Westermann 2019)](https://www.sciencedirect.com/science/article/abs/pii/S0378778819302877)\n- #PAPER [Building energy optimization using surrogate model and active sampling (Bamdad 2020)](https://www.tandfonline.com/doi/full/10.1080/19401493.2020.1821094)\n- #PAPER [Using a deep temporal convolutional network as a building energy surrogate model that spans multiple climate zones (Westermann 2020)](https://www.sciencedirect.com/science/article/abs/pii/S0306261920310758)\n- #PAPER [Machine Learning for Sustainable Energy Systems (Donti 2021)](https://www.annualreviews.org/doi/abs/10.1146/annurev-environ-020220-061831)\n- #PAPER [Facilitating a smoother transition to renewable energy with AI (Chatterjee 2022)](https://www.cell.com/action/showPdf?pii=S2666-3899%2822%2900125-8)\n- #PAPER [Universal Digital Twin: Integration of national-scale energy systems and climate data (Savage 2022)](https://www.cambridge.org/core/journals/data-centric-engineering/article/universal-digital-twin-integration-of-nationalscale-energy-systems-and-climate-data/EEBFDF0787319FC1A858BD3718F2B7A9)\n\n#### Computational Fluid Dynamics (CFD)\n- #PAPER [Accelerating urban scale simulations leveraging local spatial 3D structure (Iserte 2022)](https://www.sciencedirect.com/science/article/pii/S1877750322001326)\n\n#### Climate change\n- See [[AI4ES/Climate change]]\n\n\n## Infrastructure and data\nSee [[AI4ES/AI4ES data]]\n- [Microsfot Planetary Computer](https://planetarycomputer.microsoft.com/)\n- [European Weather Cloud](https://www.europeanweather.cloud/)\n\t- https://www.ecmwf.int/en/newsletter/165/computing/progress-towards-european-weather-cloud\n- [Climate Engine](http://climateengine.org/)\n- [The OpenWIS Association AISBL](http://openwis.github.io/openwis-documentation/)\n- [Euro Data Cube](https://www.eurodatacube.com/)\n\t- https://hub.eox.at/marketplace/notebooks\n- [Ocean OPS](https://www.ocean-ops.org/board)\n\t- Integrated information, maps and tools to help coordinate and monitor global ocean observation efforts\n- [EUMETSAT data portal](https://www.eumetsat.int/who-we-work/access-copernicus-data)\n\t- [EUMETView](https://view.eumetsat.int/productviewer?v=default)\n\t- [Product navigator](https://navigator.eumetsat.int/start)\n- AI4ES/Pangeo Forge. See [[AI4ES/Pangeo]]\n\n## Code\nSee [[AI4ES/Pangeo]]\n- #CODE [Lexcube - Leipzig explorer of Earth data cubes](https://www.lexcube.org/)\n- #CODE [Ncvue](https://github.com/mcuntz/ncvue) - A minimal GUI for a quick view of netcdf files\n- #CODE [xcast](https://github.com/kjhall01/xcast) - A High-Performance Data Science Toolkit for the Earth Sciences\n- #CODE [climate_indices](https://github.com/monocongo/climate_indices)\n\t- Climate indices for drought monitoring, community reference implementations in Python\n- #CODE [CliMetLab - Python package to easy access to weather and climate data](https://github.com/ecmwf/climetlab)\n\t- https://climetlab.readthedocs.io/en/latest/index.html\n- #CODE [intake - lightweight package for finding, investigating, loading and disseminating data](https://github.com/intake/intake)\n\t- https://medium.com/pangeo/cesm-lens-on-aws-4e2a996397a1\n\t- [example](https://aws-uswest2-binder.pangeo.io/v2/gh/NCAR/cesm-lens-aws/master?urlpath=lab)\n\t- https://www.anaconda.com/blog/intake-discovering-and-exploring-data-in-a-graphical-interface\n- #CODE [intake-esm - An intake plugin for parsing an Earth System Model (ESM) catalog and loading assets into xarray datasets](https://github.com/intake/intake-esm)\n\t- https://intake-esm-test.readthedocs.io\n- #CODE [Aospy - Python package for automated analysis and management of gridded climate data](https://github.com/spencerahill/aospy)\n- #CODE [EarthPy](https://github.com/earthlab/earthpy)\n\t- A package built to support working with spatial data using open source python\n\t- https://earthpy.readthedocs.io/en/latest/\n- #CODE [Psyplot - Python package for interactive data visualization](https://github.com/psyplot/psyplot)\n\t- https://psyplot.readthedocs.io/en/latest/\n\t- https://psyplot.readthedocs.io/projects/psyplot-gui/en/latest/index.html#psyplot-gui\n\t- https://psyplot.readthedocs.io/projects/psy-view/en/latest/index.html#psy-view\n- #CODE [PyRain](https://github.com/FrontierDevelopmentLab/PyRain)\n\t- [[AI4ES/AI4ES data#^rainbench]]\n- #CODE [Verde](https://github.com/fatiando/verde)\n\t- Processing and interpolating spatial data with a twist of machine learning\n\t- https://github.com/fatiando/verde\n\t- https://www.fatiando.org/verde/latest/index.html\n- #CODE [Radiant MLHub API](https://github.com/radiantearth/radiant-mlhub)\n\t- Open Library for Earth Observations Machine Learning\n\t- https://www.radiant.earth/mlhub/\n\t- https://github.com/radiantearth/mlhub-tutorials\n\t- [Radiant MLHub](https://www.mlhub.earth/#datasets)\n- #CODE [GIBS Downloader](https://github.com/spaceml-org/GIBS-Downloader)\n\t- command-line tool which facilitates the downloading of NASA satellite imagery and offers different functionalities in order to prepare the images for training in a machine learning pipeline\n\t- #CODE https://github.com/spaceml-org/Self-Supervised-Learner\n\n\n## Events\n- See [[AI4ES/EO#Events]] and [[AI4ES/Geospatial science#Events]]\n- Conferences, events, workshops and courses related to [[AI/AI]], [[AI4ES/EO]], [[AI4ES/Geospatial science]] and [[AI/Machine Learning]] applied to Earth Sciences.\n- [AI for Good. Discovery - AI and Climate Science](https://aiforgood.itu.int/eventcat/discovery-ai-and-climate-science/)\n- https://spcl.inf.ethz.ch/Bcast/\n\n### 2022\n- [ECMWF-ESA Workshop on Machine Learning for Earth Observation and Prediction](https://events.ecmwf.int/event/304/)\n- [4th NOAA Workshop on Leveraging Artificial Intelligence in Environmental Sciences](https://www.noaa.gov/ai/events/4th-noaa-ai-workshop)\n- [Advancing Technology for a Sustainable Planet](https://hai.stanford.edu/agenda-value-equitable-flourishing-planet)\n- [Weather and Climate Extremes and their Predictability](http://www.cafes2se-itn.eu/weather-and-climate-extremes-and-their-predictability-cafe-final-conference)\n- [SIAM Conference on Imaging Science (IS22)](https://www.siam.org/conferences/cm/conference/is22). March 22 - 25, 2022\n- [21st Conference on Artificial Intelligence for Environmental Science](https://annual.ametsoc.org/index.cfm/2022/program-events/conferences-and-symposia/21st-conference-on-artificial-intelligence-for-environmental-science/)\n- https://www.iarai.ac.at/workshops/workshop-on-complex-data-challenges-in-earth-observation-2022/\n- [Climate informatics 2022](https://ncics.org/news/events/ci2022/agenda/)\n\t- [handbook](https://docs.google.com/document/d/1p1CvnK1TVaLAXOCN0vpnsQxvWIGVmjpt-WXD4g0CH2E/edit?usp=sharing)\n\t- [Q\u0026A](https://app.sli.do/event/uJr35rXEM9ChavrRSAhnig/live/questions)\n\t- https://app.wonder.me/?spaceId=7b51f530-f040-40ce-a108-f06b53c18752\n\n### 2021\n- [Artificial Intelligence for Earth System Predictability](https://www.ai4esp.org/)\n- [Trustworthy Artificial Intelligence for Environmental Science (TAI4ES) Summer School](https://www2.cisl.ucar.edu/tai4es)\n\t- [Recording and slides](https://docs.google.com/document/d/1qKGbbYKswzftWKmQpfMU08LTUmBjYXGO8XY9ueB782k/edit?usp=sharing)\n- [ESA-ECMWF WORKSHOP. Machine Learning for Earth System Observation and Prediction](https://nikal.eventsair.com/esa-ecmwf-workshop-2021/)\n- [Machine learning for numerical weather predictions and climate services – A workshop for Member and Co-operating States](https://ecmwfevents.com/i/b73a4e9a-79ab-4e27-879c-d885e895cdeb/login)\n\t- https://events.ecmwf.int/event/239/timetable/\n- [ICML 2021 - Workshop Tackling Climate Change with Machine Learning](https://www.climatechange.ai/events/icml2021#about-the-workshop)\n- [WCRP Workshop on Extremes in Climate Prediction Ensembles (ExCPEns) (2021 TBD)](https://apcc21.org/act/work.do?lang=en\u0026bbsId=BBSMSTR_000000000024)\n- [2020 -\u003e 2021. ASP Colloquium \"The Science Of Subseasonal To Seasonal (S2S) Predictions\"](https://staff.ucar.edu/for-staff/daily/announcement/2020-asp-colloquium-science-subseasonal-seasonal-s2s-predictions-now)\n- [EGU 2021](https://www.egu21.eu/)\n- [19th Workshop on high performance computing in meteorology](https://events.ecmwf.int/event/169/)\n- [ECMWF - Virtual workshop: Weather and climate in the cloud](https://events.ecmwf.int/event/211/)\n- [Workshop on \"Machine Learning Advances Environmental Science (MAES)\" - organised in conjunction with The 25th International Conference on Pattern Recognition (Milan, Italy, January 10-15, 2021)](https://sites.google.com/view/maes-icpr2020/)\n- [AMS101 (10-14 january 2021)](https://annual.ametsoc.org/index.cfm/2021/)\n\t- https://annual.ametsoc.org/index.cfm/2021/program-events/conferences-and-symposia/34th-conference-on-climate-variability-and-change/\n\t- https://annual.ametsoc.org/index.cfm/2021/program-events/conferences-and-symposia/20th-conference-on-artificial-intelligence-for-environmental-science/\n\t- https://annual.ametsoc.org/index.cfm/2021/program-events/conferences-and-symposia/seventh-symposium-on-high-performance-computing-for-weather-water-and-climate/\n- [PASC21](https://pasc21.pasc-conference.org/)\n- [The ENES Climate Analytics Service (ECAS) online training](https://is.enes.org/events/trainings-and-education/joint-is-enes3-eosc-hub-online-training-event-on-data-analytics-with-enes-climate-analytics-service-ecas)\n\t- https://global.gotomeeting.com/join/415422533\n\t- https://github.com/IS-ENES-Data/Climate-data-analysis-service\n\t- https://github.com/ECAS-Lab/ecas-training\n\t- https://portal.enes.org/data/data-metadata-service/enes-climate-analytics-service-ecas\n\t- [Slides, resources](https://drive.google.com/drive/folders/1Af5GlUV27kZpoIpC6BHMXCHlZmq59232)\n- IS-ENES3/ESiWACE2 New Opportunities for AI/ML in weather/climate modelling\n\n### 2020\n- [Environmental Intelligence Conference](https://www.bigmarker.com/JCEEI/JCEEI-Environmental-Intelligence-Conference-Thursday-17th-December)\n- [ECMWF-ESA Workshop on Machine Learning for Earth System Observation and Prediction (5-8 October 2020)](https://www.ecmwf.int/en/learning/workshops/ecmwf-esa-workshop-machine-learning-earth-system-observation-and-prediction)\n- [Machine Learning for Earth Observation, In Conjunction with the ECML/PKDD 2020 (September)](https://sites.google.com/view/maclean2020/)\n- NCAR Artificial Intelligence for Earth System Science (AI4ESS) Summer School\n\t- https://www2.cisl.ucar.edu/events/summer-school/ai4ess/2020/artificial-intelligence-earth-system-science-ai4ess-summer-school\n\t- [Slides](https://www2.cisl.ucar.edu/events/summer-school/ai4ess/2020/presentation-slides)\n\t- #TALK https://www2.cisl.ucar.edu/events/summer-school/ai4ess/2020/presentation-recordings\n\t- #CODE https://github.com/NCAR/ai4ess-hackathon-2020\n- [10th CCI colocation meeting](https://nikal.eventsair.com/10th-cci-colocation-meeting/esa)\n- [Workshop \"Data Science in Climate and Climate Impact Research\" (August 20 afternoon and 21, 2020)](https://wcr.ethz.ch/news-and-events/events/workshop--data-science-in-climate-and-climate-impact-research-.html)\n- [Climate informatics (September 23-25, 2020)](https://ci2020.web.ox.ac.uk/call-papers)\n- NeurIPS 2020.\n\t- [AI for Earth Sciences](https://ai4earthscience.github.io/neurips-2020-workshop/)\n- ICLR 2020. \n\t- [AI for Earth Sciences](https://ai4earthscience.github.io/iclr-2020-workshop/)\n\t- Tackling CC with ML: \n\t\t- https://www.climatechange.ai/events/iclr2020.html\n\t\t- https://slideslive.com/iclr-2020/workshop-tackling-climate-change-with-ml\n- [6th ENES HPC workshop](https://www.esiwace.eu/events/6th-hpc-workshop/6th-hpc-workshop)\n- [Radiant Earth NASA ML Workshop](https://www.radiant.earth/events/nasa-ml-2020/ ^nasamlws)\n\t- https://www.youtube.com/playlist?list=PL3QzFgBMGnbQRa8uHP0_C_P2Fl5GIBxmn\n- [1st Workshop on Knowledge Guided Machine Learning (KGML)](https://sites.google.com/umn.edu/kgml/workshop)\n\n### 2019\n- [Machine Learning for Weather and Climate Modelling (Oxford UK, 2019)](http://users.ox.ac.uk/~phys0895/mlwc2019/index.html)\n- [The 1st Artificial Intelligence for Copernicus Workshop (Reading UK, 2019)](https://atmosphere.copernicus.eu/1st-artificial-intelligence-copernicus-workshop)\n- [Big Data Summit 2019: AI and HPC Convergence for Science](https://www.nersc.gov/research-and-development/data-analytics/big-data-center/big-data-summit-2019/)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/AI4ES-data":{"title":"AI4ES data","content":"\u003e See [[AI4ES/AI4ES#Infrastructure and data]]\n\n## Climate data\n- See [[Climate change#Data and visualizations]]\n- [Climate Data Store - Copernicus](https://cds.climate.copernicus.eu)\n\t- [CEMS - Emergency Management System](https://emergency.copernicus.eu/)\n- https://github.com/pangeo-data/\n- [NOAA gridded climate data](https://psl.noaa.gov/data/gridded/index.html)\n- [The DL4ES book, DATA](https://github.com/DL4ES/DL4ES)\n- [Climate Reanalyzer](https://climatereanalyzer.org/)\n\t- platform for visualizing climate and weather datasets\n- [AWS climate data](https://registry.opendata.aws/tag/climate/)\n- [SpatioTemporal Asset Catalogs](https://stacspec.org/)\n\t- The STAC specification is a common language to describe geospatial information, so it can more easily be worked with, indexed, and discovered.\n\t- [intake-stac](https://medium.com/pangeo/introducing-intake-stac-2c988d8e1d30)\n- [Cryosphere](https://github.com/awesome-cryosphere/cryosphere-links)\n\n- #PAPER [Enabling Immediate Access to Earth Science Models through Cloud Computing: Application to the GEOS-Chem Model (Zhuang 2019)](https://journals.ametsoc.org/bams/article/100/10/1943/344808/Enabling-Immediate-Access-to-Earth-Science-Models)\n- #PAPER [A Portal Offering Standard Visualization and Analysis on top of an Open Data Cube for Sub-National Regions: The Catalan Data Cube Example (Maso 2019)](https://www.mdpi.com/2306-5729/4/3/96)\n- #PAPER [Seven Principles for Effective Scientific Big-Data Systems (Robinson 2020)](https://arxiv.org/abs/1908.03356)\n- #PAPER [Open weather and climate science in the digital era (de Vos 2020)](https://gc.copernicus.org/articles/3/191/2020/)\n\t- The application of the findable, accessible, interoperable, and reusable (FAIR) principles to many datasets used in weather and climate science remains a challenge\n\t- This may be due to scalability (in the case of high-resolution climate model data, for example), legal barriers such as those encountered in using weather forecast data, or issues with heterogeneity (for example, when trying to make use of citizen data)\n\t- There is a need for new roles and responsibilities in the scientific process. People working at the interface of science and digital technology – e.g., data stewards and research software engineers – should collaborate with domain researchers to ensure the optimal use of open science tools and methods\n- #PAPER [The WGLC global gridded lightning climatology and time series (Kaplan 2021)](https://essd.copernicus.org/articles/13/3219/2021/)\n\n### Benchmark datasets\n- See METER-ML in [[AI4ES/AC, AQ#Methane emission sources]]\n- #PAPER [WeatherBench: A benchmark dataset for data-driven weather forecasting (Rasp 2020)](https://arxiv.org/abs/2002.00469)\n\t- https://github.com/pangeo-data/WeatherBench\n- #PAPER [RainBench - Towards Global Precipitation Forecasting from Satellite Imagery (Schroeder de Witt 2020)](https://arxiv.org/abs/2012.09670\t) \n\t- [RainBench - Enabling Data-driven precipitation forecasting on a global scale (Tong 2020)](https://www.climatechange.ai/papers/neurips2020/38)\n\t- Multi-modal benchmark dataset dedicated to advancing global precipitation forecasting\n\t\t- SimSat. ECMWF model-simulated satellite data. 3-hourly, 0.1º. Lag time of 24h\n\t\t- IMERG. NASA global half-hourly precipitation estimation. The final run product uses satellite data from multiple polar-orbiting and geo-stationary satellites, corrected with reanalysis (MERRA2, ERA5) and rain-gauge data. 0.1º. Lag time of 3-4 months\n\t\t- ERA5. Reanalysis, 1-hourly. Including other atmospheric variables (specific humidity, temperature and geopotential height). 0.25º. Lag time 5 days\n\t- PyRain works with WeatherBench. Based on NumPy memmap arrays\n\t- ConvLSTMs\n\t- Mean latitude-weighted Root-Mean Squared Error (RMSE) as loss and evaluation metric\n- #POSTER [d-IMERG: A spatiotemporal benchmark dataset for precipitation forecasting (Choi 2022)](https://drive.google.com/file/d/1KEFaebOSNLJJKlCUfsBhgS92gYz6Yd9q/view)\n\t- The d-IMERG is a subset of images of IMERG providing HDF5 format over four different regions\n\t- IMERG combines microwave satellite observations from the Global Precipitation Measurement (GPM) satellite constellation to estimate precipitation on a global scale. As microwave measurements can penetrate the precipitating clouds, it provides crucial information on precipitation and clouds. \n- #PAPER [WeatherBench Probability: A benchmark dataset for probabilistic medium-range weather forecasting along with deep learning baseline models (Garg 2022)](https://arxiv.org/pdf/2205.00865)\n\t- WeatherBench Probability extends WeatherBench to probabilistic forecasting by adding a set of established probabilistic verification metrics (continuous ranked probability score, spread-skill ratio and rank histograms) and a state-of-the-art operational baseline using the ECWMF IFS ensemble forecast\n\n#### Extreme events labeled data\nSee [[AI4ES/Extremes events#Databases]]\n- #PAPER [MPING: Crowd-Sourcing Weather Reports for Research (Elmore 2014)](https://journals.ametsoc.org/bams/article/95/9/1335/87658/MPING-Crowd-Sourcing-Weather-Reports-for-Research)\n- #PAPER [ExtremeWeather - A large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events (Racah 2017)](https://arxiv.org/abs/1612.02095)\n\t- https://extremeweatherdataset.github.io/ \n\t- https://papers.nips.cc/paper/6932-extremeweather-a-large-scale-climate-dataset-for-semi-supervised-detection-localization-and-understanding-of-extreme-weather-events\n- #PAPER [A High-Resolution Global Gridded Historical Dataset of Climate Extreme Indices (Mistry, 2019)](https://www.mdpi.com/2306-5729/4/1/41/htm)\n- #PAPER [ClimateNet: an expert-labelled open dataset and Deep Learning architecture for enabling high-precision analyses of extreme weather (Prabhat 2020)](https://gmd.copernicus.org/preprints/gmd-2020-72/) \n\t- https://portal.nersc.gov/project/ClimateNet/ \n\t- #CODE https://github.com/andregraubner/ClimateNet\n\t- ClimateNet – an open, community-sourced human expert-labeled curated dataset – that captures tropical cyclones (TCs) and atmospheric rivers (ARs) in high-resolution climate model output from a simulation of a recent historical period\n\t- The key contribution of this work is that it paves the way for DL-based automated, hi-fidelity and highly precise analytics of climate data using a curated expert-labelled dataset – ClimateNet\n\t- https://cs.lbl.gov/news-media/news/2019/climatenet-aims-to-improve-machine-learning-applications-in-climate-science-on-a-global-scale/ \n\t- https://www.nersc.gov/research-and-development/data-analytics/big-data-center/climatenet/ \n\t- https://eos.org/articles/teaching-machines-to-detect-climate-extremes#.XuxgZhBVnts.twitter\n- #PAPER [Deepti: Deep-Learning-Based Tropical Cyclone Intensity Estimation System (Maskey 2020)](https://ieeexplore.ieee.org/document/9149719)\n\t- http://registry.mlhub.earth/10.34911/rdnt.xs53up/\n\n### Projections\n- [CMIP6](https://pcmdi.llnl.gov/CMIP6/)\n\t- Coupled Model Intercomparison Project Phase 6\n- [CIL Global Downscaled Projections for Climate Impacts Research](https://planetarycomputer.microsoft.com/dataset/group/cil-gdpcir)\n\t- The Global Downscaled Projections for Climate Impacts Research dataset makes this modeling more applicable to understanding the impacts of changes in the climate on humans and society with two key developments: trend-preserving bias correction and downscaling. In this dataset, the Climate Impact Lab provides global, daily minimum and maximum air temperature at the surface (tasmin and tasmax) and daily cumulative surface precipitation (pr) corresponding to the CMIP6 historical, ssp1-2.6, ssp2-4.5, ssp3-7.0, and ssp5-8.5 scenarios for 25 global climate models on a 1/4-degree regular global grid.\n\n### Seasonal forecasts\n- [C3S Seasonal forecasts](https://climate.copernicus.eu/seasonal-forecasts)\n- #PAPER [SEAS5: the new ECMWF seasonal forecast system (Johnson 2019)](https://gmd.copernicus.org/articles/12/1087/2019/) ^seas5\n\t- ECMWF's fifth generation seasonal forecast system\n\t- https://www.ecmwf.int/sites/default/files/medialibrary/2017-10/System5_guide.pdf\n\t- https://www.ecmwf.int/en/newsletter/154/meteorology/ecmwfs-new-long-range-forecasting-system-seas5\n\n### AC forecasts\n- CAMS - Copernicus Atmosphere Monitoring Service: \n\t- https://www.ecmwf.int/en/forecasts/dataset/cams-global-atmospheric-composition-forecasts\n\t- https://atmosphere.copernicus.eu/accessing-atmospheric-composition-forecasts-made-easy\n\t- https://ads.atmosphere.copernicus.eu/cdsapp#!/dataset/cams-global-atmospheric-composition-forecasts?tab=doc\n\t- [CAMSRA global reanalysis at 0.8 deg (80x80 km)](https://www.ecmwf.int/en/forecasts/dataset/cams-global-reanalysis)\n\t- CAMS regional reanalysis at 0.1 deg (10x10 km):\n\t\t- https://confluence.ecmwf.int/display/CKB/CAMS+Regional%3A+European+air+quality+analysis+and+forecast+data+documentation\n\t\t- https://ads.atmosphere.copernicus.eu/cdsapp#!/dataset/cams-europe-air-quality-forecasts?tab=overview\n\t- #PAPER [The CAMS reanalysis of atmospheric composition (Inness 2019)](https://acp.copernicus.org/articles/19/3515/2019/)\n\n### Reanalysis \n- [Advancing Reanalysis](https://reanalyses.org/ \"Home\")\n- #PAPER [Comparison of ERA5-Land and UERRA MESCAN-SURFEX Reanalysis Data with Spatially Interpolated Weather Observations for the Regional Assessment of Reference Evapotranspiration (Pelosi 2020)](https://www.mdpi.com/2073-4441/12/6/1669/htm)\n- #PAPER [The ERA5 global reanalysis (Hersbach 2020)](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.3803) \n\t- [ERA5](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview)\n\t- https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5\n\t- ERA5 is an atmospheric reanalysis, so uses ocean and land surface only as boundary condition\n\t- The data cover the Earth on a 30km grid and resolve the atmosphere using 137 levels from the surface up to a height of 80km\n\t- ERA5 includes information about uncertainties for all variables at reduced spatial and temporal resolutions\n\t- ERA5 combines vast amounts of historical observations into global estimates using advanced modelling and data assimilation systems\n- [ERA5 land](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview)\n\t- ERA5-Land is a reanalysis dataset providing a consistent view of the evolution of land variables over several decades at an enhanced resolution (0.1 degrees) compared to ERA5\n- [gridMET](https://www.climatologylab.org/gridmet.html)\n\t- gridMET is a dataset of daily high-spatial resolution (~4-km, 1/24th degree) surface meteorological data covering the contiguous US from 1979-yesterday\n- [UERRA](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-uerra-europe-single-levels?tab=overview) regional reanalysis for Europe\n\t- http://www.uerra.eu/component/dpattachments/?task=attachment.download\u0026id=385\n\t- www.uerra.eu/component/dpattachments/?task=attachment.download\u0026id=399\n- [JRA-55](https://climatedataguide.ucar.edu/climate-data/jra-55)\n\t- Spanning 1958-present, JRA-55 is the longest third-generation reanalysis that uses the full observing system\n\n### Precipitation\n- [Precipitation datasets comparison](https://climatedataguide.ucar.edu/climate-data/precipitation-data-sets-overview-comparison-table)\n- See UERRA, ERA5 and ERA5-land reanalyses \n- #PAPER [Evaluation of Gridded Precipitation Data Products for Hydrological Applications in Complex Topography (Gampe 2017)](https://www.mdpi.com/2306-5338/4/4/53)\n- #PAPER [PTHRES. High-Resolution Temperature Datasets in Portugal from a Geostatistical Approach: Variability and Extremes (Fonseca, 2017)](https://journals.ametsoc.org/jamc/article/57/3/627/68273/High-Resolution-Temperature-Datasets-in-Portugal)\n- #PAPER [An Ensemble Version of the E-OBS Temperature and Precipitation Data Sets (Cornes 2018)](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2017JD028200)\n\t- [E-OBS ](https://climatedataguide.ucar.edu/climate-data/e-obs-high-resolution-gridded-meanmaxmin-temperature-precipitation-and-sea-level )\n\t- daily data with extent: 25N-71.5N x 25W-45E  \n\t- [Southeast Asia version of E-OBS](http://sacad.database.bmkg.go.id/)\n- #PAPER [The Global Precipitation Climatology Project (GPCP) Monthly Analysis (New Version 2.3) and a Review of 2017 Global Precipitation (Adler 2018)](https://www.mdpi.com/2073-4433/9/4/138)\n\t- https://climatedataguide.ucar.edu/climate-data/gpcp-monthly-global-precipitation-climatology-project\n- #PAPER [Iberia01: a new gridded dataset of daily precipitation and temperatures over Iberia (Herrera 2019)](https://essd.copernicus.org/articles/11/1947/2019/)\n\t- showed that Iberia01 produces more realistic precipitation patterns than E-OBS for the mean and extreme indices considered, although both are comparable for temperatures\n- #PAPER [FROGS: a daily 1°  ×  1° gridded precipitation database of rain gauge, satellite and reanalysis products (Roca 2019)](https://essd.copernicus.org/articles/11/1017/2019/  )\n\t- Global precipitation\n- #PAPER [IMERG V06: Changes to the Morphing Algorithm (Tan 2019)](https://journals.ametsoc.org/view/journals/atot/36/12/jtech-d-19-0114.1.xml)\n\t- https://disc.gsfc.nasa.gov/datasets/GPM_3IMERGHH_06/summary\n\t- https://gpm.nasa.gov/data/imerg\n\t- [Global precipitation measurement](https://gpm.nasa.gov/)\n\t- Global precipitation\n- #PAPER [MSWEP V2 Global 3-Hourly 0.1° Precipitation: Methodology and Quantitative Assessment (Beck 2019)](https://journals.ametsoc.org/view/journals/bams/100/3/bams-d-17-0138.1.xml)\n\t- Old paper: [MSWEP: 3-hourly 0.25◦global gridded precipitation (1979–2015)by merging gauge, satellite, and reanalysis data (Beck 2017)](https://hess.copernicus.org/preprints/hess-2017-508/hess-2017-508.pdf)\n\t- http://www.gloh2o.org/mswep/\n\t- Multi-Source Weighted-Ensemble Precipitation\n\t- Fully global (including ocean areas) historical precipitation dataset (1979–2019) with a 3‑hourly temporal and 0.1° spatial resolution\n\t- MSWEP takes advantage of the complementary strengths of gauge‑, satellite‑, and reanalysis-based data to provide reliable precipitation estimates over the entire globe\n- #PAPER [Rainfall Estimates on a Gridded Network (REGEN) – a global land-based gridded dataset of daily precipitation from 1950 to 2016 (Contractor 2020)](https://www.hydrol-earth-syst-sci.net/24/919/2020/)\n\t- Global precipitation\n- #PAPER [Comprehensive Comparisons of State-of-the-Art Gridded Precipitation Estimates for Hydrological Applications over Southern China (GAO 2020)](https://www.mdpi.com/2072-4292/12/23/3997?type=check_update\u0026version=3)\n\n### Temperature\n- See UERRA and ERA5-land reanalyses\n- [HadCRUT5 - gridded dataset of global historical surface temperature anomalies relative to a 1961-1990 reference period](https://www.metoffice.gov.uk/hadobs/hadcrut5/)\n\n### Soil moisture\n- See ERA5-Land reanalysis\n- #PAPER [GLEAM v3: satellite-based land evaporation and root-zone soil moisture (Marterns 2017)](https://gmd.copernicus.org/articles/10/1903/2017/)\n\t- [GLEAM - Global Land Evaporation Amsterdam Model](https://www.gleam.eu/)\n\t- different components of land evaporation (often referred to as '_evapotranspiration_’): transpiration, bare-soil evaporation, interception loss, open-water evaporation and sublimation\n\t- soon to come HR evaporation data\n\t- products: Soil Evaporation, Snow Sublimation, Transpiration, Open-water Evaporation, Evaporative Stress, Root-zone Soil Moisture, Surface Soil Moisture\n\n### Wind\n- #PAPER [What global reanalysis best represents near-surface winds? (Ramon 2019)](https://rmets.onlinelibrary.wiley.com/doi/epdf/10.1002/qj.3616)\n\t- In an effort to identify the products that best represent the wind speed features at turbine hub heights, five state-of-the-art global reanalyses have been analysed: ERA5,ERA-Interim, the Japanese 55-year Reanalysis (JRA55), the Modern Era Retrospective Analysis for Research and Applications-2 (MERRA2), and the National Centersfor Environmental Prediction (NCEP)/National Center for Atmospheric Research(NCAR) Reanalysis 1 (R1)\n\t- Comparison with in situ observations shows that the ERA5 surface winds offer the best agreement, correlating and reproducing the observed variability better than a multi-reanalysis mean in 35.1% of the tall tower sites on a daily time-scale.\n- #PAPER [A collection and categorization of open-source wind and wind power datasets (Effenberger 2022)](https://onlinelibrary.wiley.com/doi/10.1002/we.2766)\n\n### Fires\n- [MODIS Thermal Anomalies/Fire](https://modis.gsfc.nasa.gov/data/dataprod/mod14.php)\n- FireCCI51 and FireCCILT11, ESA Climate Change Initiative\n\t- https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-3/New_long-term_dataset_to_analyse_global_fire_trends\n\t- The current focus of the team, led by Emilio Chuvieco from the University of Alcalá in Spain, is to merge data from Copernicus Sentinel-3’s Ocean and Land Colour Instrument (OLCI) and its Sea and Land Surface Temperature Radiometer (SLSTR) into their existing global burned area product, FireCCI51 (2001–19)\n- #PAPER [1980–2018 global fire danger re-analysis dataset for the Canadian Fire Weather Indices (Vitolo 2019)](https://www.nature.com/articles/sdata201932)\n\t- 38 years of global reanalysis of wildfire danger\n\t- The scientific community is actively studying (through in situ observation and remote sensing) fire behavior to better identify the atmospheric predictors that determine a sustained fire activity once an ignition has occurred\n\t- It is intuitive that low humidity combined to high temperature tends to dry dead and live fuels which ignite easier than moist fuel\n\t- Canadian Fire Weather Index (FWI) - is one of the most widely used model to estimate fire danger worldwide\n\t- The FWI operates by predicting the responses of fuel moisture to atmospheric forcings at different soil depths and by combining these to derive fire behavior indices in terms of ease of spread and intensity\n\t- The FWI danger rating system was designed to exploit the information provided by in situ observations and it only depends on weather variables\n\t- The fire danger reanalysis dataset is made of seven gridded fields (or indices) calculated from the Canadian Fire Weather Index model using weather forcings from the ECMWF ERA-Interim reanalysis dataset\n\t- #CODE https://github.com/esowc/wildfire-forecasting\n- [Global Fire Emission Database (GFED4)](http://www.globalfiredata.org)\n\t- Global Fire Emissions Database version 4 with small fires (GFEDv4s)\n- [The CAMS Global Fire Assimilation System (GFAS) ](https://atmosphere.copernicus.eu/global-fire-emissions)\n\t- GFAS assimilates fire radiative power (FRP) observations from satellite-based sensors to produce daily estimates of wildfire and biomass burning emissions. It also provides information about injection heights derived from fire observations and meteorological information from the operational weather forecasts of ECMWF\n\t- The GFAS data output includes spatially gridded Fire Radiative Power (FRP), dry matter burnt and biomass burning emissions for a large set of chemical, greenhouse gas and aerosol species\n\t- Data are available globally on a regular latitude-longitude grid with horizontal resolution of 0.1 degrees from 2003 to present\n\n### Biomass\n- [CCI biomass](https://climate.esa.int/en/projects/biomass/)\n\t- [Data access requirements](https://climate.esa.int/sites/default/files/Biomass%20D1.3%20Data%20Access%20Requirement%20Document%20V1.0.pdf)\n\n\n## EO and Satellite data\n- [Awesome Satellite Imagery Datasets](https://github.com/chrieke/awesome-satellite-imagery-datasets)\n- [Hyperlabelme](https://ieeexplore.ieee.org/document/8113131/authors#authors )\n- [HyRank (hyperspectral dataset)](http://www2.isprs.org/commissions/comm3/wg4/HyRANK.html )\n- [Euro Data Cube](https://eurodatacube.com/)\n- [AIREO – AI ready EO training datasets](https://eo4society.esa.int/projects/aireo/)\n- [Kelvins - ESA's Advanced Concepts Competition Website. Data challenges](https://kelvins.esa.int/  )\n- [AVIRIS-NG aerial hyperspectral remote sensing data](https://avirisng.jpl.nasa.gov/dataportal/)\n\t- The AVRIS-NG data portal includes an unparalleled publicly available dataset of hyperspectral remote sensing aerial surveys on multiple continents, including detected large point-source methane emissions (for many campaigns, plus some point-source CO2 emissions)\n\n### Benchmark datasets\n- #PAPER [EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification (Helber 2019)](https://arxiv.org/abs/1709.00029)\n\t- https://github.com/phelber/eurosat\n- #PAPER [Object Detection in Optical Remote Sensing Images: A Survey and A New Benchmark (Li 2019)](https://arxiv.org/abs/1909.00133) \n- #PAPER [DOTA: A Large-scale Dataset for Object Detection in Aerial Images (Xia 2019)](https://arxiv.org/abs/1711.10398)\n- #PAPER [EarthNet2021: A novel large-scale dataset and challenge for forecasting localized climate impacts (Requena-Mesa 2020)](https://arxiv.org/abs/2012.06246v1)\n\t- https://www.earthnet.tech/docs/ds-download/\n- #PAPER [FAIR1M: A Benchmark Dataset for Fine-grained Object Recognition in High-Resolution Remote Sensing Imagery (Sun 2021)](https://arxiv.org/abs/2103.05569) \n- #PAPER [SpaceML: Distributed Open-source Research with Citizen Scientists for the Advancement of Space Technology for NASA (Koul 2021)](https://arxiv.org/abs/2012.10610)\n- #PAPER [BigEarthNet-MM: A Large Scale Multi-Modal Multi-Label Benchmark Archive for Remote Sensing Image Classification and Retrieval (Sumbul 2021)](https://arxiv.org/pdf/2105.07921)\n\t- [BigEarthNet - A New Large-Scale Sentinel-2 Benchmark Archive](http://bigearth.net/)\n\t- [BigEarthNet Benchmark Archive Now Available on Radiant MLHub](https://medium.com/radiant-earth-insights/bigearthnet-benchmark-archive-now-available-on-radiant-mlhub-the-open-repository-for-geospatial-d6c5dbe898c4), the Open Repository for Geospatial Training Data\n- #PAPER [Open High-Resolution Satellite Imagery: The WorldStrat Dataset -- With Application to Super-Resolution (Cornebise 2022)](https://arxiv.org/pdf/2207.06418v1)\n\t- https://github.com/worldstrat/worldstrat\n\t- Nearly 10,000 km² of free high-resolution satellite imagery of unique locations which ensure stratified representation of all types of land-use across the world: from agriculture to ice caps, from forests to multiple urbanization densities\n\t- Each high-resolution image (1.5 m/pixel) comes with multiple temporally-matched low-resolution images from the freely accessible lower-resolution Sentinel-2 satellites (10 m/pixel)\n\t- See [[AI/Computer Vision/Super-resolution]]\n- #PAPER [Current Trends in Deep Learning for Earth Observation: An Open-source Benchmark Arena for Image Classification (Dimitrovski 2022)](https://arxiv.org/pdf/2207.07189)\n\t- AiTLAS: Benchmark Arena -- an open-source benchmark framework for evaluating state-of-the-art deep learning approaches for image classification in Earth Observation\n\t- #CODE https://github.com/biasvariancelabs/aitlas-arena\n\n### LULC\n- [Dynamic World](https://github.com/google/dynamicworld)\n\t- #PAPER [Dynamic World, Near real-time global 10 m land use land cover mapping (Brown 2022)](https://www.nature.com/articles/s41597-022-01307-4)\n\t- Dynamic World V1 is built by training a deep learning model on densely annotated training labels for 9 land cover classes, and is generated using Google Earth Engine and AI Platform\n\t- Dynamic World is producing land cover probabilities per pixel for the Sentinel-2 1C: Multispectral TOA mission\n- [Impact Observatory, Microsoft and ESRI - Land use/cover (LULC)](https://learn-about.impactobservatory.com/maps)\n\t- Microsoft AI for Earth, Microsoft Planetary Computer (Sentinel-2 data)\n\t- https://caitlin-kontgis.medium.com/mapping-the-world-in-unprecedented-detail-7c0513205b90\n\t- https://www.arcgis.com/home/item.html?id=d3da5dd386d140cf93fc9ecbf8da5e31\n\n\n### Sentinel 5p (TROPOMI)\n- https://docs.sentinel-hub.com/api/latest/data/sentinel-5p-l2/\n- [NASA ARSET: Introducing TROPOMI - High Resolution NO2 Observations from Space, Part 2/3](https://www.youtube.com/watch?v=-yOInEUJTYM)\n\n### SAR\n- POLinSAR - SAR polarimetry and polarimetric interferometry\n\t- https://www.esa.int/Applications/Observing_the_Earth/POLinSAR_Advances_in_radar_remote_sensing\n\n## Other datasets\n- [Population gridded data](https://www.pbl.nl/en/image/links/hyde)\n- [Word pop](https://www.worldpop.org/)\n- [GHS-pop](https://ghsl.jrc.ec.europa.eu/download.php?ds=pop)\n- [Open Government Building Data](https://ual.sg/project/ogbd/)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Bias-correction-adjustment":{"title":"Bias correction, adjustment","content":"\u003e See: \n\u003e - [[AI4ES/Statistical downscaling]]\n\u003e - [[AI4ES/S2S]], [[AI4ES/S2D]]\n\u003e - [[AI4ES/Ensembles, multi-models]]\n\n## Resources\n- [Seasonal forecast calibration](https://www.metoffice.gov.uk/research/climate/seasonal-to-decadal/gpc-outlooks/user-guide/calibration)\n\n\n## Courses\n- #COURSE [Statistical post-processing of ensemble weather forecasts: Current developments and future directions (Tilmann Gneiting)](https://confluence.ecmwf.int/download/attachments/45754015/TK_StatisticalPostrocessing_2015.mp4?version=1\u0026modificationDate=1424535945271\u0026api=v2)\n\n\n## References\n- #PAPER [#BSC Use of bias correction techniques to improve seasonal forecasts for reservoirs - A case-study in northwestern Mediterranean (Marcos 2018)](https://pubmed.ncbi.nlm.nih.gov/28803203/)\n- #PAPER [Neural networks for post-processing ensemble weather forecasts (Rasp 2018)](https://journals.ametsoc.org/view/journals/mwre/146/11/mwr-d-18-0187.1.xml)\n\t- Extend to gridded data with CNNs?\n- #PAPER [Bias adjustment and ensemble recalibration methods for seasonal forecasting: a comprehensive intercomparison using the C3S dataset (Manzanas 2019)](https://link.springer.com/article/10.1007%2Fs00382-019-04640-4 )\n\t- https://core.ac.uk/download/pdf/326021617.pdf\n- #PAPER [Machine learning for observation bias correction with application to dust storm data assimilation (Jin 2019)](https://acp.copernicus.org/articles/19/10009/2019/)\n- #PAPER [Calibration of ECMWF seasonal SEAS5 models monthly temperature re-forecasts over the southeast Asia region (Yun 2020)](https://www.researchgate.net/publication/338335009)\n- #PAPER [Comparative Assessment of Various Machine Learning‐Based Bias Correction Methods for Numerical Weather Prediction Model Forecasts of Extreme Air Temperatures in Urban Areas (Cho 2020)](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2019EA000740)\n- #TALK [Downscaling and bias correction of seasonal forecasts to support climate services for the Alpine regions (Crespi 2020)](https://meetingorganizer.copernicus.org/EGU2020/EGU2020-10109.html)\n- #PAPER [Deep learning for Post-Processing Ensemble Weather Forecasts (Gronquist, 2020)](https://arxiv.org/abs/2005.08748 ) ^gronquist20\n   - https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2020.0092?af=R\n   - #CODE https://github.com/spcl/deep-weather\n   - #TALK https://www.youtube.com/watch?v=5REg7_UtJcs\n   - Bias correction with [[AI/Deep learning/DL]] \n   - Simulations are started from GT (from data assimilation)\n   - Then get statistics of the ensemble. This is very costly. Can we learn mu and sigma from smaller ensembles?\n   - ENS10 and ERA5, selected variables\n   - Bias correction input (ERA5) model\n   - Uncertainty quantification (ENS10)\n   - ResNet, 3D UNET with added locally-connected network (LCN) as the last layer\n   - SSIM as training loss\n   - CRPS loss function\n   - Extreme events too\n- #PAPER [A new bias-correction method for precipitation over complex terrain suitable for different climate states: a case study using WRF (Velasquez 2020)](https://gmd.copernicus.org/articles/13/5007/2020/)\n- #PAPER [Deep learning for bias correction of MJO prediction (Kim 2021)](https://www.nature.com/articles/s41467-021-23406-3)\n\t- #CODE https://github.com/HyemiKim77/DLcorrection_MJO\n\n\n### MOS\n- [Model Output Statistics](https://en.wikipedia.org/wiki/Model_output_statistics)\n\t- MOS is a multiple linear regression technique in which predictands, often near-surface quantities, such as 2-meter (AGL) air temperature, horizontal visibility, and wind direction, speed and gusts, are related statistically to one or more predictors\n\n- #PAPER [Deep Learning for Climate Model Output Statistics (Steininger 2020)](https://www.climatechange.ai/papers/neurips2020/7)\n\t- https://meetingorganizer.copernicus.org/EGU21/EGU21-2175.html\n- #PAPER [[Ensembles, multi-models#^gronquist20]]\n- #PAPER [A Model Output Deep Learning Method for Grid Temperature Forecasts in Tianjin Area (Chen 2020)](https://www.mdpi.com/2076-3417/10/17/5808/htm)\n\t- This paper proposes a model output deep learning (MODL) method for post-processing\n\t- Samples are multi-variable and spatio-temporal (53 time steps as leadtime)\n\t- The core of the MODL is 3D Fully Convolutional Neural Networks (3D FCNN)\n\t- The 3D FCNN or MODL-PLAIN is composed of three convolutional layers. Compared with a UNET-style CNN architecture\n\t- Each CNN block has CON3d -\u003e activation -\u003e BatchNorm\n\t- Two DL models, one with 3 CNN layers, one with a UNET-like structure\n\t- MSE loss function\n\t- MODL method is better than the univariate linear MOS method, the MOML method based random forest, and linear regression with a running period, and it has the ability to improve grid temperature forecast results in Tianjin area\n\t- Weather (few days) forecasting\n- #PAPER [Adjusting spatial dependence of climate model outputs with Cycle-Consistent Adversarial Networks (Francois 2021)](https://www.researchsquare.com/article/rs-299929/v1)\n\t- #CODE https://github.com/bastien-francois/MBC_CycleGAN\n\t- multivariate bias correction (MBC) method\n\t- adapted  a computer vision technique used for Image-to-Image translation tasks (CycleGAN) for the adjustment of spatial dependence structures of climate model projections\n\t- the method is applied to adjust maps of temperature and precipitation from climate simulations through two cross-validation approaches\n\t- The first one is designed to assess two different post-processing schemes (Perfect Prognosis and Model Output Statistics)\n\t- The second one assesses the influence of nonstationary properties of climate simulations on the performance of MBC-CycleGAN to adjust spatial dependences\n\t- For the performance assessment of the CycleGAN model during training, the energy distance is used\n\t- This metric, already used in the bias correction literature permits to measure the statistical discrepancy between two multivariate distributions that are potentially in high dimension\n- #PAPER [On the use of convolutional Gaussian processes to improve the seasonal forecasting of precipitation and temperature (Wang 2021)](https://www.sciencedirect.com/science/article/abs/pii/S0022169420313238?dgcid=rss_sd_all)\n- #PAPER [Correcting Coarse-Grid Weather and Climate Models by Machine Learning From Global Storm-Resolving Simulations (Bretherton 2022)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021MS002794)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Causal-modeling-in-ES":{"title":"Causal modeling in ES","content":"\u003e See: \n\u003e - [[Causality]]\n\t- [[AI4ES/Extremes events#Causality studies]]\n\n## Resources\n- [Inferring causality in time series data](https://towardsdatascience.com/inferring-causality-in-time-series-data-b8b75fe52c46#586a)\n- [CauseME - A platform to benchmark causal discovery methods](https://causeme.uv.es/)\n\n## Talks\n- #TALK [Causal Networks as a framework for climate science to improve process understanding (Marlene Kretschmer)](https://vimeo.com/472722333)\n\t- https://www.ecmwf.int/sites/default/files/medialibrary/2020-10/27_October.pdf\n- #TALK [Machine Learning in Climate Science: Finding causal connections and improving seasonal forecasts (Dim Coumou)](https://vimeo.com/467030105)\n\n## Code\n- #CODE [Tigramite - Tigramite is a time series analysis python module for causal discovery](https://github.com/jakobrunge/tigramite)\n\t- https://jakobrunge.github.io/tigramite/\n\t- PCMCI algorithm. Causal discovery\n- #CODE [RGCPD - Investigate teleconnections, test for causality, and make forecasts](https://github.com/semvijverberg/RGCPD)\n\t- RG-CPD is a framework to process 3-dimensional climate data, such that relationships based on correlation can be tested for conditional independence, i.e. causality\n\t- https://zenodo.org/record/1486739#.X8Y0emT0mx0\n\n## References\n- #PAPER [Using Causal Effect Networks to Analyze Different Arctic Drivers of Midlatitude Winter Circulation (Kretschmer 2016)](https://journals.ametsoc.org/jcli/article/29/11/4069/35432/Using-Causal-Effect-Networks-to-Analyze-Different)\n- #PAPER [Unsupervised Discovery of El Nino Using Causal Feature Learning on Microlevel Climate Data (Chalupka 2016)](https://arxiv.org/abs/1605.09370)\n- #PAPER [Early prediction of weak stratospheric polar vortex states using causal precursors (Kretschmer 2017)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017GL074696)\n- #PAPER [Detecting causal associations in large nonlinear time series datasets (Runge 2019)](https://arxiv.org/abs/1702.07007)\n\t- https://advances.sciencemag.org/content/5/11/eaau4996\n\t- PCMCI algorithm\n- #PAPER [Inferring causation from time series in Earth system sciences (Runge 2019)](https://www.nature.com/articles/s41467-019-10105-3)\n- #PAPER [A Novel Data-driven Approach for Tropical Cyclone Tracks Prediction Based on Granger Causality and GRU (Dong 2019)](https://www.semanticscholar.org/paper/A-Novel-Data-driven-Approach-for-Tropical-Cyclone-Dong-Lian/a391af3f58933f373ba2f812305fa0fd9521f656) ^d43897\n- #PAPER [Robust predictors for seasonal Atlantic hurricane activity (Pfleiderer 2020)](https://wcd.copernicus.org/articles/1/313/2020/wcd-1-313-2020.html) ^c4333d\n\t- #TALK https://vimeo.com/472722333\n- #PAPER [Estimating causal networks in biosphere–atmosphere interaction with the PCMCI approach (Krich 2020)](https://www.biogeosciences.net/17/1033/2020/)\n- #PAPER [Causal networks for climate model evaluation and constrained projections (Nowack 2020)](https://www.nature.com/articles/s41467-020-15195-y)\n\t- apply causal discovery algorithms to sea level pressure data from a large set of climate model simulations and, as a proxy for observations, meteorological reanalyses\n\t- the resulting causal networks (fingerprints) offer an objective pathway for process-oriented model evaluation\n- #PAPER [Reconstructing regime-dependent causal relationships from observational time series (Saggioro 2020)](https://arxiv.org/abs/2007.00267)\n- #PAPER [Dominant patterns of interaction between the tropics and mid-latitudes in boreal summer: causal relationships and the role of timescales (Di Capua 2020)](https://wcd.copernicus.org/articles/1/519/2020/)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Climate-change":{"title":"Climate change","content":"\u003e See \"Extreme events and Climate Change\" in [[AI4ES/Extremes events]]\n\n## Resources\n- [The IPCC’s sixth assessment report on climate science (summary)](https://www.carbonbrief.org/in-depth-qa-the-ipccs-sixth-assessment-report-on-climate-science)\n- [Climate change: science and solutions](https://royalsociety.org/topics-policy/projects/climate-change-science-solutions/)\n- [Carbonbrief](https://www.carbonbrief.org/) - website covering the latest developments in climate science, climate policy and energy policy\n- [Using AI and machine learning to kickstart climate change fightback](https://www.itpro.co.uk/technology/artificial-intelligence-ai/368494/using-ai-and-machine-learning-to-kickstart-climate)\n- [Digital technology and the planet](https://royalsociety.org/topics-policy/projects/digital-technology-and-the-planet/) - How can digital technologies be harnessed to tackle climate change? \n- [Artificial Intelligence and Climate Change Opportunities, considerations, and policy levers to align AI with climate change goals](https://eu.boell.org/en/2020/12/03/artificial-intelligence-and-climate-change)\n- [To what extent can artificial intelligence help tackle climate change today?](https://therising.co/2020/05/08/artificial-intelligence-tackle-climate-change/) \n- [Most important numbers to know about climate change](https://forum.climatechange.ai/t/most-important-numbers-to-know-about-climate-change/507)\n- [Global Carbon Budget](https://www.globalcarbonproject.org/carbonbudget/)\n- [Global Carbon Atlas](http://globalcarbonatlas.org/en/content/welcome-carbon-atlas)\n- [Some new climate models are projecting extreme warming. Are they correct?](https://www.yaleclimateconnections.org/2020/07/some-new-climate-models-are-projecting-extreme-warming-are-they-correct/)\n- [Climate change indices](http://etccdi.pacificclimate.org/list_27_indices.shtml)\n- [Resource Watch provides trusted and timely data for a sustainable future](https://resourcewatch.org/)\n- [Centre for AI \u0026 climate](https://www.c-ai-c.org/)\n\t- The Centre for AI \u0026 Climate is the leading organisation focused on advancing the application of data science and AI to accelerate action on climate change.\n- [Very Few Young Techies Are Trying to Do the Big Hard Things](https://marcwinkelmann.de/coders_clive_thompson_interview/)\n- [AI Is Not a Silver Bullet Against Climate Change - interview Lynn Kaack](https://marcwinkelmann.de/interview_lynn_kaack_climate-change-ai/)\n- [Is AI and Deep Learning a Climate Change Threat?](https://www.ibm.com/uk-en/it-infrastructure/learn/ai-and-deep-learning-climate-change-threat) \n- [Extreme weather takes climate change models ‘off the scale’](https://www.fr24news.com/a/2021/07/extreme-weather-takes-climate-change-models-off-the-scale.html)\n- [Climate Central](https://www.climatecentral.org/library)\n\t- Researching and reporting the science and impacts of climate change\n\n### ESA CCI\n- [ESA climate office](https://climate.esa.int/en/)\n- [Climate change initiative (CCI)](http://cci.esa.int/)\n\t- [CCI toolbox](https://cci-tools.github.io/#interfaces)\n\t\t- Command line\n\t\t- [GUI](https://github.com/CCI-Tools/cate-desktop)\n\t\t- [Python API](https://github.com/CCI-Tools/cate)\n\t- [CCI research fellowship](http://cci.esa.int/content/climate-change-initiative-launches-new-research-fellowship)\n\t- What is an ECV? http://cci.esa.int/content/what-ecv\n- [Copernicus climate change service (C3S)](https://climate.copernicus.eu/)\n\n### ClimateChange AI\n- https://www.climatechange.ai/\n- [Climate Change AI Wiki](https://wiki.climatechange.ai/wiki/Welcome_to_the_Climate_Change_AI_Wiki)\n- [Climate change 101](https://docs.google.com/presentation/d/1KxVq-FlngspK687AvdEYJ2IXZQaK0tbQPPsek6rC7jA/edit#slide=id.p)\n- [CCAI webinars](https://www.climatechange.ai/webinars)\n- #TALK https://www.youtube.com/channel/UCyjDr_aoMlzhSvCTdT7eZ9g/videos\n- #TALK [Machine Learning 101 for CC](https://www.youtube.com/watch?v=mc9QG2R-rf4) \n\n\n## Code\n- #CODE [Code Carbon](https://codecarbon.io/)\n\t- Python package that integrates into your code and estimates the amount of CO2 used by the computing resources used to execute the code\n\t- #PAPER [Energy Usage Reports: Environmental awareness as part of algorithmic accountability (Lottick 2020)](https://arxiv.org/abs/1911.08354)\n\n\n## Data and visualizations\n- [ En-ROADS Climate Solutions Simulator](https://en-roads.climateinteractive.org/scenario.html?v=22.3.0)\n\t- fast, powerful climate simulation tool for understanding how we can achieve our climate goals through changes in energy, land use, consumption, agriculture, and other policies. The simulator focuses on how changes in global GDP, energy efficiency, technological innovation, and carbon price influence carbon emissions, global temperature, and other factors\n- [Climate impact explorer](http://climate-impact-explorer.climateanalytics.org/)\n- [CO₂ and Greenhouse Gas Emissions](https://ourworldindata.org/co2-and-other-greenhouse-gas-emissions)\n- [Datasets APIs and open source projects related to Climate Change](https://github.com/KKulma/climate-change-data)\n- [IPCC Working Group I (WGI) - Sixth Assessment Report - Interactive Atlas](https://interactive-atlas.ipcc.ch/)\n- [Attributing extreme weather to climate change (VIZ)](https://www.carbonbrief.org/mapped-how-climate-change-affects-extreme-weather-around-the-world)\n\n\n## Courses\n- #COURSE [Climate Change: The Science and Global Impact (EDX)](https://www.edx.org/course/climate-change-the-science-and-global-impact)\n\n\n## Talks\n- #TALK [Artificial Intelligence in ESA Contribution to the United Nations Framework Convention on Climate Change (UNFCCC) : An Overview](https://events.ecmwf.int/event/172/contributions/1719/)\n- #TALK [Digital twins for understanding and adapting to climate change (Bjorn Stevens)](https://www.nvidia.com/gtc/session-catalog/?search=S41950\u0026search=S41950%2C+S41950\u0026tab.scheduledorondemand=1583520458947001NJiE\u0026ncid=em-even-878227-general\u0026mkt_tok=MTU2LU9GTi03NDIAAAGDVJIckDR-eNvplu5zP5U6wChea9lbDNdxzK9j2oiXSgURVx489ABLbGUVkRjjtgkPw4pVTd83UwS6fTUpy1blJ4ANwPJjSh1h_k3gs8n8v51ArowVTw#/session/1638815834579001GVCZ)\n\n\n## References\n- #PAPER [The ESA Climate Change Initiative: Satellite Data Records for Essential Climate Variables (Hollmann 2013)](https://www.researchgate.net/publication/258226469_The_ESA_Climate_Change_Initiative_Satellite_Data_Records_for_Essential_Climate_Variables)\n- #PAPER [High chance that current atmospheric greenhouse concentrations commit to warmings greater than 1.5 °C over land (Huntingford 2016)](https://www.nature.com/articles/srep30294)\n- #PAPER [Tackling Climate Change with Machine Learning (Rolnick 2019)](https://arxiv.org/abs/1906.05433)\n\t- https://blogs.royalsociety.org/in-verba/2019/07/23/tackling-climate-change-with-ai/\n- #PAPER [Developing an Open Data Portal for the ESA Climate Change Initiative (Kershaw 2020)](https://www.researchgate.net/publication/340462964_Developing_an_Open_Data_Portal_for_the_ESA_Climate_Change_Initiative)\n- #PAPER [Global warming makes weather in boreal summer more persistent (Coumou 2020)](https://wcd.copernicus.org/preprints/wcd-2020-40/)\n- #PAPER [The Climate Response to Emissions Reductions Due to COVID‐19: Initial Results From CovidMIP (Jones 2021)](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020GL091883)\n- #PAPER [Artificial Intelligence and Climate Change (Kaack, CCAI people 2021)](https://eu.boell.org/en/2020/12/03/artificial-intelligence-and-climate-change)\n- #PAPER [Increasing probability of record-shattering climate extremes (Fischer 2021)](https://www.nature.com/articles/s41558-021-01092-9)\n\t- https://www.theguardian.com/environment/2021/jul/26/record-shattering-heat-becoming-much-more-likely-says-climate-study\n- #PAPER [The geographic disparity of historical greenhouse emissions and projected climate change (Van Houtan 2021)](https://advances.sciencemag.org/content/7/29/eabe4342.full)\n- #PAPER [Using Machine Learning to Analyze Physical Causes of Climate Change: A Case Study of U.S. Midwest Extreme Precipitation (Davenport 2021)](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021GL093787)\n- #PAPER [Aligning artificial intelligence with climate change mitigation (Kaack 2022)](https://www.nature.com/articles/s41558-022-01377-7.epdf?sharing_token=VNkvWalL1KVrxYte7VHfTtRgN0jAjWel9jnR3ZoTv0PFrrDwT9y68ah6oNg1ZvjBfcIb3Kbp_v5VihLBWDydbfc5jhcVPwJLve592DM4ofdyb9-AdB37nZsc6NVbVb-fttOlElGgXuHDhQRUp82Rwc9buEoGydxnCgU609qUgUY%3D)\n\n### AI carbon footprint\n- #PAPER [Measuring the Carbon Intensity of AI in Cloud Instances (Dodge 2022)](https://arxiv.org/pdf/2206.05229)\n- #PAPER [Aligning artificial intelligence with climate change mitigation (Kaack 2022)](https://www.nature.com/articles/s41558-022-01377-7)\n\t- https://www.hertie-school.org/en/news/allcontent/detail/content/assessing-the-impact-of-ai-and-ml-on-greenhouse-gas-emissions","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Data-assimilation":{"title":"Data assimilation","content":"## Courses\n- #COURSE [ECMWF An introduction to data assimilation](https://www.ecmwf.int/assets/elearning/da/da1/story_html5.html)\n- #COURSE [ECMWF Training course: Data assimilation](https://events.ecmwf.int/event/153/contributions/)\n\n## Talks\n- #TALK [Ensemble Data Assimilation](https://confluence.ecmwf.int/display/OPTR/Our+training+resources?preview=/35751136/36012464/EDA.png)\n\n## References\n- #PAPER [A review of operational methods of variational and ensemble‐variational data assimilation (Bannister 2016)](https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.2982)\n- #PAPER [Learning earth system models from observations: machine learning or data assimilation? (Geer 2020)](https://www.ecmwf.int/en/elibrary/19525-learning-earth-system-models-observations-machine-learning-or-data-assimilation)\n- #PAPER [Towards an unbiased stratospheric analysis (Laloyaux 2020)](https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.3798)\n\t- [Weak-constraint 4D-Var](https://www.ecmwf.int/en/newsletter/163/meteorology/improving-handling-model-bias-data-assimilation)\n- #PAPER [Attention-based Convolutional Autoencoders for 3D-Variational Data Assimilation (Mack 2020)](https://www.sciencedirect.com/science/article/pii/S004578252030476X) ^81c123\n\t- Proposed a new ‘Bi-Reduced Space’ approach to solving 3D Variational Data Assimilation.\n\t- Used Convolutional Autoencoders to create the reduced space for solving 3D Var\n\t- Proved that our approach has the same solution as previous methods for reducing 3D Var space\n\t- Lower computational complexity of previous methods\n\t- Tested the new method with data from a real-world application: a pollution model in London\n- #PAPER [Deep Data Assimilation: Integrating Deep Learning with Data Assimilation (Arcucci 2021)](https://www.mdpi.com/2076-3417/11/3/1114)\n\n\n\n### ECMWF-ESA Workshop on ML for Earth System Observation and Prediction (2020)\n- #POSTER [A Neural Network-Based Observation Operator for Coupled Ocean-Acoustic Variational Data Assimilation](https://ecmwfevents.com/i/2b97c2c6-d313-4e63-bcce-440cf1ea4746/posters/d8a72240-382e-4857-a66c-a3d430092e0c)\n- #POSTER [DAN - An optimal Data Assimilation framework based on machine learning recurrent Networks](https://ecmwfevents.com/i/2b97c2c6-d313-4e63-bcce-440cf1ea4746/posters/d692728d-d047-4f0c-b05b-c5c87cfcf602)\n- #POSTER [Toward an integrated NWP-DA-AI system for precipitation prediction](https://ecmwfevents.com/i/2b97c2c6-d313-4e63-bcce-440cf1ea4746/posters/fef6393a-a97f-42c9-ac2d-3649c8c0dfc6)\n\t- Phased-Array Weather Radar (PAWR) scans the whole sky in the 60-km range every 30 seconds at 110 elevation angles\n\t- 3D extension of the Convolutional Long Short-Term Memory (Conv-LSTM; Shi et al., 2015) is applied to PAWR nowcasting\n\t- In addition to the Conv-LSTM with past observations, we also develop a Conv-LSTM that accepts forecast data\n- [#POSTER  Using machine learning to correct model error and application to data assimilation with a quasi-geostrophic model](https://ecmwfevents.com/i/2b97c2c6-d313-4e63-bcce-440cf1ea4746/posters/39c445b7-cfc8-4bf7-aec2-0de39999f102)\n- #TALK [Data Assimilation and Machine Learning Science at ECMWF (Bonavita)](https://ecmwfevents.com/i/2b97c2c6-d313-4e63-bcce-440cf1ea4746/oral-presentations/c0d620fc-8923-480c-94f3-0be38c871553)\n- #TALK [Artificial Neural Network at the service of Data Assimilation (and vice versa) (Arcucci)](https://ecmwfevents.com/i/2b97c2c6-d313-4e63-bcce-440cf1ea4746/oral-presentations/234cff11-da9b-485f-82e3-daf106739905)\n\t- [[Data assimilation#^81c123]]\n\t- #POSTER [ICLR - Urban air pollution forecasts generated from latent space representation](https://openreview.net/forum?id=VY1hqB5Z7V#1d2023)\n\t- Combination of simulation (process driven) data and observations (data-driven)\n\t- The Ensemble Kalman filter, at least 1000 members to better capture underlying PDF\n\t- DA methods assume linearity, ML could capture non-linearities (LSTMs)\n\t- Computational fluid dynamics software could be replaced by ML\n- #PAPER [Combining data assimilation and machine learning to estimate parameters of a convective-scale model (Legler 2021)](https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4235?af=R)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/EO":{"title":"EO","content":"## Resources\n- [Towards a European AI for Earth Observation Research \u0026 Innovation Agenda](http://blogs.esa.int/philab/files/2018/07/Towards-a-European-AI-for-Earth-Observation-Research-Innovation-Agenda-.pdf)\n- [Is DS 4 EO BS?](https://labo.obs-mip.fr/multitemp/is-ds-4-eo-bs/)\n- [The value of super resolution — real world use case](https://medium.com/sentinel-hub/the-value-of-super-resolution-real-world-use-case-2ba811f4cd7f)\n- [Mapping roads through deep learning and weakly supervised training](https://ai.facebook.com/blog/mapping-roads-through-deep-learning-and-weakly-supervised-training/)\n- [Example of SuperRes with Sentinel 2 data](https://mdl4eo.irstea.fr/2019/03/29/enhancement-of-sentinel-2-images-at-1-5m/  )\n- [Quantifying the surface area of road networks in cities](https://roadsfromabove.netlify.com/)\n\t- Nice visualization\n- [CNN-Sentinel](https://github.com/jensleitloff/CNN-Sentinel)\n\t- Analyzing Sentinel-2 satellite data in Python with Keras (repository of our talks at Minds Mastering Machines 2019 and PyCon 2018)\n- https://interestingengineering.com/mapping-every-solar-panel-in-the-world-with-machine-learning\n- [Image Classification with Hugging Face Transformers and Keras (EuroSAT dataset)](https://www.philschmid.de/image-classification-huggingface-transformers-keras)\n\n## Events\n- [ESA EO Phi-week](https://phiweek.esa.int/)\n- [ESA Living Planet symposium](https://www.eumetsat.int/living-planet-symposium)\n\n## Courses\n- #COURSE [Artificial Intelligence (AI) for Earth Monitoring](https://www.futurelearn.com/courses/artificial-intelligence-for-earth-monitoring)\n- #COURSE [ESA MOOCs](https://eo4society.esa.int/training-education/massive-open-online-courses-moocs/)\n- #COURSE [ESA ML lectures 2018](https://github.com/jmartinezheras/2018-MachineLearning-Lectures-ESA)\n\n## Data and benchmark datasets\nSee [[AI4ES/AI4ES data#EO and Satellite data]]\n\n## Code\n- #CODE [TorchGeo (Microsoft)](https://github.com/microsoft/torchgeo)\n\t- https://torchgeo.readthedocs.io/\n- #CODE [Raster vision](https://github.com/azavea/raster-vision)\n\t- https://docs.rastervision.io/en/0.13/\n- #CODE [Google Earth Engine](https://developers.google.com/earth-engine/)\n\t- https://developers.google.com/earth-engine/datasets/catalog\n\t- https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR\n\t- https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_DAILY\n- #CODE [eo-learn: eo-learn makes extraction of valuable information from satellite imagery easy](https://github.com/sentinel-hub/eo-learn)\n- #CODE [OpenEO - A Common, Open Source Interface between Earth Observation Data Infrastructures and Front-End Applications](https://github.com/open-eo)\n- #CODE [Satpy - package is a python library for reading and manipulating meteorological remote sensing data and writing it to various image and data file formats](https://github.com/pytroll/satpy)\n- #CODE [rasterio - access to geospatial raster data](https://github.com/mapbox/rasterio)\n- #CODE [EODAG - Earth Observation Data Access Gateway](https://github.com/CS-SI/eodag)\n\t- https://eodag.readthedocs.io/en/latest/\n\t- https://www.youtube.com/watch?v=R18yTXKhF-I\u0026list=PLvT7fd9OiI9XORxAfLw_f9CsDkvM9lfKs\u0026index=23\n- #CODE [EOmaps](https://github.com/raphaelquast/EOmaps)\n\t- A library to create interactive maps of geographical datasets\n\t- https://raphaelquast.github.io/EOmaps/\n- #CODE [Pyinterpolate](https://github.com/DataverseLabs/pyinterpolate)\n\t- interpolate spatial data with the Kriging technique\n\t- https://pyinterpolate.readthedocs.io/en/latest/\n- #CODE [EOreader](https://github.com/sertit/eoreader)\n\t- Remote-sensing opensource python library reading optical and SAR sensors, loading and stacking bands, clouds, DEM and spectral indices in a sensor-agnostic way\n\t- https://eoreader.readthedocs.io/en/latest/\n\t- #TALK https://submit.geopython.net/geopython-2022/talk/FQPN3Q/\n\t\t- https://submit.geopython.net/media/eoreader_geopython_2022_compressed_lQL1HCR.pdf\n\n## References\n- #PAPER [Machine Learning Applications for Earth Observation (Lary 2018)](https://www.researchgate.net/publication/322659251_Machine_Learning_Applications_for_Earth_Observation)\n- #PAPER [Learning Spectral-Spatial-Temporal Features via a Recurrent Convolutional Neural Network for Change Detection in Multispectral Imagery (Mou 2018)](https://arxiv.org/abs/1803.02642 )\n- #PAPER [Multi-Stream CNNs for SAR Automatic Target Recognition (Zhao 2018)](https://www.mdpi.com/2072-4292/10/9/1473)\n- #PAPER [Multi-Temporal Land Cover Classification with Sequential Recurrent Encoders (Rubwurm 2018)](http://arxiv.org/abs/1802.02080)\n- #PAPER [Dialectical GANs for SAR Image Translation: From Sentinel-1 to TerraSAR-X  (Ao 2018)](https://arxiv.org/abs/1807.07778)\n- #PAPER [Machine Learning Using Hyperspectral Data Inaccurately Predicts Plant Traits Under Spatial Dependency (Rocha 2018)](https://www.mdpi.com/2072-4292/10/8/1263)\n- #PAPER [Satellite Imagery Multiscale Rapid Detection with Windowed Networks (Van Etten 2018)](https://arxiv.org/abs/1809.09978)\n\t- #CODE https://github.com/avanetten/simrdwn\n\t-  The SIMRDWN pipeline includes a modified version of YOLO (known as YOLT), along with the models of the tensorflow object detection API: SSD, Faster R-CNN, and R-FCN\n- #PAPER #REVIEW [Survey of Deep Learning Approaches for Remote Sensing Observation Enhancement (Tsagkatakis 2019)](https://www.mdpi.com/1424-8220/19/18/3929)\n- #PAPER [AI Data Science Methodology for Earth Observation (Dumitru 2019)](https://www.intechopen.com/books/advanced-analytics-and-artificial-intelligence-applications/artificial-intelligence-data-science-methodology-for-earth-observation)\n- #PAPER [Next Generation Mapping: Combining DL, Cloud Computing, and Big Remote Sensing Data (Parente 2019)](https://www.mdpi.com/2072-4292/11/23/2881)\n- #PAPER [Temporal CNNs for the Classification of Satellite Image Time Series (Pelletier 2019)](https://arxiv.org/abs/1811.10166)\n- #PAPER [Combining Sentinel-1 and Sentinel-2 Satellite Image Time Series for land cover mapping via a multi-source deep learning architecture (Ienco 2019)](https://www.sciencedirect.com/science/article/abs/pii/S0924271619302278?via%3Dihub)\n- #PAPER [The Challenge of Machine Learning in Space Weather: Nowcasting and Forecasting (Camporeale 2019)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018SW002061)\n\t- New trends in ML: Physics‐informed NNs, Automatic machine learning, Adversarial training.\n\t- Future challenges in ML for space weather: The information problem, The gray‐box problem, The surrogate problem (What components in the Space Weather chain can be replaced by an approximated black‐box surrogate model?), The uncertainty problem (Assessing the uncertainty associated to Weather predictions), The too often too quiet problem (data sets are typically imbalanced. Use synthetic data? Use simulated data), The knowledge discovery problem (How do we distill some knowledge from a machine learning model and improve our understanding of a given system? How do we open the black‐box and reverse‐engineer a machine learning algorithm?)\n- #PAPER [Machine Learning for Precipitation Nowcasting from Radar Images (Agrawal 2019)](https://arxiv.org/abs/1912.12132)\n\t- https://ai.googleblog.com/2020/01/using-machine-learning-to-nowcast.html\n- #PAPER [DL meets SAR (Xiang Zhu 2020)](https://arxiv.org/abs/2006.10027v1)\n- #PAPER [Sentinel-2 Sharpening via Parallel Residual Network (Wu 2020)](https://www.mdpi.com/2072-4292/12/2/279/htm)\n- #PAPER [Spectral Variability in Hyperspectral Data Unmixing: A Comprehensive Review (Borsoi 2020)](http://arxiv.org/abs/2001.07307)\n- #PAPER [Nonlinear PCA for Spatio-Temporal Analysis of Earth Observation Data (Bueso 2020)](https://arxiv.org/abs/2002.04539)\n\t- #CODE https://github.com/DiegoBueso/ROCK-PCA\n\t- Dimensionality  reduction  methods  can  work  with  spatio-temporal datasets and decompose the information efficiently. Principal Component Analysis (PCA), also known as Empirical Orthogonal Functions (EOF) in geophysics, has been traditionally used to analyze climatic data\n\t- When nonlinear feature relations are present, PCA/EOF fails\n\t- Propose a nonlinear PCA method to deal with spatio-temporal Earth System data\n\t- The proposed method, called Rotated Complex Kernel PCA (ROCK-PCA for short), works in reproducing kernel Hilbert spaces to account for nonlinear processes, operates in the complex kernel domain to account for both space and time features, and adds an extra rotation for improved flexibility\n\t- Results of the decomposition of three essential climate variables are shown: satellite-based global Gross Primary Productivity (GPP) and Soil Moisture (SM), and reanalysis Sea Surface Temperature (SST) data\n\t- The ROCK-PCA method allows identifying their annual and seasonal oscillations, as well as their non-seasonal trends and spatial variability patterns.\n- #PAPER [Accounting for Training Data Error in Machine Learning Applied to Earth Observations (Elmes 2020)](https://www.mdpi.com/2072-4292/12/6/1034/htm)\n- #PAPER [Uncertainty Quantification in Machine Learning Modeling for Multi-Step Time Series Forecasting:Example of Recurrent Neural Networks in Discharge Simulations (Song 2020)](https://www.mdpi.com/2073-4441/12/3/912/htm)\n- #PAPER [Model and data uncertainty for satellite time series forecasting with deep recurrent models (Rubwurm 2020)](https://elib.dlr.de/139306/1/igarss2020_tex.pdf)\n- #PAPER [Living in the Physics and Machine Learning Interplay for Earth Observation (Camps-Valls 2020)](https://arxiv.org/abs/2010.09031)\n- #PAPER [NightVision: Generating Nighttime Satellite Imagery from Infra-Red Observations (Harder 2020)](https://arxiv.org/abs/2011.07017)\n- #PAPER [DEEPCUBE: Explainable AI pipelines for big Copernicus data (Papoutsis 2021)](http://cgi.di.uoa.gr/~koubarak/publications/2021/BIDS21_paper54.pdf) ^deepcube\n- #PAPER [Towards global flood mapping onboard low cost satellites with machine learning (Mateo-Garcia 2021)](https://www.nature.com/articles/s41598-021-86650-z)\n- #PAPER [A generalizable and accessible approach to machine learning with global satellite imagery (Rolf 2021)](https://www.nature.com/articles/s41467-021-24638-z)\n\t- #CODE https://github.com/Global-Policy-Lab/mosaiks-paper\n\t- https://cega.berkeley.edu/research/mosaiks-a-generalizable-and-accessible-approach-to-machine-learning-with-global-satellite-imagery/\n\t- #TALK https://cega.berkeley.edu/resource/video-afternoon-keynotes-catherine-wolfram-sol-hsiang-infra4dev-2020/\n\t- ML system to tap the problem-solving potential of satellite imaging, using low-cost, easy-to-use technology that could bring access and analytical power to researchers and governments worldwide\n- #PAPER [Spatially autocorrelated training and validation samples inflate performance assessment of convolutional neural networks (Kattenborn 2022)](https://www.sciencedirect.com/science/article/pii/S2667393222000072)\n- #PAPER #REVIEW [ESA-ECMWF Report on recent progress and research directions in machine learning for Earth System observation and prediction (Schneider 2022)](https://www.nature.com/articles/s41612-022-00269-z)\n\n### Object detection/recognition\n- #PAPER DIOR (see [[AI4ES/AI4ES data#EO and Satellite data]])\n- #PAPER [Object Detection in Remote Sensing Images Based on Improved Bounding Box Regression and Multi-Level Features Fusion (Qian 2020)](https://www.mdpi.com/2072-4292/12/1/143/htm)\n- #PAPER [An Enriched Automated PV Registry: Combining Image Recognition and 3D Building Data (Rausch 2020)](https://www.climatechange.ai/papers/neurips2020/46/paper.pdf)\n\t- #CODE https://github.com/kdmayer/PV4GER\n\t- computer vision-based pipeline leveraging aerial imagery with a spatial resolution of 10 cm/pixel and 3D building data to automatically create address-level PV registries for all counties within Germany's most populous state North Rhine-Westphalia\n- #PAPER FAIR1M (see [[AI4ES/AI4ES data#EO and Satellite data]])\n\n### Semantic Segmentation and Hyperspectral Image Classification\n- #PAPER [Multi3Net: Segmenting Flooded Buildings via Fusion of Multiresolution, Multisensor, and Multitemporal Satellite Imagery (Rudner 2018)](https://arxiv.org/abs/1812.01756)\n- #PAPER [Feature Extraction and Classification Based on Spatial-Spectral ConvLSTM Neural Network for Hyperspectral Images (Hu 2019)](https://arxiv.org/abs/1905.03577)\n\t- ConvLSTM 3-D\n- #PAPER [Semantic segmentation of slums in satellite images using transfer learning on fully convolutional neural networks (Wurm 2019)](https://www.sciencedirect.com/science/article/pii/S0924271619300383)\n- #PAPER [Wide-Area Land Cover Mapping with Sentinel-1 Imagery using DL Semantic Segmentation Models (Scepanovic 2020)](https://arxiv.org/abs/1912.05067v2)\n- #PAPER [Dense Dilated Convolutions Merging Network for Land Cover Classification (Liu 2020)](https://arxiv.org/abs/2003.04027v1)\n- #PAPER [Continental-Scale Building Detection from High Resolution Satellite Imagery (Sirko 2021)](https://arxiv.org/abs/2107.12283)\n\t- https://ai.googleblog.com/2021/07/mapping-africas-buildings-with.html\n- #PAPER [Semantic segmentation of PolSAR image data using advanced deep learning model (Garg 2021)](https://www.nature.com/articles/s41598-021-94422-y)\n- #PAPER [A Dual Network for Super-Resolution and Semantic Segmentation of Sentinel-2 Imagery (Abadal 2021)](https://www.mdpi.com/2072-4292/13/22/4547/htm)\n\t- https://imatge.upc.edu/web/publications\n- #PAPER [Evaluation of Semantic Segmentation Methods for Land Use with Spectral Imaging Using Sentinel-2 and PNOA Imagery (Pedrayes 2021)](https://www.mdpi.com/2072-4292/13/12/2292/htm)\n- #PAPER [Deep Residual Involution Network for Hyperspectral Image Classification (Meng 2021)](https://www.mdpi.com/2072-4292/13/16/3055/htm)\n- #PAPER #REVIEW [Hyperspectral Image Classification Using Deep Learning Models: A Review (Kumar 2021)](https://iopscience.iop.org/article/10.1088/1742-6596/1950/1/012087)\n\n### Super-resolution\nSee [[Super-resolution]] and [[AI4ES/Statistical downscaling]]\n- #PAPER [PanNet: A deep network architecture for pan-sharpening (Yang 2017)](http://openaccess.thecvf.com/content_iccv_2017/html/Yang_PanNet_A_Deep_ICCV_2017_paper.html)\n\t- #CODE https://github.com/oyam/PanNet-Landsat\n- #PAPER [Target-adaptive CNN-based pansharpening (Scarpa 2018)](https://arxiv.org/abs/1709.06054)\n- #PAPER [Super-resolution of Sentinel-2 images: Learning a globally applicable deep neural network (Lanaras 2018)](http://arxiv.org/abs/1803.04271)\n- #PAPER [Deep Distillation Recursive Network for Remote Sensing Imagery Super-Resolution (Jiang 2018)](https://www.mdpi.com/2072-4292/10/11/1700/htm)\n- #PAPER [Super-Resolution of PROBA-V Images Using CNNs (Martens 2019)](http://arxiv.org/abs/1907.01821)\n- #PAPER [Deep Learning for Multiple-Image Super-Resolution (Kawulok 2019)](https://arxiv.org/abs/1903.00440)\n\t- EvoNet employs a deep ResNet to enhance the capabilities of evolutionary imaging model (EvoIM) for multiple-image SRR\n\t- https://www.youtube.com/watch?v=_RFQP1rRusQ\u0026list=PLvT7fd9OiI9XORxAfLw_f9CsDkvM9lfKs\u0026index=18\u0026t=0s\n- #PAPER [Super-Resolution Restoration of MISR Images Using the UCL MAGiGAN System (Tao 2019)](https://www.mdpi.com/2072-4292/11/1/52/htm)\n- #PAPER [A Multi-Scale Wavelet 3D-CNN for Hyperspectral Image Super-Resolution (Yang 2019)](https://www.mdpi.com/2072-4292/11/13/1557/htm)\n- #PAPER #REVIEW [Deep Learning for Single Image Super-Resolution:A Brief Review (Yang 2019)](https://arxiv.org/abs/1808.03344)\n- #PAPER [Ultra-dense GANs for satellite imagery super-resolution (2020)](https://www.sciencedirect.com/science/article/abs/pii/S0925231219314602)\n- #PAPER [Super-resolution of multispectral satellite images using convolutional neural networks (Muller 2020)](https://arxiv.org/abs/2002.00580)\n- #PAPER [DeepSUM: Deep neural network for Super-resolution of Unregistered Multitemporal images (Bordone Molini 2020)](https://arxiv.org/abs/1907.06490)\n\t- Winner of the PROBA-V super-resolution challenge issued by the European Space Agency\n\t- #CODE https://github.com/diegovalsesia/deepsum\n- #PAPER [DeepSUM++: Non-local Deep Neural Network for Super-Resolution of Unregistered Multitemporal Images  (Bordone Molini 2020)](https://arxiv.org/abs/2001.06342)\n- #PAPER [D-SRGAN: DEM Super-Resolution with GANs (Demiray 2020)](https://arxiv.org/abs/2004.04788)\n- #PAPER [Super-Resolution of Sentinel-2 Imagery Using Generative Adversarial Networks (Salgueiro Romero 2020)](https://www.mdpi.com/2072-4292/12/15/2424/htm)\n\t- https://upcommons.upc.edu/bitstream/handle/2117/329711/Final_thesis_OEC.pdf\n\n\n### Data Fusion\n- #PAPER [The SEN1-2 Dataset for DL in SAR-Optical Data Fusion (Schmitt 2018)](http://arxiv.org/abs/1807.01569)\n- #PAPER [Urban big data fusion based on deep learning: An overview (Liu 2020)](https://www.sciencedirect.com/science/article/pii/S1566253519301393)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/ESM-performance":{"title":"ESM performance","content":"## Resources\n- [Weather at Exascale: Load Balancing for Heterogeneous Systems](https://www.hpcwire.com/2020/03/30/weather-at-exascale-load-balancing-for-heterogeneous-systems/)\n- [Improving HPC Big Data Storage through I/O Load Balancing | Computer Science and Mathematics](https://csmd.ornl.gov/highlight/improving-hpc-big-data-storage-through-io-load-balancing)\n- Dynamic Load Balancing at #BSC (Marta Garcia):\n\t- https://hbp-hpc-platform.fz-juelich.de/?hbp_software=dynamic-load-balancing\n\t- https://www.bsc.es/research-development/research-areas/programming-models/dlb-dynamic-load-balancing\n\n\n## References\n- #PAPER [Machine-Learning-Based Load Balancing for Community Ice Code Component in CESM (Blaprakash 2015)](https://link.springer.com/chapter/10.1007/978-3-319-17353-5_7)\n\t- https://www.mcs.anl.gov/papers/P4070-0413.pdf\n\t- https://www.anl.gov/mcs/article/using-machine-learning-approaches-for-load-balancing-of-climate-models\n- #PAPER [Multi-Level Load Balancing with an Integrated Runtime Approach (Bak 2017)](https://ieeexplore.ieee.org/abstract/document/8411007)\n\t- https://www.researchgate.net/publication/326434358\n- #PAPER [Performance Optimization of Geophysics Stencils on Multicore Architectures: A Machine Learning Approach (Martinez 2018)](http://www.red-ricap.org/documents/1071192/1486440/Carla18Pos/51326921-4480-41e7-a980-4ebcd80c3652)\n- #PAPER [An Efficient Dynamic Load Balancing Algorithm Using Machine Learning Technique in Cloud Environment (Panchal 2018)](http://ijsrset.com/paper/4504.pdf)\n- #PAPER [I/O Load Balancing for Big Data HPC Applications (Paul 2018)](https://ieeexplore.ieee.org/document/8257931)\n\t- https://www.researchgate.net/profile/Arnab_Paul5/publication/321851758_IO_load_balancing_for_big_data_HPC_applications/links/5a3521a445851532e82f0e5b/I-O-load-balancing-for-big-data-HPC-applications.pdf\n- #PAPER [Adaptive Load Balancing based on Machine Learning for Iterative Parallel Applications (Oikawa 2020)](https://www.computer.org/csdl/proceedings-article/pdp/2020/09092148/1jPb1yDHZa8)\n\t- https://hal.archives-ouvertes.fr/hal-02570549/document\n- #PAPER [Climate Modelling in Low-Precision: Effects of both Deterministic \u0026 Stochastic Rounding (Adam Paxton 2021)](https://arxiv.org/abs/2104.15076)\n\t- Although double precision(52 significant bits) is standard across operational climate models, in our experiments we find that single precision (23 sbits) is more than enough and that as low as half-precision (10 sbits) is often sufficient\n\t- Wasserstein distance","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/ESM-tuning":{"title":"ESM tuning","content":"## Resources\n- Better exploration of the parameter space\n\t- #BSC Markus F. and Martí G. work with Genetic algorithms \n\t- MCMC, Nested sampling. Bayesian model selection (see [[AI/Math and Statistics/Math and Statistics#^1ef748]])\n\t- Reinforcement Learning \t\t\n- #POSTER [Machine learning surrogate models for parameter tuning: The Lorenz 96 as a test case (Lguensat)](https://events.ecmwf.int/event/172/contributions/1727/attachments/875/1548/Machine-Learning-WS_Lguensat.pdf)\n\t- #TALK https://www.youtube.com/watch?v=j5Tx05xzA-k\n\n## References\n- #PAPER [Bayesian optimization for tuning chaotic systems (Abbas 2014)](https://npg.copernicus.org/preprints/npg-2014-51/)\n- #PAPER [Empirical evaluation of Bayesian optimization in parametric tuning of chaotic systems (Abbas 2016)](https://pdfs.semanticscholar.org/af49/04931008e4fe8fcfbbf27cb743a40c5f622a.pdf)\n- #PAPER [The Art and Science of Climate Model Tuning (Hourdin 2016)](https://journals.ametsoc.org/doi/10.1175/BAMS-D-15-00135.1)\n- [#THESIS/PHD Training methods for climate and neural network models (Abbas 2018)](https://aaltodoc.aalto.fi/bitstream/handle/123456789/34496/isbn9789526082592.pdf?sequence=1)\n\t- Bayesian optimization for tuning chaotic systems, see other two papers Abbas 2014, 2016\n- #PAPER [How parameter specification of an Earth system model of intermediate complexity influences its climate simulations (Shi 2019)](https://link.springer.com/article/10.1186/s40645-019-0294-x)\n- #PAPER [Model Parameter Optimization: ML-guided trans-resolution tuning of physical models (Partee 2019)](https://ml4physicalsciences.github.io/2019/files/NeurIPS_ML4PS_2019_103.pdf)\n- #PAPER [Toward efficient calibration of higher-resolution Earth System Models (Fletcher 2021)](https://www.climatechange.ai/papers/icml2021/51.html)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/ESMs-GCMs":{"title":"ESMs, GCMs","content":"## Resources\n- [Climate model](https://en.wikipedia.org/wiki/Climate_model)\n- [Global Climate Models](https://www.gfdl.noaa.gov/climate-modeling/)\n\t- A global climate model (GCM) is a complex mathematical representation of the major climate system components (atmosphere, land surface, ocean, and sea ice), and their interactions.  Earth’s energy balance between the four components is the key to long-term climate prediction.  The main climate system components treated in a climate model are:\n\t\t- The atmospheric component, which simulates clouds and aerosols, and plays a large role in transport of heat and water around the globe.\n\t\t- The land surface component, which simulates surface characteristics such as vegetation, snow cover, soil water, rivers, and carbon storing.\n\t\t- The ocean component, which simulates current movement and mixing, and biogeochemistry, since the ocean is the dominant reservoir of heat and carbon in the climate system.\n\t\t- The sea ice component, which modulates solar radiation absorption and air-sea heat and water exchanges.\n- [General circulation model](https://en.wikipedia.org/wiki/General_circulation_model)\n\t- A general circulation model (GCM) is a type of climate model. It employs a mathematical model of the general circulation of a planetary atmosphere or ocean. It uses the Navier–Stokes equations on a rotating sphere with thermodynamic terms for various energy sources (radiation, latent heat).\n\n## Talks\n- #TALK [SC20 Keynote: Climate Science in the Age of Exascale with Professor Bjorn Stevens](https://www.youtube.com/watch?v=0LROF_k6vLo)\n\n## References\n- #PAPER [The computational future for climate and Earth system models: on the path to petaflop and beyond (Washington 2018)](https://royalsocietypublishing.org/doi/10.1098/rsta.2008.0219)\n\n\n### Tuning of ESMs\nSee [[ESM tuning]]\n\n### Emulators and surrogates\nSee [[Emulators]] \n\n### Parameterizations\nSee [[Parameterizations]]\n\n### Data assimilation\nSee [[Data assimilation]]\n\n### Ensembles, multi-models \nSee [[Ensembles, multi-models]]\n\n## Bias correction and adjustment\nSee [[AI4ES/Bias correction, adjustment]]\n\n## Porting models to GPUs \n- [Accelerating Operational Earth Systems Models using GPUs](https://ddd.uab.cat/pub/tfg/2019/tfg_182307/TFG.pdf)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Emulators":{"title":"(Earth system model) Emulators and surrogates","content":"\u003e See:\n\u003e - [[Parameterizations]]\n\n## Resources\n- [Earth system modelling](https://www.climateurope.eu/earth-system-modeling-a-definition/)\n\t- Earth system models (ESM) seek to simulate all relevant aspects of the Earth system. They include physical, chemical and biological processes, therefore reaching far beyond their predecessors, the global climate models (GCM), which just represented the physical atmospheric and oceanic processes.\n\t- At their core ESMs have the atmospheric and ocean components of a GCM however to this they add representations of the global carbon cycle, dynamic vegetation, atmospheric chemistry, ocean bio-geo-chemistry and even continental ice sheets.\n- [What is an Earth System Model (ESM)?](https://soccom.princeton.edu/content/what-earth-system-model-esm)\n\t- A coupled climate model is a computer code that estimates the solution to differential equations of fluid motion and thermodynamics to obtain time and space dependent values for temperature, winds and currents, moisture and/or salinity and pressure in the atmosphere and ocean. \n\n\n## References\n- #PAPER [Efficient surrogate modeling methods for large-scale Earth system models based on machine-learning techniques (Lu 2018)](https://gmd.copernicus.org/articles/12/1791/2019/)\n\t- Proposed an efficient surrogate method capable of using a few ESM runs to build an accurate and fast-to-evaluate surrogate system of model outputs over large spatial and temporal domains. \n\t- SVD to reduce the output dimensions and then use Bayesian optimization techniques to generate an accurate neural network surrogate model based on limited ESM simulation samples. \n\t- Our Machine Learning-based surrogate methods can build and evaluate a large surrogate system of many variables quickly\n- #PAPER [Toward Data‐Driven Weather and Climate Forecasting: Approximating a Simple General Circulation Model With Deep Learning (Scher 2018)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018GL080704)\n\t- Emulated the dynamics of a simple general circulation model with a deep neural network. After being trained on the model, the network can predict the complete model state several time steps ahead—which conceptually is making weather forecasts in the model world\n- #PAPER [Weather and climate forecasting with neural networks: using general circulation models (GCMs) with different complexity as a study ground (Scher 2019)](https://gmd.copernicus.org/articles/12/2797/2019/)\n- #PAPER [Deep learning for physical processes: incorporating prior scientific knowledge (Bezenac 2019)](https://iopscience.iop.org/article/10.1088/1742-5468/ab3195)\n- #PAPER [Emulating Numeric Hydroclimate Models with Physics-Informed cGANs (Manepalli 2019)](https://par.nsf.gov/servlets/purl/10137369)\n\t- workshop on climate informatics\n\t- https://slideslive.com/38922409/emulating-numeric-hydroclimate-models-with-physicsinformed-cgans \n- #PAPER [Achieving Conservation of Energy in Neural Network Emulators for Climate Modeling (Beucler 2019)](https://arxiv.org/abs/1906.06622)\n\t- NN models do not intrinsically conserve energy and mass, which is an obstacle to using them for long-term climate predictions. \n\t- Proposed two methods to enforce linear conservation laws in neural-network emulators of physical models: Constraining (1) the loss function or (2) the architecture of the network itself. \n\t- Applied to the emulation of explicitly-resolved cloud processes in a prototype multi-scale climate model, we show that architecture constraints can enforce conservation laws to satisfactory numerical precision, while all constraints help the neural-network better generalize to conditions outside of its training set, such as global warming.\n- #PAPER [Deep Learning for Precipitation Estimation from Satellite and Rain Gauges Measurements (Moraux, 2019)](https://www.mdpi.com/2072-4292/11/21/2463/htm)\n\t- This paper proposes a multimodal and multi-task deep-learning model for instantaneous precipitation rate estimation. \n\t- Using both thermal infrared satellite radiometer and automatic rain gauge measurements as input, our encoder–decoder convolutional neural network performs a multiscale analysis of these two modalities to estimate simultaneously the rainfall probability and the precipitation rate value.\n- #PAPER DeepClimGAN: A High-Resolution Climate Data Generator (Puchko 2019): \n\t- https://www.semanticscholar.org/paper/DeepClimGAN%3A-A-High-Resolution-Climate-Data-Puchko-Link/86b9db65ff46e8dfe0ee6e3fa8b5f16f5eee0735\n\t- #CODE https://github.com/JGCRI/DeepClimGAN\n\t- DeepClimGAN is a conditional GAN, capable of producing a spatio-temporal forecast\n- #PAPER [Applying Machine Learning to Improve Simulations of a Chaotic Dynamical System Using Empirical Error Correction (Pag 2019)](https://europepmc.org/article/PMC/6618166)\n\t- #CODE https://github.com/PAGWatson/Lorenz96_and_neural_networks\n\t- Dynamical weather and climate prediction models underpin many studies of the Earth system and hold the promise of being able to make robust projections of future climate change based on physical laws\n\t- Simulations from these models still show many differences compared with observations\n\t- Tested a framework using machine learning together with physically-derived models, in which it is learnt how to correct the errors of the latter from time step to time step\n\t- This maintains the physical understanding built into the models, while allowing performance improvements, and also requires much simpler algorithms and less training data\n\t- This is tested in the context of simulating the chaotic Lorenz '96 system, and it is shown that the approach yields models that are stable and that give both improved skill in initialized predictions and better long-term climate statistics\n- #PAPER [Up to two billion times acceleration of scientific simulations with deep neural architecture search (Kasim 2020)](https://arxiv.org/abs/2001.08055)\n\t- A promising route to accelerate simulations by building fast emulators with machine learning requires large training datasets, which can be prohibitively expensive to obtain with slow simulations. \n\t- Presented a method based on neural architecture search to build accurate emulators even with a limited number of training data. \n\t- The method successfully accelerates simulations by up to 2 billion times in 10 scientific cases including astrophysics, climate science, biogeochemistry, high energy density physics, fusion energy, and seismology, using the same super-architecture, algorithm, and hyperparameters\n- #PAPER [DPM: A deep learning PDE augmentation method with application to large-eddy simulation (Sirignano 2020)](https://www.sciencedirect.com/science/article/pii/S0021999120305854)\n\t- https://techxplore.com/news/2020-11-method-physics-deep-simulate-turbulence.html\n- #PAPER [Hybrid modeling: fusion of a deep learning approach and a physics-based model for global hydrological modeling (Kraft 2020)](https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/1537/2020/)\n\t- Reichstein et al, physics-based ML\n\t- Presented an end-to-end hybrid modeling approach that learns and predicts spatial-temporal variations of observed and unobserved (latent) hydrological variables globally\n- #PAPER [Enforcing statistical constraints in generative adversarial networks for modeling chaotic dynamical systems (Wu 2020)](https://www.sciencedirect.com/science/article/pii/S0021999119309143)\n\t- https://arxiv.org/abs/1905.06841\n\t- Confirmed statistics-conforming property of [[GANs]] for modeling dynamical systems\n\t- Highlighted the lack of robustness of GANs and need of explicit physical constraints\n\t- Improved training robustness of GANs by explicitly enforcing statistical constraints. Constraint on optimization with penalty  terms  added  into  the  optimization loss function of GANs (distance measure between two covariance structures, related to symmetrized Kullback–Leibler divergence) \n\t- Demonstrated merits of statistics-informed GANs on modeling Rayleigh-Bénard convection\n- #PAPER [Boosting performance in Machine Learning of Turbulent and Geophysical Flows via scale separation (Faranda 2020)](https://npg.copernicus.org/preprints/npg-2020-39/)\n\t- Uses [[RNNs#Echo state networks ESN]] for forecasting [[Weather forecasting, nowcasting]] dynamics of complex systems (sea level pressure data)\n\t- #TALK https://www.youtube.com/watch?v=qztvuflzNfQ\n- #PAPER [Towards Physics-informed Deep Learning for Turbulent Flow Prediction (Wang 2020)](https://arxiv.org/abs/1911.08655)\n\t- Aimed to predict turbulent flow by learning its highly nonlinear dynamics from spatiotemporal velocity fields of large-scale fluid flow simulations of relevance to turbulence modeling and climate modeling\n\t- Introduced trainable spectral filters in a coupled model of Reynolds-averaged Navier-Stokes (RANS) and Large Eddy Simulation (LES), followed by a specialized U-net for prediction.\n\t- The turbulent-Flow Net (TF-Net), is grounded in a principled physics model, yet offers the flexibility of learned representations\n- #TALK [Loosely Conditioned Emulation of Global Climate Models With Generative Adversarial Networks (Ayala 2020)](https://www.climatechange.ai/papers/neurips2020/61.html)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Ensembles-multi-models":{"title":"Ensembles, multi-models","content":"\u003e  See:\n\u003e  - [[Weather forecasting, nowcasting]] \n\u003e  - [[S2S]]\n\u003e  - [[S2D]]\n\n## Resources\n- Improving predictions of Ensembles and averaging. Reducing uncertainty on future predictions\n- No one model predicts best all the time, for all variables \n   - [Best predictor: Average predictions over all models](http://www.cmap.polytechnique.fr/~zoltan.szabo/ml_external_seminar_EcoleP/2018_04_10_Claire_Monteleoni_slides.pdf )\n\t   - Average prediction weights all models equally \n\t   - Weighted average prediction gives varying weights to each models based on past performances\n\t   - Adaptive weighted average prediction identifies current best predicting model vs one that quickly switching to other models \n\t- Online Learning: Non stationary data. Learns the switching rate: level of non-stationarity \n   - Multi-model assessment of seasonal T and precipitation forecasts over Europe \n- [Ensemble Verification Metrics](https://www.ecmwf.int/sites/default/files/elibrary/2017/17626-ensemble-verification-metrics.pdf)\n- [IPCC Expert Meeting on Assessing and Combining Multi Model Climate Projections — IPCC ](https://www.ipcc.ch/publication/ipcc-expert-meeting-on-assessing-and-combining-multi-model-climate-projections/)\n\n## Talks\n- #TALK [Statistical post-processing of ensemble weather forecasts: Current developments and future directions (Tilmann Gneiting)](https://confluence.ecmwf.int/display/OPTR/Our+training+resources?preview=/35751136/45942083/Screen%20Shot%202015-02-15%20at%2019.38.24.png)\n- #TALK [Multi-model ensemble predictions on seasonal timescale](https://confluence.ecmwf.int/display/OPTR/Our+training+resources?preview=/35751136/36012483/stockdale.png)\n\n## Courses\n- #COURSE [Ensemble forecasting: sources of forecast uncertainty (ECMWF)](https://www.ecmwf.int/en/elibrary/18119-ensemble-forecasting-sources-forecast-uncertainty)\n\n## References\n- #PAPER [Decomposition of the Continuous Ranked Probability Score for Ensemble Prediction Systems (Hersbach 2000)](https://journals.ametsoc.org/view/journals/wefo/15/5/1520-0434_2000_015_0559_dotcrp_2_0_co_2.xml)\n\t- The CRPS can be seen as a ranked probability score with an infinite number of classes, each of zero width\n\t- Alternatively, it can be interpreted as the integral of the Brier score over all possible threshold values for the parameter under consideration \n\t- For a deterministic forecast system the CRPS reduces to the mean absolute error\n\t- CRPS can be decomposed into three parts:\n\t\t- reliability, is closely related to the rank histogram. The reliability should be zero for an ensemble system with the correct statistical properties. \n\t\t- uncertainty, is the best achievable value of the continuous ranked probability score, in case only climatological information is available.\n\t\t- resolution, expresses the superiority of a forecast system with respect to a forecast system based on climatology.\n- #PAPER [A multiple model assessment of seasonal climate forecast skill for applications (Lavers 2009)](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2009GL041365)\n- #PAPER [Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles (Lakshminarayanan 2017)](https://arxiv.org/abs/1612.01474)\n- #PAPER [Predicting Weather Forecast Uncertainty with Machine Learning (Scher 2018)](https://www.researchgate.net/publication/328264084_Predicting_Weather_Forecast_Uncertainty_with_Machine_Learning)\n- #PAPER [Using multi‐model ensembles of CMIP5 global climate models to reproduce observed monthly rainfall and temperature with machine learning methods in Australia (Wang 2018)](https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/joc.5705)\n\t- https://agrivy.oss-cn-zhangjiakou.aliyuncs.com/papers_agrivy/webfiles/papers/2018-IJC-WANG-BIN.pdf\n\t- The purpose of this study is to compare the capacity of four different multi-model ensemble (MME) methods (random forest, support vector machine, Bayesian model averaging and the arithmetic ensemble mean) in reproducing observed monthly rainfall and temperature\n- #PAPER [Predicting Weather Uncertainty with Deep CNNs (Gronquist 2019)](https://arxiv.org/abs/1911.00630)\n\t- Ensembles uncertainty estimation with DL\n\t- WF uncertainty quantification using ensembles prediction system (nonparametrics stats on multiple perturbed simulations)\n\t- Intensive simulations (dozens and up to 50)\n\t- Each ensemble member is perturbed, the STDDEV of the embers can be used to identify the uncertainty of a HRes forecast\n\t- Data: ERA5 (similar to production NWP data) Reanalysis by ECMWF with weather data reanalysis from 1979. \n\t- Ensemble of 9 perturbed trajectories and a single unperturbed (control) one. Mapped to 0.5 degree resolution, 37 pressure levels. Temperature prediction. \n\t- Subset of IPs that have an influence on Temp: zonal and meridional wind, geopotential, temperature, relative humidity and the factions of cloud cover  \n\t- Cropping for EU and Atlantic, 40 lat by 136 lon  \n\t- 7 pressure levels including 500 hPa, 850 hPa  \n\t- Temporally: 2000 – 2011, between 0600 and 1800 UTC with forecasts made for 3h and 6h into the future  \n\t- Standardize the data for each pressure level and parameter  \n\t- Second dataset:  ENS10, re-forecast with 10 perturbed members, 24 h intervals. 2 times per week the last 20 years. Similar to the operational 51-member ensemble, but coarser resolution of 0.5 degrees\n\t- Model: Weight sharing on each pressure level separately (\"full\"), more representational power but more parameters \n\t- Point-wise affine transforms per pressure level after each convolution (\"affine\") 2D convs followed by 1D vertical convs (\"separable\") \n\t- Temporal trends (can the temporal progression of the spread be learned?): data of the spread of all 10 trajectories at times 0h, 3h and 6h Tried CLSTMs At the end, treating time sequences as additional channels in U-Net and ResNet Not enough timesteps to learn temporal dynamics \n\t- Data parallelism, eventually could use pipeline parallelism for network depth and model parallelism for HiRes data \n\t- Evaluation: RMSE as the optimization target, visualization \n\t- Comparison with linear regression on the full ensemble spread at time t 0h \n\t- Model using only one unperturbed trajectory provides a better spread estimation than using four perturbed trajectories, then 5 ensembles (half of what is available) IPs concatenated to input data \n\t- No improvement using temporal models ENS10, model approximates larger ensembles using only a few input trajectories\n- #PAPER [Ensemble size: How suboptimal is less than infinity? (Leutbecher 2019)](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.3387)\n- #PAPER [Multi-model skill assessment of seasonal temperature and precipitation forecasts over Europe (Mishra 2019)](https://link.springer.com/article/10.1007%2Fs00382-018-4404-z)\n\t- https://www.researchgate.net/publication/327349294_Multi-model_skill_assessment_of_seasonal_temperature_and_precipitation_forecasts_over_Europe\n\t- #BSC, Chloe Prodhomme\n\t- [IMPREX, legacy open data](https://imprex.eu/system/files/generated/files/resource/imprex-opendata-overview.pdf)\n- #PAPER Gronquist 2020 in [[AI4ES/Bias correction, adjustment]]\n- #TALK [A new approach to subseasonal multi-model forecasting: Online prediction with expert advice (Brayshaw and Gonzalez 2020)](https://meetingorganizer.copernicus.org/EGU2020/EGU2020-17663.html)\n\t- Tested algorithms to perform ‘online prediction with expert advice’ (Cesa-Bianchi et al. 2006). These methods consider a set of weighted ‘experts’ (usually uniformly weighted at the start of the process) to produce subsequent predictions in which the combination or mixture is updated to optimize a loss or skill function\n\t- [S2S4E](https://s2s4e.eu/) \n\t- The online learning algorithms\n\t\t- BOA: Bernstein online aggregation\n\t\t- MLpol: Polynomial potential aggregation\n\t- Compared to the 'exponentiated gradient' method as a reference, which is a sequential learning algorithm previously used in weather and climate -\u003e EGA_NWP\n\t- The BOA and MLpol methods show skill improvements for leads beyond week 3, a horizon rarely beaten by ECMWF at the country level\n- #PAPER [Multi-model ensemble predictions of precipitation and temperature using machine learning algorithms (Ahmed 2020)](https://www.sciencedirect.com/science/article/pii/S0169809519309858)\n\t- Optimum performance of multi-model ensemble is achieved with 50% of top-ranked GCMs\n\t- K-Nearest Neighbour and Relevance Vector Machine are good for multi-model ensembles\n\t- Artificial Neural Network multi-model ensembles showed large performance fluctuations in space\n\t- Machine learning-based multi-model ensembles outperformed simple ensemble mean\n- #PAPER [A data-driven multi-model ensemble for deterministic and probabilistic precipitation forecasting at seasonal scale (Xu 2020)](https://link.springer.com/article/10.1007/s00382-020-05173-x)\n\t- Current numerical models have large uncertainty in model structure, parameterization and initial conditions\n\t- A data-driven multi-model ensemble is constructed using a series of statistical and machine learning methods with varying inputs\n\t- Deterministic precipitation forecasts are produced by the weighting of ensemble members using Bayesian model averaging (BMA) and probabilistic forecasts are generated by sampling from BMA predictive probability density function (PDF)\n\t- The results demonstrate that the accuracy in the statistical ensemble is significantly higher than the North American multi-model ensemble (NMME) for both deterministic and probabilistic precipitation forecasts, especially at 1-month lead\n- #PAPER [How to create an operational multi-model of seasonal forecasts? (Hemri 2020)](https://link.springer.com/article/10.1007/s00382-020-05314-2)\n\t- #BSC Paco Doblas-Reyes","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Extremes-events":{"title":"Extremes events","content":"\u003e See:\n\u003e - [[AI/Anomaly and Outlier Detection]]\n\n\n## Resources\n- [CASCADE - multidivisional, collaborative project at Lawrence Berkeley National Laboratory (LBNL)](https://cascade.lbl.gov/)\n- [CLIMATE EXTREMES (Coumou)](https://climateextremes.eu/)\n- [EO-ALERT (2018-2021) - Next generation satellite processing chain for rapid civil alerts](http://eo-alert-h2020.eu/)\n\t- [AI for Earth observation and numerical weather prediction](http://eo-alert-h2020.eu/2019/04/22/ai-for-earth-observation-and-numerical-weather-prediction/)\n- [National Meteorological Library and Archive Fact sheet 3 — Water in the atmosphere](https://www.metoffice.gov.uk/binaries/content/assets/metofficegovuk/pdf/research/library-and-archive/library/publications/factsheets/factsheet_3-water-in-the-atmosphere.pdf)\n- https://www.deeprain-project.de/en/publications-2/\n- [Severe weather Europe](https://www.severe-weather.eu/)\n\n### Hurricanes\n- [Hurricanes Database](https://products.climate.ncsu.edu/weather/hurricanes/database/?search=year\u0026yr=2017)\n- [Barometric Pressure \u0026 Hurricanes](https://sciencing.com/barometric-pressure-hurricanes-22734.html)\n\n### Wildfires\n- [EOS - Forest Fire Monitoring](https://eos.com/industries/forestry/forest-fires-identification/) \n- [2017 Conference on Fire Prediction Across Scales](http://extremeweather.columbia.edu/events/past-events/2017-conference-on-fire-prediction-across-scales/\n- [Climate Change Increases the Risk of Wildfires](https://sciencebrief.org/briefs/wildfires)\n- [Leverhulme Centre for Wildfires, Environment and Society](https://centreforwildfires.org/projects/) \n\n### Atmospheric rivers\n- See ClimateNet dataset\n- https://en.wikipedia.org/wiki/Atmospheric_river\n- [About ARs (NOAA)](https://www.psl.noaa.gov/arportal/about/)\n\n\n## Code\n- #CODE [ecPoint-Rainfall - Global probabilistic rainfall at point-scale from ECMWF ensemble](https://www.ecmwf.int/en/elibrary/18331-ecpoint-rainfall-global-probabilistic-rainfall-point-scale-ecmwf-ensemble)\n- #CODE [TECA - the Toolkit for Extreme Climate Analysis](https://github.com/LBL-EESA/TECA)\n\t- TECA (Toolkit for Extreme Climate Analysis) is a collection of climate analysis algorithms geared toward extreme event detection and tracking implemented in a scalable parallel framework. The core is written in modern c++ and uses MPI+thread for parallelism\n\n\n## Databases\nSee [[AI4ES/AI4ES data#Extreme events labeled data]]\n- [Copernicus Emergency Management Service (EMS)](https://emergency.copernicus.eu/mapping/ems/service-overview)\n\t- EMS uses satellite imagery and other geospatial data to provide free of charge mapping service in cases of natural disasters, human-made emergency situations and humanitarian crises throughout the world\n\t- [List of EMS Rapid Mapping Activations](https://emergency.copernicus.eu/mapping/list-of-activations-rapid)\n\t- Flood, wildfire, volcanic events, earthquakes\n- [European Drought Observatory](https://edo.jrc.ec.europa.eu/edov2/php/index.php?id=1000)\n- [IBTrACS](https://www.ncdc.noaa.gov/ibtracs/)\n\t- https://climetlab.readthedocs.io/en/latest/firststeps.html\n- [ESWD](\u003c[European Severe Weather Database](https://eswd.eu/cgi-bin/eswd.cgi#lookupanchor)\u003e)  \n\t- \"Extreme Weather Database\" will be a nice thing to test because it contains events that are not resolved by the reanalysis. So will really help to identify local-scale (convective) high-impact events\n\t- Type of events: dust, sand- or steam devils, gustnadoes, large hail, heavy rain, tornadoes, severe wind gusts, heavy snowfalls/snowstorms, ice accumulations, avalanches, damaging lightning strikes \n- [NCEI's Severe Weather Data Inventory (US)](https://www.ncdc.noaa.gov/ncdcs-severe-weather-data-inventory)\n- [TEMPEST (UK)](https://www.nottingham.ac.uk/research/groups/weather-extremes/research/tempest-database.aspx)\n\t- Tracking Extremes of Meteorological Phenomena Experienced in Space and Time\n\t- Work in progress\n\n\n## References - Climate\n- #PAPER [Climate and Weather Extremes (Nature paper collection)](https://www.nature.com/collections/kpzbllmxxw)\n\t- [Progress in subseasonal to seasonal prediction through a joint weather and climate community effort (Mariotti 2018)](https://www.nature.com/articles/s41612-018-0014-z)\n\t- [The sub-seasonal to seasonal prediction project (S2S) and the prediction of extreme events (Vitart 2018)](https://www.nature.com/articles/s41612-018-0013-0)\n- #PAPER [Simulation and Prediction of Category 4 and 5 Hurricanes in the High-Resolution GFDL HiFLOR Coupled Climate Model (Murakami 2015)](https://journals.ametsoc.org/jcli/article/28/23/9058/34488/Simulation-and-Prediction-of-Category-4-and-5)\n- #PAPER [A toolkit for climate change analysis and pattern recognition for extreme weather conditions – Case study: California-Baja California Peninsula (Vaghefi 2017)](http://www.sciencedirect.com/science/article/pii/S1364815216303188)\n- #PAPER [Urban heat wave hazard and risk assessment (Jedlovec 2017)](https://www.sciencedirect.com/science/article/pii/S2211379717316686)\n- #PAPER [Defining Extreme Events: A Cross‐Disciplinary Review (McPhillips, 2018)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017EF000686)\n\t- Extreme events are of interest worldwide given their potential for substantial impacts on social, ecological, and technical systems\n\t- Many climate‐related extreme events are increasing in frequency and/or magnitude due to anthropogenic climate change \n\t- A lack of coherence exists in what constitutes and defines an extreme event across these fields, which impedes our ability to holistically understand and manage these events\n\t- Found a wide range in definitions and thresholds, with more than half of examined papers not providing an explicit definition, and disagreement over whether impacts are included in the definition\n\t- Distinction should be made between extreme events and their impacts, so that we can better assess when responses to extreme events have actually enhanced resilience\n- #PAPER [Sense‐making in social media during extreme events (Stieglitz, 2018)](https://onlinelibrary.wiley.com/doi/full/10.1111/1468-5973.12193)\n- #PAPER [Complex networks reveal global pattern of extreme-rainfall teleconnections (Boers 2019)](https://www.nature.com/articles/s41586-018-0872-x)\n- #PAPER [A ranking of concurrent precipitation and wind events for the Iberian Peninsula (Henin 2020)](https://rmets.onlinelibrary.wiley.com/doi/10.1002/joc.6829)\n- #PAPER [Atmospheric convection, dynamics and topography shape the scaling pattern of hourly rainfall extremes with temperature globally (Moustakis 2020)](https://www.nature.com/articles/s43247-020-0003-0)\n\n### Droughts\n- #PAPER [Development of a Combined Drought Indicator to detect agricultural drought in Europe (Sepulcre-Canto 2012)](https://doi.org/10.5194/nhess-12-3519-2012)\n- #PAPER [Seasonal Drought Prediction: Advances, Challenges, and Future Prospects (Hao 2018)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016RG000549)\n- #PAPER [Machine learning–based observation-constrained projections reveal elevated global socioeconomic risks from wildfire (Yu 2022)](https://www.nature.com/articles/s41467-022-28853-0)\n\n### Wildfires\n- #PAPER [Seasonal predictions of Fire Weather Index: Paving the way for their operational applicability in Mediterranean Europe (Bedia 2018)](https://www.sciencedirect.com/science/article/pii/S2405880716300826)\n\t- See [[AI4ES/S2S]]\n- #PAPER [Skillful forecasting of global fire activity using seasonal climate predictions (Turco 2018)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6045620/)\n\t- See [[AI4ES/S2S]]\n- #PAPER [The Global Fire Atlas of individual fire size, duration, speed and direction (Andela 2019)](https://essd.copernicus.org/articles/11/529/2019/)\n\n### Atmospheric rivers\n- #PAPER [Daily Precipitation Extreme Events in the Iberian Peninsula and Its Association with Atmospheric Rivers (Ramos 2015)](https://journals.ametsoc.org/view/journals/hydr/16/2/jhm-d-14-0103_1.xml)\n- #PAPER [On the relationship between atmospheric rivers, weather types and floods in Galicia, NW Spain (Eiras-Barca 2018)](https://nhess.copernicus.org/articles/18/1633/2018/)\n- #PAPER [Predictive skill for atmospheric rivers in the western Iberian Peninsula (Ramos 2020)](https://nhess.copernicus.org/articles/20/877/2020/)\n- #PAPER [Atmospheric Rivers and Associated Precipitation over France and Western Europe: 1980–2020 Climatology and Case Study (Doiteau 2021)](https://www.mdpi.com/2073-4433/12/8/1075)\n\n### Extreme events and Climate Change\n- [Extreme Climate and Weather Events in a Warmer World](https://kids.frontiersin.org/articles/10.3389/frym.2022.682759)\n- [Wildfires and Climate Change](https://www.c2es.org/content/wildfires-and-climate-change/)\n- [Commentary: How summer 2021 has changed our understanding of extreme weather](https://www.channelnewsasia.com/commentary/commentary-how-summer-2021-has-changed-our-understanding-extreme-weather-2098356)\n- [Extreme weather: How is it connected to climate change?](https://www.bbc.com/news/science-environment-58073295)\n- [Yes, climate change can affect extreme weather – but there is still a lot to learn](https://theconversation.com/yes-climate-change-can-affect-extreme-weather-but-there-is-still-a-lot-to-learn-136003)\n- [Is the weather actually becoming more extreme? - R. Saravanan (TED, POPSCI)](https://www.youtube.com/watch?v=NCPTbfQyMt8)\n- [Attributing extreme weather toclimate change (interactive map of studies worldwide)](https://www.carbonbrief.org/mapped-how-climate-change-affects-extreme-weather-around-the-world?utm_content=buffer4760c)\n- [ClimExtreme - A research network on climate change and extreme events](https://www.climxtreme.net)\n\t- https://www.xces.dkrz.de/\n\n\n## References - ML\n- #PAPER [Machine Learning for Projecting Extreme Precipitation Intensity for Short Durations in a Changing Climate (Hu 2019)](https://www.mdpi.com/2076-3263/9/5/209/htm)\n- #PAPER [Extreme precipitation events under climate change in the Iberian Peninsula (Cardoso, 2019)](https://rmets.onlinelibrary.wiley.com/doi/10.1002/joc.6269 )\n\t- https://www.researchgate.net/publication/335040085_Extreme_Precipitation_Events_under_Climate_Change_in_the_Iberian_Peninsula\n\n### Supervised learning approaches\nSee [[AI/Supervised Learning/Supervised learning]] \n- #PAPER [Application of Deep Convolutional Neural Networks for Detecting Extreme Weather in Climate Datasets (Liu 2016)](https://arxiv.org/abs/1605.01156)\n\t- Detecting extreme events in large datasets is a major challenge in climate science research.   \n\t- Current algorithms for extreme event detection are build upon human expertise in defining events based on subjective thresholds of relevant physical variables\n\t- Developed deep [[AI/Deep learning/CNNs]] classification system and demonstrated the usefulness of [[AI/Deep learning/DL]]  technique  for  tackling  climate  pattern  detection problems\n\t- Achieved 89%-99% of accuracy in detecting extreme events (Tropical Cyclones, Atmospheric Rivers and Weather Fronts)\n- #PAPER [Resolution Reconstruction of Climate Data with Pixel Recursive Model (Kim 2017)](https://ieeexplore.ieee.org/document/8215679)\n\t- https://www.researchgate.net/publication/322001089_Resolution_Reconstruction_of_Climate_Data_with_Pixel_Recursive_Model\n\t- CNNs to detect extreme climate events without handcrafted algorithmic definition: detect and localize tropical cyclone in GCM scaled low resolution reanalysis data, which suggests the possibility to reduce the computing load of conventional expensive downscaling process\n\t- Combined pixel recursive super resolution techniques with localization CNNs to achieve better SR performance and to improve localization accuracy\n\t- Implemented distributed training in pixel recursive module to fasten training using GPU\n- #PAPER [Segmenting and Tracking Extreme Climate Events using Neural Networks (Mudigonda 2017)](https://www.semanticscholar.org/paper/Segmenting-and-Tracking-Extreme-Climate-Events-Mudigonda-Kim/44c74b5a8dab90153dd81394d43a9de718478dbd)\n\t- https://dl4physicalsciences.github.io/files/nips_dlps_2017_20.pdf\n- #PAPER [Leveraging LSTM for rapid intensifications prediction of tropical cyclones (Gong Li 2017)](https://www.semanticscholar.org/paper/Leveraging-LSTM-for-rapid-intensifications-of-Li-Yang/bcd623da4eed9197dd1a25f69d496171c99a1cce)\n\t- TC intensity forecasting helps people prepare for the extreme weather and could save lives and properties. Rapid Intensifications (RI) of TCs are the major error sources of TC intensity forecasting\n\t- Experiments show that the long short-term memory (LSTM) network provides the ability to leverage past conditions to predict TC rapid intensifications\n\t- SHIPS (DeMaria and Kaplan 1994) database is chosen for this study as it contains most well-known environmental predictors relevant  to  TC  intensity  changes,  such  as  Reynolds  SST  (sea surface temperature), SLP (sea level pressure). \n\t- These predictor values are from reanalysis fields as well as satellite derived variable values and stored as a text file in ASCII format\n\t- According  to  the  definition  of  RI,  if  the  maximum  wind increased more than 30 knots (15.4 m/s) over the past 24 hours (Kaplan and DeMaria 2003), the record is marked as RI case, otherwise, it is labeled UNRI\n- #PAPER [A machine learning workﬂow for hurricane prediction (Kahira 2018)](https://upcommons.upc.edu/handle/2117/124992)\n\t- #BSC LP Caron, Leonardo Bautista \n- #PAPER [Training deep neural networks with low precision input data: a hurricane prediction case study (Kahira 2018)](https://upcommons.upc.edu/handle/2117/132833)\n- #PAPER [Fused DL for Hurricane Track Forecast from Reanalysis Data (Giffard-Roisin 2018)](https://www.semanticscholar.org/paper/Fused-Deep-Learning-for-Hurricane-Track-Forecast-Giffard-Roisin-Yang/6aad16c4cfc5bf73f74671dddd01a47f63e71e30)\n- #PAPER [Lightning Prediction for Australia Using Multivariate Analyses of Large-Scale Atmospheric Variables (Bates 2018)](https://journals.ametsoc.org/jamc/article/57/3/525/68263/Lightning-Prediction-for-Australia-Using)\n- #PAPER [Defining heatwave thresholds using an inductive machine learning approach (Park and Kim, 2018)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206872)\n\t- Establishing appropriate heatwave thresholds is important in reducing adverse human health consequences as it enables a more effective heatwave warning system and response plan\n\t- This paper defined such thresholds by focusing on the non-linear relationship between heatwave outcomes and meteorological variables as part of an inductive approach\n\t- Daily data on emergency department visitors who were diagnosed with heat illnesses and information on 19 meteorological variables were obtained for the years 2011 to 2016 from relevant government agencies\n\t- A Multivariate Adaptive Regression Splines (MARS) analysis was performed to explore points (referred to as “knots”) where the behaviour of the variables rapidly changed\n- #PAPER [Predicting Hurricane Trajectories using a Recurrent Neural Network (Alemany 2018)](http://arxiv.org/abs/1802.02548)\n- #PAPER [Exascale DL for Climate Analytics (Kurth 2018)](https://arxiv.org/abs/1810.01993)\n\t- #CODE https://github.com/sparticlesteve/climate-seg-benchmark\n\t- #TALK [Exascale Deep Learning for Climate Analytics (Thorsten Kurth, Lawrence Berkeley National Laboratory, TF Dev Summit ‘19)](https://www.youtube.com/watch?v=4uq9OODJpO0)\n\t\t- Climate change will have fundamental socio-economic impact and it is imperative for us to understand it better. This talk will show how TensorFlow was utilized on the world’s fastest supercomputer in order to extract pixel level segmentation masks of extreme weather phenomena in climate simulation data, thereby enabling climate scientists to perform high-fidelity, fine grained geo-spatial analyses of the effects of climate change \n\t- DeepLabv3 — Atrous Convolution (Semantic Segmentation) \n\t\t- https://towardsdatascience.com/review-deeplabv3-atrous-convolution-semantic-segmentation-6d818bfd1d74 \n\t\t- https://towardsdatascience.com/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5 \n- #PAPER [DeepTC: ConvLSTM Network for Trajectory Prediction of Tropical Cyclone using Spatiotemporal Atmospheric Simulation Data (Kim 2018)](https://www.semanticscholar.org/paper/DeepTC%3A-ConvLSTM-Network-for-Trajectory-Prediction-Kim-Kang/e342082b0a9581a89360e4327d241684ec4fc8c6)\n- #PAPER [Deep-Hurricane-Tracker - Tracking and Forecasting Extreme Climate Events (Kim 2019)](https://ieeexplore.ieee.org/document/8658402)\n\t- http://www.joonseok.net/papers/wacv19.pdf\n\t- #CODE https://github.com/kim79sookyung/hurricane_detection_cnn\n\t- Convolutional LSTM (ConvLSTM)-based spatio-temporal models to track and predict hurricane trajectories from large-scale climate data. To address the tracking problem, we model time-sequential density maps of hurricane trajectories, enabling to capture not only the temporal dynamics but also spatial distribution of the trajectories. Furthermore, we introduce anew trajectory prediction approach as a problem of sequential forecasting from past to future hurricane density map sequences  \n\t- CAM5 (zonal wind (U850), meridional wind(V850),  and precipitation (PRECT)) and TECA labels (automated heuristics)\n\t- http://www.joonseok.net/papers/deep_tracker.pdf (Climate informatics 2018)\n- #PAPER [Improving Atmospheric River Forecasts With Machine Learning (Chapman 2019)](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019GL083662)\n- #PAPER [High Resolution Forecasting of Heat Waves impacts on Leaf Area Index by Multiscale Multitemporal Deep Learning (Gobbi 2019)](https://arxiv.org/abs/1909.07786)\n- #PAPER [A hybrid CNN-LSTM model for typhoon formation forecasting (Cheng 2019)](https://www.semanticscholar.org/paper/A-hybrid-CNN-LSTM-model-for-typhoon-formation-Chen-Wang/41dc8080372075d3f29df7fb43bf326bbf9900d1)\n\t- Traditional numerical forecast models based on fluid mechanics have difficulty in predicting the intensity of typhoons. Forecasts based on statistics and machine learning fail to take into account the spatial and temporal relationships among typhoon formation variables leading to weaknesses in the predictive power of this model\n\t- Proposed a hybrid model, which we argue, can produce a more realist and accurate account of typhoon ‘behavior’ as it focuses on both the spatio-temporal correlations of atmospheric and oceanographic variables\n\t- The CNN-LSTM model introduces 3D convolutional neural networks (3DCNN) and 2D convolutional neural networks (2DCNN) as a method to better understand the spatial relationships of the features of typhoon formation. LSTM is used to examine the temporal sequence of relations in typhoon progression\n- #PAPER [Deep Learning for Spatially Explicit Prediction of Synoptic-Scale Fronts (Lagerquist, 2019)](https://journals.ametsoc.org/waf/article/34/4/1137/344706/Deep-Learning-for-Spatially-Explicit-Prediction-of)\n\t- This paper describes the use of [[AI/Deep learning/CNNs]], a type of deep learning, to identify fronts in gridded data, followed by a novel postprocessing method that converts probability grids to objects\n\t- Synoptic-scale fronts are often associated with extreme weather in the mid latitudes\n\t- Predictors are 1000-mb (1 mb = 1 hPa) grids of wind velocity, temperature, specific humidity, wet-bulb potential temperature, and/or geopotential height from the North American Regional Reanalysis\n\t- Labels are human-drawn fronts from Weather Prediction Center bulletins\n\t- To evaluate our system, we compare the objects (predicted warm and cold fronts) with human-analyzed warm and cold fronts, matching fronts of the same type within a 100- or 250-km neighborhood distance. At 250 km our system obtains a probability of detection of 0.73, success ratio of 0.65 (or false-alarm rate of 0.35), and critical success index of 0.52. These values drastically outperform the baseline, which is a traditional method from numerical frontal analysis\n- #PAPER [High Resolution Forecasting of Heat Waves impacts on Leaf Area Index by Multiscale Multitemporal Deep Learning (Gobbi 2019)](http://arxiv.org/abs/1909.07786v1)\n- #PAPER [Make Thunderbolts Less Frightening -- Predicting Extreme Weather Using Deep Learning (Schon 2019)](https://arxiv.org/abs/1912.01277v2)\n- #TALK [Probabilistic Detection of Extreme Weather Using Deep Learning Methods (Mahesh 2019)](https://ams.confex.com/ams/2019Annual/webprogram/Paper354370.html)\n\t- Atmospheric rivers (ARs) are a particularly challenging class of extreme weather event, since there is no single community-accepted AR identification algorithm\n\t- To represent the uncertainty expressed by contemporary, state-of-the-science AR tracking methods, we create probabilistic AR detection fields from 14 algorithms submitted to the Atmospheric River Tracking Method Intercomparison Project (ARTMIP). Each algorithm identifies grid cells associated with ARs in over 30 years of 3-hourly data from the MERRA reanalysis\n\t- Estimated each grid cell’s probability of AR detection as the proportion of ARTMIP algorithms that identify an AR in that grid cell \n\t- [[AI/Deep learning/CNNs]] segmentation model used to generate probabilistic AR identifications that are quite close to the ARTMIP mean, with an average RMSE of 0.03\n- #PAPER [DeepRI: End-to-end Prediction of Tropical Cyclone Rapid Intensification from Climate Data (Jing 2019)](https://www.semanticscholar.org/paper/DeepRI%3A-End-to-end-Prediction-of-Tropical-Cyclone-Jing/985bf8e2cb37ddfab7a912f596156018bc737e7c)\n\t- NeurIPS 2019\n\t- TC track forecasting has improved significantly in the past decades, intensity forecasting still shows large forecast error, largely due to the challenge in predicting TC rapid intensification\n\t- Rapid intensification (RI) is the significant strengthening in storm wind speed within a short time(e.g. \u003e30 kt over 24 hours), and almost all historical category 4 and 5 hurricanes are RI storms\n\t- Data from multiple resources including visible and infrared satellite imagery provided by operational geostationary satellites and passive microwave imagery from polar-orbiting satellites. Augmented with synthetic data from climate model projections, such as HiFLOR, which is able to simulate Category 4 and 5 TCs\n\t- Trained separate models for RI prediction for different lead-time, i.e. 6h, 12h, 18h, 24h, and create corresponding training data sets respectively.  For each lead-time, we split independent TCs into training and test split to prevent potential correlations. Overall, this gives us by estimation roughly4000 TCs in training set, and each TC provides a series of pairs of feature map and ground truth binary label indicating whether RI happens. \n- #PAPER [Machine Learning for Generalizable Prediction of Flood Susceptibility (Sidrane 2019)](https://arxiv.org/abs/1910.06521)\n- #PAPER [Forecasting El Niño with Convolutional and Recurrent Neural Networks (Mahesh 2019)](https://www.researchgate.net/publication/343794841)\n- #PAPER [Spherical CNNs on unstructured grids (Jiang 2019)](https://arxiv.org/abs/1901.02039)\n\t- #CODE https://github.com/maxjiang93/ugscnn\n\t- Based on https://github.com/jonas-koehler/s2cnn\n- #PAPER [A mixed model approach to drought prediction using artificial neural networks: Case of an operational drought monitoring environment (Adede 2019)](https://arxiv.org/abs/1901.04927)\n\t- The study uses 10 precipitation and vegetation variables that are lagged over 1, 2 and 3-month time-steps to predict drought situations\n\t- In the model space search for the most predictive artificial neural network (ANN) model, as opposed to the traditional greedy search for the most predictive variables, we use the General Additive Model (GAM) approach\n- #PAPER [Tropical Cyclone Track Forecasting using Fused Deep Learning from Aligned Reanalysis Data (Giffard-Roisin 2020)](https://arxiv.org/abs/1910.10566)\n\t- Proposed a neural network model fusing past trajectory data and reanalysis atmospheric images (wind and pressure 3D fields)\n\t- Used a moving frame of reference that follows the storm center for the 24h tracking forecast\n\t- Model trained to estimate the longitude and latitude displacement of tropical cyclones and depressions from a large database from both hemispheres (more than 3000 storms since 1979, sampled at a 6 hour frequency)\n- #PAPER [Tropical and Extratropical Cyclone Detection Using Deep Learning (Kumler-Bonfanti 2020)](https://arxiv.org/abs/2005.09056)\n\t- U-Net trained with IBTrACS labels on GOES water vapor\n\t- #TALK ML for Segmentation of Atmospheric Phenomena (Jebb Stewart, NOAA ESRL)\n\t\t- https://www.youtube.com/watch?v=mQ3jAxMmeRU\u0026list=PLbelYhZAAHEIr4iC1FNcPXUUYXI0zg_96\u0026index=14\u0026t=0s\n\t\t- https://www2.cisl.ucar.edu/sites/default/files/1010%20June%2024%20Stewart%20%281%29.pdf\n- #PAPER [Tropical and Extratropical Cyclone Detection Using Deep Learning (Kumler-Bonfanti 2020)](https://arxiv.org/abs/2005.09056v1)\n\t- This paper discusses four different state-of-the-art U-Net models designed for detection of tropical and extratropical cyclone Regions Of Interest (ROI) from two separate input sources: total precipitable water output from the Global Forecasting System (GFS) model and water vapor radiance images from the Geostationary Operational Environmental Satellite (GOES)\n\t- These models are referred to as IBTrACS-GFS, Heuristic-GFS, IBTrACS-GOES, and Heuristic-GOES. All four U-Nets are fast information extraction tools and perform with a ROI detection accuracy ranging from 80% to 99%\n\t- These are additionally evaluated with the Dice and Tversky Intersection over Union (IoU) metrics, having Dice coefficient scores ranging from 0.51 to 0.76 and Tversky coefficients ranging from 0.56 to 0.74\n- #PAPER [Improving Emergency Response during Hurricane Season using Computer Vision (Bosch 2020)](https://arxiv.org/abs/2008.07418v2)\n- #PAPER [Spatio-temporal segmentation and tracking of weather patterns with light-weight Neural Networks (Kapp-Schwoerer 2020)](https://ai4earthscience.github.io/neurips-2020-workshop/papers/ai4earth_neurips_2020_55.pdf)\n\t- Uses the ClimateNet [[AI4ES/AI4ES data#Extreme events labeled data]] and the CGNet architecture [[Semantic segmentation]]\n\t- Weather pattern recognition by deep neural networks can work remarkably better than feature engineering, such as hand-crafted heuristics, used traditionally in climate science\n\t- Deep Learning - based semantic segmentation of atmospheric rivers and tropical cyclones on the expert-annotated ClimateNet data set, and track individual events using a spatio-temporal overlapping approach\n- #PAPER [HydroDeep -- A Knowledge Guided Deep Neural Network for Geo-Spatiotemporal Data Analysis (Sarkar 2020)](https://arxiv.org/abs/2010.04328)\n\t- Application to floods\n\t- This paper demonstrates a neural network architecture (HydroDeep) that couples a process-based hydro-ecological model with a combination of Deep Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) Network to build a hybrid baseline model\n- #PAPER [Graph Neural Networks for Improved El Niño Forecasting (Ruhling Cachay 2020)](https://arxiv.org/abs/2012.01598)\n\n### Semi-supervised learning approaches\nSee [[AI/Semi-supervised learning]]\n- #PAPER [Analog forecasting of extreme-causing weather patterns using deep learning (Chattopadhyay, 2020)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019MS001958) ^d42267\n\t- LENS data (CESM1 model), [[AI/Deep learning/CapsNets]] and [[AI/Deep learning/CNNs]], extreme temperature events\n\t- CapsNets are trained on midtropospheric large‐scale circulation patterns (Z500) labeled 0–4 depending on the existence and geographical region of surface temperature extremes over North America several days ahead\n\t- Impact‐based autolabeling strategy: Knowing the surface temperature over North America on a given day, the Z500 pattern of several days earlier is labeled as 0 (no extreme onset) or 1, 2, 3, or 4 (the cluster indices of T2m extremes)\n\t- The trained networks predict the occurrence/region of cold or heat waves, only using Z500, with accuracies (recalls) of 69–45% (77–48%) or 62–41% (73–47%) 1–5 days ahead\n\n### Unsupervised learning\nSee [[AI/Unsupervised learning/Unsupervised learning]]\n- #PAPER [Spatial clustering of summer temperature maxima from the CNRM-CM5 climate model ensembles \u0026 E-OBS over Europe (Bador 2015)](https://www.sciencedirect.com/science/article/pii/S2212094715300013)\n- #PAPER [Multiscale Variability in North American Summer Maximum Temperatures and Modulations from the North Atlantic Simulated by an AGCM (Vigaud 2018)](https://journals.ametsoc.org/jcli/article/31/7/2549/89965/Multiscale-Variability-in-North-American-Summer) ^25cb40\n- #PAPER [DisCo: Physics-Based Unsupervised Discovery of Coherent Structures in Spatio-temporal Systems (Rupe, 2019)](https://arxiv.org/abs/1909.11822)\n\t- #CODE https://github.com/adamrupe/DisCo\n- #PAPER [Towards Unsupervised Segmentation of Extreme Weather Events (Rupe, 2019)](https://arxiv.org/abs/1909.07520)\n\t- Tests on CAM5.1 water vapor data -\u003e extreme weather identification from unlabeled climate model simulation data\n\t- While the results in using TECA show that DL can improve upon it, the accuracy rates reach 97% and thus essentially just reproduce the output of TECA\n\t- Though an improvement over automated heuristics, expert-labeled data is still not an objective ground truth\n\t- To circumvent these challenges of DL-based approaches, here we take an alternative physics-based unsupervised approach, complementary to DL\n\n### Probabilistic approaches\n- #PAPER [Bayesian Anomaly Detection and Classification (Roberts, 2019)](https://arxiv.org/abs/1902.08627)\n- #PAPER [A probabilistic gridded product for daily precipitation extremes over  the United States (Risser 2019)](https://arxiv.org/pdf/1807.04177)\n- #PAPER [Detection Uncertainty Matters for Understanding Atmospheric Rivers (Obrien 2020)](https://journals.ametsoc.org/view/journals/bams/101/6/BAMS-D-19-0348.1.xml)\n- #PAPER [Probabilistic forecasts of extreme heatwaves using convolutional neural networks in a regime of lack of data (Miloshevich 2022)](https://arxiv.org/abs/2208.00971)\n\t- Demonstrate that DNNs have the ability to predict the probability of occurrence of long lasting 14-day heatwaves over France, up to 15 days ahead of time for fast dynamical drivers (500 hPa geopotential height fields), and also at much longer lead times for slow physical drivers (soil moisture)\n\t- Used a 8,000-year dataset obtained from the Planet Simulator (PlaSim) climate model. The PlaSim model has physical parameterizations that are of a lesser quality compared to up-to-date climate models which are used for CMIP experiment\n\t- Softmax parametrization is a way to output probabilities associated with a discrete variable\n\t- Used a definition of heatwaves that actually involves a measure related to both the persistence and the amplitude of air temperature close to the ground. We thus define heatwave as time and area average of daily 2-meter temperature\n\t- 3-layer CNN with ReLU activations and maxpool in between -\u003e dense layer -\u003e 2 outputs. Softmax function (not sigmoid? what about calibration of \"probabilities\")\n\n### Active learning approaches\nSee [[AI/Active learning]]\n- #PAPER [Incorporating Expert Feedback into Active Anomaly Discovery (Das, 2016)](http://web.engr.oregonstate.edu/~tgd/publications/das-wong-dietterich-fern-emmott-incorporating-expert-feedback-into-active-anomaly-discovery-icdm2016.pdf)\n- #PAPER [Incorporating Feedback into Tree-based Anomaly Detection (2017)](https://arxiv.org/abs/1708.09441)\n\n### GANs-based approaches\nSee [[AI/Deep learning/GANs]]\n- #PAPER [Learning to Focus and Track Extreme Climate Events (Kim 2019)](https://bmvc2019.org/wp-content/uploads/papers/0728-paper.pdf)\n- #PAPER [Visualizing the Consequences of Climate Change Using Cycle-Consistent Adversarial Networks (Schmidt 2019)](https://arxiv.org/abs/1905.03709)\n- #PAPER [ExGAN: Adversarial Generation of Extreme Samples (Bhatia 2021)](https://arxiv.org/abs/2009.08454)\n\t- #CODE https://github.com/Stream-AD/ExGAN\n\t- https://www.kdnuggets.com/2021/02/adversarial-generation-extreme-samples.html\n\n### Causality studies\n- [[Causal modeling in ES#^d43897]]\n- [[Causal modeling in ES#^c4333d]]\n\n### Droughts\n- #PAPER [Construction of Comprehensive Drought Monitoring Model in Jing-Jin-Ji Region Based on Multisource Remote Sensing Data (Yu 2019)](https://www.mdpi.com/2073-4441/11/5/1077)\n- #PAPER [Meteorological drought forecasting based on a statistical model with machine learning techniques in Shaanxi province, China (Zhang 2019)](https://www.sciencedirect.com/science/article/pii/S0048969719302281)\n- #PAPER [Using LSTMs for climate change assessment studies on droughts and floods (Krazert 2019)](https://arxiv.org/abs/1911.03941)\n- #PAPER [Construction of a drought monitoring model using deep learning based on multi-source remote sensing data (Shen 2019)](https://www.sciencedirect.com/science/article/abs/pii/S0303243418307803)\n- #PAPER [A Global Probabilistic Dataset for Monitoring Meteorological Droughts (Turco 2020)](https://journals.ametsoc.org/bams/article/101/10/E1628/345597/A-Global-Probabilistic-Dataset-for-Monitoring)\n\t- #BSC Markus Donat\n\n### Wildfires\n- #PAPER [Mapping regional forest fire probability using artificial neural network model in a Mediterranean forest ecosystem (Satir 2015)](https://www.tandfonline.com/doi/full/10.1080/19475705.2015.1084541) \n- #PAPER [Global Wildfire Outlook Forecast with Neural Networks (Song 2020)](https://www.mdpi.com/2072-4292/12/14/2246/htm)\n- #PAPER [Physics-Informed Machine Learning Simulator for Wildfire Propagation (Bottero 2020)](https://arxiv.org/abs/2012.06825v1) \n- #PAPER [Convolutional LSTM Neural Networks for Modeling Wildland Fire Dynamics (Burge 2021)](https://arxiv.org/abs/2012.06679v2) \n\n### Extreme events and climate change\n- #PAPER [Fingerprinting Heatwaves and Cold Spells and Assessing Their Response to Climate Change Using Large Deviation Theory (Galfi and Licarini 2021)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.127.058701)\n\t- https://phys.org/news/2021-08-fingerprints-extreme-weather-revealed-statistical.html\n\n#### Attribution studies\n- Attribution studies remain our best (and only) tool for understanding the impact of climate change on extreme weather and on our daily lives. They play a key role in helping [decision makers plan for, or avoid, a future where extreme weather events](https://www.climatecentre.org/news/1253/climate-attribution-work-in-mit-review-ten-a-breakthrough-technologiesa-for-2020) are more likely and intense due to global warming.\n- Attribution studies are also really important within climate science as they bridge the gap between observations and model projections. They test climate models in a real-world context, allowing scientists to understand better where they can have more confidence in their projections and where model improvements are needed before projections can be used for decision making.\n- https://science2017.globalchange.gov/chapter/3/\n- [Detection and Attribution Methodologies Overview](https://science2017.globalchange.gov/chapter/appendix-c/)\n- #PAPER [Precipitation downscaling under climate change: Recent developments to bridge the gap between dynamical models and the end user (2010)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2009RG000314)\n- #PAPER [Detection and attribution of climate extremes in the observed record (Easterling 2016)](https://www.sciencedirect.com/science/article/pii/S2212094716300020)\n- #PAPER [Adapting attribution science to the climate extremes of tomorrow (Harrington 2018)](https://iopscience.iop.org/article/10.1088/1748-9326/aaf4cc)\n- #PAPER [Investigating the Role of the Relative Humidity in the Co‐Occurrence of Temperature and Heat Stress Extremes in CMIP5 Projections (2019)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019GL084156)\n- #PAPER [Towards reliable extreme weather and climate event attribution (Bellprat 2019)](https://www.nature.com/articles/s41467-019-09729-2)\n\t- Showed how exploiting advanced correction techniques from the weather forecasting field, that correcting properly for model probabilities alters the attributable risk of extreme events to climate change. \n\t- This study illustrates the need to correct for this type of model error in order to provide trustworthy assessments of climate change impacts.","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Filling-observational-gaps":{"title":"Filling observational gaps","content":"\u003e See [[AI/Computer Vision/Inpainting and restoration]]\n\n## References\n- #PAPER [Inpainting of Remote Sensing SST Images With Deep Convolutional Generative Adversarial Network (Dong 2018)](https://ieeexplore.ieee.org/document/8480867/authors#authors)\n- #PAPER [Unsupervised Inpainting for Occluded Sea Surface Temperature Sequences (Yin et al., 2019)](https://ieeexplore.ieee.org/document/8019401)\n\t- #CODE https://github.com/yuan-yin/UNISST \n\t- [Unsupervised Spatiotemporal Data Inpainting](https://openreview.net/forum?id=rylqmxBKvH)\n- #PAPER [Artificial intelligence reconstructs missing climate information (Kadow 2020)](https://doi.org/10.1038/s41561-020-0582-5)\n\t- https://ecmwfevents.com/assets/posters/machine-learning-ws-kadow1601285092.pdf\n\t- #CODE https://github.com/FREVA-CLINT/climatereconstructionAI\n- #PAPER [Predicting into unknown space? Estimating the area of applicability of spatial prediction models (Meyer 2020)](https://arxiv.org/abs/2005.07939)\n\t- #CODE https://github.com/HannaMeyer/AOA_CaseStudy\n- #PAPER [CLIMFILL v0.9: a framework for intelligently gap filling Earth observations (Bessenbacher 2022)](https://gmd.copernicus.org/articles/15/4569/2022/)\n\t- #CODE https://github.com/climachine/climfill\n\t- CLIMFILL fills gaps in gridded geoscientific observational data by taking into account spatial neighborhood, temporal context and multivariate dependencies. It takes a multivariate dataset with any number and pattern of missing values per variable and returns the dataset with all missing points replaced by estimates\n- #PAPER [Positional Encoder Graph Neural Networks for Geographic Data (Klemmer 2022)](https://arxiv.org/pdf/2111.10144)\n\t- #CODE https://github.com/konstantinklemmer/pe-gnn","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Geospatial-science":{"title":"Geospatial science, geoinformatics","content":"\u003e Geospatial sciences covers the technical disciplines used to collect and analyse information tied to a location and time – in essence this is all forms of data (biophysical, human, social and economic) across many discipline areas\n\n\u003e See [[AI4ES/EO]]\n\n## Resources\n- [Geospatial Artificial Intelligence: Emerging Trends and Challenges](https://www.gislounge.com/geospatial-artificial-intelligence-emerging-trends-challenges/)\n- [Geospatial science](https://sees.uq.edu.au/research/themes/geospatial-science)\n\n## Events\n- [SIGSpatial](https://dl.acm.org/sig/sigspatial)\n- [GeoAI workshops ata SIGSpatial](https://geoai.ornl.gov/acmsigspatial-geoai/)\n- [GeoPython 2022](https://2022.geopython.net/)\n\t- https://submit.geopython.net/geopython-2022/schedule/\n\n## Code\n- https://sungsoo.github.io/2021/09/02/geospatial-python.html\n- #CODE [Geopandas](https://github.com/geopandas/geopandas)\n\t- Python tools for geographic data\n\t- http://geopandas.readthedocs.io/\n- #CODE [Shapely](https://github.com/shapely/shapely)\n\t- Manipulation and analysis of geometric objects\n\t- https://shapely.readthedocs.io/en/stable/manual.html\n\n## References\n- Special Issue \"[Geospatial Artificial Intelligence](https://www.mdpi.com/journal/ijgi/special_issues/geo_ai)\"\n- #PAPER [Emerging trends in geospatial artificial intelligence (geoAI): potential applications for environmental epidemiology (VoPham 2018)](https://ehjournal.biomedcentral.com/articles/10.1186/s12940-018-0386-x)\n- #PAPER [GeoAI: spatially explicit artificial intelligence techniques for geographic knowledge discovery and beyond (Janowicz 2019)](https://www.tandfonline.com/doi/full/10.1080/13658816.2019.1684500)\n- #PAPER [GeoAI: a review of artificial intelligence approaches for the interpretation of complex geomatics data (Pierdicca 2022)](https://gi.copernicus.org/articles/11/195/2022/)\n- #PAPER [A Review of Location Encoding for GeoAI: Methods and Applications (Mai 2022)](https://arxiv.org/pdf/2111.04006)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/HPC-AI-convergence":{"title":"HPC-AI convergence","content":"\u003e See:\n\u003e - [[AI4ES/AI4ES data]]\n\u003e - [[AI4ES/Pangeo]]\n\n## Resources\n- #TALK [Innovator Insights: HW \u0026 SW Platforms for HPC, AI and ML](https://www.youtube.com/watch?v=g4gNb5sEqyM)\n- #TALK [HPC + AI: Machine Learning Models in Scientific Computing](https://www.youtube.com/watch?time_continue=1\u0026v=SV3cnWf39kc\u0026feature=emb_title)\n\t- https://es.slideshare.net/insideHPC/hpc-ai-machine-learning-models-in-scientific-computing\n\n- The increasing interest in the usage of [[Machine Learning]] (ML) and Artificial Intelligence techniques ([[AI]]) to tackle high-impact research problems requires High Performance Computing (HPC) resources to efficiently compute and scale complex algorithms across thousands of nodes (Brayford et al. 2019). A diverse group of disciplines could be impacted by the integration of HPC and AI, especially those dealing with massive quantities of multi-dimensional data such as high energy physics, astrophysics and medical imaging.  \n- The Barcelona Supercomputing Center (BSC), is in a privileged position for developing an AI centered research strategy thanks to, not only its vast expertise with HPC and running one of the largest supercomputers in Europe (the MareNostrum 4), but to the diverse and rich network of Machine Learning projects spread among its several departments. In particular, for the Earth Science department, it is of critical importance the extraction of knowledge from PB-sized databases coming from observations, numerical modeling, simulations, and other sources. \n\n### HPC vs AI programming models \n- One of the main challenges in the convergence of HPC and AI is the gap between programming models. \n- The worlds of HPC and AI deal with different computing paradigms or programming models. On one hand, for HPC it is the norm to use well tested and closed source code written in low-level languages (C, Fortran), distributed computing API's (MPI, OpenMPI), the command line and workload managers (SLURM), and systems that grant users restricted administrator privileges (no connection to external systems). On the other, in ML/AI fields the applications are usually developed using high-level scripting languages or frameworks (Python, Julia, Tensorflow) that usually address the challenges of writing performant and distributed code, and heavily relying on open source libraries which need to be downloaded from external sources (internet). The way ML applications are developed requires an interactive computing platform where new models could be tested and validated quickly without the overhead of restrictive administrative rules (very often related to security measures).The interactive computing paradigm implies code development, real-time exploratory data analytics, and visualizations of inputs and results. The design of ML models, opposed to calling pre-coded numerical models, requires a lot of experimentation.  \n- The most recent family of ML algorithms, based on deep neural networks (Deep Learning, DL), has become the workhorse of AI. In order to handle complex problems, DL relies on training increasingly bigger deep networks on large amounts of data, which usually make use of specialized hardware, such as Graphical Processing Units (GPU).  \n\n### Interactive computing and containers \n- [[AI/DS and DataEng/Data Science]] and ML require interactive/exploratory computing platforms and more flexible environments that allow on-the-fly software stack modifications (the installation of new libraries) and reproducibility of these software stacks. For Python this could be achieved with Pipenv or Conda (without sudo). However, a more general solution is to use containers, which are a combination of Kernel \"cgroups\" and \"namespaces\" to create isolated environments. Docker provided a complete tool chain to simplify using containers from build to run. Containers address a few of the aspects described before, which are very relevant to modern scientific computing: reusability, collaboration, reproducibility and portability.  Unfortunately, some of the characteristics of Docker prevent from it being in HPC systems:  \n\t- Uses an all or nothing security model, which would grant users with system privilege. \n\t- It does not play well with batch systems, \n\t- Assumes a local disk. \n\t- Requires a very modern kernel. \n\t- Its adoption would imply adding new layers of complexity to the HPC systems. \n- In order to deal with the security and integration issues of Docker, several HPC container systems were created. Usually these container solutions are backwards compatible with Docker, and among them the most widespread and mature are: \n\t- [Shifter](https://github.com/NERSC/shifter) \n\t\t- developed at NERSC to enable Docker images to be securely executed on a HPC ecosystem, enabling user independence, shared resource availability and high security1\n\t- [Singularity](https://github.com/sylabs/singularity)\n\t\t- very popular container used in many supercomputing centers, with a similar runtime compared to Shifter\n\t- [Charliecloud](https://github.com/hpc/charliecloud)\n\t\t- light-weight container system developed at LANL with high standards of security\n\n#### Talks\n- #TALK [Reproducible Science with Containers on HPC through Singularity](https://insidehpc.com/2019/02/video-reproducible-science-with-containers-on-hpc-through-singularity/)\n- #TALK Containers in HPC. IDEAS webinar by Shane Canon \n\t- http://ideas-productivity.org/wordpress/wp-content/uploads/2019/02/webinar026-containers.pdf \n\t- https://www.youtube.com/watch?v=vzHnIS-bQQY \n- #TALK [Distributed HPC Applications with Unprivileged Containers](https://insidehpc.com/2020/02/distributed-hpc-applications-with-unprivileged-containers/)\n- Container technologies:\n\n### Jupyter project \nSee [[AI/DS and DataEng/Jupyter#Jupyter in HPC]]\n- The goal of this short text is to propose solutions in order to close the gap between the programming models of HPC and AI. These solutions are based on a review of the developments done in other supercomputing centers around the world. The idea is to share this text with Kim and Paco, to hopefully motivate future discussions with the Operations department.\n\n\n## References\n- #PAPER [The Convergence of AI and HPC](https://www.intel.com/content/www/es/es/high-performance-computing/ai-hpc-is-happening-now-report.html)\n- #PAPER [Convergence of HPC and AI: 2 directions of connection (Ismayilova 2018)](http://azjhpc.org/issua2/doi.org:10.32010:26166127.2018.1.2.179.184.pdf)\n- #PAPER [Deploying AI Frameworks on Secure HPC Systems with Containers (Brayford 2019)](https://arxiv.org/abs/1905.10090)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/ML-interpretability-in-ES":{"title":"ML interpretability in ES","content":"\u003e See:\n\u003e - [[XAI]]\n\u003e - [[Causal modeling in ES]]\n\n\n## References\n- #PAPER [Physically Interpretable Neural Networks for the Geosciences: Applications to Earth System Variability (Toms 2020)](https://arxiv.org/abs/1912.01752)\n\t- Showed that the interpretation of neural networks can enable the discovery of scientifically meaningful connections within geoscientific data\n\t- Used two methods for neural network interpretation: backwards optimization and LRP. Both project the decision pathways of a network back onto the original input dimensions\n- #PAPER [Investigating the fidelity of explainable artificial intelligence methods for applications of convolutional neural networks in geoscience (Mamalakis 2022)](https://arxiv.org/abs/2202.03407)\n- #PAPER [Indicator patterns of forced change learned by an artificial neural network (Barnes 2020)](https://www.semanticscholar.org/paper/Indicator-patterns-of-forced-change-learned-by-an-Barnes-Toms/38018254d806f18352f2f3702380c18403aeef35)\n- #PAPER [Evaluation, Tuning and Interpretation of Neural Networks for Meteorological Applications (Ebert-Uphoff 2020)](https://www.semanticscholar.org/paper/Evaluation%2C-Tuning-and-Interpretation-of-Neural-for-Ebert-Uphoff-Hilburn/b31e4e9d6ba87a8e709d743b1e96a18c8dd0bbf6)\n- #PAPER [Detecting climate signals using explainable AI with single-forcing large ensembles (Labe 2021)](https://www.essoar.org/doi/10.1002/essoar.10505762.1)\n- #PAPER [Oceanic Harbingers of Pacific Decadal Oscillation Predictability in CESM2 Detected by Neural Networks (Gordon 2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021GL095392)\n- #POSTER [Mapped-PCMCI: an algorithm for causal discovery at the grid level (Tibau Alberdi 2021)](https://meetingorganizer.copernicus.org/EGU21/EGU21-5633.html)\n- #PAPER [Assessing Decadal Predictability in an Earth-System Model Using Explainable Neural Networks (Toms 2021)](https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1029/2021GL093842)\n- #PAPER [Predicting Slowdowns in Decadal Climate Warming Trends With Explainable Neural Networks (Labe 2022)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2022GL098173)\n- #PAPER [Neural network attribution methods for problems in geoscience: A novel synthetic benchmark dataset (Mamalakis 2022)](https://www.cambridge.org/core/journals/environmental-data-science/article/neural-network-attribution-methods-for-problems-in-geoscience-a-novel-synthetic-benchmark-dataset/DDA562FC7B9A2B30710582861920860E)\n\t- #CODE https://github.com/amamalak/Neural-Network-Attribution-Benchmark-for-Regression","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Pangeo":{"title":"Pangeo","content":"## Resources\n- [Pangeo - A community platform for Big Data geoscience](https://pangeo.io/)\n- https://github.com/pangeo-data/education-material\n- https://github.com/pangeo-data/awesome-open-climate-science\n- https://github.com/pangeo-data/ml-workflow-examples\n- https://github.com/pangeo-data/\n- https://discourse.pangeo.io/\n- [Pangeo Forge](https://pangeo-forge.org/)\n\t- Pangeo Forge is an open source platform for data Extraction, Transformation, and Loading (ETL). The goal of Pangeo Forge is to make it easy to extract data from traditional data repositories and deposit in cloud object storage in analysis-ready, cloud-optimized (ARCO) format\n\t- https://pangeo-forge.org/catalog\n\n\n## Code\n- #CODE [Pangeo](https://github.com/pangeo-data)\n- #CODE [Rechunker - Disk-to-disk chunk transformation for chunked arrays](https://github.com/pangeo-data/rechunker)\n\t- https://rechunker.readthedocs.io/en/latest/\n- #CODE [Climpred - Verification of weather and climate forecasts](https://github.com/pangeo-data/climpred)\n\t- https://climpred.readthedocs.io/en/stable/index.html\n\t- [Metrics for forecast verification](https://climpred.readthedocs.io/en/stable/metrics.html)\n- #CODE [xESMF: Universal Regridder for Geospatial Data](https://github.com/pangeo-data/xESMF)\n\t- https://pangeo-xesmf.readthedocs.io/en/latest/\n\t- [Comparison of 5 regridding algorithms](https://xesmf.readthedocs.io/en/latest/notebooks/Compare_algorithms.html)\n\n\n## References\n### Pangeo for HPC\n- [Pangeo for DL](https://github.com/pangeo-data/pangeo/issues/567)\n- [Streaming with Zarr](https://medium.com/pangeo/streaming-zarr-ccf0d518b1c0)\n\n-   #PAPER [The PANGEO Big Data Ecosystem and its use at CNES (Eynard-Bontemps 2019)](https://oceanrep.geomar.de/45866/)\n    -   https://medium.com/pangeo/why-and-how-we-use-pangeo-at-cnes-74553c7fb19b\n-   #PAPER [The Pangeo Ecosystem: Interactive Computing Tools for the Geosciences: Benchmarking on HPC (Odaka 2019)](https://www.springerprofessional.de/en/the-pangeo-ecosystem-interactive-computing-tools-for-the-geoscie/17832674)\n    -   https://archimer.ifremer.fr/doc/00597/70946/\n    -   #CODE https://github.com/pangeo-data/benchmarking\n\n\n### Dask\nSee [[AI/DS and DataEng/Dask]]\n```python\n    # For the dask dashboard\n\tfrom dask.distributed import Client\n\tclient = Client()\n\tdisplay(client)\n``` \n\n### Xarray\nSee [[AI/DS and DataEng/Xarray]]\n- https://medium.com/pangeo/thoughts-on-the-state-of-xarray-within-the-broader-scientific-python-ecosystem-5cee3c59cd2b\n- [Slow performance of open_mfdataset](https://github.com/pydata/xarray/issues/1385)\n\t- https://xarray.pydata.org/en/stable/io.html#reading-multi-file-datasets\n\n\n### Jupyter\nSee [[AI/DS and DataEng/Jupyter]]","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/Parameterizations":{"title":"Parameterizations","content":"\u003e See [[AI4ES/Emulators]]\n\n## Resources\n- [Parametrization (atmospheric modeling)](https://en.wikipedia.org/w/index.php?title=Parametrization_(atmospheric_modeling)\u0026oldid=917836406)\n- #TALK [Critical challenges in the simulation of tropical clouds and climate (Maloney, Climate Informatics workshop 2018)](https://www.youtube.com/watch?v=xXUe1WQKV_E\u0026t=1s  )\n- #COURSE [ ECMWF Introduction to the parametrization of sub-grid processes](https://www.ecmwf.int/assets/elearning/parametrization/param1/story_html5.html)\n- #COURSE ECMWF Cloud and precipitation parametrization \n\t- [1. overview and warm-phase microphysics](https://www.ecmwf.int/en/elibrary/18666-cloud-and-precipitation-parametrization-1-overview-and-warm-phase-microphysics)\n\t- [2. ice and mixed-phase microphysics](https://www.ecmwf.int/en/elibrary/18667-cloud-and-precipitation-parametrization-2-ice-and-mixed-phase-microphysics)\n\n\n## References\n- #PAPER [Using Ensemble of Neural Networks to Learn Stochastic Convection Parameterizations for Climate and Numerical Weather Prediction Models from Data Simulated by a Cloud Resolving Model (Krasnopolsky 2013)](https://www.hindawi.com/journals/aans/2013/485913/)\n- #PAPER [Modeling haboob dust storms in large-scale weather and climate models (Pantillon 2016)](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2015JD024349)\n- #PAPER [Stochastic Parameterization: Toward a New View of Weather and Climate Models (Berner 2017)](https://journals.ametsoc.org/bams/article/98/3/565/70029/Stochastic-Parameterization-Toward-a-New-View-of)\n- #PAPER [Deep learning to represent subgrid processes in climate models (Rasp 2018)](https://www.pnas.org/content/115/39/9684)\n- #PAPER [Challenges and design choices for global weather and climate models based on machine learning (Dueben and Bauer 2018)](https://gmd.copernicus.org/articles/11/3999/2018/)\n- #PAPER [Could Machine Learning Break the Convection Parameterization Deadlock? (Gentine 2018)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018GL078202)\n- #PAPER [Prognostic Validation of a Neural Network Unified Physics Parameterization (Brenowitz and Bretherton 2018)](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018GL078510)\n- #PAPER [Using Machine Learning to Parameterize Moist Convection: Potential for Modeling of Climate, Climate Change, and Extreme Events (O'Gorman and Dwyer 2018)](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018MS001351)\n- #PAPER [Model Parameter Optimization: ML-guided trans-resolution tuning of physical models (Nowack 2018)](https://iopscience.iop.org/article/10.1088/1748-9326/aae2be)\n- #PAPER [Applications of Deep Learning to Ocean Data Inference and Subgrid Parameterization (Bolton and Zanna 2019)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018MS001472)\n- #PAPER [A data-driven approach to precipitation parameterizations using convolutional encoder-decoder neural networks (Rozas Larraondo 2019)](http://arxiv.org/abs/1903.10274)\n\t- ERA-Interim data, precipitation as predictant\n\t- encoder-decoder [[CNNs]] can be used to derive total precipitation using geopotential height as the only input\n\t- several popular neural network architectures, from the field of image processing, are considered and a comparison with baseline [[machine learning]] methodologies is provided. UNET show best performance\n- #PAPER [Fast domain-aware neural network emulation of a planetary boundary layer parameterization in a numerical weather forecast model (Wang 2019)](https://www.geosci-model-dev.net/12/4261/2019/)\n- #PAPER [Spatially Extended Tests of a Neural Network Parametrization Trained by Coarse‐Graining (Brenowitz and Bretherton, 2019)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019MS001711)\n\t- this article describes an NN parametrization trained by coarse‐graining a near‐global CRM simulation with a 4‐km horizontal grid spacing\n\t- the NN predicts the residual heating and moistening averaged over (160 km)2 grid boxes as a function of the coarse‐resolution fields within the same atmospheric column\n- #PAPER [Machine Learning for Stochastic Parameterization: GANs in the Lorenz ’96Model (John Gagne II 2019)](https://arxiv.org/abs/1909.04711)\n\t- simulations of the atmosphere must approximate the effects of small-scale processes with simplified functions called parameterizations\n\t- standard parameterizations only predict one output for a given input, but stochastic parameterizations can sample from all the possible outcomes that can occur under certain conditions\n\t- developed a generative adversarial network machine learning stochasticparameterization of sub-grid forcing for the Lorenz ’96 dynamical mode\n\t- the generative adversarial networks closely reproduce the spatio-temporal cor-relations and regimes of the Lorenz ’96 system\n- #PAPER [Prognostic validation of a neural network unified physics parameterization (Brenowitz and Bretherton, 2020)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018GL078510)\n\t- a NN based parameterization is trained using a global-scale cloud-resolving simulation. The NN predicts the apparent sources of heat and moisture averaged onto (160 km)^2 grid boxes. A numerically stable scheme is obtained by minimizing the prediction error over multiple time steps rather than single one. In prognostic single column model tests, this scheme outperforms the Community Atmosphere Model by reducing both long-term bias and short-term errors.\n- #PAPER [Interpreting and Stabilizing Machine-learning Parametrizations of Convection (Brenowitz 2020)](https://www.semanticscholar.org/paper/Interpreting-and-Stabilizing-Machine-learning-of-Brenowitz-Beucler/a4782e1224121185e11bfa5926717e8f8cff8f0f)\n- #PAPER [Stable machine-learning parameterization of subgrid processes for climate modeling at a range of resolutions (Li 2020)](https://arxiv.org/abs/2001.03151)\n- #PAPER [Building a machine learning surrogate model for wildfire activities within a global Earth system model (Zhu 2022)](https://gmd.copernicus.org/articles/15/1899/2022/)\n\t- DNN scheme that surrogates the process-based wildfire model with the Energy Exascale Earth System Model (E3SM) interface. The DNN wildfire model accurately simulates observed burned area with over 90 % higher accuracy with a large reduction in parameterization time compared with the current process-based wildfire model\n\t- DNN: seems to be a 5-layer MLP [[AI/Deep learning/MLPs]] with softplus activation. The surrogate DNN-Fire is improved by fine-tuning the weight parameters using observations\n\t- The DNN wildfire model accurately simulates observed burned area with over 90 % higher accuracy with a large reduction in parameterization time compared with the current process-based wildfire model\n- #PAPER [Benchmarking of machine learning ocean subgrid parameterizations in an idealized model (Slavin Ross 2022)](https://www.essoar.org/doi/10.1002/essoar.10511742.1)","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/S2D":{"title":"S2D","content":"## References\n- #PAPER [Decadal Climate Predictions Using Sequential Learning Algorithms (Strobach 2016)](https://journals.ametsoc.org/view/journals/clim/29/10/jcli-d-15-0648.1.xml)\n- #PAPER [Decadal climate predictions improved by ocean ensemble dispersion filtering (Kadow 2017)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016MS000787)\n- #PAPER [Multi-year prediction of European summer drought conditions for the agricultural sector (Solaraju-Murali 2019)](https://iopscience.iop.org/article/10.1088/1748-9326/ab5043)\n\t- #BSC, LP Caron, Paco\n\t- Decadal climate prediction, where climate models are initialized with the contemporaneous state of the Earth system and run for a decade into the future, represents a new source of near-term climate information to better inform decisions and policies across key climate-sensitive sectors\n\t- This paper illustrates the potential usefulness of such predictions for building a climate service for agricultural needs\n\t- In particular, we assess the forecast quality of multi-model climate predictions in estimating two user-relevant drought indices, Standardized Precipitation Evapotranspiration Index (SPEI) and Standardized Precipitation Index (SPI), at multi-annual timescales during European summer\n- #PAPER [Current and Emerging Developments in Subseasonal to Decadal Prediction (Merryfield, 2020)](https://journals.ametsoc.org/bams/article/101/6/E869/345572/Current-and-Emerging-Developments-in-Subseasonal)\n\t- The S2S and S2D communities share common scientific and technical challenges: forecast initialization and ensemble generation; initialization shock and drift; understanding the onset of model systematic errors; bias correction, calibration, and forecast quality assessment; model resolution; atmosphere–ocean coupling; sources and expectations for predictability; and linking research, operational forecasting, and end-user needs\n\t- Performance of S2D predictions is strongly tied to initialization of model components beyond the lower atmosphere. For example, stratospheric initial conditions are a source of seasonal winter NAO skill, and ocean initial conditions are crucial for skillfully predicting ENSO, as well as decadal variability in the subpolar North Atlantic\n\t- Many decisions are made on the S2S forecasting time scale, which sits between weather forecasts and S2D climate outlooks; therefore, the continued development of S2S forecasts has the potential to benefit many sectors of society","lastmodified":"2022-09-05T14:10:31.890036032Z","tags":null},"/AI4ES/S2S":{"title":"S2S","content":"\u003e See:\n\u003e - [[S2D]]\n\u003e - [[Ensembles, multi-models]]\n\u003e - [[AI4ES/AI4ES data#Seasonal forecasts]]\n\n## Resources\n- [S2Sprediction project](http://s2sprediction.net/)\n- [Challenge to improve Sub-seasonal to Seasonal Predictions using Artificial Intelligence](https://s2s-ai-challenge.github.io/)\n- [The Subseasonal Experiment (SubX)](https://cpo.noaa.gov/Meet-the-Divisions/Earth-System-Science-and-Modeling/MAPP/Research-to-Operations-and-Applications/Subseasonal-Experiment)\n\t- [Customized Subseasonal Weekly Forecasts](http://wxmaps.org/subx_custom.php)\n- [The Subseasonal Rodeo](https://www.drought.gov/drought/forecast-rodeo-ii-leaderboard )\n\t- [Dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IHBANG)\n\t- https://www.microsoft.com/en-us/research/blog/predicting-the-holy-grail-of-climate-forecasting-a-new-model-and-a-new-public-dataset/\n\t- #TALK [Machine learning seminar series - Enhancing Western United States Sub-Seasonal Forecasts: Forecast Rodeo Prize Competition Series](https://events.ecmwf.int/event/218/) ^c044aa\n- [EGU 2020 Session. Subseasonal-to-Seasonal Prediction: meteorology and impacts](https://meetingorganizer.copernicus.org/EGU2020/displays/36782)\n- [Improved three-week weather forecasts could save lives from disaster](https://www.sciencenews.org/article/climate-weather-forecast-three-week-disaster-storms)\n\t- Between short-term and seasonal prediction lies the realm of subseasonal prediction. Making such forecasts is hard because the initial information that drives short-term forecasts is no longer useful, but the longer-term trends that drive seasonal forecasts have not yet become apparent.\n\t- Short-term weather predictions and longer-term seasonal forecasts are relatively good. People need something in between, so researchers are trying to improve subseasonal forecasts, which look ahead a few weeks, using information from many sources, including predictable weather systems.\n\t- Part of the challenge stems from the fact that many patterns influence weather on the subseasonal scale — and some of them aren’t predictable. \n\t- E.g. MJO: A belt of thunderstorms that typically starts in the Indian Ocean and travels eastward, that happens several times a year. The MJO travels eastward along the equator as winds push warm, wet air high into the atmosphere, where the air dries out, cools and descends back toward the surface.\n\t- “If you can predict the MJO better, then you can predict the weather better” \n\t-  Another weather pattern that might help improve subseasonal forecasts is a quick rise in temperature in the stratosphere, a layer of the upper atmosphere, above the Arctic or Antarctic. These “sudden stratospheric warming” events happen once every couple of years in the Northern Hemisphere and much less often in the Southern Hemisphere. But when one shows up, it affects weather worldwide. \n- [Climate Indices: Monthly Atmospheric and Ocean Time Series](https://psl.noaa.gov/data/climateindices/)\n\t- Plot, analyze and compare different monthly mean climate time series\n\nMJO:\n- [Check updates in](http://s2sprediction.net/xwiki/bin/view/Phase2/MJOTel)\n- #PAPER [Madden–Julian Oscillation impacts on South American summer monsoon season: precipitation anomalies, extreme events, teleconnections, and role in the MJO cycle (Grimm 2019)](https://link.springer.com/article/10.1007/s00382-019-04622-6)\n\n\n## Code\n- #CODE [xskillscore - Metrics for verifying forecasts](https://github.com/xarray-contrib/xskillscore)\n\t- https://xskillscore.readthedocs.io/en/stable/quick-start.html\n- #CODE [Climpred - Verification of weather and climate forecasts](https://github.com/pangeo-data/climpred)\n\t- https://climpred.readthedocs.io/en/stable/\n\n\n## Books\n- #BOOK [Sub-Seasonal to Seasonal Prediction - The Gap Between Weather and Climate Forecasting](https://www.sciencedirect.com/book/9780128117149/sub-seasonal-to-seasonal-prediction)\n- #BOOK [Statistical Postprocessing of Ensemble Forecasts (2018, ELSEVIER)](https://www.elsevier.com/books/statistical-postprocessing-of-ensemble-forecasts/vannitsem/978-0-12-812372-0)\n\n\n## Courses\n- #COURSE [Seasonal forecasting (ECMWF)](https://www.ecmwf.int/en/elibrary/19273-seasonal-forecasting)\n- #COURSE [Using stochastic physics to repesent model uncertainty (ECMWF)](https://www.ecmwf.int/en/elibrary/19275-using-stochastic-physics-repesent-model-uncertainty)\n- #COURSE [Ensemble forecasting: sources of forecast uncertainty (Richardson, ECMWF)](https://www.ecmwf.int/en/elibrary/18119-ensemble-forecasting-sources-forecast-uncertainty)\n- #COURSE [ECMWF extended range forecasts](https://learning.ecmwf.int/group/guest/lesson-viewer?p_p_id=com_arcusys_valamis_web_portlet_LessonViewerView\u0026p_p_lifecycle=0\u0026p_p_state=maximized\u0026p_p_mode=view\u0026p_p_auth=Jze9AVQe\u0026_com_arcusys_valamis_web_portlet_LessonViewerView_lesson_id=1847)\n- #COURSE Advanced School and Workshop on Subseasonal to Seasonal (S2S) Prediction and Application to Drought Prediction: \n\t- https://www.youtube.com/playlist?list=PLos1JqOLJm3uvpiao2C71Pa-9SpmkrKih\n\t- [Forecast verification](https://www.youtube.com/watch?v=SUu4oIERgRw)\n\t- [Sub-Seasonal forecasting,Forecasting system design](https://www.youtube.com/watch?v=L3vKJ1vwpr4\u0026list=PLos1JqOLJm3uvpiao2C71Pa-9SpmkrKih\u0026index=6)\n\t- [An introduction to numerical weather prediction and climate model uncertainly](https://www.youtube.com/watch?v=DYPqo16oOts\u0026list=PLos1JqOLJm3uvpiao2C71Pa-9SpmkrKih\u0026index=3)\n\n\n## References\n- #PAPER [Kullback–Leibler Divergence as a Forecast Skill Score with Classic Reliability–Resolution–Uncertainty Decomposition (Weijs 2010)](https://journals.ametsoc.org/view/journals/mwre/138/9/2010mwr3229.1.xml)\n- #PAPER [Winter Precipitation Forecast in the European and Mediterranean Regions Using Cluster Analysis (Totz 2017)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017GL075674)\n- #PAPER [Seasonal Drought Prediction: Advances, Challenges, and Future Prospects (Hao 2018)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016RG000549) ^seasdroughthao18\n- #PAPER [S2S reboot: An argument for greater inclusion of machine learning in subseasonal to seasonal forecasts (Cohen, 2019)](https://onlinelibrary.wiley.com/doi/full/10.1002/wcc.567)\n\t- The discipline of seasonal climate prediction began as an exercise in simple statistical techniques. Beginning in the 1990s, forecasts from dynamical models of increasing complexity were introduced into the operational production of S2S forecasts while inclusion of statistical techniques was phased out\n\t- today the large government forecast centers almost exclusively rely on complex fully coupled dynamical forecast systems for their subseasonal to seasonal (S2S) predictions while statistical techniques are mostly neglected and those techniques still in use have not been updated in decades\n\t- new statistical techniques mostly developed outside the field of climate science, collectively referred to as machine learning, can be adopted by climate forecasters to increase the accuracy of S2S predictions\n\t- traditional forecast methodologies based on CCA http://rcc.imdpune.gov.in/Training/SASCOF12/CPT_Dayone/PCR_CCA_Nachiketa.pdf\n\t- novel ones (unsupervised)\n\t\t- [(hierarchical) clustering ](https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fwcc.567\u0026file=wcc567-sup-0001-AppendixS1.pdf)\n\t\t- other potential (supervised) ML approaches are outlined in that supplement\n\t\t- multilinear regression\n\t- the lack of attention, resources and implementation of statistical techniques is a mistake and deprives the public of immediate and relatively inexpensive improvements to S2S prediction\n\t- Statistical predictions in general and machine learning techniques in particular are likely to improve subseasonal climate forecasts where there are repeatable patterns in the atmosphere and where there are fairly consistent sequences of events\n- #PAPER [Improving Subseasonal Forecasting in the Western U.S. with Machine Learning (Hwang 2019)](https://arxiv.org/abs/1809.07394)\n\t- #CODE https://github.com/paulo-o/forecast_rodeo\n\t- https://www.microsoft.com/en-us/research/project/subseasonal-climate-forecasting/\n\t- NOAA launched the Subseasonal Climate Forecast Rodeo, a year-long real-time forecasting challenge in which participants aimed to skillfully predict temperature and precipitation in the western U.S. two to four weeks and four to six weeks in advance\n\t- [Subseasonal Climate Forecast Rodeo (2016-2018)](https://www.challenge.gov/challenge/sub-seasonal-climate-forecast-rodeo/)\n\t- ML approach (ensemble of two nonlinear regression models) to the Rodeo and release our SubseasonalRodeo dataset, collected to train and evaluate our forecasting system \n- #PAPER [El Niño-Southern Oscillation forecasting using complex networks analysis of LSTM neural networks (Broni-Bedaiko 2019)](https://www.semanticscholar.org/paper/El-Ni%C3%B1o-Southern-Oscillation-forecasting-using-of-Broni-Bedaiko-Katsriku/3ebe4aa92226fa22100dce93dc385bd93a417fd3)\n\t- El Niño-Southern Oscillation (ENSO) is the most influential climatological phenomenon that has been intensively researched during the past years. \n\t- The scientific community knows much about the underlying processes of ENSO phenomenon, however, its predictability for longer horizons, which is very important for human society and the natural environment is still a challenge in the scientific community\n- #PAPER [Machine learning climate variability (Hwan Park 2019)](https://ml4physicalsciences.github.io/2019/files/NeurIPS_ML4PS_2019_84.pdf)\n\t- MLP, LSTM, PCA+LSTM, ConvLSTM\n\t- The more sophisticated of these network architectures (ConvLSTM) is able to perform skillfully at lead times of up to about a year\n- #PAPER Deep learning for multi-year ENSO forecasts (Ham 2019):  https://www.researchgate.net/publication/335896498_Deep_learning_for_multi-year_ENSO_forecasts\n\t- #CODE https://github.com/jeonghwan723/DL_ENSO/tree/v1.0\n\t- [Slides](https://meso.nju.edu.cn/DFS//file/2019/11/26/201911261121480744epw3l.pdf?iid=6240)\n\t- https://phys.org/news/2019-09-deep-application-el-nio-events.html \n\t- Uses a sort of transfer learning (models and reanalysis)\n- #PAPER [Diagnosing Secular Variations in Retrospective ENSO Seasonal Forecast Skill Using CMIP5 Model‐Analogs (Ding 2019)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018GL080598)\n- #PAPER [Prediction of North Atlantic Oscillation Index with Convolutional LSTM Based on Ensemble Empirical Mode Decomposition (Yuan 2019)](https://www.mdpi.com/2073-4433/10/5/252/htm)\n\t- NAO is the most significant mode of the atmosphere in the North Atlantic, and it plays an important role in regulating the local weather and climate and even those of the entire Northern Hemisphere\n\t- An effective neural network model EEMD-ConvLSTM (based on ConvLSTM) with Ensemble Empirical Mode Decomposition (EEMD), is proposed for NAO index prediction\n\t- EEMD is applied to preprocess NAO index data, which are issued by the NOAA and NAO index data are decomposed into several Intrinsic Mode Functions (IMFs)\n- #PAPER [The Application of Machine Learning Techniques to Improve El Niño Prediction Skill (Dijkstra 2019)](https://www.frontiersin.org/articles/10.3389/fphy.2019.00153/full)\n- #PAPER [Sub-Seasonal Climate Forecasting via Machine Learning: Challenges, Analysis, and Advances (He, 2020)](https://arxiv.org/abs/2006.07972)\n\t- Sub-seasonal climate forecasting (SSF) focuses on predicting key climate variables such as temperature and precipitation in the 2-week to 2-month time scales\n\t- immense societal value, in areas such as agricultural productivity, water resource management, transportation and aviation systems, and emergency planning for extreme weather events\n\t- In this paper, we carefully study a variety of machine learning (ML) approaches for SSF over the US mainland\n\t- Among a broad suite of 10 ML approaches considered, gradient boosting performs the best, and deep learning (DL) methods show some promise with careful architecture choices\n\t- DL models explored: Encoder (LSTM)-Decoder (FNN), CNN-LSTM\n\t- Empirical results show the gradient boosting model XGBoost, the DL model Encoder (LSTM)-Decoder (FNN), and linear models, such as Lasso, consistently outperform state-of-the-art forecasts. XGBoost has the highest skill over all models, and demonstrates its predictive power\n- #PAPER [Choices in the Verification of S2S Forecasts and Their Implications for Climate Services (Manrique-Sunen 2020)](https://journals.ametsoc.org/mwr/article/148/10/3995/353477/Choices-in-the-Verification-of-S2S-Forecasts-and)\n- #PAPER [The influence of aggregation and statistical post‐processing on the subseasonal predictability of European temperatures (van Straaten 2020)](https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.3810)\n- #PAPER [North Atlantic climate far more predictable than models imply (Smith 2020)](https://www.nature.com/articles/s41586-020-2525-0)\n- #PAPER [The Importance of Past MJO Activity in Determining the Future State of the Midlatitude Circulation (Tseng 2020)](https://journals.ametsoc.org/view/journals/clim/33/6/jcli-d-19-0512.1.xml)\n- #PAPER [Prediction of monthly Arctic sea ice concentrations using satellite and reanalysis data based on convolutional neural networks (Kim 2020)](https://tc.copernicus.org/articles/14/1083/2020/)\n- #PAPER [Testing the Reliability of Interpretable Neural Networks in Geoscience Using the Madden-Julian Oscillation (Toms, 2020)](https://arxiv.org/abs/1902.04621)\n\t- Tested the reliability of two neural network interpretation techniques, backward optimization and layerwise relevance propagation, within geoscientific applications by applying them to a commonly studied geophysical phenomenon, the Madden-Julian Oscillation. \n\t- The Madden-Julian Oscillation is a multi-scale pattern within the tropical atmosphere that has been extensively studied over the past decades, which makes it an ideal test case to ensure the interpretability methods can recover the current state of knowledge regarding its spatial structure. \n\t- The neural network identifies the phase of the Madden-Julian Oscillation twice as accurately as linear regression, which means that nonlinearities used by the neural network are important to the structure of the Madden-Julian Oscillation\n\t- used the interpretations to identify the seasonality of the Madden-Julian Oscillation, and find that the conventionally defined extended seasons should be shifted later by one month\n\t- [Deep Learning for Scientific Inference from Geophysical Data: The Madden-Julian Oscillation as a Test Case (Toms, 2020)](https://arxiv.org/abs/1902.04621v1)\n- #PAPER [Improving subseasonal precipitation forecasts through a statistical–dynamical approach: application to the southwest tropical Pacific (Specq 2020)](https://link.springer.com/article/10.1007/s00382-020-05355-7)\n- #TALK [Predictable weather regimes at the S2S time scale (Cortesi 2020)](https://meetingorganizer.copernicus.org/EGU2020/EGU2020-1580.html)\n\t- #BSC Nicola Cortesi  \n\t- weather regime classification at the s2s time scale for enhancing s2s predictability of the frequencies of weather regimes\n\t- using clustering techniques (k-means) and weighting based on the anomaly correlation coeff. (ACC) \n\t- using NCEP reanalysis 40 years, Euro-Atlantic region\n\t- forecasts from the 2018 Monthly forecast system ECMWF-MFS\n- #PAPER [Monthly and Quarterly Sea Surface Temperature Prediction Based on Gated Recurrent Unit Neural Network (Zhang 2020)](https://www.mdpi.com/2077-1312/8/4/249/htm)\n\t- A medium and long-term SST prediction model is designed on the basis of the gated recurrent unit (GRU) neural network algorithm\n\t- Data: NOAA 1/4° daily Optimum Interpolation (OISST), reanalysis. This study selects the site data from January 1982 to December 2019 and reorganizes the data on the basis of the monthly and seasonal averages\n\t- Model: A neural network model for the high-precision prediction of medium and long-term SSTs based on GRU and a fully connected layer is constructed. Six-layer neural network model, which includes one input layer, three GRU layers, and two dense layers. \n\t- The input data are the time series of the SST. In this experiment, the time series of monthly and quarterly scales are used to verify the model, and the amount of data fed into the network at one time is determined by the length of the set learning sequence and the number of batch trainings. On the basis of the variation law of SST, the lengths of learning sequences used in monthly and quarterly trainings are set to 12 and 4, respectively.\n\t- The 38-year history of SST observation data is sorted on the basis of two different scales: monthly and quarterly\n\t- The designed SST prediction model based on GRU can efficiently fit the trend of the real SST\n- #PAPER [Improving seasonal forecast using probabilistic deep learning (Pan 2020)](https://arxiv.org/abs/2010.14610v1)\n\t- Conditional variational autoencoders (conditional generative model that marries probabilistic graphical models with deep learning)\n\t- Saliency maps\n- #PAPER [Predicting global patterns of long-term climate change from short-term simulations using machine learning (Mansfield 2020)](https://www.nature.com/articles/s41612-020-00148-5)\n\t- introduced a machine learning approach, which utilises a unique dataset of existing climate model simulations to learn relationships between short-term and long-term temperature responses to different climate forcing scenarios\n\t- done via a fast \"surrogate model\" to find a mapping from short-term to long-term response patterns within a given GCM\n\t- this approach not only has the potential to accelerate climate change projections by reducing the costs of scenario computations, but also helps uncover early indicators of modelled long-term climate responses, which is of relevance to climate change detection, predictability, and attribution\n- #PAPER [Prediction Skill of Extended Range 2-m Maximum Air Temperature Probabilistic Forecasts Using Machine Learning Post-Processing Methods (Peng 2020)](https://www.mdpi.com/2073-4433/11/8/823/htm)\n- #PAPER [The influence of aggregation and statistical post-processing on the subseasonal predictability of European temperatures (van Straatem 2020)](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.3810?utm_campaign=RESR_MRKT_Researcher_inbound\u0026af=R\u0026utm_medium=referral\u0026utm_source=researcher_app\u0026sid=researcher)\n- #PAPER [Seasonal Arctic sea ice forecasting with probabilistic deep learning (Andersson 2021)](https://eartharxiv.org/repository/view/2027/)\n\t- present a probabilistic, deep learning sea ice forecasting system, IceNet, trained on climate simulations and observational data to forecast the next 6 months of monthly-averaged sea ice concentration maps\n- #PAPER [Applying machine learning for drought prediction using data from a large ensemble of climate simulations (Felsche 2021)](https://nhess.copernicus.org/preprints/nhess-2021-110/)\n- #PAPER [Subseasonal Forecasts of Opportunity Identified by an Explainable Neural Network (Mayer 2021)](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020GL092092)\n\t- https://meetingorganizer.copernicus.org/EGU21/EGU21-9015.html\n\t- Layer-wise relevance propagation (LRP)\n\t- K-Means Clustering of LRP Maps\n- #PAPER [Subseasonal predictability of the North Atlantic Oscillation (Albers 2021)](https://iopscience.iop.org/article/10.1088/1748-9326/abe781)\n- #PAPER [Sub-seasonal forecasting with a large ensemble of deep-learning weather prediction models (Weyn 2021)](https://arxiv.org/abs/2102.05107) ^weyn21dls2s\n- #PAPER [Extreme Precipitation Seasonal Forecast Using a Transformer Neural  Network (Civitarese 2021)](https://arxiv.org/pdf/2107.06846)\n- #PAPER [Training machine learning models on climate model output yields skillful interpretable seasonal precipitation forecasts (Gibson 2021)](https://www.nature.com/articles/s43247-021-00225-4)\n- #PAPER [Seasonal Arctic sea ice forecasting with probabilistic deep learning (Andersson 2021)](https://www.nature.com/articles/s41467-021-25257-4)\n- #PAPER [Dynamical–statistical seasonal forecasts of winter and summer precipitation for the Island of Ireland (Goliam 2022)](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/joc.7557)\n- #PAPER [Using Explainable Machine Learning Forecasts to Discover Subseasonal Drivers of High Summer Temperatures in Western and Central Europe (van Straatem 2022)](https://journals.ametsoc.org/view/journals/mwre/150/5/MWR-D-21-0201.1.xml)\n- #PAPER [Opportunistic Mixture Model for S2S Predictions of Temperature and Precipitation (Landry 2022)](http://s2sprediction.net/file/newsletter/Newsletter%2020_Aug%202022.pdf)\n\t- #CODE https://github.com/crim-ca/crims2s\n\t- #TALK https://www.bilibili.com/video/BV1Nv4y1K7Sy/\n\t- https://events.ecmwf.int/event/294/contributions/3053/attachments/1748/3161/ML-WS_Landry.pdf\n\n### Verification\n- [#BSC Seasonal forecasts quality assessment report (report by Marcos, ESS)](https://zenodo.org/record/2391735#.X_29a9Yo9qg)\n- [Guidance on Verification of Operational Seasonal Climate Forecasts](https://library.wmo.int/doc_num.php?explnum_id=4886)\n- [Forecast Verification methods Across Time and Space Scales](https://www.cawcr.gov.au/projects/verification/)\n- [Verification of climate forecasts](http://indico.ictp.it/event/a09161/session/29/contribution/17/material/0/0.pdf)\n\n- #PAPER [The Discrete Brier and Ranked Probability Skill Scores (Weigel 2007)](https://journals.ametsoc.org/view/journals/mwre/135/1/mwr3280.1.xml)","lastmodified":"2022-09-05T14:10:31.89403632Z","tags":null},"/AI4ES/Statistical-downscaling":{"title":"Statistical downscaling","content":"---\n\n\u003e See: \n\u003e - [[Super-resolution]] \n\u003e - [[EO#Super-resolution]] \n\u003e - [[Image-to-image translation]]\n\u003e - [[AI4ES/Bias correction, adjustment]]\n\n## Resources\n- https://en.wikipedia.org/wiki/Downscaling\n- Downscaling is any procedure to infer high-resolution information from low-resolution variables. This technique is based on dynamical or statistical approaches commonly used in several disciplines, especially meteorology, climatology and remote sensing. The term downscaling usually refers to an increase in spatial resolution, but it is often also used for temporal resolution.\n- Statistical downscaling or what climate can I expect in my own backyard? Statistical DS learns a functional mapping between low and high-resolution climate models from observed data (computationally efficient and scalable across multi-model ensembles) vs dynamical DS, where all the local processes are encoded, such as convective precipitation and vegetation schemes, with subgrid parameters and GCM boundary conditions for HR projections (high computational costs) \n- \"downscaling\" is a climate modeling term while \"downsampling\" comes from signal processing. Confusingly, \"downscaling\" is actually equivalent to \"upsampling\", both referring to \"increasing resolution\"\n- #TALK [What is bias correction/adjustment and statistical downscaling?](https://www.youtube.com/watch?v=diCEdcDTtgw)\n- #TALK [Different methods for bias adjustment and downscaling](https://www.youtube.com/watch?v=f5yGo9hcjbk)\n- #TALK [Statistical Downscaling (South Central Climate Adaptation Science Center)](https://www.youtube.com/watch?v=etaMadjy12k)\n- #TALK [Webinar: The Ins and Outs of Downscaling: Simple to Complex Techniques Explained Simply (2015)](https://www.youtube.com/watch?v=rSkeaDu3K68)\n- [Santander group](https://www.meteo.unican.es/en/research/statistical_downscaling)\n\t- https://meteo.unican.es/trac/estcena/wiki/Downscaling/MetodosDownscaling\n\t- #TALK [Statistical downscaling with deep learning: A contribution to CORDEX-CORE](https://www.meteo.unican.es/en/node/73512)\n\t- [CORDEX](https://www.meteo.unican.es/en/projects/CORDEX)\n\t- https://www.meteo.unican.es/files/posters/2019_Bano-Medina_CORDEX.pdf \n\t- https://github.com/SantanderMetGroup/DeepDownscaling/blob/master/2020_Bano_GMD_FULL.ipynb \n\t- https://github.com/SantanderMetGroup/DeepDownscaling/blob/master/2020_Bano_GMD.ipynb \n\t- https://github.com/SantanderMetGroup/downscaleR.keras/blob/master/R/prepareData.keras.R \n\t \n\n## Code\n- #CODE [DL4DS - Deep Learning for empirical DownScaling](https://github.com/carlos-gg/dl4ds)\n\t- Python package with state-of-the-art and novel deep learning algorithms for empirical/statistical downscaling of gridded data\n- #CODE [PyESD](https://github.com/Dan-Boat/PyESD)\n\t- Python Package for Empirical Statistical Downscaling. This repository contains all scripts of the pyESD package which is under development. The purpose of the package is to downscale climate variables like precipitation and temperature from large-scale reanalysis datasets (eg. ERA5) to point scale\n- #CODE [Equidistant quantile matching (EDCDFm)](https://github.com/scrim-network/red_river)\n\t- Bias correction and SD in python and R\n- #CODE [Scikit-downscale](https://github.com/jhamman/scikit-downscale/)\n\t- https://scikit-downscale.readthedocs.io/en/latest/roadmap.html#models\n\t- https://github.com/earthcube2020/ec20_hamman_etal\n\t- https://figshare.com/articles/Scikit-downscale_an_open_source_Python_package_for_scalable_climate_downscaling/12506648/1\n- #CODE [Bias Correction Spatial Disaggregation](https://github.com/tjvandal/bcsd-python#prism-downscaling-merra-2","lastmodified":"2022-09-05T14:10:31.89403632Z","tags":null},"/AI4ES/Weather-forecasting-nowcasting":{"title":"Weather forecasting, nowcasting","content":"\u003e See:\n\u003e - [[AI4ES/Emulators]]\n\u003e - [[AI/Computer Vision/Video segmentation and prediction]]\n\u003e - [[AI/Deep learning/CNNs]]\n\u003e - [[AI/Deep learning/RNNs]]\n\u003e - [[AI/Deep learning/Fourier Neural Operators]]\n\n\n## Code\n- #CODE [PySTEPS - Python framework for short-term ensemble prediction systems](https://github.com/pySTEPS/pysteps)\n\t- https://pysteps.github.io/\n\n## Courses\n- #COURSE [ Sources of uncertainty (Buizza, ECMWF)](https://www.ecmwf.int/en/elibrary/19274-sources-uncertainty)\n- #COURSE [Using stochastic physics to represent model uncertainty](https://www.ecmwf.int/assets/elearning/stochphysics/stochphysics1/story_html5.html)\n\n\n## References\n- #PAPER [ConvLSTM: Convolutional LSTM Network- A Machine Learning Approach for Precipitation Nowcasting (Shi 2015)](https://arxiv.org/abs/1506.04214)\n\t- #CODE https://keras.io/examples/conv_lstm/\n- #PAPER [Deep Learning for Precipitation Nowcasting: A Benchmark and A New Model, trajGRU (Shi 2017)](https://arxiv.org/abs/1706.03458)\n\t- https://github.com/CNALeon007/TrajGRU\n- #PAPER [Automating weather forecasts based on CNNs (Rozas Larraondo 2017)](https://deepstruct.github.io/ICML17/1stDeepStructWS_paper_2.pdf)\n- [#THESIS/PHD Application of machine learning techniques to weather forecasting (Rozas Larraondo 2019)](https://addi.ehu.es/handle/10810/32532)\n- #PAPER [A Generative Adversarial Gated Recurrent Unit Model for Precipitation Nowcasting (Tian, 2019)](https://ieeexplore.ieee.org/document/8777193)\n- #PAPER [Can machines learn to predict weather? Using deep learning to predict gridded 500‐hPa geopotential height from historical weather data (Weyn 2019)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019MS001705)\n- #PAPER [Reversible Deep Generative Models for Climate Informatics (Rosenfeld 2019)](https://sailinglab.github.io/pgm-spring-2019/assets/project/final-reports/project7.pdf)\n- #PAPER [Prediction of Rainfall Using Intensified LSTM Based Recurrent Neural Network with Weighted Linear Units (Poornima 2019)](https://www.mdpi.com/2073-4433/10/11/668)\n- #PAPER [Data-driven predictions of a multiscale Lorenz 96 chaotic system using machine-learning methods: reservoir computing, artificial neural network, and LSTM (Chattopadhyay 2019)](https://arxiv.org/abs/1906.08829)\n\t- #CODE https://github.com/ashesh6810/RCESN_spatio_temporal\n- #PAPER [Deep Uncertainty Quantification: A Machine Learning Approach for Weather forecasting (Wang 2019)](https://arxiv.org/abs/1812.09467)\n\t- Proposed data-driven method augmented by an effective information fusion mechanism to learn from historical data that incorporates prior knowledge from NWP\n\t- Weather forecasting problem posed as an end-to-end deep learning problem and solve it by proposing a novel negative log-likelihood error (NLE) loss function\n\t- A notable advantage of our proposed method is that it simultaneously implements single-value forecasting and uncertainty quantification, which we refer to as deep uncertainty quantification (DUQ)\n\t- The proposed DUQ is based on sequence-to-sequence (seq2seq, a.k.a Encoder-Decoder)\n\t- DUQ predicts two values at each timestep corresponding to the predicted mean and variance to parameterize the Gaussian distributions\n- #PAPER [Computer Vision in Precipitation Nowcasting: Applying Image Quality Assessment Metrics for Training Deep Neural Networks (Tran 2019)](https://www.mdpi.com/2073-4433/10/5/244/htm)\n- #PAPER [Technical note: DL for creating surrogate models of precipitation in Earth system models (Weber 2020)](https://www.atmos-chem-phys.net/20/2303/2020/)\n\t- Precipitation forecasting using resnets\t\t\n\t- #CODE https://github.com/hutchresearch/deep_climate_emulator\n- #PAPER [Improving data-driven global weather prediction using deep CNNs on a cubed sphere (Weyn 2020)](https://arxiv.org/abs/2003.11927) ^bd4b0a\n\t- https://github.com/jweyn/DLWP-CS\n\t- New developments in this framework include an offline volume-conservative mapping to a cubed-sphere grid, improvements to the CNN architecture (U-NET), and the minimization of the loss function over multiple steps in a prediction sequence.\n\t- The cubed-sphere remapping minimizes the distortion on the cube faces on which convolution operations are performed and provides natural boundary conditions for padding in the CNN. \n\t- Our improved model produces weather forecasts that are indefinitely stable and produce realistic weather patterns at lead times of several weeks and longer\n\t- #TALK [S2S forecasting using large ensembles of data-driven global weather prediction models](https://www.youtube.com/watch?v=Yk0eSNs7nbs)\n- #PAPER [A Machine-Learning-Based Global Atmospheric Forecast Model (Szunyogh 2020)](https://www.essoar.org/doi/10.1002/essoar.10502527.2)\n\t- The paper investigates the applicability of machine learning (ML) to weather prediction by building a reservoir-computing-based, low-resolution, global prediction model. \n\t- The model is designed to take advantage of the massively parallel architecture of a modern supercomputer. \n\t- The forecast performance of the model is assessed by comparing it to that of daily climatology, persistence, and a numerical (physics-based) model of identical prognostic state variables and resolution\n- #PAPER [MetNet: A Neural Weather Model for Precipitation Forecasting (Sonderby 2020)](https://arxiv.org/abs/2003.12140)\n\t- #TALK https://vimeo.com/417618472\n\t\t- https://www.ecmwf.int/sites/default/files/medialibrary/2020-05/12_May.pdf\n- #PAPER [TRU-NET: A Deep Learning Approach to High Resolution Prediction of Rainfall (Adewoyin 2020)](https://arxiv.org/abs/2008.09090v1)\n\t- #CODE https://github.com/Akanni96/TRUNET\n- #PAPER [Predicting clustered weather patterns: A test case for applications of convolutional neural networks to spatio-temporal climate data (Chattopadhyay, 2020)](https://www.nature.com/articles/s41598-020-57897-9) ^e83f4e\n\t- Introduced an unsupervised auto-labeling strategy that can facilitate exploring the capabilities of supervised deep learning techniques such as CNNs in studying problems in climate and environmental sciences\n\t- Applied this strategy to clustered daily large-scale weather patterns over North America\n\t\t- focused on re-identifying and predicting the daily weather patterns over North America in summer and winter\n\t\t- focus on daily averaged geopotential height at 500 hPa (Z500 hereafter), whose isolines are approximately the streamlines of the large-scale circulation at mid-troposphere and are often used to represent weather patterns\n\t\t- used data from the Large Ensemble (LENS) Community Project, which consists of a 40-member ensemble of fully-coupled Community Earth System Model version 1 (CESM1) simulations with historical radiative forcing from 1920 to 2005\n\t\t- daily Z500 from 1980 to 2005 provides  ~95000 samples for summer months and for winter months over North America\n\t\t- the K-means algorithm is used to classify the winter days and summer days (separately) into n = 4 clusters\n\t\t- the clustering analysis is performed on zonal-mean-removed daily Z500 anomalies projected on 22 EOFS that retain approximately 95% of the variance\n\t\t- the computed cluster index for each day is used to label the full Z500 pattern of that day and 5 days earlier\n\t\t- full Z500 fields are used, rather than the computed anomalies (or any other type of anomalies), because one hopes to use CNN with minimally pre-processed data\n\t\t- task: re-identifying and predicting the clusters in the full Z500 fields, which include complex temporal variabilities such as the seasonal cycle and non-stationarity resulting from the low-frequency coupled ocean-atmosphere modes and changes in the radiative forcing between 1980 and 2005\n\t\t- network: trivial CNN for classification with a final output of 4 values (categorical cross-entropy)\n\t- Showed the outstanding performance of CNNs in re-identifying and predicting patterns in chaotic, multi-scale, non-stationary, spatio-temporal data with minimal pre-processing\n\t- CNNs are not used as a clustering technique, as clusters are already found using an unsupervised method (the K-means algorithm). Rather, CNNs are used to predict which cluster index a Z500 pattern will belong to in 1–5 days in the future\n\t- The cluster-based forecasting of circulation patterns that is presented here, again if performed using a CNN trained on reanalysis data and using more input variables, might help with prediction of low-frequency variability in the S2S timescales (see [[S2S]])\n\t- The scaling (of the prediction accuracy of the CNNs) that is found here shows a nonlinear relation between accuracy and N, and suggests that the amount of data currently available from reanalysis since 1979 can be enough to successfully train an accurate CNN for applications involving daily large-scale weather patterns\n\t- Follow up paper using CapsNets and extreme temperature clusters [[AI4ES/Extremes events#^d42267]]\n- #PAPER [A review of radar-based nowcasting of precipitation and applicable machine learning techniques (Prudden, 2020)](https://arxiv.org/abs/2005.04988)\n- #PAPER [Boosting performance in machine learning of geophysical flows via scale separation (Faranda 2020)](https://npg.copernicus.org/preprints/npg-2020-39/)\n- #PAPER [DeepClimGAN: A High-Resolution Climate Data Generator (Puchko 2020)](https://arxiv.org/abs/2011.11705)\n\t- [[GANs]] for spatio-temporal forecasting\n\t- https://www.climatechange.ai/CameraReadySubmissions%202-119/52/CameraReadySubmission/nips2019_icml.pdf\n- #PAPER [A generative adversarial network approach to (ensemble) weather prediction (Bihlo 2020)](https://arxiv.org/abs/2006.07718)\n\t- Implemented a deep convolutional [[GANs]] to predict the geopotential height of the 500 hPa pressure level, the two-meter temperature and the total precipitation for the next 24 hours over Europe\n\t- The proposed models are trained on 4 years of ERA5 reanalysis data from 2015–2018 with the goal to predict the associated meteorological fields in 2019\n\t- The forecasts show a good qualitative and quantitative agreement with the true reanalysis data for the geopotential height and two-meter temperature, while failing for total precipitation, thus indicating that weather forecasts based on data alone may be possible for specific meteorological parameters\n- #PAPER [Ensemble methods for neural network-based weather forecasts (Scher 2020)](https://arxiv.org/abs/2002.05398v2)\n\t- #CODE https://github.com/sipposip/ensemble-neural-network-weather-forecasts\n\t- Aimed to transform a deterministic neural network weather forecasting system into an ensemble forecasting system\n\t- Tested four methods to generate the ensemble: random initial perturbations, retraining of the neural network, use of random dropout in the network, and the creation of initial perturbations with singular vector decomposition\n\t- The latter method is widely used in numerical weather prediction models, but is yet to be tested on neural networks\n\t- The ensemble mean forecasts obtained from these four approaches all beat the unperturbed neural network forecasts, with the retraining method yielding the highest improvement\n\t- The skill of the neural network fore-casts is systematically lower than that of state-of-the-art numerical weather prediction models\n- #PAPER [Spherical convolution and other forms of informed machine learning for deep neural network based weather forecasts (Scher 2020)](https://arxiv.org/abs/2008.13524)\n\t- CNN-based weather forecasting solutions are are usually trained on atmospheric data represented as regular latitude-longitude grids, neglecting the curvature of the Earth\n\t- Showed the benefit of replacing the convolution operations with a spherical convolution operation, which takes into account the geometry of the underlying data, including correct representations near the poles\n\t- Additionally, studied the effect of including the information that the two hemispheres of the Earth have “flipped” properties - for example cyclones circulating in opposite directions - into the structure of the network\n\t- Using spherical convolution leads to an additional improvement in forecast skill, especially close to the poles in the first days of the forecast\n\t- The spherical convolution is implemented flexibly and scales well to high resolution datasets, but is still significantly more expensive than a standard convolution operation\n- #THESIS/PHD [Artificial intelligence in weather and climate prediction (Scher 2020)](https://www.diva-portal.org/smash/get/diva2:1425352/FULLTEXT01.pdf ^2e6f0f)\n- #THESIS/MSC [Geometric deep learning for medium-range weather prediction (Llorens 2020)](https://infoscience.epfl.ch/record/278138)\n\t- #CODE https://github.com/illorens/weather_prediction\n\t- Spherical CNNs benchmarking\n- #PAPER [Temporal convolutional neural (TCN) network for an effective weather forecasting using time-series data from the local weather station (Hewage 2020)](https://link.springer.com/article/10.1007/s00500-020-04954-0)\n- #PAPER [Optimization of Deep Learning Precipitation Models Using Categorical Binary Metrics (Rozas Larraondo 2020)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019MS001909)\n\t- #CODE https://github.com/prl900/weather_encoders\n\t- This work introduces a methodology for optimizing neural network models using a combination of continuous and categorical binary indices in the context of precipitation forecasting\n\t- Proposed an alternative formulation for these categorical indices that are differentiable and we demonstrate how they can be used to optimize the skill of precipitation neural network models defined as a multiobjective optimization problem\n- #PAPER [Localized Convolutional Neural Networks for Geospatial Wind Forecasting (Uselis 2020)](https://www.mdpi.com/1996-1073/13/13/3440/htm) ^uselis20\n\t- #CODE https://github.com/oshapio/Localized-CNNs-for-Geospatial-Wind-Forecasting\n\t- In a convolutional layer, each neuron has a fixed local receptive field of the layer input and shares its weights with all the other (repeated) neurons arranged in a lattice corresponding to the dimensions of the input\n\t- Typically, an element-wise nonlinear function is applied to the results of the convolution which gives a lattice of identical weighted-sum-and-non linearity neurons each looking at a different k×k size patch of the input image\n\t- Convolutions give CNNs some unique benefits, compared to regular MLPs: less trainable weights (faster and with less overfitting), every filter is trained on every k×k patch of every input image g(·,·), which utilizes the training data well, the architecture and learned weights of the convolutional layer do not depend on the size of the input image (easier to reuse), convolutions give translation invariance (the features are detected the same way, no matter where they are in the image)\n\t- Translation invariance is very important for good generalization when objects being detected are randomly framed in the images. Translation invariance, however, is absolute in convolutional layers\n\t- This location agnosticism might not always be optimal even for images as not all objects or features are equally likely to appear in every part of them. This is especially evident when the images have a constant static framing, eg., geospatial ad meteorological data\n\t- While the same laws of atmospheric physics apply at every location, each location typically also has its own unique features like altitude, terrain, land use, large objects, sun absorption, the heat capacity of the ground,heat sources, etc. that affect the dynamics\n\t- The complete location agnosticism in CNNs can be remedied in several ways by supplying different additional static location-dependent features:\n\t\t- The explicit coordinates of each location like in CoordConv \n\t\t- A combination of local random static location-dependent inputs, that could potentially allow us to uniquely “identify” each location as well\n\t\t- The above mentioned real-world relevant unique location-specific features if they are explicitly available (typically not all of them are)\n\t- Additionally, location-based differences could be learned more directly by introducing additional (at every input lattice location): \n\t\t- Learnable local inputs/latent variables\n\t\t- Learnable local transformations of the inputs in the form of local weights\n\t- “Localized CNNs” - models that learn to treat the different locations/pixels in the input similarly, but not identically\n- #PAPER [Deep spatial transformers for autoregressive data-driven forecasting of geophysical turbulence (Chattopadhyay 2020)](https://dl.acm.org/doi/10.1145/3429309.3429325)\n\t- https://eartharxiv.org/repository/view/118/\n- #PAPER [Data-driven medium-range weather prediction with a Resnet pretrained on climate simulations: A new model for WeatherBench (Rasp 2021)](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020MS002405)\n\t- There are three fundamental techniques for creating data‐driven forecasts: direct, continuous and iterative. For direct forecasts, a separate model is trained directly for each desired forecast time. In continuous models, time is an additional input and a single model is trained to predict all forecast lead times (as in MetNet). Finally, iterative forecasts are created by training a direct model for a short forecast time (e.g., 6 h) and then running the model several times using its own output from the previous iteration. As mentioned above, this is the approach taken by Weyn et al. 2020\n\t- First train our model using the 150 years of CMIP data described above. We then take the pretrained model and fine‐tune it using the ERA data\n- #PAPER [Evaluation and interpretation of convolutional long short-term memory networks for regional hydrological modelling (Anderson 2022)](https://hess.copernicus.org/articles/26/795/2022/hess-26-795-2022.html)\n\t- #CODE https://github.com/andersonsam/cnn_lstm_era\n- #PAPER [FourCastNet: A Global Data-driven High-resolution Weather Model using Adaptive Fourier Neural Operators (Pathak 2022)](https://arxiv.org/abs/2202.11214)            \n\t- [Accelerating Extreme Weather Prediction with FourCastNet](https://www.youtube.com/watch?v=nuT_U1AQz3g)\n\t- #TALK [Building Digital Twins of the Earth for NVIDIA's Earth-2 Initiative](https://www.youtube.com/watch?v=IBTVAC82xtQ)\n\t- #CODE https://github.com/NVlabs/FourCastNet\n\t- #CODE (NOT OFFICIAL) https://github.com/HFAiLab/FourCastNet\n\t- ERA5 0.25 deg, 20 variables, from 1979 (~50k training samples)\n\t- Unparalleled accuracy at forecast lead times of up to one week, challenging variables such as surface winds and precipitation\n\t- FourCastNet has eight times greater resolution than state-of-the-art DL-based global weather models\n\t- FourCastNet’s predictions are comparable to the IFS model on metrics of RMSE and Anomaly Correlation Coefficient (ACC) at lead times of up to three days\n\t- FourCastNet’s reliable, rapid, and computationally inexpensive forecasts facilitate the generation of very large ensembles, thus enabling estimation of well-calibrated and constrained uncertainties in extremes with higher confidence than current NWP ensembles\n\t- The AFNO model is unique in that it frames the mixing operation as continuous global convolution, implemented efficiently in the Fourier domain with FFTs, which allows modeling dependencies across spatial and channel dimensions flexibly and scalably\n- #PAPER [Forecasting large-scale circulation regimes using deformable convolutional neural networks and global spatiotemporal climate data (Holm Nielsen 2022)](https://arxiv.org/abs/2202.04964)\n\t- supervised machine learning approach based on deformable convolutional neural networks (deCNNs) and transfer learning to forecast the North Atlantic-European weather regimes during extended boreal winter for 1 to 15 days into the future\n\t- authors could extract and learn transformation-invariant spatial patterns across large geographical areas using deformable convolutions, which is not possible with regular CNNs\n\t- used pre-training (training on the large 20CRv3 reanalysis dataset spanning from 1836 to 1980, then transfer learning)\n\t- using a interpretation technique called integrated gradients, we could attribute each variable’s contributions for a particular observation on a grid-point basis. This is especially important if we want to understand global climate processes better and explain drivers behind specific weather regimes that account for major uncertainty in NWP models days to weeks ahead\n- #PAPER [Towards physics-inspired data-driven weather forecasting: integrating data assimilation with a deep spatial-transformer-based U-NET in a case study with ERA5 (Chattopadhyay 2022)](https://gmd.copernicus.org/articles/15/2221/2022/)\n- #PAPER [Earthformer: Exploring Space-Time Transformers for Earth System Forecasting (Gao 2022)](https://arxiv.org/pdf/2207.05833)\n\t- Earthformer is a space-time Transformer for Earth system forecasting. Earthformer is based on a generic, flexible and efficient space-time attention block, named Cuboid Attention\n\t- The idea is to decompose the data into cuboids and apply cuboid-level self-attention in parallel. These cuboids are further connected with a collection of global vectors","lastmodified":"2022-09-05T14:10:31.89403632Z","tags":null},"/AI4G/AI4good":{"title":"AI for good (AI4G)","content":"## References\n- #PAPER [AI for social good: unlocking the opportunity for positive impact (Tomasev 2020)](https://www.nature.com/articles/s41467-020-15871-z)\n\n## Resources\n- (Legacy) Overview of the Data Science and AI for good movement, on [Medium](https://towardsdatascience.com/data-science-and-ai-for-good-an-overview-577c9c2a3dcb)\n- [Public lecture slides: Beyond the Hype - how we can make AI work for humanity (Yoshua Bengio)](https://docs.google.com/presentation/d/e/2PACX-1vRTUkjOSeF1bEt1MNNkTWST1DEPTwr6C8_0mnICcv-9R4px8xCQjbBPHQE2rO-HJGGIGxS-ry8mgYzP/pub)\n- [Twitter : data4good hashtag](https://twitter.com/hashtag/data4good?lang=en)\n- [DS for Good resources](https://github.com/darenasc/data-science-for-good)\n- [The good AI](https://thegoodai.co/)\n- [Report - AI for Good](https://www.diplomaticourier.com/report-ai-for-good/)\n- [How to Use Data for Good to Impact Society](https://www.gartner.com/doc/3880666/use-data-good-impact-society#a1960121054)\n- [Challenges and opportunities of Artificial Intelligence for Good.](https://news.itu.int/challenges-and-opportunities-of-artificial-intelligence-for-good/)\n- [La inteligencia artificial al servicio del bien social en América Latina y el Caribe](https://publications.iadb.org/publications/spanish/document/La-inteligencia-artificial-al-servicio-del-bien-social-en-America-Latina-y-el-Caribe-Panor%C3%A1mica-regional-e-instant%C3%A1neas-de-doce-paises.pdf) \n- [A skeptic’s guide to thinking about AI](https://www.fastcompany.com/90252753/a-skeptics-guide-to-thinking-about-ai)\n- [Why “data for good” lacks precision](https://towardsdatascience.com/why-data-for-good-lacks-precision-87fb48e341f1)\n- [Five principles for applying data science for social good](https://www.oreilly.com/ideas/five-principles-for-applying-data-science-for-social-good)\n- [Artificial Intelligence as a Force for Good](https://ssir.org/articles/entry/artificial_intelligence_as_a_force_for_good)\n- [AI for the Common Good?! Pitfalls, challenges, and Ethics Pen-Testing (paper on Arxiv)](https://arxiv.org/abs/1810.12847)\n- [AI for Good – An Overview of Benevolent AI Initiatives (AI by nonprofits and companies in education, environment and health sectors)](https://emerj.com/ai-sector-overviews/ai-for-good-initiatives/)\n- [Why AI for social good is a thing (podcast)](https://www.techtarget.com/searchcio/podcast/Why-AI-for-social-good-is-a-thing)\n- [Is the Purpose of Artificial Intelligence to Sell Sugar Water?](https://medium.com/intuitionmachine/is-the-purpose-of-ai-to-sell-sugar-water-e6466d574ec0)\n\n### Climate (change) applications\n- See [[AI4ES/AI4ES]]\n- [A running list of 200+ companies hiring for geospatial \u0026 climate-tech roles](https://www.linkedin.com/pulse/running-list-200-companies-hiring-geospatial-roles-ali-ahmadalipour/)\n- [ClimateChangeAI](https://forum.climatechange.ai/)\n- [Work on Climate](https://workonclimate.org/)\n- [AI for the planet](https://www.aifortheplanet.org/en)\n- [Predictive Analytics World - Climate](https://predictiveanalyticsworldclimate.com/agenda/2022-north-america/)\n\t- [Videos](https://www.youtube.com/playlist?list=PLGRPEjgVM822OQnBvo2AmSCgagMnGVSLj)\n\n### Sustainable Development Goals (SDGs)\n- [United Nations SDGs](https://www.un.org/sustainabledevelopment/sustainable-development-goals/)\n- [17goals.org - learn about the SDGs](http://17goals.org/)\n- [SDG Academy](https://sdgacademy.org/)\n- [SDGs dashboard](http://www.sdgsdashboard.org/) \n- [SDG index](http://sdgindex.org/) \n- [A Guide to SDG Interactions: from Science to Implementation](https://council.science/publications/a-guide-to-sdg-interactions-from-science-to-implementation)\n- [The trouble with the UN SDGs 2030 global goals](https://medium.com/@lauraom/the-trouble-with-the-un-sdgs-2030-global-goals-99111a176585)\n\n### Healthcare (resources, applications and challenges)\n- [Stanford AI for healthcare](https://medium.com/stanford-ai-for-healthcare)\n- [Fighting Tuberculosis with GPUs and Deep Learning](https://blogs.nvidia.com/blog/2017/07/20/fighting-tuberculosis/)\n- [Hearth disese diagnosis with DL](https://blog.insightdatascience.com/heart-disease-diagnosis-with-deep-learning-c2d92c27e730)\n- [Intro to biomedical image analysis with tensorflow/DLTK](https://medium.com/tensorflow/an-introduction-to-biomedical-image-analysis-with-tensorflow-and-dltk-2c25304e7c13)\n- [ML in biomed](https://github.com/chvlyl/ML_in_Biomed)\n- [Course - Data Science in Stratified Healthcare and Precision Medicine](https://www.coursera.org/learn/datascimed)\n- [Meaningless comparisons lead to false optimism in medical machine learning (paper on Arxiv)](https://arxiv.org/abs/1707.06289)\n\n### Bootcamps and fellowships \nSee [[AI4G/Bootcamps and fellowships]]\n\n### Entrepreneurship\nSee [[AI4G/Entrepreneurship]]\n\n### Inititatives\n- [AI commons](https://www.aicommons.com/)\n\t- Addressing the world’s grandest challenges with Artificial Intelligence.\n\t- We seek to gather a true ecosystem to democratize access to AI capabilities, to allow anyone, anywhere to benefit from the possibilities that AI can provide.\n\t- We are working to connect problem owners with the community of solvers, to collectively create solutions with AI. We aim to implement a framework for participation and cooperation to make using and benefiting from AI available to all.\n- [ITU AI repository](https://www.itu.int/en/ITU-T/AI/Pages/ai-repository.aspx)\n\t- Following the success of the first AI for Good Global Summit, ITU has launched a global Artificial Intelligence (AI) repository to identify AI related projects, research initiatives, think-tanks and organizations that can accelerate progress towards the “17 UN Sustainable Development Goals (SDGs)”.\n\t- The \"AI Repository\" is open to all and we invite anyone working in the field of AI to contribute to this resource. To submit a project, just fill in the on-line questionnaire below and provide all relevant details of your project. You will also be asked to map your project to the relevant WISIS action lines and UN Sustainable Development Goals. Approved projects will be officially registered in the repository database and your project details will become visible on the website, connecting you with likeminded AI stakeholders, world-wide. It’s that simple!\n- [The Ethics and Governance of AI](https://aiethicsinitiative.org/)\n\t- Launched in 2017, the Ethics and Governance of AI Initiative is a hybrid research effort and philanthropic fund that seeks to ensure that technologies of automation and machine learning are researched, developed, and deployed in a way which vindicate social values of fairness, human autonomy, and justice. The Initiative is a joint project of the MIT Media Lab and the Harvard Berkman-Klein Center for Internet and Society. It incubates a range of research, prototyping, and advocacy activities within these two anchor institutions and across the broader ecosystem of civil society. \n- [AI for Good (UK)](https://www.aiforgood.co.uk/)\n\t- On a mission to help 100 million people by solving some of the toughest challenges facing humanity\n- [AI for Good (Microsoft)](https://www.microsoft.com/en-us/ai/ai-for-good)\n\t- #TALK [AI for Good: Deploying Microsoft AI to help solve society’s greatest challenges](https://www.youtube.com/watch?v=YtiWxpuD1Rc)\n- [Google AI for social good](https://ai.google/social-good)\n- [Partnership for sustainable development data](http://www.data4sdgs.org/index.php/)\n\t- The Global Partnership for Sustainable Development Data is a global network bringing together governments, the private sector, and civil society organizations dedicated to using the data revolution to achieve the Sustainable Development Goals.\n- [Data for democracy](https://www.datafordemocracy.org/)\n\t- [https://github.com/Data4Democracy](https://github.com/Data4Democracy)\n\t- Data for Democracy is a worldwide community of passionate volunteers working together to promote trust and understanding in data and technology.\n- [Data for good (Canada)](https://dataforgood.ca/)\n\t- Data For Good is a collective of do gooders, who want to use their powers for good, and not evil, to help make our communities better through data. We are a national not for profit organization, with chapters across the county, that help other not for profit, and non-governmental, organizations harness the power of their data to make more informed and better decisions in their quest to make their communities flourish.\n- [Data for good (France)](https://dataforgood.fr/)\n\t- Les technologies numériques sont incroyablement puissantes et redéfinissent le fonctionnement de notre société. Mais tous les domaines ne se transforment pas à la même vitesse. Très souvent, les acteurs qui œuvrent pour l’intérêt général (citoyens, associations, institutions publiques et entreprises à fort impact social) sont en retard par rapport aux startups et aux géants de la tech. Data for Good existe pour rétablir l’équilibre.\n- [AI for good (Netherlands)](https://www.aiforgood.nl/)\n\t- LET'S USE A.I. FOR GOOD\n\t- Met AI for GOOD brengen we twee werelden bij elkaar: talent op het gebied van kunstmatige intelligentie (artificial intelligence) en niet-commerciële organisaties zoals NGOs en Gemeentes. Samen gaan we op zoek naar oplossingen voor uitdagende data-challenges.\n- [ESA EO4SD](http://eo4sd.esa.int/)\n\t- EO4SD – Earth Observation for Sustainable Development – is a new ESA initiative which aims to achieve a step increase in the uptake of satellite-based environmental information in the IFIs regional and global programs. It will follow a systematic, userdriven approach in order to meet longer-term, strategic geospatial information needs in the individual developing countries, as well as international and regional development organizations.\n- [DSSG Berlin](https://dssg-berlin.org/)\n- [Data for good lab](http://www.ise.bgu.ac.il/labs/fire/index.html)\n\t- Our name-the Data Science for Social Good Lab-reflects our goal: to improve the world through data. A gigantic volume of data is now available in the world, and much can be accomplished if we attain and utilize it in an effective manner. Our aim is to make our research reproducible and open on this website.\n- [Lacuna fund](https://lacunafund.org/)\n\t- Putting the benefits of machine learning within reach of data scientists, researchers, and social entrepreneurs worldwide.\n\t- We mobilize funding for labeled datasets that solve urgent problems in low- and middle-income contexts globally\n\n### Organizations\n- [AI for good foundation](https://ai4good.org/)\n\t- Chartered in 2016, the AI for Good Foundation fosters activities to maximize the benefit of AI technologies for social good through the lens of global sustainable development.\n\t- [Applying data science for a sustainable planet](https://ai4good.org/what-we-do/fragile-earth/)\n- [Partnership on AI](https://www.partnershiponai.org/)\n\t- The Partnership on AI to Benefit People and Society was established to study and formulate best practices on AI technologies, to advance the public’s understanding of AI, and to serve as an open platform for discussion and engagement about AI and its influences on people and society.\n- [Copernicus Institute of Sustainable Development](https://www.uu.nl/en/research/copernicus-institute-of-sustainable-development)\n\t- The Copernicus Institute of Sustainable Development is the scientific institute for sustainability research and teaching of Utrecht University. We contribute to the transition to a sustainable society through scientific excellence in a multi-disciplinary environment.\n- [The Alan Turing institute](https://www.turing.ac.uk/)\n\t- The Alan Turing Institute is the national institute for data science and artificial intelligence, with headquarters at the British Library\n- [AI2 - Allen Institute for Artificial Intelligence](https://allenai.org/)\n\t- AI2 was founded in 2014 with the mission of conducting high-impact AI research and engineering in service of the common good. AI2 is the creation of Paul Allen, Microsoft co-founder, and is led by Dr. Oren Etzioni, a leading AI researcher.\n- [Nesta](https://www.nesta.org.uk/)\n\t- Nesta is a global innovation foundation. We back new ideas to tackle the big challenges of our time, from the pressures of an ageing population to stretched public services and a fast changing jobs market.\n- [Delta Analytics](http://www.deltanalytics.org/)\n\t- Delta Analytics has two parallel goals. First, we bridge the skill gap faced by nonprofits by providing free data consulting and data services. Second, we build technical capacity in communities around the world by providing free trainings to help democratize access to machine learning and data tools. We are a non-profit run entirely without a full-time staff; instead, our work is possible because of the volunteer efforts of a rich community of data professionals.\n- [Data Orchard](http://dataorchard.co.uk/)\n\t- Data Orchard is a unique research company. Our work combines specialist skills in research, statistics and data with shared passions around making the world a better place socially, economically and environmentally.\n- [DataKind](http://www.datakind.org/)\n\t- This is, without hyperbole, a historic time for humanity. Mobile phones, sensors, and new software have created an abundance of data that can be mined, understood, and harnessed to gain new insights about our world and transform almost every sector. The same algorithms and techniques that companies use to boost profits can be leveraged by mission-driven organizations to improve the world, from battling hunger to advocating for child well-being and more. However, most social change organizations don’t have the budget or staff to take full advantage of this data revolution and most data scientists don't realize just how valuable their skills can be.\n\t- http://www.datakind.org/chapters/\n- [AI 4 all](http://ai-4-all.org/)\n\t- AI4ALL is Educating the Next Generation of AI Technologists, Thinkers, and Leaders\n- [Hack 4 impact](https://hack4impact.org/)\n\t- Hack4Impact is a 501 (c)(3) nonprofit organization founded at the University of Pennsylvania in Philadelphia, with chapters at various colleges across the United States. We collaborate with nonprofits and other socially responsible organizations to develop software that meets important social and humanitarian needs.\n- [Accel.AI](https://www.accel.ai/)\n\t- Shaping the Next Generation of AI Engineers \u0026 Enthusiasts. Accel.AI was founded in September of 2016, our mission is to lower the barriers to entry in engineering artificial intelligence. We focus on integrating AI and Social Impact through consulting, workshops, and research on ethical AI development and applied AI engineering.\n\n\n### Challenges, competitions\n- [AI4EO](https://ai4eo.eu/)\n\t- AI4EO is organising several artificial intelligence-based challenges with world-class partners and sponsors. Through these challenges we will foster the growth of the AI4EO community, support researchers and coders by promoting their work and use AI to extract more information from EO to solve some of the pressing challenges faced by our society.\n- [Big data for social good (IBM)](https://ibmhadoop.devpost.com/)\n\t- IBM invites developers and data enthusiasts to take a deep dive into real world civic issues using big data and IBM Bluemix’s Analytics for Hadoop service. Analyze one of our curated datasets or bring your own (provided it meets these requirements)! Use Hadoop and your data to create a clickable and interactive data visualization to highlight insights that you’ve found.\n- [Data Science Bowl](https://datasciencebowl.com/)\n\t- For us, data science is more than a skill or profession. It is a calling and a way of life. It rewards grit as much as talent. Failure, curiosity, and small successes lead to discovery. Data science grants the power of entire nations or corporations to the individual. It gives a megaphone to those who were previously silent. Our purpose is bigger than any one of us.\n- [Call for Code - Global](https://callforcode.org/)\n\t- Developers have revolutionized the way people live and interact with virtually everyone and everything. Where most people see challenges, developers see possibilities. That’s why David Clark Cause is launching Call for Code alongside Founding Partner IBM. This multi-year global initiative is a rallying cry to developers to use their skills and mastery of the latest technologies, and to create new ones, to drive positive and long-lasting change across the world with their code. The inaugural Call for Code Challenge theme is Natural Disaster Preparedness and Relief.\n- [Zindi](https://zindi.africa/)\n- [Data Science for good on Kaggle](https://www.kaggle.com/search?q=data+science+for+good)\n\t- Zindi hosts the largest community of African data scientists, working to solve the world’s most pressing challenges using machine learning and AI. We connect data scientists with organisations, and provide a place to learn, hone your skills and find a job. We want to transform the African continent and showcase African data science talent to the world\n\t- https://techcrunch.com/2021/12/02/south-african-crowd-solving-startup-zindi-building-a-community-of-data-scientists-and-using-ai-to-solve-real-world-problems/?guccounter=1\n- [Driven Data competitions](https://www.drivendata.org/competitions/)\n\t- At DrivenData, we bring cutting-edge practices in data science and crowdsourcing to some of the world's biggest social challenges and the organizations taking them on. We host online challenges, usually lasting 2-3 months, where a global community of data scientists competes to come up with the best statistical model for difficult predictive problems that make a difference.\n- [AI to solve the world's challenges (IBM, XPrize)](https://www.xprize.org/prizes/artificial-intelligence)\n\t- The $5 million IBM Watson AI XPRIZE is a global competition challenging teams to develop and demonstrate how humans can collaborate with powerful AI technologies to tackle the world’s Grand Challenges.\n- [GEOSS + AWS](http://www.earthobservations.org/aws.php)\n\t- $1.5 million worth of cloud services available for projects that improve understanding of our planet\n- [Grand Challenges in Biomedical Image Analysis](https://grand-challenge.org/)\n\n\n### Open data\n- [Data for Humanity: An Open Letter](http://www.bigdata.uni-frankfurt.de/dataforhumanity/)\n- [Datasets for Social Good Projects](https://github.com/shreyashankar/datasets-for-good)\n- [Medical imaging datasets](https://github.com/sfikas/medical-imaging-datasets)\n- [Open Knowledge International](https://okfn.org/)\n\t- [How to open data](https://okfn.org/opendata/how-to-open-data/)\n\t- [The Global Open Data Index](https://index.okfn.org/)\n\t\t- The Global Open Data Index provides the most comprehensive snapshot available of the state of open government data publication\n- [UN data](http://data.un.org/Explorer.aspx?d=GHG)\n\t- UNdata is a web-based data service for the global user community. It brings international statistical databases within easy reach of users through a single-entry point. Users can search and download a variety of statistical resources compiled by the United Nations (UN) statistical system and other international agencies. The numerous databases or tables collectively known as \"datamarts\" contain over 60 million data points and cover a wide range of statistical themes including agriculture, crime, communication, development assistance, education, energy, environment, finance, gender, health, labour market, manufacturing, national accounts, population and migration, science and technology, tourism, transport and trade.\n- [Datahub](https://datahub.io/)\n- [Humanitarian Data Exchange](https://data.humdata.org/)\n- [UCI ML repository](http://archive.ics.uci.edu/ml/datasets.html?sort=nameUp\u0026view=list)\n- [EnergyData](https://energydata.info/)\n\n### Events\n- [ACM FAT*](https://www.fatconference.org/)- ACM Conference on Fairness, Accountability, and Transparency (ACM FAT*)\n- [Re-work - AI for good summit](https://www.re-work.co/events/ai-for-good-summit-seattle-2022)\n- [AI for good global summit (ITU)](https://www.itu.int/en/ITU-T/AI/Pages/default.aspx)\n- [Data4good conference](https://www.data4goodconf.org.uk/)\n- [NeurIPS, ICML, ICLR - AI for social good workshop](https://aiforsocialgood.github.io/2018/)\n- DS for Social Good (SoGood)\n- [SoGood 2021](https://sites.google.com/view/ecmlpkddsogood2021/home)- The 6th Workshop on Data Science for Social Good \n- [Data For Good Exchange](https://www.bloomberg.com/company/d4gx/) - D4GX, an initiative of Bloomberg’s Office of the CTO, brings together data scientists with nonprofits and government agencies to solve some of the world’s biggest problems\n- [AI for Social Good (CCC)](https://cra.org/ccc/events/ai-social-good/#overview)\n- Data for good meetups\n\t- [Data for Good - Toronto (Toronto, ON)](https://www.meetup.com/DataforGood/)\n\t- [Data for Good - Calgary (Calgary, AB)](https://www.meetup.com/Data-for-Good-Calgary/)\n\t- [Data for Good - Vancouver (Vancouver, BC)](https://www.meetup.com/DataforGood-Vancouver/)\n\t- [Data for Good - Waterloo Region (Waterloo, ON)](https://www.meetup.com/Data-for-Good-WR/)\n\t- [Data for Good - Ottawa (Ottawa, ON)](https://www.meetup.com/DataforGoodYOW/)\n\t- [Data for Good (Paris, France)](https://www.meetup.com/Data-for-Good-FR/)\n\t- [Data For Good Barcelona (Barcelona, Spain)](https://www.meetup.com/Data-For-Good-Barcelona/)\n\t- [Data for Good (San Francisco, CA)](https://www.meetup.com/DataScienceforGood/)\n\t- [Data + the Greater Good (New York, NY)](https://www.meetup.com/greatergood/)\n\t- [Sheffield Data for Good (Sheffield, United Kingdom)](https://www.meetup.com/Sheffield-Data-for-Good/)","lastmodified":"2022-09-05T14:10:31.89403632Z","tags":null},"/AI4G/Bootcamps-and-fellowships":{"title":"AI4G - Bootcamps and fellowships","content":"## AI4Good lab\n- https://www.ai4goodlab.com/\n- We train and mentor women to succeed in AI\n\n\n## Data Science for Social Good\n- https://www.dssgfellowship.org/\n- The Data Science for Social Good Fellowship is a full-time summer program to train aspiring data scientists to work on machine learning, data science, and AI projects with social impact in a fair and equitable manner. Working closely with governments and nonprofits, fellows take on real-world problems in education, health, criminal justice, sustainability, public safety, workforce development, human services, transportation, economic development, international development, and more.\n\n\n## Data Fellows Programme\n- [https://centre.humdata.org/data-fellows-programme/](https://centre.humdata.org/data-fellows-programme/)\n- The Centre hosts Data Fellows in The Hague in June and July each year. Through this programme, the Fellows design and deliver targeted projects that contribute to the overall goals of the Centre. The programme is residential, with Fellows living and working in The Hague under the direction of the Data Fellows Programme Coordinator and with support from the entire Centre team.\n\n\n## Uptake data fellows\n- [https://www.uptake.org/data-fellows.html](https://www.uptake.org/data-fellows.html)\n- The Uptake.org Data Fellows program is a six-month fellowship designed to connect data professionals at non-profits, foundations, governmental agencies, and social enterprises to experts in data science and security. The fellowship begins with a week in Chicago where fellows meet with mentors, participate in workshops on topics in data science, and network with like-minded data-for-good professionals.\n\n\n## Frontier development lab\n- In USA: [https://frontierdevelopmentlab.org/#!/](https://frontierdevelopmentlab.org/#!/)\n- In Europe: [https://fdleurope.org](https://fdleurope.org/)\n- FDL is an applied artificial intelligence research accelerator established to maximize new AI technologies and capacities emerging in academia and the private sector and apply them to challenges in the space sciences.\n- Commercial, international and academic partners, such as Nvidia, Intel, Google, IBM and Lockheed Martin, SpaceResources Luxembourg, USC MASCLE, KBRWyle, XPrize, Kx and Miso Technologies provide capital, expertise and vast compute resources necessary for rapid experimentation and iteration in data intensive areas.\n\n\n## Sabudh foundation internship\n- [http://sabudh.org/](http://sabudh.org/)\n- Sabudh foundation is welcoming aspiring Data Scientists to undergo six months internship and become a SABUDH FELLOW. The foundation works on Data Science projects having real social impact. The interns will be learning machine learning and AI from the leading lights in the industry and academia.\n- These interns will be working on real-world, high impact problems in areas such as agriculture, governance, healthcare, and education with potential employment offered after the completion of the internship.","lastmodified":"2022-09-05T14:10:31.89403632Z","tags":null},"/AI4G/Entrepreneurship":{"title":"AI4G - Entrepreneurship","content":"## Google impact challenge\n- https://www.google.org/opportunities/\n- Working together to apply AI for social good\n- Google.org is issuing an open call to organizations around the world to submit their ideas for how they could use AI to help address societal challenges. Selected organizations will receive support from Google’s AI experts, Google.org grant funding from a $25M pool, credit and consulting from Google Cloud, and more.\n- [Supporting social impact startups](https://www.blog.google/around-the-globe/google-europe/supporting-social-impact-startups/)\n- [Climate innovation challenge](https://cloud.google.com/blog/topics/sustainability/climate-innovation-challenge-provides-google-cloud-credits)\n\n## UNICEF Innovation Fund Call for DS \u0026 AI\n- [http://unicefstories.org/datascienceAI/](http://unicefstories.org/datascienceAI/)\n- The UNICEF Innovation Fund is looking to fund and support, with both data and technical expertise, startups that are working with sophisticated applications of computer science including data mining, data processing, machine learning, artificial intelligence, and others, to help make the world a better place.\n- For our Data-Science cohort of investees we are particularly interested in the following areas:\n\t- Generating large data collections\n\t- Understanding complex environments\n\t- Processing satellite images\n\t- Applying Artificial Intelligence\n\n## Climate Launchpad\n- [https://climatelaunchpad.org](https://climatelaunchpad.org/)\n- ClimateLaunchpad is the world’s largest green business ideas competition. Innovation and invention can lead the way to a clean future. That’s why we create a stage for the people who have great cleantech ideas and help them develop those ideas into startups making global impact. ClimateLaunchpad is part of the Entrepreneurship offerings of Climate-KIC.\n- Fixing climate change, one start-up at a time.\n\n## Microsoft AI for accessibility\n- [https://www.microsoft.com/en-us/ai-for-accessibility](https://www.microsoft.com/en-us/ai-for-accessibility)\n- A Microsoft grant program that harnesses the power of AI to amplify human capability for the more than one billion people around the world with a disability.\n\n## Microsoft AI for Earth grants\n- [https://www.microsoft.com/en-us/ai-for-earth/grants](https://www.microsoft.com/en-us/ai-for-earth/grants)\n- [https://www.microsoft.com/en-us/ai-for-earth](https://www.microsoft.com/en-us/ai-for-earth)\n- AI for Earth awards grants to support projects that change the way people and organizations monitor, model, and ultimately manage Earth’s natural systems. Depending on project need, our grants can award Microsoft Azure cloud computing resources (including AI tools) and/or data labeling services.\n\n\n## Social Nest\n- https://socialnest.org/\n- We are a global platform supporting entrepreneurs, corporates, governments and investors with needed resources, opportunities and tailored guidance so they can create solutions to the world's most pressing challenges.\n\n\n## Samsung For Impact\n- https://www.samsungforimpact.com/\n- Samsung For Impact is a European impact acceleration program designed to discover and bolster promising impact startups and entrepreneurs working to achieve social good through their business or developing innovative technologies with a social purpose.\n\n\n## Good AI capital\n- https://goodai.capital/\n- Based on a high conviction strategy, Good AI Capital invests in a small number of high-quality startups where we can add value and contribute towards their long-term success.","lastmodified":"2022-09-05T14:10:31.89403632Z","tags":null}}