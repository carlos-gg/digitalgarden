<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AIs on</title><link>https://carlos-gg.github.io/AIDigitalGarden/ai/</link><description>Recent content in AIs on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://carlos-gg.github.io/AIDigitalGarden/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Active learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Active-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Active-learning/</guid><description>Resources https://en.wikipedia.org/wiki/Active_learning_(machine_learning) Active learning refers to algorithms that take an active role in the selection of which ex-amples are labeled.</description></item><item><title>Anomaly and Outlier Detection</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Anomaly-and-Outlier-Detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Anomaly-and-Outlier-Detection/</guid><description>See Active learning for anomaly discovery
Resources Most of the outlier detection approaches belong to [[Unsupervised learning]] although it might be framed as a [[Semi-supervised learning]] problem.</description></item><item><title>Artificial Intelligence</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/AI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/AI/</guid><description>Resources The expression artificial intelligence is an umbrella term encompassing a suite of technologies that can perform complex tasks when acting in conditions of uncertainty, including visual perception, speech recognition, natural language processing, reasoning, learning from data, and a range of optimisation problems.</description></item><item><title>Autoencoders</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Autoencoders/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Autoencoders/</guid><description>Resources Dimensionality Reduction: https://www.cs.toronto.edu/~hinton/science.pdf
The classical approach for unsupervised learning using neural networks. The basic version consists of a Multilayer Perceptron (MLP) where the input and output layer have the same size and a smaller hidden layer is trained to recover the input.</description></item><item><title>Automated planning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Automated-planning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Automated-planning/</guid><description>Resources AI Planning is a branch of artificial intelligence that concerns the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles.</description></item><item><title>AutoML</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/AutoML/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/AutoML/</guid><description>See Model selection and tuning
Resources https://en.wikipedia.org/wiki/Automated_machine_learning
Automated machine learning (AutoML) is the process of automating the process of applying machine learning to real-world problems.</description></item><item><title>Background subtraction</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Background-subtraction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Background-subtraction/</guid><description>Resources https://en.wikipedia.org/wiki/Foreground_detection
https://github.com/murari023/awesome-background-subtraction
Foreground detection is one of the major tasks in the field of computer vision and image processing whose aim is to detect changes in image sequences.</description></item><item><title>Bayesian modelling</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Bayesian-modelling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Bayesian-modelling/</guid><description>See Bayesian neural networks
Resources https://en.wikipedia.org/wiki/Bayesian_statistics https://en.wikipedia.org/wiki/Bayesian_inference http://brohrer.github.io/how_bayesian_inference_works.html http://willwolf.io/en/2017/02/07/bayesian-inference-via-simulated-annealing/ #TALK Bayesian Inference, Shakir Mohamed, MLSS 2020: Part I: https://www.</description></item><item><title>Bayesian Neural Networks (BNNs)</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Bayesian-neural-networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Bayesian-neural-networks/</guid><description>Resources Bayesian Neural Network tutorial: http://edwardlib.org/tutorials/bayesian-neural-network Bayesian Deep Learning - NeurIPS Workshop: http://bayesiandeeplearning.org/ Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe [[AI]].</description></item><item><title>Capsule Neural networks (CapsNets)</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/CapsNets/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/CapsNets/</guid><description>Resources https://en.wikipedia.org/wiki/Capsule_neural_network
A Capsule Neural Network (CapsNet) is a machine learning system that is a type of artificial neural network (ANN) that can be used to better model hierarchical relationships.</description></item><item><title>Causality</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Causality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Causality/</guid><description>Resources To Build Truly Intelligent Machines, Teach Them Cause and Effect: https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/
Representing uncertain knowledge: https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture5.md</description></item><item><title>Class imbalance</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Class-imbalance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Class-imbalance/</guid><description>Resources https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis http://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation http://www.alfredo.motta.name/cross-validation-done-wrong/ http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/ http://www.chioka.in/class-imbalance-problem/ http://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html https://svds.com/learning-imbalanced-classes/ Conventional algorithms are often biased towards the majority class because their loss functions attempt to optimize quantities such as error rate, not taking the data distribution into consideration.</description></item><item><title>Classification</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Classification/</guid><description>Resources https://github.com/jmportilla/Udemy---Machine-Learning/blob/master/Multi-Class%20Classification.ipynb Comparison of classifiers https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html https://medium.com/@maheshkkumar/implementing-a-binary-classifier-in-python-b69d08d8da21#.goynlh7ah Metrics https://www.neuraldesigner.com/blog/methods-binary-classification http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/ http://docs.aws.amazon.com/machine-learning/latest/dg/binary-model-insights.html Naive Bayes https://blancosilva.</description></item><item><title>Clustering</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Unsupervised-learning/Clustering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Unsupervised-learning/Clustering/</guid><description>Resources Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters).</description></item><item><title>Computer Vision</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Computer-vision/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Computer-vision/</guid><description>See [[CNNs]] [[MLPs#MLPs for vision and language]] [[Transformers#For Computer Vision]] [[Generative modelling#Generative models for Image data]] [[GANs]]
Resources https://github.com/jbhuang0604/awesome-computer-vision Papers with code - computer vision: https://paperswithcode.</description></item><item><title>Convolutional Neural Networks (CNNs)</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/CNNs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/CNNs/</guid><description>Resources https://github.com/kjw0612/awesome-deep-vision https://en.wikipedia.org/wiki/Convolutional_neural_network In [[deep learning]], a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery.</description></item><item><title>Dask</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Dask/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Dask/</guid><description>Resources #TALK Dask for ad hoc distributed computing (Pydata): https://www.youtube.com/watch?v=EEfI-11itn0 #TALK Using Dask for Parallel Computing in Python: https://www.youtube.com/watch?v=s4ChP7tc3tA #TALK Parallelizing Scientific Python with Dask | SciPy 2017 Tutorial | James Crist: https://www.</description></item><item><title>Data Engineering and Computer Science</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Data-engineering-and-computer-science/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Data-engineering-and-computer-science/</guid><description>Resources https://github.com/ossu/computer-science Data engineering role is ensuring uninterrupted flow of data between servers and applications. https://www.datacamp.com/community/blog/data-engineering-vs-data-science-infographic#gs.pvMeguY Interaction between ML and CS teams: https://labs.</description></item><item><title>Data Science</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Data-Science/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Data-Science/</guid><description>Resources https://en.wikipedia.org/wiki/Data_science https://github.com/bulutyazilim/awesome-datascience Reproducible Data Analysis in Jupyter (Vanderplas): https://jakevdp.github.io/blog/2017/03/03/reproducible-data-analysis-in-jupyter/ Cookiecutter Data Science: https://drivendata.github.io/cookiecutter-data-science/ An Executive&amp;rsquo;s Guide To Understanding Cloud-based ML Services: https://www.</description></item><item><title>Deep belief network</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Deep-belief-network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Deep-belief-network/</guid><description>Resources In machine learning, a deep belief network (DBN) is a generative graphical model, or alternatively a type of deep neural network, composed of multiple layers of latent variables(&amp;ldquo;hidden units&amp;rdquo;), with connections between the layers but not between units within each layer.</description></item><item><title>Deep Learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Deep-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Deep-learning/</guid><description>Resources DL is a branch of [[Machine Learning]] and [[AI]] based on a set of algorithms that attempt to model high level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear transformations.</description></item><item><title>Dimensionality reduction and low-rank modeling</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Unsupervised-learning/Dimensionality-reduction-and-low-rank-modeling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Unsupervised-learning/Dimensionality-reduction-and-low-rank-modeling/</guid><description>Resources The Beginner&amp;rsquo;s Guide to Dimensionality Reduction: https://idyll.pub/post/visxai-dimensionality-reduction-1dbad0a67a092b007c526a45/ Distances, Neighborhoods, or Dimensions? Projection Literacy for the Analysis of Multivariate Data: https://visxprojections.</description></item><item><title>Distributed Deep learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Distributed-DL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Distributed-DL/</guid><description>Resources https://d2l.ai/chapter_computational-performance/multiple-gpus.html https://jhui.github.io/2017/03/07/TensorFlow-GPU/ https://www.logicalclocks.com/blog/goodbye-horovod-hello-collectiveallreduce Twelve ways to fool the masses when reporting performance of deep learning workloads: https://htor.inf.ethz.ch/blog/index.php/2018/11/08/twelve-ways-to-fool-the-masses-when-reporting-performance-of-deep-learning-workloads/ Distributed Deep Learning 101: Introduction: https://towardsdatascience.</description></item><item><title>Encoder-decoder networks</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Encoder-decoder-networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Encoder-decoder-networks/</guid><description>Resources Very common models for semantic segmentation tasks. [[Deep learning]] architectures composed of two paths, an encoding and a decoding one.</description></item><item><title>Ensemble learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Ensemble-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Ensemble-learning/</guid><description>Resources https://en.wikipedia.org/wiki/Ensemble_learning In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.</description></item><item><title>Explainable AI (XAI)</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/XAI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/XAI/</guid><description>Resources https://github.com/anguyen8/XAI-papers https://en.wikipedia.org/wiki/Explainable_artificial_intelligence Ideas on interpreting [[machine learning]]: https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning Explainable AI demos: https://lrpserver.hhi.fraunhofer.de/ Why you need to care about Explainable Machine Learning Interpreting machine learning models I.</description></item><item><title>Feature learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Feature-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Feature-learning/</guid><description>Resources In machine learning, feature learning or representation learning is a set of techniques that allows a system to automatically discover the representations needed for feature detection or classification from raw data.</description></item><item><title>Feature selection</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Feature-selection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Feature-selection/</guid><description>See Regression#Regularized regression
Resources https://en.wikipedia.org/wiki/Feature_selection http://machinelearningmastery.com/an-introduction-to-feature-selection/ http://scikit-learn.org/stable/modules/feature_selection.html Removing features with low variance: http://scikit-learn.org/stable/modules/feature_selection.html#removing-features-with-low-variance Univariate feature selection: http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection Recursive feature elimination: http://scikit-learn.</description></item><item><title>Forecasting</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Forecasting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Forecasting/</guid><description>See: Time Series analysis Regression RNNs CNNs#Sequence time series modelling Transformers#For NLP
Resources https://en.wikipedia.org/wiki/Forecasting Microsoft - Time Series Forecasting Best Practices &amp;amp; Examples: https://github.</description></item><item><title>Fourier Neural Operator</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Fourier-Neural-Operators/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Fourier-Neural-Operators/</guid><description>References #PAPER Fourier Neural Operator for Parametric Partial Differential Equations (Li 2020): https://arxiv.org/abs/2010.08895 #CODE https://github.com/zongyi-li/fourier_neural_operator https://zongyi-li.github.io/blog/2020/fourier-pde/ https://www.technologyreview.com/2020/10/30/1011435/ai-fourier-neural-network-cracks-navier-stokes-and-partial-differential-equations/ Function approximation in Fourier space instead of a the Euclidian (with conventional convolutions) Paper explained: https://www.</description></item><item><title>Gaussian Process</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Gaussian-Process/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Gaussian-Process/</guid><description>Resources https://en.wikipedia.org/wiki/Gaussian_process In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i.</description></item><item><title>Generative Adversarial Networks</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/GANs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/GANs/</guid><description>Resources In brief, a GAN consists of two networks; a generator (G) and a discriminator (D), given a set of training examples, G will generate outputs and D will classify them as either being from the same distribution as the training examples or not.</description></item><item><title>Generative modeling</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Generative-modelling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Generative-modelling/</guid><description>Resources Generative models: https://openai.com/blog/generative-models/ Deep Generative Models: https://www.cs.toronto.edu/~slwang/generative_model.pdf Taxonomy of Generative Models: https://christineai.blog/taxonomy/ Courses #COURSE Deep Generative Modeling: VAEs and GANs (MIT 6.</description></item><item><title>Geometric deep learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Geometric-deep-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Geometric-deep-learning/</guid><description>Talks and courses #TALK Geometric Deep Learning: The Erlangen Programme of ML (M Bronstein, ICLR 2021 Keynote): https://www.youtube.com/watch?v=w6Pw4MOzMuo #COURSE Geometric Deep Learning: https://geometricdeeplearning.</description></item><item><title>Gradient boosting</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Gradient-boosting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Gradient-boosting/</guid><description>See Ensemble learning
Resources Outperforms Random Forests and AdaBoost. RF is easier to tune and less prone to overfitting http://arogozhnikov.</description></item><item><title>Graph neural networks (GNNs)</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/GNNs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/GNNs/</guid><description>Resources Graph Neural networks (GNNs) are being widely adopted for diverse applications and domains. This is in part due to their effectiveness on complex data structures, improved performance and scalability, and availability of approaches A Gentle Introduction to Graph Neural Networks: https://distill.</description></item><item><title>Horovod</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Horovod/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Horovod/</guid><description>References #PAPER Horovod: fast and easy distributed deep learning in TensorFlow (Sergeev 2018): http://arxiv.org/abs/1802.05799 #CODE https://github.com/horovod/horovod https://horovod.readthedocs.io/en/latest/keras.html https://horovod.readthedocs.io/en/stable/tensorflow.html https://eng.</description></item><item><title>Image and video captioning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Image-and-video-captioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Image-and-video-captioning/</guid><description>References Review papers:
#PAPER A Systematic Literature Review on Image Captioning (Staniute 2019): https://www.mdpi.com/2076-3417/9/10/2024/htm
#PAPER Survey of convolutional neural networks for image captioning (Kalra 2020): https://www.</description></item><item><title>Image-to-image translation</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Image-to-image-translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Image-to-image-translation/</guid><description>Resources The task of Image-to-image translation is to learn the mapping from a given image (X) to a specific target image (Y), e.</description></item><item><title>Inpainting</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Inpainting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Inpainting/</guid><description>Resources https://en.wikipedia.org/wiki/Inpainting Inpainting is a conservation process where damaged, deteriorating, or missing parts of an artwork are filled in to present a complete image https://www.</description></item><item><title>Jupyter</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Jupyter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Jupyter/</guid><description>Resources #CODE Jupyter: https://github.com/jupyter #CODE Jupyterlab: https://github.com/jupyterlab/jupyterlab #CODE Jupyter(hub): https://jupyter.org/hub #CODE Jupyterlite: https://github.com/jupyterlite https://blog.jupyter.org/jupyterlite-jupyter-%EF%B8%8F-webassembly-%EF%B8%8F-python-f6e2e41ab3fa #CODE Papermill - Parameterize, execute, and analyze notebooks: https://github.</description></item><item><title>Learning to rank</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Learning-to-rank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Learning-to-rank/</guid><description>Resources https://en.wikipedia.org/wiki/Learning_to_rank Learning to rank or machine-learned ranking (MLR) is the application of machine learning, typically supervised, semi-supervised or [[reinforcement learning]], in the construction of ranking models for information retrieval systems.</description></item><item><title>Machine Learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Machine-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Machine-Learning/</guid><description>Resources Machine learning identifies patterns using statistical learning and computers by unearthing boundaries in data sets. Awesome ML: https://github.com/josephmisiti/awesome-machine-learning Machine Learning Research Articles: https://deepai.</description></item><item><title>Maths and Statistics</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Math-and-stats/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Math-and-stats/</guid><description>Resources Statistics cheatsheet: https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-statistics https://github.com/rouseguy/intro2stats Stanford-cs-229 ML, probability and stats refresher: https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-probabilities-statistics.pdf https://www.khanacademy.org/math/statistics-probability http://christopherroach.com/articles/statistics-for-hackers/ http://students.brown.edu/seeing-theory/ https://scipy-latinamerica.github.io/revista.io/blog/2018/10/22/probabilidad-y-estadistica-con-python/ Trigonometry refresher: https://stanford.edu/~shervine/teaching/cme-102/trigonometry Books #BOOK Essential Mathematics and Statistics for Science (Currell 2009, WILEY): https://www.</description></item><item><title>ML ops</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/MLops/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/MLops/</guid><description>Resources https://en.wikipedia.org/wiki/MLOps Set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently. The word is a compound of &amp;ldquo;machine learning&amp;rdquo; and the continuous development practice of DevOps in the software field https://github.</description></item><item><title>Model selection and tuning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Model-selection-and-tuning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Model-selection-and-tuning/</guid><description>See [[AutoML]] See [[Data engineering and computer science#Workflow managers distributed ML]]
Resources Model selection and evaluation: https://scikit-learn.org/stable/model_selection.html Code See MLops</description></item><item><title>Multilayer perceptrons (MLPs)</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/MLPs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/MLPs/</guid><description>Resources A multilayer perceptron (MLP) is a feed forward artificial neural network model that maps sets of input data onto a set of appropriate outputs.</description></item><item><title>Multimodal learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Multimodal-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Multimodal-learning/</guid><description>Resources General-purpose neural networks capable of handling diverse inputs and output tasks Multimodal Deep Learning: https://multimodal-dl.mpi-inf.mpg.de/ Code #CODE Pykale (in pytorch): https://github.</description></item><item><title>Natural Language Processing (NLP)</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/NLP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/NLP/</guid><description>Resources https://en.wikipedia.org/wiki/Natural_language_processing A Computer Science field connected to Artificial Intelligence and Computational Linguistics which focuses on interactions between computers and human language and a machine’s ability to understand, or mimic the understanding of human language.</description></item><item><title>Neural Ordinary Differential Equations</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Neural-ODEs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Neural-ODEs/</guid><description>Resources https://github.com/Zymrael/awesome-neural-ode Understanding Neural ODE&amp;rsquo;s: https://jontysinai.github.io/jekyll/update/2019/01/18/understanding-neural-odes.html Neural Ordinary Differential Equations and Dynamics Models: https://medium.com/@ml.at.berkeley/neural-ordinary-differential-equations-and-dynamics-models-1a4277fbb80 ODEs are often used to describe the time derivatives of a physical situation, referred to as the dynamics.</description></item><item><title>Normalizing flows</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Normalizing-flows/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Normalizing-flows/</guid><description>Resources Normalizing flow models are generative models, i.e. they infer the underlying probability distribution of an observed dataset. With that distribution we can do a number of interesting things, namely sample new realistic points and query probability densities.</description></item><item><title>Object classification, image recognition</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Object-classification-image-recognition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Object-classification-image-recognition/</guid><description>See: CNNs Object detection Semantic segmentation Residual and dense neural networks
Resources https://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception/ https://blog.paralleldots.com/data-science/must-read-path-breaking-papers-about-image-classification/ References #PAPER AlexNet: ImageNet Classification with Deep Convolutional Neural Networks (2012): https://papers.</description></item><item><title>Object detection</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Object-detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Object-detection/</guid><description>See Semantic segmentation
Code https://github.com/microsoft/computervision-recipes/tree/master/scenarios/detection #CODE MMdetection: https://github.com/open-mmlab/mmdetection OpenMMLab Detection Toolbox and Benchmark (pytorch) https://mmdetection.readthedocs.io/ #CODE TensorFlow object detection API Repository: https://github.</description></item><item><title>One, few-shot learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/One-few-shot-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/One-few-shot-learning/</guid><description>Resources https://en.wikipedia.org/wiki/One-shot_learning One-shot learning is an object categorization problem, found mostly in computer vision. Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of samples/images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training samples/images.</description></item><item><title>Probabilistic machine learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Probabilistic-machine-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Probabilistic-machine-learning/</guid><description>See: Bayesian neural networks Bayesian modelling
Resources https://en.wikipedia.org/wiki/Graphical_model References #BOOK Probabilistic Graphical Models: Principles and Techniques (Koller, 2009 MIT): http://pgm.</description></item><item><title>Problem Solving and Search</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Problem-Solving-and-Search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Problem-Solving-and-Search/</guid><description>Resources Solving problems by searching: https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture2.md Problem solving and search: https://www.emse.fr/~picard/cours/ai/chapter03.pdf Constraint satisfaction problems: Constraint satisfaction problems (CSPs) are mathematical questions defined as a set of objects whose state must satisfy a number of constraints or limitations.</description></item><item><title>Random forest</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Random-forest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Random-forest/</guid><description>See Ensemble learning
Resources https://github.com/kjw0612/awesome-random-forest https://sebastianraschka.com/faq/docs/bagging-boosting-rf.html Bagging and random forests are “bagging” algorithms that aim to reduce the complexity of models that overfit the training data.</description></item><item><title>Recurrent Neural Networks (RNNs)</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/RNNs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/RNNs/</guid><description>Resources https://en.wikipedia.org/wiki/Recurrent_neural_network https://github.com/kjw0612/awesome-rnn Recurrent Neural Networks cheatsheet: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks Tensorflow, DL and RNNs without a PhD: https://docs.google.com/presentation/d/e/2PACX-1vRouwj_3cYsmLrNNI3Uq5gv5-hYp_QFdeoan2GlxKgIZRSejozruAbVV0IMXBoPsINB7Jw92vJo2EAM/pub?slide=id.p http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/ http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html http://karpathy.github.io/2015/05/21/rnn-effectiveness/ http://www.</description></item><item><title>Regression</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Regression/</guid><description>See: Time Series analysis RNNs CNNs#Sequence time series modelling
Resources https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/ https://towardsdatascience.com/a-beginners-guide-to-regression-analysis-in-machine-learning-8a828b491bbf http://www.datasciencecentral.com/profiles/blogs/10-types-of-regressions-which-one-to-use http://www.datasciencecentral.com/profiles/blogs/23-types-of-regression Curve fitting vs regression: https://blog.datazar.com/curve-fitting-vs-regression-752ce295b0b1 Goodness of fit: Coefficient of determination (The R-squared measure of goodness of fit): http://blog.</description></item><item><title>Reinforcement learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Reinforcement-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Reinforcement-learning/</guid><description>Resources Reinforcement learning is the task of learning what actions to take, given a certain situation/environment, so as to maximize a reward signal.</description></item><item><title>Residual and dense neural networks</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Residual-and-dense-neural-networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Residual-and-dense-neural-networks/</guid><description>Resources https://en.wikipedia.org/wiki/Residual_neural_network Training and investigating Residual Nets: http://torch.ch/blog/2016/02/04/resnets.html References #PAPER Deep Residual Learning for Image Recognition, Resnet-50 (He 2015): http://arxiv.</description></item><item><title>Self-supervised learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Self-supervised-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Self-supervised-learning/</guid><description>Resources https://github.com/jason718/awesome-self-supervised-learning https://hackernoon.com/self-supervised-learning-gets-us-closer-to-autonomous-learning-be77e6c86b5a Self-Supervised Representation Learning: https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html Self-Supervised Vision Models (2021, Dr. Ishan Misra - FAIR): https://www.youtube.com/watch?v=EXJmodhu4_4 Self-supervised learning: The dark matter of intelligence: https://ai.</description></item><item><title>Semantic segmentation</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Semantic-segmentation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Semantic-segmentation/</guid><description>See: Encoder-decoder networks for image segmentation Object detection
Resources https://en.wikipedia.org/wiki/Image_segmentation https://github.com/mrgloom/awesome-semantic-segmentation https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4 Overview of semantic image segmentation: https://www.jeremyjordan.me/semantic-segmentation/ Code #CODE DeepLab2: https://github.</description></item><item><title>Semi-supervised learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Semi-supervised-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Semi-supervised-learning/</guid><description>Resources https://en.wikipedia.org/wiki/Semi-supervised_learning Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training.</description></item><item><title>Super-resolution</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Super-resolution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Super-resolution/</guid><description>See [[Image-to-image translation]]
Resources https://github.com/ptkin/Awesome-Super-Resolution https://github.com/ChaofWang/Awesome-Super-Resolution https://keras.io/examples/vision/super_resolution_sub_pixel/ Image Super-Resolution: A Comprehensive Review (2020): https://blog.paperspace.com/image-super-resolution/ #TALK How Super Resolution Works (2019): https://www.</description></item><item><title>Supervised Learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Supervised-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Supervised-Learning/Supervised-learning/</guid><description>Resources https://en.wikipedia.org/wiki/Supervised_learning Supervised Learning cheatsheet: https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning http://scikit-learn.org/stable/supervised_learning.html Metrics: http://docs.aws.amazon.com/machine-learning/latest/dg/binary-model-insights.html ROC curves, AUC http://www.dataschool.io/roc-curves-and-auc-explained/ http://corysimon.github.io/articles/what-is-an-roc-curve/ Classification See Classification</description></item><item><title>Tensorflow, Keras</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Tensorflow-keras/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Tensorflow-keras/</guid><description>Code #CODE Tensorflow (Google): https://github.com/tensorflow/tensorflow http://playground.tensorflow.org/ https://cloud.google.com/blog/big-data/2016/07/understanding-neural-networks-with-tensorflow-playground https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc#.dg41ldof5 https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0 Tensorflow 2.0: models migration and new design: https://pgaleone.eu/tensorflow/gan/2018/11/04/tensorflow-2-models-migration-and-new-design/ http://planspace.org/20170404-how_not_to_program_the_tensorflow_graph/ #CODE TF Similarity: https://github.</description></item><item><title>Time series analysis</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Time-Series-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Time-Series-analysis/</guid><description>See: Forecasting RNNs CNNs#Sequence time series modelling Deep learning#Deep learning for tabular data
Resources https://en.wikipedia.org/wiki/Time_series https://github.com/MaxBenChrist/awesome_time_series_in_python https://github.com/frutik/awesome-timeseries https://github.com/cuge1995/awesome-time-series http://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/ Python to work with time series data: https://github.</description></item><item><title>Transfer learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Transfer-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Transfer-learning/</guid><description>Resources https://en.wikipedia.org/wiki/Transfer_learning Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem https://github.</description></item><item><title>Transformers</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Transformers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Deep-learning/Transformers/</guid><description>Resources https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/ (from RNNs with attention to Transformers) https://analyticsindiamag.com/a-complete-learning-path-to-transformers/ https://analyticsindiamag.com/transformers-for-vision-7-works-that-indicate-fusion-is-the-future-of-ai/ Code #CODE Transformers: https://github.com/huggingface/transformers #CODE Xformers: https://github.com/facebookresearch/xformers For NLP #PAPER Attention is all you need (Vaswani 2017): https://arxiv.</description></item><item><title>Unsupervised learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Unsupervised-learning/Unsupervised-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Unsupervised-learning/Unsupervised-learning/</guid><description>Resources https://en.wikipedia.org/wiki/Unsupervised_learning Unsupervised Learning cheatsheet: https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-unsupervised-learning Unsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from &amp;ldquo;unlabeled&amp;rdquo; data (a classification or categorization is not included in the observations).</description></item><item><title>Video segmentation and prediction</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Video-segmentation-and-prediction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Computer-Vision/Video-segmentation-and-prediction/</guid><description>See: Encoder-decoder networks Deep learning#Deep learning for multi-dimensional data RNNs
Resources Spatiotemporal classification and regression
Hybrid convolutional and recurrent networks, 3dconv and related approaches</description></item><item><title>Visualization</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Visualization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Visualization/</guid><description>Resources https://github.com/fasouto/awesome-dataviz http://keshif.me/demo/VisTools The visualization universe: http://visualizationuniverse.com/ http://visualizationuniverse.com/charts/ Dataviz project: https://datavizproject.com/ UW Interactive Data Lab: http://idl.cs.washington.edu/ Flowing Data Tutorials: https://flowingdata.</description></item><item><title>Weakly supervised learning</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Weakly-supervised-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Weakly-supervised-learning/</guid><description>See: Transfer learning Active learning Semi-supervised learning
Resources Weak supervision is a branch of machine learning where noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts of training data in a supervised learning setting.</description></item><item><title>Xarray</title><link>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Xarray/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://carlos-gg.github.io/AIDigitalGarden/AI/Data-Science-Data-Engineering/Xarray/</guid><description>Code #code Xarray - N-D labeled arrays and datasets in Python: https://github.com/pydata/xarray #PAPER Xarray - N-D labeled Arrays and Datasets in Python (Hoyer 2017): https://openresearchsoftware.</description></item></channel></rss>