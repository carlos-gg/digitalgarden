---
title: "Model validation and drift"
---

> "Drift" is a term used in machine learning to describe how the performance of a machine learning model in production slowly gets worse over time. This can happen for a number of reasons, such as changes in the distribution of the input data over time or the relationship between the input (x) and the desired target (y) changing

## Resources
- [Understanding Data Drift and Model Drift: Drift Detection in Python](https://www.datacamp.com/tutorial/understanding-data-drift-model-drift)
- [Machine Learning Model Drift](https://towardsdatascience.com/machine-learning-model-drift-9cc43ad530d6)

## Code
- #CODE [Evidently](https://github.com/evidentlyai/evidently) - Evaluate and monitor ML models from validation to production
	- https://docs.evidentlyai.com/
- #CODE [Frouros](https://github.com/IFCA/frouros) - Open-source Python library for drift detection in machine learning systems
	- https://frouros.readthedocs.io/en/latest/
- #CODE [Alibi-detect](https://github.com/SeldonIO/alibi-detect) - Algorithms for outlier, adversarial and drift detection

## References
- #PAPER [A survey on concept drift adaptation (Gama 2014)](https://dl.acm.org/doi/10.1145/2523813)
