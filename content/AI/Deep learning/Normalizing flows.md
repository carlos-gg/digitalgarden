---
title: "Normalizing flows"
disableToc: false 
---

## Resources
- Normalizing flow models are generative models, i.e. they infer the underlying probability distribution of an observed dataset. With that distribution we can do a number of interesting things, namely sample new realistic points and query probability densities.
- https://github.com/janosh/awesome-normalizing-flows
- Flow-based Deep Generative Models: https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html
- https://deepgenerativemodels.github.io/notes/flow/ 
- http://akosiorek.github.io/ml/2018/04/03/norm_flows.html 

- #TALK Introduction to Normalizing Flows (ECCV2020 Tutorial): https://www.youtube.com/watch?v=u3vVyFVU_lI


## Code
- #CODE Normalizing Flows in JAX: https://github.com/ChrisWaites/jax-flows
- #CODE NuX - Normalizing Flows using JAX: https://github.com/Information-Fusion-Lab-Umass/NuX


## References
Review papers:
- #PAPER Normalizing Flows: An Introduction and Review of Current Methods (Kobyzev 2020): https://arxiv.org/abs/1908.09257

- #PAPER NICE: Non-linear Independent Components Estimation (Dinh 2015): https://arxiv.org/abs/1410.8516
- #PAPER Glow: Generative Flow with Invertible 1x1 Convolutions (Kingma 2018): https://arxiv.org/abs/1807.03039
	- https://openai.com/blog/glow/
	- #CODE https://github.com/openai/glow


### Image-to-image translation
See [Image-to-image translation#Flow-based](Image-to-image%20translation.md#Flow-based)

