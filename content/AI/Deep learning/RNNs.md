---
title: "Recurrent Neural Networks (RNNs)"
---

> See:
> - [[AI/Deep learning/LSTMs]]
> - [[AI/Deep learning/GRUs]]
> - [[AI/Deep learning/Reservoir computing]] 
> - [[AI/Deep learning/Transformers]]

## Resources
- https://en.wikipedia.org/wiki/Recurrent_neural_network
- https://github.com/kjw0612/awesome-rnn
- [Recurrent Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)
- [Tensorflow, DL and RNNs without a PhD](https://docs.google.com/presentation/d/e/2PACX-1vRouwj_3cYsmLrNNI3Uq5gv5-hYp_QFdeoan2GlxKgIZRSejozruAbVV0IMXBoPsINB7Jw92vJo2EAM/pub?slide=id.p)
- http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html
- http://karpathy.github.io/2015/05/21/rnn-effectiveness/
- https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0
- https://www.kaggle.com/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru
- https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21
- [4 Sequence Encoding Blocks You Must Know Besides RNN/LSTM in Tensorflow](https://hanxiao.github.io/2018/06/24/4-Encoding-Blocks-You-Need-to-Know-Besides-LSTM-RNN-in-Tensorflow/)
- [When Recurrent Models Don't Need to be Recurrent (recurrent vs feed-forward models)](http://www.offconvex.org/2018/07/27/approximating-recurrent/)
- [Deep Learning: No, LSTMs Are Not Dead!](https://towardsdatascience.com/deep-learning-no-lstms-are-not-dead-20217553b87a)

## References
- #PAPER [Neural Turing Machines (Graves 2014)](http://arxiv.org/abs/1410.5401)
- #PAPER [Attention and Augmented Recurrent Neural Networks (Olah 2016)](http://distill.pub/2016/augmented-rnns/)
- #PAPER [Engineering Extreme Event Forecasting at Uber with Recurrent Neural Networks (Laptev 2017)](https://eng.uber.com/neural-networks/)
- #PAPER [Deep and Confident Prediction for Time Series at Uber (Zhu 2017)](https://arxiv.org/abs/1709.01907)
	- https://eng.uber.com/neural-networks-uncertainty-estimation/ 
	- introduced a new end-to-end Bayesian neural network (BNN) architecture that more accurately forecasts time series predictions and uncertainty estimations at scale
- #PAPER [Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau 2016)](https://arxiv.org/abs/1409.0473)
	- https://medium.com/datadriveninvestor/attention-in-rnns-321fbcd64f05
- #PAPER [DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks (Salinas 2019)](https://arxiv.org/abs/1704.04110)            

### LSTMs
See [[AI/Deep learning/LSTMs]]

### GRUs
See [[AI/Deep learning/GRUs]]

### Reservoir computing
See [[AI/Deep learning/Reservoir computing]]






