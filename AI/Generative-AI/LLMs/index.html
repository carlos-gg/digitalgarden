<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Large Language Models are artificial intelligence models that are trained on vast amounts of text data to generate, understand, and generate human-like language."><title>LLMs</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://carlos-gg.github.io/digitalgarden//icon.png><link href=https://carlos-gg.github.io/digitalgarden/styles.b3e1e36b0403ac565c9392b3e23ef3b6.min.css rel=stylesheet><link href=https://carlos-gg.github.io/digitalgarden/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://carlos-gg.github.io/digitalgarden/js/darkmode.18b7c6dfe67ae3bf2317338cf4189144.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/popover.abe6a51cc7138c5dff00f151dd627ad1.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://carlos-gg.github.io/digitalgarden/",fetchData=Promise.all([fetch("https://carlos-gg.github.io/digitalgarden/indices/linkIndex.fcb56eed4d98466ce4e3e3c2d06d318e.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://carlos-gg.github.io/digitalgarden/indices/contentIndex.60acff7161c0de36f595b69d91177ef6.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://carlos-gg.github.io/digitalgarden",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!0;drawGraph("https://carlos-gg.github.io/digitalgarden",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/carlos-gg.github.io\/digitalgarden\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-S103D50NQ0"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-S103D50NQ0",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://carlos-gg.github.io/digitalgarden/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://carlos-gg.github.io/digitalgarden/>CarlosGG's Knowledge Garden ü™¥</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>LLMs</h1><p class=meta>Last updated
Nov 14, 2024
<a href=https://github.com/jackyzha0/quartz/tree/hugo/content/AI/Generative%20AI/LLMs.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details open><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#resources>Resources</a><ol><li><a href=#apis>APIs</a></li><li><a href=#benchmarks>Benchmarks</a><ol><li><a href=#metrics-and-evaluation>Metrics and evaluation</a></li></ol></li><li><a href=#tuning-llms>Tuning LLMs</a></li><li><a href=#quantization>Quantization</a></li><li><a href=#interfaces-model-hubs-and-uis>Interfaces, model hubs and UIs</a></li><li><a href=#services-and-aplications>Services and aplications</a><ol><li><a href=#tabular-data>Tabular data</a></li><li><a href=#time-series-data>Time series data</a></li><li><a href=#search-engines>Search engines</a></li><li><a href=#chatbots>Chatbots</a></li><li><a href=#ner>NER</a></li><li><a href=#text-to-sql-dynamic-reports-and-analysis>Text-to-sql, dynamic reports and analysis</a></li><li><a href=#medicine>Medicine</a></li></ol></li><li><a href=#llms-in-production>LLMs in production</a><ol><li><a href=#servir-llms>Servir LLMs</a></li></ol></li></ol></li><li><a href=#courses>Courses</a></li><li><a href=#code>Code</a><ol><li><a href=#lifecycle-and-deployment>Lifecycle and deployment</a></li><li><a href=#frameworks>Frameworks</a></li></ol></li><li><a href=#references>References</a><ol><li><a href=#causality-and-llms>Causality and LLMs</a></li></ol></li></ol></nav></details></aside><blockquote><p>Large Language Models are artificial intelligence models that are trained on vast amounts of text data to generate, understand, and generate human-like language. These models are designed to process and analyze large volumes of text, allowing them to learn patterns, relationships, and nuances in language. The development of Large Language Models has revolutionized the field of NLP, enabling applications like chatbots, virtual assistants, and language translation tools. They have also sparked significant advancements in areas like research, education, and entertainment.</p></blockquote><blockquote><p>See:</p><ul><li><a href=/digitalgarden/AI/Generative-AI/Foundation-models rel=noopener class=internal-link data-src=/digitalgarden/AI/Generative-AI/Foundation-models>Foundation models</a></li><li><a href=/digitalgarden/AI/Generative-AI/Agents rel=noopener class=internal-link data-src=/digitalgarden/AI/Generative-AI/Agents>Agents</a></li><li><a href=/digitalgarden/AI/Generative-AI/LLM-Ops rel=noopener class=internal-link data-src=/digitalgarden/AI/Generative-AI/LLM-Ops>LLM Ops</a></li><li><a href=/digitalgarden/AI/Generative-AI/RAG rel=noopener class=internal-link data-src=/digitalgarden/AI/Generative-AI/RAG>RAG</a></li><li><a href=/digitalgarden/AI/Generative-AI/Prompt-engineering rel=noopener class=internal-link data-src=/digitalgarden/AI/Generative-AI/Prompt-engineering>Prompt engineering</a></li><li><a href=/digitalgarden/AI/Generative-AI/Fine-tuning-LLMs rel=noopener class=internal-link data-src=/digitalgarden/AI/Generative-AI/Fine-tuning-LLMs>Fine tuning LLMs</a></li></ul></blockquote><a href=#resources><h2 id=resources><span class=hanchor arialabel=Anchor># </span>Resources</h2></a><ul><li><a href=https://github.com/eugeneyan/open-llms rel=noopener>eugeneyan/open-llms: üìã A list of open LLMs available for commercial use. (github.com)</a></li><li><a href=https://github.com/NiuTrans/ABigSurveyOfLLMs rel=noopener>NiuTrans/ABigSurveyOfLLMs: A collection of 150+ surveys on LLMs (github.com)</a></li><li><a href=https://cookbook.openai.com/examples/question_answering_using_embeddings rel=noopener>Question answering using embeddings-based search | OpenAI Cookbook</a></li><li><a href=https://medium.com/@johnthuo/chat-with-your-pdf-using-langchain-f-a-i-s-s-and-openai-to-query-pdfs-e7bfde086155 rel=noopener>Chat with your PDF: Using Langchain, F.A.I.S.S., and OpenAI to Query PDFs | by johnthuo | Medium</a></li><li><a href=https://sapling.ai/llm/index rel=noopener>The Large Language Model (LLM) Index | Sapling</a></li><li><a href=https://mlabonne.github.io/blog/ rel=noopener>Maxime Labonne - LLM Articles</a><ul><li><a href=https://mlabonne.github.io/blog/posts/2024-01-08_Merge_LLMs_with_mergekit.html rel=noopener>Maxime Labonne - Merge Large Language Models with MergeKit</a></li><li><a href=https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html rel=noopener>Decoding strategies in LLMs</a> - understanding temperature, topk, topp, numbeams</li></ul></li><li>Pricing calculators:<ul><li><a href="https://docsbot.ai/tools/gpt-openai-api-pricing-calculator?utm_source=pocket_shared" rel=noopener>Free OpenAI & every-LLM API Pricing Calculator | Updated Nov 2024</a></li><li><a href="https://yourgpt.ai/tools/openai-and-other-llm-api-pricing-calculator?utm_source=pocket_saves" rel=noopener>LLM Cost Calculator: Compare OpenAI, Claude2, PaLM, Cohere & More</a></li><li><a href="https://gptforwork.com/tools/openai-chatgpt-api-pricing-calculator?utm_source=pocket_shared" rel=noopener>OpenAI API Pricing Calculator</a></li><li><a href="https://www.launchnow.pro/openai-chatgpt-api-pricing-calculator?utm_source=pocket_saves" rel=noopener>OpenAI API Pricing Calculator | 100% Free</a></li></ul></li></ul><a href=#apis><h3 id=apis><span class=hanchor arialabel=Anchor># </span>APIs</h3></a><ul><li>OpenAI<ul><li><a href=https://platform.openai.com/docs/models/models rel=noopener>OpenAI Platform - Models</a></li><li><a href=https://platform.openai.com/docs/assistants/overview rel=noopener>OpenAI Platform - Assistants</a></li><li><a href=https://platform.openai.com/docs/guides/vision rel=noopener>Vision - OpenAI API</a></li><li><a href=https://openai.com/product/gpt-4 rel=noopener>GPT-4</a><ul><li><a href="https://www.youtube.com/watch?v=7VSWyghVZIg" rel=noopener>OpenAI GPT-4 - The Future Is Here!</a></li></ul></li><li><a href=https://openai.com/blog/chatgpt rel=noopener>ChatGPT (OpenAI)</a><ul><li><a href=https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/ rel=noopener>ChatGPT Gets Its ‚ÄúWolfram Superpowers‚Äù!</a></li><li><a href=https://www.datacamp.com/cheat-sheet/chatgpt-cheat-sheet-data-science rel=noopener>ChatGPT Cheat Sheet for Data Science</a></li><li><a href=https://beebom.com/how-train-ai-chatbot-custom-knowledge-base-chatgpt-api/ rel=noopener>How to Train an AI Chatbot With Custom Knowledge Base Using ChatGPT API</a></li></ul></li></ul></li><li><a href=https://openrouter.ai/ rel=noopener>https://openrouter.ai/</a> - A unified interface for LLMs</li><li><a href=https://groq.com/ rel=noopener>Groq is Fast AI Inference</a><ul><li><a href=https://github.com/groq/groq-python rel=noopener>GitHub - groq/groq-python: The official Python Library for the Groq API</a></li></ul></li><li>HuggingFace
<a href=https://huggingface.co/docs/api-inference/index rel=noopener>Serverless Inference API</a></li></ul><a href=#benchmarks><h3 id=benchmarks><span class=hanchor arialabel=Anchor># </span>Benchmarks</h3></a><ul><li><a href=https://chat.lmsys.org/ rel=noopener>Chat with Open Large Language Models (lmsys.org)</a></li><li><a href=https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu rel=noopener>MMLU Benchmark (Multi-task Language Understanding) | Papers With Code</a></li><li><a href=https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard rel=noopener>Open LLM Leaderboard 2 - a Hugging Face Space by open-llm-leaderboard</a></li><li><a href=https://lmarena.ai/ rel=noopener>Chat bot arena</a></li></ul><a href=#metrics-and-evaluation><h4 id=metrics-and-evaluation><span class=hanchor arialabel=Anchor># </span>Metrics and evaluation</h4></a><ul><li>First 3 could be the primary and the last 3 as secondary.<ul><li>MixEval: A dynamic benchmark evaluating LLMs using real-world user queries and benchmarks, achieving a 0.96 model ranking correlation with Chatbot Arena.
<a href=https://mixeval.github.io/ rel=noopener>https://mixeval.github.io/</a></li><li>IFEval: Assess the ability to follow detailed, verifiable instructions. For example, a prompt might instruct, &ldquo;Write an article with more than 800 words&rdquo; or &ldquo;Wrap your response in double quotation marks&rdquo;.
<a href=https://lnkd.in/eq9PCFCT rel=noopener>https://lnkd.in/eq9PCFCT</a></li><li>Arena-Hard: Evaluating LLMs using challenging user queries, reflecting real-world preferences. Successor to MT-Bench and is similar to AlpacaEval 2.0, focusing on multi-turn conversations and instruction-following tasks.
<a href=https://lnkd.in/eV7pavKT rel=noopener>https://lnkd.in/eV7pavKT</a></li><li>MMLU (Pro/Redux): Testing on diverse subjects, evaluating zero-shot and few-shot settings.
<a href=https://lnkd.in/epgM393X rel=noopener>https://lnkd.in/epgM393X</a></li><li>GSM8K: Diverse grade school math problems for testing multi-step arithmetic reasoning.
<a href=https://lnkd.in/eiJUS-Uv rel=noopener>https://lnkd.in/eiJUS-Uv</a></li><li>HumanEval: Evaluating code generation models using hand-crafted programming problems and unit tests.
<a href=https://lnkd.in/eNcTCanG rel=noopener>https://lnkd.in/eNcTCanG</a></li></ul></li></ul><a href=#tuning-llms><h3 id=tuning-llms><span class=hanchor arialabel=Anchor># </span>Tuning LLMs</h3></a><ul><li>Tuning your LLM (prompt vs rag vs fine tuinig):
<a href=https://deci.ai/blog/fine-tuning-peft-prompt-engineering-and-rag-which-one-is-right-for-you/ rel=noopener>Full Fine-Tuning, PEFT, Prompt Engineering, or RAG? (deci.ai)</a></li><li><a href=https://www.elastic.co/search-labs/blog/domain-specific-generative-ai-pre-training-fine-tuning-rag rel=noopener>Domain specific generative AI: pre-training, fine-tuning & RAG ‚Äî Elastic Search Labs</a></li><li>Methods:<ul><li><a href=/digitalgarden/AI/Generative-AI/Prompt-engineering rel=noopener class=internal-link data-src=/digitalgarden/AI/Generative-AI/Prompt-engineering>Prompt engineering</a></li><li><a href=/digitalgarden/AI/Generative-AI/RAG rel=noopener class=internal-link data-src=/digitalgarden/AI/Generative-AI/RAG>RAG</a></li><li><a href=/digitalgarden/AI/Generative-AI/Fine-tuning-LLMs rel=noopener class=internal-link data-src=/digitalgarden/AI/Generative-AI/Fine-tuning-LLMs>Fine tuning LLMs</a></li><li>RLHF:
<a href=https://huggingface.co/blog/rlhf rel=noopener>Illustrating Reinforcement Learning from Human Feedback (RLHF) (huggingface.co)</a><ul><li><a href=https://www.ibm.com/mx-es/topics/rlhf rel=noopener>¬øQu√© es el RLHF? | IBM</a></li></ul></li></ul></li></ul><a href=#quantization><h3 id=quantization><span class=hanchor arialabel=Anchor># </span>Quantization</h3></a><ul><li><a href=https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html rel=noopener>Maxime Labonne - Quantize Llama models with GGUF and llama.cpp</a></li><li><a href=https://medium.com/@siddharth.vij10/llm-quantization-gptq-qat-awq-gguf-ggml-ptq-2e172cd1b3b5 rel=noopener>LLM Quantization | GPTQ | QAT | AWQ | GGUF | GGML | PTQ</a></li><li><a href="https://medium.com/@ingridwickstevens/quantization-of-llms-with-llama-cpp-9bbf59deda35#:~:text=cpp%2C-Q4_K_M-refers-to-a,means-clustering-in-the-quantization." rel=noopener>Quantization of LLMs with llama.cpp | by Ingrid Stevens | Medium</a></li></ul><a href=#interfaces-model-hubs-and-uis><h3 id=interfaces-model-hubs-and-uis><span class=hanchor arialabel=Anchor># </span>Interfaces, model hubs and UIs</h3></a><ul><li><a href=https://ollama.com/ rel=noopener>Ollama</a><ul><li><a href=https://www.markhneedham.com/blog/2023/10/18/ollama-hugging-face-gguf-models/ rel=noopener>https://www.markhneedham.com/blog/2023/10/18/ollama-hugging-face-gguf-models/</a></li></ul></li><li><a href=https://github.com/sammcj/gollama rel=noopener>GoLlama</a> - Gollama is a macOS / Linux tool for managing Ollama models</li><li><a href=https://github.com/open-webui/open-webui rel=noopener>Open-WebUI</a> - User-friendly WebUI for LLMs (Formerly Ollama WebUI)</li><li><a href=https://jan.ai/ rel=noopener>Jan</a><ul><li><a href=https://github.com/janhq/jan rel=noopener>https://github.com/janhq/jan</a></li></ul></li><li><a href=https://lmstudio.ai/ rel=noopener>LM studio</a></li><li><a href=https://llmfarm.site/ rel=noopener>LLM farm</a><ul><li><a href=https://github.com/guinmoon/LLMFarm rel=noopener>https://github.com/guinmoon/LLMFarm</a></li></ul></li><li><a href=https://sanctum.ai/ rel=noopener>Sanctum</a></li><li><a href=https://msty.app/ rel=noopener>Msty</a></li><li><a href=https://github.com/jasonacox/TinyLLM rel=noopener>jasonacox/TinyLLM: Setup and run a local LLM and Chatbot using consumer grade hardware. (github.com)</a><ul><li>Builds a local OpenAI API web service via ollama, vllm</li><li>Serves up a Chatbot web interface with customizable prompts, accessing external websites (URLs), vector databases and other sources (e.g. news, stocks, weather)</li></ul></li></ul><a href=#services-and-aplications><h3 id=services-and-aplications><span class=hanchor arialabel=Anchor># </span>Services and aplications</h3></a><a href=#tabular-data><h4 id=tabular-data><span class=hanchor arialabel=Anchor># </span>Tabular data</h4></a><ul><li><a href=https://github.com/dreamquark-ai/tabnet rel=noopener>dreamquark-ai/tabnet: PyTorch implementation of TabNet paper : https://arxiv.org/pdf/1908.07442.pdf (github.com)</a><ul><li>#PAPER
<a href="https://arxiv.org/abs/1908.07442?utm_source=pocket_reader" rel=noopener>[1908.07442] TabNet: Attentive Interpretable Tabular Learning (arxiv.org)</a></li><li><a href="https://francescopochetti.com/tabular-deep-leaning-tabnet-deep-dive/?utm_source=pocket_reader" rel=noopener>Tabular Deep Leaning: TabNet deep-dive - (francescopochetti.com)</a></li><li><a href=https://github.com/OKUA1/tabnet-keras rel=noopener>OKUA1/tabnet-keras (github.com)</a></li></ul></li><li><a href=https://github.com/automl/TabPFN rel=noopener>automl/TabPFN: Official implementation of the TabPFN paper (https://arxiv.org/abs/2207.01848) and the tabpfn package. (github.com)</a><ul><li>#PAPER
<a href=https://arxiv.org/abs/2207.01848 rel=noopener>[2207.01848] TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second (arxiv.org)</a></li></ul></li></ul><a href=#time-series-data><h4 id=time-series-data><span class=hanchor arialabel=Anchor># </span>Time series data</h4></a><p>See <a href=/digitalgarden/AI/Time-Series-analysis rel=noopener class=internal-link data-src=/digitalgarden/AI/Time-Series-analysis>Time Series analysis</a></p><ul><li>TimeGPT<ul><li>#PAPER
<a href=https://arxiv.org/abs/2310.03589 rel=noopener>[2310.03589] TimeGPT-1 (arxiv.org)</a></li><li><a href=https://github.com/Nixtla/nixtla rel=noopener>Nixtla/nixtla: TimeGPT-1: production ready pre-trained Time Series Foundation Model for forecasting and anomaly detection. Generative pretrained transformer for time series trained on over 100B data points. It&rsquo;s capable of accurately predicting various domains such as retail, electricity, finance, and IoT with just a few lines of code üöÄ. (github.com)</a></li><li><a href=https://towardsdatascience.com/timegpt-the-first-foundation-model-for-time-series-forecasting-bf0a75e63b3a rel=noopener>TimeGPT: The First Foundation Model for Time Series Forecasting | by Marco Peixeiro | Towards Data Science</a></li></ul></li><li>Chronos<ul><li><a href=https://github.com/amazon-science/chronos-forecasting rel=noopener>amazon-science/chronos-forecasting: Chronos: Pretrained (Language) Models for Probabilistic Time Series Forecasting (github.com)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/2403.07815 rel=noopener>[2403.07815] Chronos: Learning the Language of Time Series</a></li><li><a href=https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-chronos.html rel=noopener>Forecasting with Chronos - AutoGluon 1.1.0 documentation</a></li></ul></li><li>TimesFM<ul><li>#PAPER
<a href=https://arxiv.org/abs/2310.10688 rel=noopener>[2310.10688] A decoder-only foundation model for time-series forecasting (arxiv.org)</a></li><li><a href="https://huggingface.co/google/timesfm-1.0-200m?utm_source=pocket_reader" rel=noopener>google/timesfm-1.0-200m ¬∑ Hugging Face</a></li></ul></li><li>TimesNet<ul><li>#PAPER
<a href=https://arxiv.org/abs/2210.02186 rel=noopener>[2210.02186] TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis (arxiv.org)</a></li><li><a href=https://github.com/thuml/Time-Series-Library rel=noopener>thuml/Time-Series-Library: A Library for Advanced Deep Time Series Models. (github.com)</a></li><li><a href=https://towardsdatascience.com/timesnet-the-latest-advance-in-time-series-forecasting-745b69068c9c rel=noopener>TimesNet: The Latest Advance in Time Series Forecasting | by Marco Peixeiro | Towards Data Science</a></li></ul></li><li>MOMENT<ul><li>#PAPER
<a href=https://arxiv.org/abs/2402.03885 rel=noopener>[2402.03885] MOMENT: A Family of Open Time-series Foundation Models (arxiv.org)</a></li><li><a href=https://huggingface.co/AutonLab/MOMENT-1-large rel=noopener>AutonLab/MOMENT-1-large ¬∑ Hugging Face</a></li></ul></li></ul><a href=#search-engines><h4 id=search-engines><span class=hanchor arialabel=Anchor># </span>Search engines</h4></a><ul><li><a href=https://copilot.microsoft.com/ rel=noopener>Copilot</a></li><li><a href="https://you.com/search?q=who+are+you&tbm=youchat&cfr=chat" rel=noopener>You chat</a></li><li><a href=https://www.perplexity.ai/ rel=noopener>Perplexity.ai</a></li></ul><a href=#chatbots><h4 id=chatbots><span class=hanchor arialabel=Anchor># </span>Chatbots</h4></a><ul><li><a href=https://python.langchain.com/docs/use_cases/chatbots/ rel=noopener>Chatbots | ü¶úÔ∏èüîó Langchain</a></li><li><a href=https://python.langchain.com/docs/modules/model_io/chat/custom_chat_model rel=noopener>Custom Chat Model | ü¶úÔ∏èüîó Langchain</a></li><li>Evaluaci√≥n rendimiento:<ul><li><a href=https://gus.chat/blog/metricas-para-medir-el-exito-de-tu-chatbot/ rel=noopener>M√©tricas que te ayudar√°n a medir el √©xito de tu chatbot - Gus</a></li><li><a href="https://planetachatbot.com/metricas-para-analizar-el-rendimiento-de-un-chatbot/#:~:text=Aqu%C3%AD-est%C3%A1n-las-12-m%C3%A9tricas-principales%2C-en-nuestra,de-c%C3%B3mo-se-puede-mejorar.-...-M%C3%A1s-elementos" rel=noopener>12 m√©tricas para analizar el rendimiento de un chatbot - Planeta Chatbot</a></li><li><a href=https://www.unite.ai/es/evaluaci%C3%B3n-de-modelos-de-lenguaje-grandes-una-gu%C3%ADa-t%C3%A9cnica/ rel=noopener>Evaluaci√≥n de modelos de lenguaje grandes: una gu√≠a t√©cnica - Unite.AI</a></li></ul></li></ul><a href=#ner><h4 id=ner><span class=hanchor arialabel=Anchor># </span>NER</h4></a><ul><li><a href=https://cookbook.openai.com/examples/named_entity_recognition_to_enrich_text rel=noopener>Named Entity Recognition to Enrich Text | OpenAI Cookbook</a></li></ul><a href=#text-to-sql-dynamic-reports-and-analysis><h4 id=text-to-sql-dynamic-reports-and-analysis><span class=hanchor arialabel=Anchor># </span>Text-to-sql, dynamic reports and analysis</h4></a><ul><li>#CODE
<a href=https://github.com/microsoft/lida rel=noopener>microsoft/lida: Automatic Generation of Visualizations and Infographics using Large Language Models (github.com)</a><ul><li><a href=https://medium.com/@c17hawke/lida-automatically-generate-visualization-and-with-llms-the-future-of-data-visualization-6bc556876b46 rel=noopener>LIDA | Automatically Generate Visualization with LLMs | The Future of Data Visualization | by Sunny Bhaveen Chandra | Medium</a></li></ul></li><li><a href=https://www.graphext.com/ rel=noopener>Graphext</a> (paid service - startup)</li><li><a href=https://ai.plainenglish.io/goodbye-text2sql-why-table-augmented-generation-tag-is-the-future-of-ai-driven-data-queries-892e24e06922 rel=noopener>Goodbye, Text2SQL: Why Table-Augmented Generation (TAG) is the Future of AI-Driven Data Queries! | by Pavan Emani | Sep, 2024 | Artificial Intelligence in Plain English</a></li><li><a href=https://arxiv.org/html/2408.14717v1 rel=noopener>Text2SQL is Not Enough: Unifying AI and Databases with TAG</a></li><li><a href=https://bird-bench.github.io/ rel=noopener>BIRD-bench</a></li><li><a href=https://arxiv.org/html/2408.07702v2 rel=noopener>The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models</a></li><li>LOTUS<ul><li>#PAPER
<a href=https://arxiv.org/abs/2407.11418 rel=noopener>[2407.11418] LOTUS: Enabling Semantic Queries with LLMs Over Tables of Unstructured and Structured Data</a></li><li><a href=https://github.com/TAG-Research/lotus rel=noopener>TAG-Research/lotus: LOTUS: The semantic query engine - process data with LLMs as easily as writing pandas code</a></li></ul></li></ul><a href=#medicine><h4 id=medicine><span class=hanchor arialabel=Anchor># </span>Medicine</h4></a><ul><li><a href=https://www.ibm.com/mx-es/topics/artificial-intelligence-medicine rel=noopener>Inteligencia Artificial en la Medicina | IBM</a></li><li><a href="https://opendatascience.com/elevating-healthcare-documentation-the-significance-of-soap-birp-and-the-promise-of-generative-ai/?utm_campaign=Newsletters&utm_medium=email&_hsenc=p2ANqtz-8eiEqdD2RmUZeW_8gBTEfT66SkjB32BLvRsvUrbMLcV1JIJfiJvzMpLn3EH5M-C0EAr4xwdOdTFvhWeZh_ENTx_6G_OUynAscJP8X5JGPJ3UBDQlo&_hsmi=305226791&utm_content=305211788&utm_source=hs_email" rel=noopener>Elevating Healthcare Documentation With Generative AI (opendatascience.com)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/2309.00087 rel=noopener>[2309.00087] Large language models in medicine: the potentials and pitfalls (arxiv.org)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/2403.03640 rel=noopener>[2403.03640] Apollo: An Lightweight Multilingual Medical LLM towards Democratizing Medical AI to 6B People (arxiv.org)</a><ul><li><a href=https://github.com/FreedomIntelligence/Apollo rel=noopener>FreedomIntelligence/Apollo: Multilingual Medicine: Model, Dataset, Benchmark, Code (github.com)</a></li></ul></li><li>#PAPER
<a href=https://arxiv.org/abs/2405.00715 rel=noopener>[2405.00715] Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation (arxiv.org)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/2404.18416 rel=noopener>[2404.18416] Capabilities of Gemini Models in Medicine (arxiv.org)</a><ul><li><a href=https://the-decoder.com/med-gemini-and-meditron-google-and-meta-present-new-llms-for-medicine/ rel=noopener>Med-Gemini and Meditron: Google and Meta present new LLMs for medicine (the-decoder.com)</a></li></ul></li><li>#PAPER
<a href=https://arxiv.org/abs/2402.12749 rel=noopener>[2402.12749] Me LLaMA: Foundation Large Language Models for Medical Applications (arxiv.org)</a></li><li>#PAPER
<a href=https://huggingface.co/papers/2303.14070 rel=noopener>Paper page - ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge (huggingface.co)</a></li><li>#PAPER
<a href="https://academic.oup.com/jamia/advance-article-abstract/doi/10.1093/jamia/ocae045/7645318?redirectedFrom=fulltext" rel=noopener>PMC-LLaMA: toward building open-source language models for medicine | Journal of the American Medical Informatics Association | Oxford Academic (oup.com)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/2311.16079 rel=noopener>[2311.16079] MEDITRON-70B: Scaling Medical Pretraining for Large Language Models</a><ul><li><a href=https://github.com/epfLLM/meditron rel=noopener>epfLLM/meditron: Meditron is a suite of open-source medical Large Language Models (LLMs). (github.com)</a></li></ul></li><li>#PAPER
<a href=https://arxiv.org/abs/2311.16588v2 rel=noopener>[2311.16588v2] Ascle: A Python Natural Language Processing Toolkit for Medical Text Generation (arxiv.org)</a></li><li>Datasets:<ul><li><a href=https://github.com/abachaa/Existing-Medical-QA-Datasets rel=noopener>abachaa/Existing-Medical-QA-Datasets: Multimodal Question Answering in the Medical Domain: A summary of Existing Datasets and Systems (github.com)</a></li><li><a href=https://github.com/Andy-jqa/biomedical-qa-datasets rel=noopener>Andy-jqa/biomedical-qa-datasets: Biomedical Question Answering Datasets. (github.com)</a><ul><li>Espa√±ol:
<a href=https://aghie.github.io/head-qa/ rel=noopener>HEAD-QA | A Healthcare Dataset for Complex Reasoning (aghie.github.io)</a></li></ul></li></ul></li></ul><a href=#llms-in-production><h3 id=llms-in-production><span class=hanchor arialabel=Anchor># </span>LLMs in production</h3></a><ul><li><a href="https://aws.amazon.com/es/bedrock/?trk=68f42e87-3ae0-43b3-8101-9bc153ae3b39&sc_channel=ps&s_kwcid=AL!4422!10!71468517518479!71469056518657&ef_id=47853f94ebef1464e6be5a6e07726a57:G:s" rel=noopener>Creaci√≥n de aplicaciones de IA generativa con modelos de base ‚Äì Amazon Bedrock ‚Äì AWS</a></li></ul><a href=#servir-llms><h4 id=servir-llms><span class=hanchor arialabel=Anchor># </span>Servir LLMs</h4></a><ul><li><a href=https://github.com/vllm-project/vllm rel=noopener>vllm-project/vllm: A high-throughput and memory-efficient inference and serving engine for LLMs (github.com)</a><ul><li><a href=https://docs.vllm.ai/en/latest/getting_started/quickstart.html#openai-compatible-server rel=noopener>Quickstart ‚Äî vLLM</a></li></ul></li><li><a href=https://docs.bentoml.org/en/v1.1.11/quickstarts/deploy-a-transformer-model-with-bentoml.html rel=noopener>https://docs.bentoml.org/en/v1.1.11/quickstarts/deploy-a-transformer-model-with-bentoml.html</a></li><li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-models-llama?view=azureml-api-2&tabs=llama-three" rel=noopener>How to deploy Meta Llama models with Azure Machine Learning studio - Azure Machine Learning | Microsoft Learn</a></li></ul><a href=#courses><h2 id=courses><span class=hanchor arialabel=Anchor># </span>Courses</h2></a><ul><li>#COURSE
<a href=https://github.com/decodingml/llm-twin-course rel=noopener>LLM-twin-course</a><ul><li><a href=https://medium.com/decodingml/the-llm-twin-free-course-on-production-ready-rag-pipelines-c96472f4e8c8 rel=noopener>The LLM-Twin Free Course on Production-Ready RAG applications | Decoding ML</a></li></ul></li><li>#COURSE
<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/?utm_campaign=meta-launch&utm_medium=featured-card&utm_source=dlai-homepage" rel=noopener>Prompt Engineering with Llama 2 & 3 - DeepLearning.AI</a></li><li>#COURSE Get into LLMs with roadmaps and colab notebooks<ul><li><a href="https://github.com/mlabonne/llm-course?tab=readme-ov-file" rel=noopener>mlabonne/llm-course: Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks. (github.com)</a></li><li><a href=https://github.com/machinelearnear/curso-ia-generativa-y-llms rel=noopener>machinelearnear/curso-ia-generativa-y-llms: Un curso para meterse en todo lo que es Generative AI y modelos grandes de lenguaje (LLMs) con roadmaps y notebooks para Colab. (github.com)</a></li></ul></li></ul><a href=#code><h2 id=code><span class=hanchor arialabel=Anchor># </span>Code</h2></a><ul><li>#CODE
<a href=https://github.com/openai/tiktoken rel=noopener>openai/tiktoken: tiktoken is a fast BPE tokeniser for use with OpenAI&rsquo;s models. (github.com)</a></li><li>#CODE
<a href=https://github.com/BerriAI/litellm rel=noopener>GitHub - BerriAI/litellm</a> - Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format<ul><li><a href=https://docs.litellm.ai/docs/ rel=noopener>LiteLLM - Getting Started | liteLLM</a></li></ul></li><li>#CODE
<a href=https://github.com/turboderp/exllamav2 rel=noopener>Exllamav2</a> - A fast inference library for running LLMs locally on modern consumer-class GPUs<ul><li><a href=https://mlabonne.github.io/blog/posts/ExLlamaV2_The_Fastest_Library_to_Run%C2%A0LLMs.html rel=noopener>Maxime Labonne - ExLlamaV2: The Fastest Library to Run LLMs</a></li></ul></li></ul><a href=#lifecycle-and-deployment><h3 id=lifecycle-and-deployment><span class=hanchor arialabel=Anchor># </span>Lifecycle and deployment</h3></a><ul><li>#CODE Langsmith
<a href=https://github.com/langchain-ai/langsmith-cookbook rel=noopener>langchain-ai/langsmith-cookbook (github.com)</a><ul><li><a href=https://www.langchain.com/langsmith rel=noopener>LangSmith (langchain.com)</a></li><li><a href=https://docs.smith.langchain.com/ rel=noopener>Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith (langchain.com)</a></li><li><a href=https://docs.smith.langchain.com/tutorials/Developers/evaluation rel=noopener>Evaluate your LLM application | ü¶úÔ∏èüõ†Ô∏è LangSmith (langchain.com)</a></li></ul></li></ul><a href=#frameworks><h3 id=frameworks><span class=hanchor arialabel=Anchor># </span>Frameworks</h3></a><ul><li>Framework comparisons:<ul><li><a href=https://www.gettingstarted.ai/introduction-to-rag-ai-apps-and-frameworks-haystack-langchain-llamaindex/ rel=noopener>Choosing a RAG Framework: Haystack, LangChain, LlamaIndex (gettingstarted.ai)</a></li><li><a href=https://medium.com/data-science-at-microsoft/harnessing-the-power-of-large-language-models-a-comparative-overview-of-langchain-semantic-c21f5c19f93e rel=noopener>A comparative overview of LangChain, Semantic Kernel, AutoGen and more | by Jane Huang | Data Science at Microsoft | Medium</a></li><li><a href=https://techcommunity.microsoft.com/t5/educator-developer-blog/microsoft-semantic-kernel-and-autogen-open-source-frameworks-for/ba-p/4051305 rel=noopener>Microsoft Semantic Kernel and AutoGen: Open Source Frameworks for AI Solutions</a></li></ul></li><li>#CODE
<a href=https://github.com/huggingface/transformers rel=noopener>huggingface/transformers: ü§ó Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX. (github.com)</a><ul><li><a href=https://huggingface.co/docs/transformers/index rel=noopener>ü§ó Transformers (huggingface.co)</a></li><li>Transformers-agents:
<a href=https://huggingface.co/blog/agents rel=noopener>License to Call: Introducing Transformers Agents 2.0 (huggingface.co)</a></li></ul></li><li>#CODE
<a href="https://www.langchain.com/?ref=gettingstarted.ai" rel=noopener>LangChain</a><ul><li><a href=https://cookbook.openai.com/examples/how_to_build_a_tool-using_agent_with_langchain rel=noopener>How to build a tool-using agent with LangChain | OpenAI Cookbook</a></li><li><a href=https://medium.com/artefact-engineering-and-data-science/unleashing-the-power-of-langchain-expression-language-lcel-from-proof-of-concept-to-production-8ad8eebdcb1d rel=noopener>Unleashing the Power of LangChain Expression Language (LCEL): from proof of concept to production | by Tom Darmon | Artefact Engineering and Data Science | Jan, 2024 | Medium</a></li><li><a href=https://python.langchain.com/docs/modules/chains/ rel=noopener>Chains | ü¶úÔ∏èüîó LangChain</a></li><li>LangGraph:
<a href=https://github.com/langchain-ai/langgraph rel=noopener>langchain-ai/langgraph: Build resilient language agents as graphs. (github.com)</a></li></ul></li><li>#CODE
<a href=https://github.com/microsoft/semantic-kernel rel=noopener>microsoft/semantic-kernel: Integrate cutting-edge LLM technology quickly and easily into your apps (github.com)</a><ul><li><a href=https://learn.microsoft.com/en-us/semantic-kernel/overview/ rel=noopener>Introduction to Semantic Kernel | Microsoft Learn</a></li><li><a href="https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=academic-120325-leestott" rel=noopener>microsoft/SemanticKernelCookBook: This is a Semantic Kernel&rsquo;s book for beginners (github.com)</a></li></ul></li><li>#CODE
<a href=https://github.com/microsoft/graphrag rel=noopener>microsoft/graphrag: A modular graph-based Retrieval-Augmented Generation (RAG) system (github.com)</a><ul><li><a href=https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/ rel=noopener>GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research</a></li><li><a href=https://medium.com/microsoftazure/introducing-graphrag-with-langchain-and-neo4j-90446df17c1e rel=noopener>Introducing GraphRAG with LangChain and Neo4j | by Valentina Alto | Microsoft Azure | Medium</a></li></ul></li><li>#CODE
<a href=https://github.com/microsoft/autogen rel=noopener>microsoft/autogen: A programming framework for agentic AI. Discord: https://aka.ms/autogen-dc. Roadmap: https://aka.ms/autogen-roadmap (github.com)</a><ul><li><a href=https://microsoft.github.io/autogen/ rel=noopener>AutoGen | AutoGen (microsoft.github.io)</a></li><li><a href=https://arxiv.org/abs/2308.08155 rel=noopener>[2308.08155] AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation (arxiv.org)</a></li><li><a href=https://microsoft.github.io/autogen/blog/2023/11/26/Agent-AutoBuild/ rel=noopener>Agent AutoBuild - Automatically Building Multi-agent Systems | AutoGen (microsoft.github.io)</a></li><li><a href=https://microsoft.github.io/autogen/docs/topics/non-openai-models/local-vllm/ rel=noopener>vLLM | AutoGen (microsoft.github.io)</a></li></ul></li><li>#CODE
<a href="https://github.com/microsoft/TaskWeaver?tab=readme-ov-file" rel=noopener>microsoft/TaskWeaver: A code-first agent framework for seamlessly planning and executing data analytics tasks. (github.com)</a><ul><li>A code-first agent framework for seamlessly planning and executing data analytics tasks (autonomous agent)</li><li>It translates user requests into executable code and treats user-defined plugins as callable functions. TaskWeaver supports rich data structures, flexible plugin usage, dynamic plugin selection, and harnesses LLM coding capabilities for complex logic. It also incorporates domain-specific knowledge through examples and ensures the secure execution of generated code</li><li><a href=https://arxiv.org/abs/2311.17541 rel=noopener>[2311.17541] TaskWeaver: A Code-First Agent Framework (arxiv.org)</a></li><li><a href=https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/uncover-the-future-microsoft-autonomous-ai-agents-analyzing-sap/ba-p/4005307 rel=noopener>The Future of Agent Frameworks: TaskWeaver and Microsoft Autogen and Microsoft Semantic Kernel</a></li><li><a href="https://www.youtube.com/watch?v=1CdU4n-Obsw&ab_channel=MervinPraison" rel=noopener>TaskWeaver beats AutoGen! üöÄ Microsoft&rsquo;s Code-First Agent Framework ü§Ø ( LIVE DEMO Full Tutorial ) - YouTube</a></li></ul></li><li>#CODE
<a href="https://haystack.deepset.ai/?ref=gettingstarted.ai" rel=noopener>Haystack | Haystack (deepset.ai)</a><ul><li><a href=https://github.com/deepset-ai/haystack rel=noopener>deepset-ai/haystack: :mag: LLM orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it&rsquo;s best suited for building RAG, question answering, semantic search or conversational agent chatbots. (github.com)</a></li><li><a href=https://haystack.deepset.ai/overview/intro rel=noopener>What is Haystack? | Haystack (deepset.ai)</a></li><li><a href=https://medium.com/aimonks/haystack-an-alternative-to-langchain-carrying-llms-bf7c515c9a7e rel=noopener>Haystack: An Alternative to Langchain carrying LLMs | by Amanatullah | ùêÄùêà ùê¶ùê®ùêßùê§ùê¨.ùê¢ùê® | Medium</a></li><li><a href=https://haystack.deepset.ai/tutorials/25_customizing_agent rel=noopener>Customizing Agent to Chat with Your Documents | Haystack (deepset.ai)</a></li><li><a href=https://haystack.deepset.ai/integrations/lmformatenforcer rel=noopener>LM Format Enforcer | Haystack (deepset.ai)</a></li><li><a href=https://haystack.deepset.ai/tutorials/28_structured_output_with_loop rel=noopener>Generating Structured Output with Loop-Based Auto-Correction | Haystack (deepset.ai)</a></li></ul></li><li>#CODE
<a href="https://www.llamaindex.ai/?ref=gettingstarted.ai" rel=noopener>LlamaIndex, Data Framework for LLM Applications</a><ul><li>Llama-agents:
<a href=https://github.com/run-llama/llama-agents rel=noopener>run-llama/llama-agents (github.com)</a></li><li>Llama-cloud, llama-parse:
<a href=https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b rel=noopener>Introducing LlamaCloud and LlamaParse ‚Äî LlamaIndex, Data Framework for LLM Applications</a></li></ul></li><li>#CODE
<a href=https://github.com/stanfordnlp/dspy rel=noopener>stanfordnlp/dspy: DSPy: The framework for programming‚Äînot prompting‚Äîfoundation models (github.com)</a><ul><li><a href=https://towardsdatascience.com/building-an-ai-assistant-with-dspy-2e1e749a1a95 rel=noopener>Building an AI Assistant with DSPy | by Lak Lakshmanan | Mar, 2024 | Towards Data Science</a></li></ul></li><li>#CODE
<a href=https://github.com/embedchain/embedchain rel=noopener>embedchain/embedchain: The Open Source RAG framework (github.com)</a><ul><li><a href=https://www.gettingstarted.ai/what-is-the-difference-between-embedchain-and-langchain/ rel=noopener>What is the difference between Embedchain and LangChain (gettingstarted.ai)</a></li></ul></li><li>#CODE
<a href=https://github.com/sgl-project/sglang rel=noopener>sgl-project/sglang: SGLang is a structured generation language designed for large language models (LLMs). It makes your interaction with models faster and more controllable. (github.com)</a></li><li>#CODE
<a href=https://github.com/lm-sys/FastChat rel=noopener>lm-sys/FastChat: An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena. (github.com)</a><ul><li>An open platform for training, serving, and evaluating large language models (chatbot arena)</li></ul></li></ul><a href=#references><h2 id=references><span class=hanchor arialabel=Anchor># </span>References</h2></a><ul><li>#PAPER
<a href=https://arxiv.org/abs/2304.13712 rel=noopener>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond (2023)</a></li><li>#PAPER
<a href=https://arxiv.org/pdf/2303.11366 rel=noopener>Reflexion: an autonomous agent with dynamic memory and self-reflection (2023)</a><ul><li><a href="https://www.youtube.com/watch?v=5SgJKZLBrmg" rel=noopener>Paper explained - GPT 4 Can Improve Itself</a></li></ul></li><li>#PAPER
<a href=https://arxiv.org/pdf/2410.05229 rel=noopener>GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models (2024)</a><ul><li>#CODE
<a href=https://github.com/zhaoolee/garss rel=noopener>https://github.com/zhaoolee/garss</a></li><li><a href="https://www.youtube.com/watch?v=tTG_a0KPJAc" rel=noopener>Apple drops AI bombshell: LLMs cannot Reason - YouTube</a></li></ul></li><li>#PAPER #REVIEW
<a href=https://arxiv.org/abs/2403.14608 rel=noopener>Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey (2024)</a></li></ul><a href=#causality-and-llms><h3 id=causality-and-llms><span class=hanchor arialabel=Anchor># </span>Causality and LLMs</h3></a><p>See <a href=/digitalgarden/AI/Causality/Causality rel=noopener class=internal-link data-src=/digitalgarden/AI/Causality/Causality>Causality</a></p><ul><li>#PAPER
<a href=https://arxiv.org/abs/2305.00050 rel=noopener>[2305.00050] Causal Reasoning and Large Language Models: Opening a New Frontier for Causality (arxiv.org)</a><ul><li>LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks</li><li><a href="https://www.youtube.com/watch?v=PT1NoaeYwDs&ab_channel=Metaculus" rel=noopener>Metaculus Presents ‚Äî Causal Inference and LLMs: A New Frontier - YouTube</a></li></ul></li><li>#PAPER
<a href=https://arxiv.org/abs/2304.05524 rel=noopener>[2304.05524] Understanding Causality with Large Language Models: Feasibility and Opportunities (arxiv.org)</a><ul><li>LLMs are not yet able to provide satisfactory answers for discovering new knowledge or for high-stakes decision-making tasks with high precision</li><li>Current LLMs can answer causal questions with existing causal knowledge as combined domain experts</li></ul></li><li>#PAPER
<a href=https://arxiv.org/abs/2112.03753 rel=noopener>[2112.03753] Tell me why! Explanations support learning relational and causal structure (arxiv.org)</a><ul><li><a href=https://github.com/google-deepmind/tell_me_why_explanations_rl rel=noopener>google-deepmind/tell_me_why_explanations_rl (github.com)</a></li></ul></li><li>#PAPER
<a href=https://arxiv.org/abs/2305.16183 rel=noopener>[2305.16183] Passive learning of active causal strategies in agents and language models (arxiv.org)</a></li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/digitalgarden// data-ctx=LLMs data-src=/ class=internal-link>CarlosGG's AI Knowledge Garden ü™¥</a></li><li><a href=/digitalgarden/AI/Causality/Causality/ data-ctx="AI/Generative AI/LLMs#Causality and LLMs" data-src=/AI/Causality/Causality class=internal-link>Causality</a></li><li><a href=/digitalgarden/AI/Generative-AI/Foundation-models/ data-ctx=LLMs data-src=/AI/Generative-AI/Foundation-models class=internal-link>Foundation models</a></li><li><a href=/digitalgarden/AI/Generative-AI/GenAI/ data-ctx=LLMs data-src=/AI/Generative-AI/GenAI class=internal-link>GenAI</a></li><li><a href=/digitalgarden/AI/Generative-AI/LLM-Ops/ data-ctx=LLMs data-src=/AI/Generative-AI/LLM-Ops class=internal-link>LLM Ops</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://carlos-gg.github.io/digitalgarden/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Carlos Alberto Gomez Gonzalez using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, ¬© 2024</p><ul><li><a href=https://carlos-gg.github.io/digitalgarden/>Home</a></li><li><a href=https://carlos-gg.github.io>Carlos'Homepage</a></li></ul></footer></div></div></body></html>