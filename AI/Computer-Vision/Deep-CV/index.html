<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="DL is used in the domain of digital image processing to solve difficult problems (e.g.image colorization, classification, segmentation and detection)."><title>Deep CV</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://carlos-gg.github.io/digitalgarden//icon.png><link href=https://carlos-gg.github.io/digitalgarden/styles.b3e1e36b0403ac565c9392b3e23ef3b6.min.css rel=stylesheet><link href=https://carlos-gg.github.io/digitalgarden/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://carlos-gg.github.io/digitalgarden/js/darkmode.18b7c6dfe67ae3bf2317338cf4189144.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/popover.abe6a51cc7138c5dff00f151dd627ad1.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://carlos-gg.github.io/digitalgarden/",fetchData=Promise.all([fetch("https://carlos-gg.github.io/digitalgarden/indices/linkIndex.e6bf3eae1b9b834d561470875adafe62.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://carlos-gg.github.io/digitalgarden/indices/contentIndex.81cc2fd3fa699feb1af6b27e6f0de4c0.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://carlos-gg.github.io/digitalgarden",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!0;drawGraph("https://carlos-gg.github.io/digitalgarden",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/carlos-gg.github.io\/digitalgarden\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-S103D50NQ0"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-S103D50NQ0",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://carlos-gg.github.io/digitalgarden/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://carlos-gg.github.io/digitalgarden/>CarlosGG's Knowledge Garden ðŸª´</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Deep CV</h1><p class=meta>Last updated
Sep 29, 2022
<a href=https://github.com/jackyzha0/quartz/tree/hugo/content/AI/Computer%20Vision/Deep%20CV.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details open><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#resources>Resources</a><ol><li><a href=#applications>Applications</a></li></ol></li><li><a href=#references>References</a></li></ol></nav></details></aside><blockquote><p>DL is used in the domain of digital image processing to solve difficult problems (e.g.image colorization, classification, segmentation and detection). DL methods such as CNNs mostly improve prediction performance using big data and plentiful computing resources and have pushed the boundaries of what was possible. Problems which were assumed to be unsolvable are now solved with super-human accuracy (eg image classification). Since being reignited by Krizhevsky, Sutskever and Hinton in 2012, DL has dominated the domain ever since due to a substantially better performance compared to traditional methods.</p></blockquote><blockquote><p>See:</p><ul><li><a href=/digitalgarden/AI/Deep-learning/CNNs rel=noopener class=internal-link data-src=/digitalgarden/AI/Deep-learning/CNNs>AI/Deep learning/CNNs</a></li><li><a href=/digitalgarden/AI/Deep-learning/GANs rel=noopener class=internal-link data-src=/digitalgarden/AI/Deep-learning/GANs>AI/Deep learning/GANs</a></li><li><a href=/digitalgarden/AI/Deep-learning/Normalizing-flows rel=noopener class=internal-link data-src=/digitalgarden/AI/Deep-learning/Normalizing-flows>AI/Deep learning/Normalizing flows</a></li><li>&ldquo;For Computer Vision&rdquo; section in <a href=/digitalgarden/AI/Deep-learning/Transformers rel=noopener class=internal-link data-src=/digitalgarden/AI/Deep-learning/Transformers>AI/Deep learning/Transformers</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Deep-image-prior rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Deep-image-prior>AI/Computer Vision/Deep image prior</a></li></ul></blockquote><a href=#resources><h2 id=resources><span class=hanchor arialabel=Anchor># </span>Resources</h2></a><ul><li><a href=https://github.com/kjw0612/awesome-deep-vision rel=noopener>https://github.com/kjw0612/awesome-deep-vision</a></li><li><a href=https://github.com/timzhang642/3D-Machine-Learning rel=noopener>https://github.com/timzhang642/3D-Machine-Learning</a></li><li><a href=https://medium.com/@taposhdr/medical-image-analysis-with-deep-learning-i-23d518abf531 rel=noopener>https://medium.com/@taposhdr/medical-image-analysis-with-deep-learning-i-23d518abf531</a></li><li><a href=http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/ rel=noopener>http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/</a></li></ul><a href=#applications><h3 id=applications><span class=hanchor arialabel=Anchor># </span>Applications</h3></a><p>See:</p><ul><li><a href=/digitalgarden/AI/Computer-Vision/Background-subtraction rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Background-subtraction>AI/Computer Vision/Background subtraction</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Image-and-video-captioning rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Image-and-video-captioning>AI/Computer Vision/Image and video captioning</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Image-to-image-translation rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Image-to-image-translation>AI/Computer Vision/Image-to-image translation</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Inpainting-and-restoration rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Inpainting-and-restoration>AI/Computer Vision/Inpainting and restoration</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Object-classification-image-recognition rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Object-classification-image-recognition>AI/Computer Vision/Object classification, image recognition</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Object-detection rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Object-detection>AI/Computer Vision/Object detection</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Semantic-segmentation rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Semantic-segmentation>AI/Computer Vision/Semantic segmentation</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Super-resolution rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Super-resolution>AI/Computer Vision/Super-resolution</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Video-Frame-Interpolation rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Video-Frame-Interpolation>AI/Computer Vision/Video Frame Interpolation</a></li><li><a href=/digitalgarden/AI/Computer-Vision/Video-segmentation-and-prediction rel=noopener class=internal-link data-src=/digitalgarden/AI/Computer-Vision/Video-segmentation-and-prediction>AI/Computer Vision/Video segmentation and prediction</a></li></ul><a href=#references><h2 id=references><span class=hanchor arialabel=Anchor># </span>References</h2></a><ul><li>#PAPER #REVIEW
<a href=https://www.hindawi.com/journals/cin/2018/7068349/ rel=noopener>Deep Learning for Computer Vision: A Brief Review (Voulodimos 2017)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/1910.13796 rel=noopener>Deep Learning vs. Traditional Computer Vision (O&rsquo;Mahony 2019)</a></li><li>#PAPER
<a href=https://www.nature.com/articles/s41467-020-20655-6 rel=noopener>Deep learning encodes robust discriminative neuroimaging representations to outperform standard machine learning (Abrol 2021)</a></li><li>#PAPER #REVIEW
<a href=https://www.nature.com/articles/s41746-020-00376-2 rel=noopener>Deep learning-enabled medical computer vision (Esteva 2021)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/2103.06255 rel=noopener>Involution: Inverting the Inherence of Convolution for Visual Recognition, a brand new neural operator (Li 2021)</a><ul><li>#CODE
<a href=https://github.com/d-li14/involution rel=noopener>https://github.com/d-li14/involution</a></li><li>#CODE
<a href=https://github.com/PrivateMaRyan/keras-involution2Ds rel=noopener>https://github.com/PrivateMaRyan/keras-involution2Ds</a></li><li><a href="https://www.youtube.com/watch?v=pH2jZun8MoY" rel=noopener>Paper explained</a></li><li><a href=https://keras.io/examples/vision/involution/ rel=noopener>https://keras.io/examples/vision/involution/</a></li><li><a href=https://medium.com/analytics-vidhya/involution-a-step-towards-a-new-generation-of-neural-networks-for-visual-recognition-3b8ad75eb818 rel=noopener>Involution: Inverting the Inherence of Convolution for Visual Recognition</a></li><li>involution is a general-purpose neural primitive that is versatile for a spectrum of deep learning models on different vision tasks</li><li>involution bridges convolution and self-attention in design, while being more efficient and effective than convolution, simpler than self-attention in form</li><li>the proposed involution operator could be leveraged as fundamental bricks to build the new generation of neural networks for visual recognition, powering different deep learning models on several prevalent benchmarks</li></ul></li><li>#PAPER
<a href=https://arxiv.org/abs/2108.02451v3 rel=noopener>Unifying Nonlocal Blocks for Neural Networks (Zhu 2021)</a><ul><li>#CODE
<a href=https://github.com/zh460045050/SNL_ICCV2021 rel=noopener>https://github.com/zh460045050/SNL_ICCV2021</a></li></ul></li><li>#PAPER
<a href=https://arxiv.org/pdf/2106.02253 rel=noopener>X-volution: On the unification of convolution and self-attention (Chen 2021)</a></li><li>#PAPER
<a href=https://aaai-2022.virtualchair.net/poster_aaai2015 rel=noopener>Bivolution: A Static and Dynamic Coupled Filter (Hu 2022)</a><ul><li>#CODE
<a href=https://github.com/neuralchen/Bivolution rel=noopener>https://github.com/neuralchen/Bivolution</a></li></ul></li><li>#PAPER
<a href=https://www.semanticscholar.org/paper/Convolution-of-Convolution%3A-Let-Kernels-Spatially-Zhao-Li/87e0f7adce75bac24f944f0b8fb7e2441b36cfb4 rel=noopener>Convolution of Convolution: Let Kernels Spatially Collaborate (Zhao 2022)</a><ul><li>#CODE
<a href=https://github.com/Genera1Z/ConvolutionOfConvolution rel=noopener>https://github.com/Genera1Z/ConvolutionOfConvolution</a></li></ul></li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/digitalgarden/AI/Computer-Vision/Computer-vision/ data-ctx="AI/Computer Vision/Deep CV" data-src=/AI/Computer-Vision/Computer-vision class=internal-link>Computer Vision</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://carlos-gg.github.io/digitalgarden/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Carlos Alberto Gomez Gonzalez using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2022</p><ul><li><a href=https://carlos-gg.github.io/digitalgarden/>Home</a></li><li><a href=https://carlos-gg.github.io>Carlos'Homepage</a></li></ul></footer></div></div></body></html>