<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components."><title>Principal component analysis (PCA)</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://carlos-gg.github.io/digitalgarden//icon.png><link href=https://carlos-gg.github.io/digitalgarden/styles.b3e1e36b0403ac565c9392b3e23ef3b6.min.css rel=stylesheet><link href=https://carlos-gg.github.io/digitalgarden/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://carlos-gg.github.io/digitalgarden/js/darkmode.18b7c6dfe67ae3bf2317338cf4189144.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/popover.abe6a51cc7138c5dff00f151dd627ad1.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://carlos-gg.github.io/digitalgarden/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://carlos-gg.github.io/digitalgarden/",fetchData=Promise.all([fetch("https://carlos-gg.github.io/digitalgarden/indices/linkIndex.991b75f33121337e886fecf2343c36c6.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://carlos-gg.github.io/digitalgarden/indices/contentIndex.231f6e1544b0bc788d235bb4ff6ea274.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://carlos-gg.github.io/digitalgarden",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!0;drawGraph("https://carlos-gg.github.io/digitalgarden",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/carlos-gg.github.io\/digitalgarden\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-S103D50NQ0"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-S103D50NQ0",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://carlos-gg.github.io/digitalgarden/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://carlos-gg.github.io/digitalgarden/>CarlosGG's Knowledge Garden ðŸª´</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Principal component analysis (PCA)</h1><p class=meta>Last updated
Sep 3, 2022
<a href=https://github.com/jackyzha0/quartz/tree/hugo/content/AI/Unsupervised%20learning/PCA.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details open><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#resources>Resources</a><ol><li><a href=#pca-and-svd>PCA and SVD</a></li><li><a href=#incremental-pca>Incremental PCA</a></li><li><a href=#robust-pca>Robust PCA</a></li><li><a href=#multilinear-pca>Multilinear PCA</a></li></ol></li><li><a href=#code>Code</a></li><li><a href=#references>References</a></li></ol></nav></details></aside><blockquote><p>Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. The number of principal components is less than or equal to the number of original variables. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors are an uncorrelated orthogonal basis set</p></blockquote><a href=#resources><h2 id=resources><span class=hanchor arialabel=Anchor># </span>Resources</h2></a><ul><li><p><a href=https://en.wikipedia.org/wiki/Principal_component_analysis rel=noopener>https://en.wikipedia.org/wiki/Principal_component_analysis</a></p></li><li><p><a href=http://setosa.io/ev/principal-component-analysis/ rel=noopener>http://setosa.io/ev/principal-component-analysis/</a></p></li><li><p><a href=https://www.neuraldesigner.com/blog/principal-components-analysis rel=noopener>https://www.neuraldesigner.com/blog/principal-components-analysis</a></p></li><li><p><a href=http://stats.stackexchange.com/questions/110508/questions-on-pca-when-are-pcs-independent-why-is-pca-sensitive-to-scaling-why rel=noopener>http://stats.stackexchange.com/questions/110508/questions-on-pca-when-are-pcs-independent-why-is-pca-sensitive-to-scaling-why</a></p></li><li><p>Explained variance ratio:</p><ul><li><a href=http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html#explained-variance rel=noopener>http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html#explained-variance</a></li><li><a href=http://jotterbach.github.io/2016/03/24/Principal_Component_Analysis/ rel=noopener>http://jotterbach.github.io/2016/03/24/Principal_Component_Analysis/</a></li></ul></li></ul><a href=#pca-and-svd><h3 id=pca-and-svd><span class=hanchor arialabel=Anchor># </span>PCA and SVD</h3></a><ul><li>Link between <a href=/digitalgarden/AI/Math-and-Statistics/SVD rel=noopener class=internal-link data-src=/digitalgarden/AI/Math-and-Statistics/SVD>AI/Math and Statistics/SVD</a> and <a href=/digitalgarden/AI/Unsupervised-learning/PCA rel=noopener class=internal-link data-src=/digitalgarden/AI/Unsupervised-learning/PCA>AI/Unsupervised learning/PCA</a>: the eigenvectors of DDT are simply the left singular vectors of D. SVD gives us also the eigenvectors of DTD, useful for rowsâ€¯ instead of columns notation (python notation)</li><li><a href=http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues rel=noopener>http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues</a></li><li><a href=https://www.quora.com/What-is-an-intuitive-explanation-of-singular-value-decomposition-SVD rel=noopener>https://www.quora.com/What-is-an-intuitive-explanation-of-singular-value-decomposition-SVD</a></li><li><a href=https://stats.stackexchange.com/questions/10251/what-is-the-objective-function-of-pca rel=noopener>https://stats.stackexchange.com/questions/10251/what-is-the-objective-function-of-pca</a></li></ul><a href=#incremental-pca><h3 id=incremental-pca><span class=hanchor arialabel=Anchor># </span>Incremental PCA</h3></a><ul><li><a href=https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.IncrementalPCA.html rel=noopener>https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.IncrementalPCA.html</a></li><li>This algorithm has constant memory complexity, on the order of <code>batch_size * n_features</code>, enabling use of np.memmap files without loading the entire file into memory. For sparse matrices, the input is converted to dense in batches (in order to be able to subtract the mean) which avoids storing the entire dense matrix at any one time.</li></ul><a href=#robust-pca><h3 id=robust-pca><span class=hanchor arialabel=Anchor># </span>Robust PCA</h3></a><p>See <a href=/digitalgarden/AI/Unsupervised-learning/Robust-PCA rel=noopener class=internal-link data-src=/digitalgarden/AI/Unsupervised-learning/Robust-PCA>AI/Unsupervised learning/Robust PCA</a></p><a href=#multilinear-pca><h3 id=multilinear-pca><span class=hanchor arialabel=Anchor># </span>Multilinear PCA</h3></a><ul><li><a href=https://en.wikipedia.org/wiki/Multilinear_principal_component_analysis rel=noopener>https://en.wikipedia.org/wiki/Multilinear_principal_component_analysis</a></li><li><a href=http://alumni.media.mit.edu/~maov/tensorfaces/eccv02_corrected.pdf rel=noopener>http://alumni.media.mit.edu/~maov/tensorfaces/eccv02_corrected.pdf</a></li><li><a href=http://www.comp.hkbu.edu.hk/~haiping/MSL.html rel=noopener>http://www.comp.hkbu.edu.hk/~haiping/MSL.html</a></li><li><a href=http://www.mathworks.com/matlabcentral/fileexchange/26168-multilinear-principal-component-analysis--mpca rel=noopener>http://www.mathworks.com/matlabcentral/fileexchange/26168-multilinear-principal-component-analysis&ndash;mpca</a>-</li><li><a href=http://www.comm.toronto.edu/~kostas/Publications2008/pub/102.pdf rel=noopener>http://www.comm.toronto.edu/~kostas/Publications2008/pub/102.pdf</a></li></ul><a href=#code><h2 id=code><span class=hanchor arialabel=Anchor># </span>Code</h2></a><ul><li>#CODE
<a href=https://github.com/jakevdp/wpca rel=noopener>https://github.com/jakevdp/wpca</a></li></ul><a href=#references><h2 id=references><span class=hanchor arialabel=Anchor># </span>References</h2></a><ul><li>#PAPER
<a href=https://arxiv.org/pdf/1208.4122 rel=noopener>Principal Component Analysis with Noisy and/or Missing Data (Bailey 2012)</a></li><li>#PAPER
<a href=https://arxiv.org/pdf/1412.4533 rel=noopener>Weighted principal component analysis: a weighted covariance eigendecomposition approach (Delchambre 2014)</a></li><li>#PAPER
<a href=https://arxiv.org/pdf/1404.1100 rel=noopener>A Tutorial on Principal Component Analysis (Shlens 2014)</a></li><li>#PAPER
<a href="https://openreview.net/forum?id=NzTU59SYbNq" rel=noopener>EigenGame: PCA as a Nash Equilibrium (Gemp 2021)</a><ul><li><a href=https://pub.towardsai.net/deepmind-wants-to-reimagine-one-of-the-most-important-algorithms-in-machine-learning-381884d42de rel=noopener>https://pub.towardsai.net/deepmind-wants-to-reimagine-one-of-the-most-important-algorithms-in-machine-learning-381884d42de</a></li></ul></li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/digitalgarden/AI/Feature-learning/ data-ctx="AI/Unsupervised learning/PCA" data-src=/AI/Feature-learning class=internal-link>Feature learning</a></li><li><a href=/digitalgarden/AI/Math-and-Statistics/SVD/ data-ctx="AI/Unsupervised learning/PCA#PCA and SVD" data-src=/AI/Math-and-Statistics/SVD class=internal-link>Singular Value Decomposition (SVD)</a></li><li><a href=/digitalgarden/AI/Unsupervised-learning/Dimensionality-reduction-and-low-rank-modeling/ data-ctx="AI/Unsupervised learning/PCA" data-src=/AI/Unsupervised-learning/Dimensionality-reduction-and-low-rank-modeling class=internal-link>Dimensionality reduction and low-rank modeling</a></li><li><a href=/digitalgarden/AI/Unsupervised-learning/PCA/ data-ctx="AI/Unsupervised learning/PCA" data-src=/AI/Unsupervised-learning/PCA class=internal-link>Principal component analysis (PCA)</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://carlos-gg.github.io/digitalgarden/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Carlos Alberto Gomez Gonzalez using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2024</p><ul><li><a href=https://carlos-gg.github.io/digitalgarden/>Home</a></li><li><a href=https://carlos-gg.github.io>Carlos'Homepage</a></li></ul></footer></div></div></body></html>