<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Resources  https://en.wikipedia.org/wiki/Monte_Carlo_method  Sequential Monte Carlo (SMC or particle filter)  Particle filters or Sequential Monte Carlo (SMC) methods are a set of Monte Carlo algorithms used to solve filtering problems arising in signal processing and Bayesian statistical inference."><title>Monte Carlo methods</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=/icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://carlos-gg.github.io/digitalgarden/styles.cd61336c89ed6e03702366ce4a492b75.min.css rel=stylesheet><script src=https://carlos-gg.github.io/digitalgarden/js/darkmode.46b07878b7f5d9e26ad7a3c40f8a0605.min.js></script><script>const BASE_URL="https://carlos-gg.github.io/digitalgarden/",fetchData=Promise.all([fetch("https://carlos-gg.github.io/digitalgarden/indices/linkIndex.4662b1c06ac21499279f532949abefdb.min.json").then(a=>a.json()).then(a=>({index:a.index,links:a.links})),fetch("https://carlos-gg.github.io/digitalgarden/indices/contentIndex.5091725e6bbe4053e9db7cc5ceea8619.min.json").then(a=>a.json())]).then(([{index:a,links:b},c])=>({index:a,links:b,content:c}))</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-S103D50NQ0"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-S103D50NQ0',{anonymize_ip:!1})}</script><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://carlos-gg.github.io/digitalgarden/js/graph.27e8521c25c27c79dea35f434c486167.js></script><script>drawGraph("https://carlos-gg.github.io/digitalgarden/AI/Math-and-Statistics/Monte-Carlo-methods","https://carlos-gg.github.io/digitalgarden",[{"/moc":"#4388cc"}],-1,!0,!1,!0)</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script><script defer src=https://carlos-gg.github.io/digitalgarden/js/search.bc849b857f2c1b822264d40635bb67b6.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://carlos-gg.github.io/digitalgarden/>CarlosGG's Knowledge Garden ðŸª´</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Monte Carlo methods</h1><p class=meta>Last updated April 9, 2022</p><ul class=tags></ul><aside class=mainTOC><h3>Table of Contents</h3><nav id=TableOfContents><ol><li><a href=#resources>Resources</a><ol><li><a href=#sequential-monte-carlo-smc-or-particle-filter>Sequential Monte Carlo (SMC or particle filter)</a></li><li><a href=#markov-process>Markov Process</a></li><li><a href=#mcmc>MCMC</a></li><li><a href=#nested-sampling>Nested Sampling</a></li></ol></li><li><a href=#code>Code</a></li></ol></nav></aside><h2 id=resources>Resources</h2><ul><li><a href=https://en.wikipedia.org/wiki/Monte_Carlo_method>https://en.wikipedia.org/wiki/Monte_Carlo_method</a></li></ul><h3 id=sequential-monte-carlo-smc-or-particle-filter>Sequential Monte Carlo (SMC or particle filter)</h3><ul><li>Particle filters or Sequential Monte Carlo (SMC) methods are a set of Monte Carlo algorithms used to solve filtering problems arising in signal processing and Bayesian statistical inference. The filtering problem consists of estimating the internal states in dynamical systems when partial observations are made, and random perturbations are present in the sensors as well as in the dynamical system. The objective is to compute the posterior distributions of the states of some Markov process, given some noisy and partial observations.</li></ul><h3 id=markov-process>Markov Process</h3><ul><li><a href=https://en.wikipedia.org/wiki/Markov_chain>https://en.wikipedia.org/wiki/Markov_chain</a></li><li><a href=https://en.wikipedia.org/wiki/Markov_property>https://en.wikipedia.org/wiki/Markov_property</a></li><li>A stochastic process has the Markov property if the conditional probability distribution of future states of the process (conditional on both past and present states) depends only upon the present state, not on the sequence of events that preceded it. A process with this property is called a Markov process.</li><li><a href=http://setosa.io/ev/markov-chains/ rel=noopener>Markov Chains Explained Visually</a></li></ul><h4 id=hidden-markov-model-hmm>Hidden Markov Model (HMM)</h4><ul><li><a href=https://en.wikipedia.org/wiki/Hidden_Markov_model>https://en.wikipedia.org/wiki/Hidden_Markov_model</a></li><li>Hidden Markov Model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (i.e. hidden) states.</li><li>HMM is a Markov chain for which the state is only partially observable. In other words, observations are related to the state of the system, but they are typically insufficient to precisely determine the state. Several well-known algorithms for hidden Markov models exist.</li><li><a href=https://www.quora.com/What-is-a-hidden-Markov-Model-HMM-and-how-can-it-be-used-in-speech-recognition>https://www.quora.com/What-is-a-hidden-Markov-Model-HMM-and-how-can-it-be-used-in-speech-recognition</a></li><li><a href=https://www.quora.com/Why-do-we-use-Hidden-Markov-Models-for-speech-recognition>https://www.quora.com/Why-do-we-use-Hidden-Markov-Models-for-speech-recognition</a></li><li><a href=http://scikit-learn.sourceforge.net/stable/modules/hmm.html>http://scikit-learn.sourceforge.net/stable/modules/hmm.html</a></li><li><a href=https://github.com/hmmlearn/hmmlearn>https://github.com/hmmlearn/hmmlearn</a></li><li><a href=http://hmmlearn.readthedocs.io/en/latest/tutorial.html#available-models>http://hmmlearn.readthedocs.io/en/latest/tutorial.html#available-models</a></li></ul><h3 id=mcmc>MCMC</h3><ul><li>MCMC methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by recording states from the chain</li><li><a href=https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo>https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo</a></li></ul><h3 id=nested-sampling>Nested Sampling</h3><ul><li><a href=https://en.wikipedia.org/wiki/Nested_sampling_algorithm>https://en.wikipedia.org/wiki/Nested_sampling_algorithm</a></li><li>The nested sampling algorithm is a computational approach to the problem of comparing models in Bayesian statistics.</li></ul><h2 id=code>Code</h2><ul><li><a href=https://gabriel-p.github.io/pythonMCMC/ rel=noopener>A list of Python-based MCMC packages. Also hereâ€™s a nice list of MCMC algorithms</a></li><li>#CODE
<a href=http://mcleonard.github.io/sampyl/ rel=noopener>Sampyl - MCMC samplers for Bayesian estimation in Python, including Metropolis-Hastings, NUTS, and Slice</a></li><li>#CODE
<a href=http://dan.iel.fm/emcee/current/ rel=noopener>emcee</a></li><li>#CODE UltraNest - A Pythonic implementation of the Nested Sampling integration algorithm for Bayesian model comparison and parameter estimation<ul><li><a href=https://johannesbuchner.github.io/UltraNest/>https://johannesbuchner.github.io/UltraNest/</a></li><li><a href=https://johannesbuchner.github.io/UltraNest/testsuite/>https://johannesbuchner.github.io/UltraNest/testsuite/</a></li></ul></li></ul></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=https://carlos-gg.github.io/digitalgarden//AI/Bayesian-modelling>Bayesian modelling</a></li><li><a href=https://carlos-gg.github.io/digitalgarden//AI/Math-and-Statistics/Math-and-Statistics>Math and Statistics</a></li></ul></div></div><div id=contact_buttons><footer><p>Made by Carlos Alberto Gomez Gonzalez using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2022</p><a href=https://carlos-gg.github.io/digitalgarden/>Root</a><a href=https://carlos-gg.github.io>CarlosGG</a></footer></div><script src=https://carlos-gg.github.io/digitalgarden/js/popover.e57188d2e4c06b0654e020b3a734bb62.min.js></script><script>initPopover("https://carlos-gg.github.io/digitalgarden")</script></div></body></html>