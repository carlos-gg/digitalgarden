<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="See:
 [[AI/Bayesian modelling]] [[AI/Deep learning/GFlowNets]]   Resources   A Comprehensive Introduction to Bayesian Deep Learning  Bayesian Neural Network tutorial  Bayesian Deep Learning - NeurIPS Workshop  Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe AI  Making Your Neural Network Say ‚ÄúI Don‚Äôt Know‚Äù‚Ää‚Äî‚ÄäBayesian NNs using Pyro and PyTorch  Building a Bayesian deep learning classifier  Physics - a Gateway to Bayesian Deep Learning  Bayesian deep learning with Fastai : how not to be uncertain about your uncertainty!"><title>Probabilistic deep learning</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=/icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://carlos-gg.github.io/digitalgarden/styles.cd61336c89ed6e03702366ce4a492b75.min.css rel=stylesheet><script src=https://carlos-gg.github.io/digitalgarden/js/darkmode.46b07878b7f5d9e26ad7a3c40f8a0605.min.js></script>
<script>const BASE_URL="https://carlos-gg.github.io/digitalgarden/",fetchData=Promise.all([fetch("https://carlos-gg.github.io/digitalgarden/indices/linkIndex.687ef89d97995715c35fb6ef6dcf5be1.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://carlos-gg.github.io/digitalgarden/indices/contentIndex.aec436b14e880a867e4669da3a13b7d5.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n}))</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-S103D50NQ0"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-S103D50NQ0",{anonymize_ip:!1})}</script><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://carlos-gg.github.io/digitalgarden/js/graph.27e8521c25c27c79dea35f434c486167.js></script>
<script>drawGraph("https://carlos-gg.github.io/digitalgarden/AI/Deep-learning/Probabilistic-deep-learning","https://carlos-gg.github.io/digitalgarden",[{"/moc":"#4388cc"}],-1,!0,!1,!0)</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://carlos-gg.github.io/digitalgarden/js/search.bc849b857f2c1b822264d40635bb67b6.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://carlos-gg.github.io/digitalgarden/>CarlosGG's Knowledge Garden ü™¥</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Probabilistic deep learning</h1><p class=meta>Last updated June 9, 2022</p><ul class=tags></ul><aside class=mainTOC><details open><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#resources>Resources</a><ol><li><a href=#monte-carlo-dropout>Monte Carlo Dropout</a></li></ol></li><li><a href=#code>Code</a></li><li><a href=#books>Books</a></li><li><a href=#courses>Courses</a></li><li><a href=#references>References</a></li></ol></nav></details></aside><blockquote><p>See:</p><ul><li><a href=/digitalgarden/AI/Bayesian-modelling rel=noopener class=internal-link data-src=/digitalgarden/AI/Bayesian-modelling>AI/Bayesian modelling</a></li><li><a href=/digitalgarden/AI/Deep-learning/GFlowNets rel=noopener class=internal-link data-src=/digitalgarden/AI/Deep-learning/GFlowNets>AI/Deep learning/GFlowNets</a></li></ul></blockquote><h2 id=resources>Resources</h2><ul><li><a href=https://jorisbaan.nl/2021/03/02/introduction-to-bayesian-deep-learning.html rel=noopener>A Comprehensive Introduction to Bayesian Deep Learning</a></li><li><a href=http://edwardlib.org/tutorials/bayesian-neural-network rel=noopener>Bayesian Neural Network tutorial</a></li><li><a href=http://bayesiandeeplearning.org/ rel=noopener>Bayesian Deep Learning - NeurIPS Workshop</a></li><li><a href=https://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai/ rel=noopener>Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe AI</a></li><li><a href=https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd rel=noopener>Making Your Neural Network Say ‚ÄúI Don‚Äôt Know‚Äù‚Ää‚Äî‚ÄäBayesian NNs using Pyro and PyTorch</a></li><li><a href=https://towardsdatascience.com/building-a-bayesian-deep-learning-classifier-ece1845bc09 rel=noopener>Building a Bayesian deep learning classifier</a></li><li><a href=https://github.com/henripal/sgld rel=noopener>Physics - a Gateway to Bayesian Deep Learning</a></li><li><a href=https://towardsdatascience.com/bayesian-deep-learning-with-fastai-how-not-to-be-uncertain-about-your-uncertainty-6a99d1aa686e rel=noopener>Bayesian deep learning with Fastai : how not to be uncertain about your uncertainty!</a><ul><li>BNNs are a way to add uncertainty handling in our models. The idea is simple, instead of having deterministic weights that we learn, we instead learn the parameters of a random variable which we will use to sample our weights during forward propagation. Then, to learn the parameters, we will use backpropagation, sometimes with a little trick to make our parameters differentiable.</li><li>Dropout is a way to make your Neural Networks Bayesian almost for free, and to use it during inference you just have to keep the Dropout, and sample several models, this is called MC Dropout.</li></ul></li></ul><h3 id=monte-carlo-dropout>Monte Carlo Dropout</h3><ul><li><a href=https://towardsdatascience.com/monte-carlo-dropout-7fd52f8b6571 rel=noopener>Monte Carlo Dropout</a></li><li><a href=https://datascience.stackexchange.com/questions/44065/what-is-monte-carlo-dropout rel=noopener>What is MC Dropout</a></li><li>normal dropout (only at training time) serves as a regularization to avoid overfitting. During test time, dropout is not applied; instead, all nodes/connections are present, but the weights are adjusted accordingly (e.g. multiplied by the keep ratio, which is 1 - dropout_ratio). Such a model during test time can be understood as a <em>average</em> of an ensemble of neural networks.</li><li>Notice that for normal dropout, at test time the prediction is <em>deterministic</em>. Without other source of randomness, given one test data point, the model will always predict the same label or value.</li><li>For <em>Monte Carlo dropout</em>, the dropout is applied at both training and test time. At test time, the prediction is no longer deterministic, but depending on which nodes/links you randomly choose to keep. Therefore, given a same datapoint, your model could predict different values each time.</li><li>The primary goal of MC dropout is to generate random predictions and interpret them as samples from a probabilistic distribution.</li><li>#TALK
<a href=https://mvaldenegro.github.io/files/DSRP-meetup-NeurIPS-2020-incertidumbre-redes-neuronales.pdf rel=noopener>Estimacion de la Incertidumbre en Redes Neuronales (Valdenegro)</a></li></ul><h2 id=code>Code</h2><ul><li>#CODE
<a href=https://github.com/uber/pyro rel=noopener>Pyro (Uber) - Deep universal probabilistic programming with Python and PyTorch</a><ul><li><a href=http://pyro.ai rel=noopener>http://pyro.ai</a></li><li><a href=http://eng.uber.com/pyro rel=noopener>http://eng.uber.com/pyro</a></li></ul></li><li>#CODE
<a href=https://github.com/piEsposito/blitz-bayesian-deep-learning rel=noopener>Blitz - Bayesian Layers in Torch Zoo</a></li><li>#CODE
<a href=https://github.com/facebookresearch/beanmachine rel=noopener>Bean machine (Meta/Facebook)</a><ul><li><a href=https://research.facebook.com/blog/2021/12/introducing-bean-machine-a-probabilistic-programming-platform-built-on-pytorch/ rel=noopener>https://research.facebook.com/blog/2021/12/introducing-bean-machine-a-probabilistic-programming-platform-built-on-pytorch/</a></li></ul></li><li>#CODE
<a href=http://edwardlib.org/ rel=noopener>Edwardlib</a><ul><li>Edward is a Python library for probabilistic modeling, inference, and criticism</li><li><a href=https://theintelligenceofinformation.wordpress.com/2017/06/02/pydata-london-2017-bayesian-deep-learning-talk-by-andrew-rowan/ rel=noopener>https://theintelligenceofinformation.wordpress.com/2017/06/02/pydata-london-2017-bayesian-deep-learning-talk-by-andrew-rowan/</a></li><li>#TALK
<a href="https://www.youtube.com/watch?v=I09QVNrUS3Q" rel=noopener>https://www.youtube.com/watch?v=I09QVNrUS3Q</a></li><li><a href=http://willwolf.io/2017/06/15/random-effects-neural-networks/ rel=noopener>http://willwolf.io/2017/06/15/random-effects-neural-networks/</a></li></ul></li><li>#CODE
<a href=https://www.tensorflow.org/probability/ rel=noopener>TensorFlow Probability</a><ul><li><a href=https://towardsdatascience.com/bayesian-neural-networks-with-tensorflow-probability-fbce27d6ef6 rel=noopener>https://towardsdatascience.com/bayesian-neural-networks-with-tensorflow-probability-fbce27d6ef6</a></li></ul></li><li>#CODE
<a href=https://github.com/mvaldenegro/keras-uncertainty rel=noopener>keras-uncertainty</a><ul><li>Monte Carlo Dropout (MC-Dropout)</li><li>Deep Ensembles</li></ul></li></ul><h2 id=books>Books</h2><ul><li>#BOOK
<a href=http://pgm.stanford.edu/ rel=noopener>Probabilistic Graphical Models: Principles and Techniques (Koller, 2009 MIT)</a></li><li>#BOOK
<a href=https://www.manning.com/books/probabilistic-deep-learning rel=noopener>Probabilistic Deep Learning - With Python, Keras and TensorFlow Probability (Durr, MANNING 2020)</a><ul><li><a href=https://tensorchiefs.github.io/dl_book/ rel=noopener>https://tensorchiefs.github.io/dl_book/</a></li></ul></li></ul><h2 id=courses>Courses</h2><ul><li>#COURSE
<a href=https://ermongroup.github.io/cs228-notes/ rel=noopener>Introductory course on probabilistic graphical models</a></li></ul><h2 id=references>References</h2><ul><li><p>Review papers:</p><ul><li>#PAPER
<a href=https://arxiv.org/abs/2107.03342 rel=noopener>A Survey of Uncertainty in Deep Neural Networks (Gawlikowski 2022)</a></li></ul></li><li><p>#PAPER
<a href=https://www.nature.com/articles/nature14541 rel=noopener>Probabilistic machine learning and artificial intelligence (Ghahramani 2015)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1506.02142 rel=noopener>Dropout as a Bayesian Approximation:Representing Model Uncertainty in Deep Learning (Gal 2016)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1801.07710 rel=noopener>Bayesian Neural Networks (Mullachery, 2018)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1910.08168 rel=noopener>Deep Sub-Ensembles for Fast Uncertainty Estimation in Image Classification (Valdenegro-Toro 2019)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1704.02798 rel=noopener>Bayesian Recurrent Neural Networks (Fortunato 2019)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2002.08791 rel=noopener>Bayesian Deep Learning and a Probabilistic Perspective of Generalization (Gordon Wilson, 2020)</a></p><ul><li><a href=https://github.com/izmailovpavel/understandingbdl rel=noopener>https://github.com/izmailovpavel/understandingbdl</a></li></ul></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2007.06823 rel=noopener>Hands-on Bayesian Neural Networks - a Tutorial for Deep Learning Users (Jospin 2020)</a></p></li><li><p>#PAPER
<a href=https://www.nature.com/articles/s41598-021-84854-x rel=noopener>DropConnect is effective in modeling uncertainty of Bayesian deep networks (Mobiny 2021)</a></p><ul><li>#CODE
<a href=https://github.com/hula-ai/mc_dropconnect rel=noopener>https://github.com/hula-ai/mc_dropconnect</a></li></ul></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2107.08924 rel=noopener>Epistemic Neural Networks (Osband 2021)</a></p><ul><li>#CODE
<a href=https://github.com/deepmind/enn rel=noopener>https://github.com/deepmind/enn</a></li><li><a href=https://syncedreview.com/2021/07/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-69/ rel=noopener>https://syncedreview.com/2021/07/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-69/</a></li></ul></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2106.04015 rel=noopener>Uncertainty Baselines: Benchmarks for Uncertainty & Robustness in Deep Learning (Nado 2021)</a></p><ul><li><a href=https://ai.googleblog.com/2021/10/baselines-for-uncertainty-and.html rel=noopener>https://ai.googleblog.com/2021/10/baselines-for-uncertainty-and.html</a></li><li>#CODE
<a href=https://github.com/google/uncertainty-baselines rel=noopener>https://github.com/google/uncertainty-baselines</a></li></ul></li><li><p>#PAPER
<a href=https://arxiv.org/pdf/2106.00120 rel=noopener>Probabilistic Deep Learning with Probabilistic Neural Networks and Deep Probabilistic Models</a></p></li></ul></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/digitalgarden/AI/Bayesian-modelling>Bayesian modelling</a></li><li><a href=/digitalgarden/AI/Deep-learning/DL>Deep Learning (DL)</a></li></ul></div></div><div id=contact_buttons><footer><p>Made by Carlos Alberto Gomez Gonzalez using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, ¬© 2022</p><ul><li><a href=https://carlos-gg.github.io/digitalgarden/>Home</a></li><a href=https://carlos-gg.github.io>Carlos'Homepage</a></ul></footer></div><script src=https://carlos-gg.github.io/digitalgarden/js/popover.e57188d2e4c06b0654e020b3a734bb62.min.js></script>
<script>initPopover("https://carlos-gg.github.io/digitalgarden")</script></div></body></html>