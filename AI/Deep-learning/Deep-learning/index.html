<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="DL is a branch of [[Machine Learning]] and [[AI]] based on a set of algorithms that attempt to model high level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear transformations."><title>Deep Learning</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=/icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><style>:root{--lt-colours-light:var(--light) !important;--lt-colours-lightgray:var(--lightgray) !important;--lt-colours-dark:var(--secondary) !important;--lt-colours-secondary:var(--tertiary) !important;--lt-colours-gray:var(--outlinegray) !important}h1,h2,h3,h4,h5,h6,ol,ul,thead{font-family:Inter;color:var(--dark);font-weight:revert;margin:revert;padding:revert}p,ul,text{font-family:source sans pro,sans-serif;color:var(--gray);fill:var(--gray);font-weight:revert;margin:revert;padding:revert}#TableOfContents>ol{counter-reset:section;margin-left:0;padding-left:1.5em}#TableOfContents>ol>li{counter-increment:section}#TableOfContents>ol>li>ol{counter-reset:subsection}#TableOfContents>ol>li>ol>li{counter-increment:subsection}#TableOfContents>ol>li>ol>li::marker{content:counter(section)"." counter(subsection)"  "}#TableOfContents>ol>li::marker{content:counter(section)"  "}#TableOfContents>ol>li::marker,#TableOfContents>ol>li>ol>li::marker{font-family:Source Sans Pro;font-weight:700}footer{margin-top:4em;text-align:center}table{width:100%}img{width:100%;border-radius:3px;margin:1em 0}p>img+em{display:block;transform:translateY(-1em)}sup{line-height:0}p,tbody,li{font-family:Source Sans Pro;color:var(--gray);line-height:1.5em}blockquote{margin-left:0;border-left:3px solid var(--secondary);padding-left:1em;transition:border-color .2s ease}blockquote:hover{border-color:var(--tertiary)}table{padding:1.5em}td,th{padding:.1em .5em}.footnotes p{margin:.5em 0}.pagination{list-style:none;padding-left:0;display:flex;margin-top:2em;gap:1.5em;justify-content:center}.pagination>li{text-align:center;display:inline-block}.pagination>li a{background-color:initial!important}.pagination>li a[href$="#"]{opacity:.2}.section h3>a{font-weight:700;font-family:Inter;margin:0}.section p{margin-top:0}article>.meta{margin:-1.5em 0 1em;opacity:.7}article>.tags{list-style:none;padding-left:0}article>.tags .meta>h1{margin:0}article>.tags .meta>p{margin:0}article>.tags>li{display:inline-block}article>.tags>li>a{border-radius:8px;border:var(--outlinegray)1px solid;padding:.2em .5em}article>.tags>li>a::before{content:"#";margin-right:.3em;color:var(--outlinegray)}article a{font-family:Source Sans Pro;font-weight:600}article a.internal-link{text-decoration:none;background-color:rgba(143,159,169,.15);padding:0 .1em;margin:auto -.1em;border-radius:3px}.backlinks a{font-weight:600;font-size:.9rem}sup>a{text-decoration:none;padding:0 .1em 0 .2em}a{font-family:Inter,sans-serif;font-size:1em;font-weight:700;text-decoration:none;transition:all .2s ease;color:var(--secondary)}a:hover{color:var(--tertiary)!important}pre{font-family:fira code;padding:.75em;border-radius:3px;overflow-x:scroll}code{font-family:fira code;font-size:.85em;padding:.15em .3em;border-radius:5px;background:var(--lightgray)}html{scroll-behavior:smooth}html:lang(ar) p,html:lang(ar) h1,html:lang(ar) h2,html:lang(ar) h3,html:lang(ar) article{direction:rtl;text-align:right}body{margin:0;height:100vh;width:100vw;overflow-x:hidden;background-color:var(--light)}@keyframes fadeIn{0%{opacity:0}100%{opacity:1}}footer{margin-top:4em}footer>a{font-size:1em;color:var(--secondary);padding:0 .5em 3em}hr{width:25%;margin:4em auto;height:2px;border-radius:1px;border-width:0;color:var(--dark);background-color:var(--dark)}.singlePage{margin:4em 30vw}@media all and (max-width:1200px){.singlePage{margin:25px 5vw}}.page-end{display:flex;flex-direction:row;gap:2em}@media all and (max-width:780px){.page-end{flex-direction:column}}.page-end>*{flex:1 0}.page-end>.backlinks-container>ul{list-style:none;padding-left:0}.page-end>.backlinks-container>ul>li{margin:.5em 0;padding:.25em 1em;border:var(--outlinegray)1px solid;border-radius:5px}.page-end #graph-container{border:var(--outlinegray)1px solid;border-radius:5px}.centered{margin-top:30vh}article>h1{font-size:2em}header{display:flex;flex-direction:row;align-items:center}header>h1{font-size:2em}@media all and (max-width:600px){header>nav{display:none}}header>.spacer{flex:auto}header>svg{cursor:pointer;width:18px;min-width:18px;margin:0 1em}header>svg:hover .search-path{stroke:var(--tertiary)}header>svg .search-path{stroke:var(--gray);stroke-width:2px;transition:stroke .5s ease}#search-container{position:fixed;z-index:9999;left:0;top:0;width:100vw;height:100%;overflow:scroll;display:none;backdrop-filter:blur(4px);-webkit-backdrop-filter:blur(4px)}#search-container>div{width:50%;margin-top:15vh;margin-left:auto;margin-right:auto}@media all and (max-width:1200px){#search-container>div{width:90%}}#search-container>div>*{width:100%;border-radius:4px;background:var(--light);box-shadow:0 14px 50px rgba(27,33,48,.12),0 10px 30px rgba(27,33,48,.16);margin-bottom:2em}#search-container>div>input{box-sizing:border-box;padding:.5em 1em;font-family:Inter,sans-serif;color:var(--dark);font-size:1.1em;border:1px solid var(--outlinegray)}#search-container>div>input:focus{outline:none}#search-container>div>#results-container>.result-card{padding:1em;cursor:pointer;transition:background .2s ease;border:1px solid var(--outlinegray);border-bottom:none;width:100%;font-family:inherit;font-size:100%;line-height:1.15;margin:0;overflow:visible;text-transform:none;text-align:left;background:var(--light);outline:none}#search-container>div>#results-container>.result-card:hover,#search-container>div>#results-container>.result-card:focus{background:rgba(180,180,180,.15)}#search-container>div>#results-container>.result-card:first-of-type{border-top-left-radius:5px;border-top-right-radius:5px}#search-container>div>#results-container>.result-card:last-of-type{border-bottom-left-radius:5px;border-bottom-right-radius:5px;border-bottom:1px solid var(--outlinegray)}#search-container>div>#results-container>.result-card>h3,#search-container>div>#results-container>.result-card>p{margin:0}#search-container>div>#results-container>.result-card .search-highlight{background-color:#afbfc966;padding:.05em .2em;border-radius:3px}.section-ul{list-style:none;padding-left:0}.section-ul>li{border:1px solid var(--outlinegray);border-radius:5px;padding:0 1em;margin-bottom:1em}.section-ul>li h3{opacity:1;font-weight:700;margin-bottom:0}.section-ul>li .meta{opacity:.6}.popover{z-index:999;position:absolute;width:20em;display:inline-block;visibility:hidden;background-color:var(--light);padding:1em;border:1px solid var(--outlinegray);border-radius:5px;transform:translate(-50%,40%);opacity:0;pointer-events:none;transition:opacity .2s ease,transform .2s ease;transition-delay:.3s;user-select:none}@media all and (max-width:600px){.popover{display:none}}.popover.visible{opacity:1;visibility:visible;transform:translate(-50%,20%)}.popover>h3{font-size:1rem;margin:.25em 0}.popover>.meta{margin-top:.25em;opacity:.5}.popover>p{margin:0;font-weight:400;user-select:none}</style><style>.darkmode{float:right;padding:1em;min-width:30px;position:relative}@media all and (max-width:450px){.darkmode{padding:1em}}.darkmode>.toggle{display:none;box-sizing:border-box}.darkmode svg{opacity:0;position:absolute;width:20px;height:20px;top:calc(50% - 10px);margin:0 7px;fill:var(--gray);transition:opacity .1s ease}.toggle:checked~label>#dayIcon{opacity:0}.toggle:checked~label>#nightIcon{opacity:1}.toggle:not(:checked)~label>#dayIcon{opacity:1}.toggle:not(:checked)~label>#nightIcon{opacity:0}</style><style>.chroma{color:#f8f8f2;background-color:#282a36;overflow:hidden}.chroma .lntd{vertical-align:top;padding:0;margin:0;border:0}.chroma .lntable{border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block}.chroma .hl{display:block;width:100%;background-color:#ffc}.chroma .lnt{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .ln{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .k{color:#ff79c6}.chroma .kc{color:#ff79c6}.chroma .kd{color:#8be9fd;font-style:italic}.chroma .kn{color:#ff79c6}.chroma .kp{color:#ff79c6}.chroma .kr{color:#ff79c6}.chroma .kt{color:#8be9fd}.chroma .na{color:#50fa7b}.chroma .nb{color:#8be9fd;font-style:italic}.chroma .nc{color:#50fa7b}.chroma .nf{color:#50fa7b}.chroma .nl{color:#8be9fd;font-style:italic}.chroma .nt{color:#ff79c6}.chroma .nv{color:#8be9fd;font-style:italic}.chroma .vc{color:#8be9fd;font-style:italic}.chroma .vg{color:#8be9fd;font-style:italic}.chroma .vi{color:#8be9fd;font-style:italic}.chroma .s{color:#f1fa8c}.chroma .sa{color:#f1fa8c}.chroma .sb{color:#f1fa8c}.chroma .sc{color:#f1fa8c}.chroma .dl{color:#f1fa8c}.chroma .sd{color:#f1fa8c}.chroma .s2{color:#f1fa8c}.chroma .se{color:#f1fa8c}.chroma .sh{color:#f1fa8c}.chroma .si{color:#f1fa8c}.chroma .sx{color:#f1fa8c}.chroma .sr{color:#f1fa8c}.chroma .s1{color:#f1fa8c}.chroma .ss{color:#f1fa8c}.chroma .m{color:#bd93f9}.chroma .mb{color:#bd93f9}.chroma .mf{color:#bd93f9}.chroma .mh{color:#bd93f9}.chroma .mi{color:#bd93f9}.chroma .il{color:#bd93f9}.chroma .mo{color:#bd93f9}.chroma .o{color:#ff79c6}.chroma .ow{color:#ff79c6}.chroma .c{color:#6272a4}.chroma .ch{color:#6272a4}.chroma .cm{color:#6272a4}.chroma .c1{color:#6272a4}.chroma .cs{color:#6272a4}.chroma .cp{color:#ff79c6}.chroma .cpf{color:#ff79c6}.chroma .gd{color:#8b080b}.chroma .ge{text-decoration:underline}.chroma .gh{font-weight:700}.chroma .gi{font-weight:700}.chroma .go{color:#44475a}.chroma .gu{font-weight:700}.chroma .gl{text-decoration:underline}.lntd:first-of-type>.chroma{padding-right:0}.chroma code{font-family:fira code!important;font-size:.85em;line-height:1em;background:0 0;padding:0}.chroma{border-radius:3px;margin:0}</style><style>:root{--light:#faf8f8;--dark:#141021;--secondary:#284b63;--tertiary:#84a59d;--visited:#afbfc9;--primary:#f28482;--gray:#4e4e4e;--lightgray:#f0f0f0;--outlinegray:#dadada}[saved-theme=dark]{--light:#1e1e21 !important;--dark:#fbfffe !important;--secondary:#6b879a !important;--visited:#4a575e !important;--tertiary:#84a59d !important;--primary:#f58382 !important;--gray:#d4d4d4 !important;--lightgray:#292633 !important;--outlinegray:#343434 !important}</style><script>const userPref=window.matchMedia('(prefers-color-scheme: light)').matches?'light':'dark',currentTheme=localStorage.getItem('theme')??userPref;currentTheme&&document.documentElement.setAttribute('saved-theme',currentTheme);const switchTheme=a=>{a.target.checked?(document.documentElement.setAttribute('saved-theme','dark'),localStorage.setItem('theme','dark')):(document.documentElement.setAttribute('saved-theme','light'),localStorage.setItem('theme','light'))};window.addEventListener('DOMContentLoaded',()=>{const a=document.querySelector('#darkmode-toggle');a.addEventListener('change',switchTheme,!1),currentTheme==='dark'&&(a.checked=!0)})</script><script>let saved=!1;const fetchData=async()=>{if(saved)return saved;const promises=[fetch("https://carlgogo.github.io/AIDigitalGarden/linkIndex.json").then(a=>a.json()).then(a=>({index:a.index,links:a.links})),fetch("https://carlgogo.github.io/AIDigitalGarden/contentIndex.json").then(a=>a.json())],[{index,links},content]=await Promise.all(promises),res={index,links,content};return saved=res,res};fetchData()</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-S103D50NQ0"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-S103D50NQ0',{anonymize_ip:!1})}</script><script>function htmlToElement(a){const b=document.createElement('template');return a=a.trim(),b.innerHTML=a,b.content.firstChild}const baseUrl="https://carlgogo.github.io/AIDigitalGarden".replace(window.location.origin,"");document.addEventListener("DOMContentLoaded",()=>{fetchData().then(({content:a})=>{const b=[...document.getElementsByClassName("internal-link")];b.forEach(b=>{const c=a[b.dataset.src.replace(baseUrl,"")];if(c){const d=`<div class="popover">
    <h3>${c.title}</h3>
    <p>${removeMarkdown(c.content).split(" ",20).join(" ")}...</p>
    <p class="meta">${new Date(c.lastmodified).toLocaleDateString()}</p>
</div>`,a=htmlToElement(d);b.appendChild(a),b.addEventListener("mouseover",()=>{a.classList.add("visible")}),b.addEventListener("mouseout",()=>{a.classList.remove("visible")})}})})})</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/gh/nextapps-de/flexsearch@0.7.2/dist/flexsearch.bundle.js></script><script>const removeMarkdown=(c,b={listUnicodeChar:!1,stripListLeaders:!0,gfm:!0,useImgAltText:!1,preserveLinks:!1})=>{let a=c||"";a=a.replace(/^(-\s*?|\*\s*?|_\s*?){3,}\s*$/gm,"");try{b.stripListLeaders&&(b.listUnicodeChar?a=a.replace(/^([\s\t]*)([\*\-\+]|\d+\.)\s+/gm,b.listUnicodeChar+" $1"):a=a.replace(/^([\s\t]*)([\*\-\+]|\d+\.)\s+/gm,"$1")),b.gfm&&(a=a.replace(/\n={2,}/g,"\n").replace(/~{3}.*\n/g,"").replace(/~~/g,"").replace(/`{3}.*\n/g,"")),b.preserveLinks&&(a=a.replace(/\[(.*?)\][\[\(](.*?)[\]\)]/g,"$1 ($2)")),a=a.replace(/<[^>]*>/g,"").replace(/^[=\-]{2,}\s*$/g,"").replace(/\[\^.+?\](\: .*?$)?/g,"").replace(/\s{0,2}\[.*?\]: .*?$/g,"").replace(/\!\[(.*?)\][\[\(].*?[\]\)]/g,b.useImgAltText?"$1":"").replace(/\[(.*?)\][\[\(].*?[\]\)]/g,"$1").replace(/^\s{0,3}>\s?/g,"").replace(/(^|\n)\s{0,3}>\s?/g,"\n\n").replace(/^\s{1,2}\[(.*?)\]: (\S+)( ".*?")?\s*$/g,"").replace(/^(\n)?\s{0,}#{1,6}\s+| {0,}(\n)?\s{0,}#{0,} {0,}(\n)?\s{0,}$/gm,"$1$2$3").replace(/([\*_]{1,3})(\S.*?\S{0,1})\1/g,"$2").replace(/([\*_]{1,3})(\S.*?\S{0,1})\1/g,"$2").replace(/(`{3,})(.*?)\1/gm,"$2").replace(/`(.+?)`/g,"$1").replace(/\n{2,}/g,"\n\n")}catch(a){return console.error(a),c}return a}</script><script>async function run(){const g=new FlexSearch.Document({cache:!0,charset:"latin:extra",optimize:!0,worker:!0,document:{index:[{field:"content",tokenize:"strict",context:{resolution:5,depth:3,bidirectional:!0},suggest:!0},{field:"title",tokenize:"forward"}]}}),{content:d}=await fetchData();for(const[b,a]of Object.entries(d))g.add({id:b,title:a.title,content:removeMarkdown(a.content)});const j=(i,j)=>{const a=20,k=j.split(/\s+/).filter(a=>a!==""),b=i.split(/\s+/).filter(a=>a!==""),f=a=>k.some(b=>a.toLowerCase().startsWith(b.toLowerCase())),d=b.map(f);let e=0,g=0;for(let b=0;b<Math.max(d.length-a,0);b++){const f=d.slice(b,b+a),c=f.reduce((a,b)=>a+b,0);c>=e&&(e=c,g=b)}const c=Math.max(g-a,0),h=Math.min(c+2*a,b.length),l=b.slice(c,h).map(a=>{return f(a)?`<span class="search-highlight">${a}</span>`:a}).join(" ").replaceAll('</span> <span class="search-highlight">'," ");return`${c===0?"":"..."}${l}${h===b.length?"":"..."}`},m=({url:b,title:c,content:d,term:a})=>{const e=removeMarkdown(d),f=j(c,a),g=j(e,a);return`<button class="result-card" id="${b}">
        <h3>${f}</h3>
        <p>${g}</p>
    </button>`},h=(a,b)=>{window.location.href="https://carlgogo.github.io/AIDigitalGarden"+`${a}#:~:text=${encodeURIComponent(b)}`},l=a=>({id:a,url:a,title:d[a].title,content:d[a].content}),c=document.getElementById('search-bar'),e=document.getElementById("results-container");let b;c.addEventListener("keyup",a=>{if(a.key==="Enter"){const a=document.getElementsByClassName("result-card")[0];h(a.id,b)}}),c.addEventListener('input',a=>{b=a.target.value,g.search(b,[{field:"content",limit:10,suggest:!0},{field:"title",limit:5}]).then(d=>{const a=b=>{const a=d.filter(a=>a.field===b);return a.length===0?[]:[...a[0].result]},f=new Set([...a('title'),...a('content')]),c=[...f].map(l);if(c.length===0)e.innerHTML=`<button class="result-card">
                    <h3>No results.</h3>
                    <p>Try another search term?</p>
                </button>`;else{e.innerHTML=c.map(a=>m({...a,term:b})).join("\n");const a=document.getElementsByClassName("result-card");[...a].forEach(a=>{a.onclick=()=>h(a.id,b)})}})});const a=document.getElementById("search-container");function f(){a.style.display==="none"||a.style.display===""?(c.value="",e.innerHTML="",a.style.display="block",c.focus()):a.style.display="none"}function i(){a.style.display="none"}document.addEventListener('keydown',a=>{a.key==="/"&&(a.preventDefault(),f()),a.key==="Escape"&&(a.preventDefault(),i())});const k=document.getElementById("search-icon");k.addEventListener('click',a=>{f()}),k.addEventListener('keydown',a=>{f()}),a.addEventListener('click',a=>{i()}),document.getElementById("search-space").addEventListener('click',a=>{a.stopPropagation()})}run()</script><div class=singlePage><header><h1 id=page-title><a href=https://carlgogo.github.io/AIDigitalGarden>ðŸª´ AI and DS Digital Garden</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Deep Learning</h1><p class=meta>Last updated March 7, 2022</p><ul class=tags></ul><aside class=mainTOC><h3>Table of Contents</h3><nav id=TableOfContents><ol><li><a href=#books>Books</a></li><li><a href=#talks>Talks</a></li><li><a href=#courses>Courses</a></li><li><a href=#code>Code</a></li></ol><ol><li><a href=#generalization>Generalization</a></li><li><a href=#regularization>Regularization</a><ol><li><a href=#data-augmentation>Data augmentation</a></li><li><a href=#dropout>Dropout</a></li><li><a href=#normalization>Normalization</a></li></ol></li><li><a href=#activations>Activations</a></li><li><a href=#losscost-functions>Loss/Cost functions</a></li><li><a href=#optimizers-and-backprop>Optimizers and backprop</a></li><li><a href=#efficiency-and-performance>Efficiency and performance</a></li><li><a href=#attention>Attention</a></li><li><a href=#deep-learning-for-multi-dimensional-data>Deep learning for multi-dimensional data</a></li><li><a href=#deep-learning-for-tabular-data>Deep learning for tabular data</a></li></ol><ol><li><a href=#mlps>[[MLPs]]</a></li><li><a href=#deep-belief-network>[[Deep belief network]]</a></li><li><a href=#autoencoders>[[Autoencoders]]</a></li><li><a href=#cnns>[[CNNs]]</a></li><li><a href=#rnns>[[RNNs]]</a></li><li><a href=#capsnets>[[CapsNets]]</a></li><li><a href=#gans>[[GANs]]</a></li><li><a href=#bayesian-neural-networks>[[Bayesian neural networks]]</a></li><li><a href=#gnns>[[GNNs]]</a></li><li><a href=#residual-and-dense-neural-networks>[[Residual and dense neural networks]]</a></li><li><a href=#neural-odes>[[Neural ODEs]]</a></li><li><a href=#fourier-neural-operators>[[Fourier Neural Operators]]</a></li><li><a href=#multimodal-learning>[[Multimodal learning]]</a></li><li><a href=#geometric-deep-learning>[[Geometric deep learning]]</a></li></ol></nav></aside><ul><li>DL is a branch of [[Machine Learning]] and [[AI]] based on a set of algorithms that attempt to model high level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear transformations.</li><li>DL uses huge neural networks with many layers of processing units, taking advantage of advances in computing power and improved training techniques to learn complex patterns in large amounts of data.</li><li><a href=https://github.com/ChristosChristofidis/awesome-deep-learning>https://github.com/ChristosChristofidis/awesome-deep-learning</a></li><li><a href=https://github.com/endymecy/awesome-deeplearning-resources>https://github.com/endymecy/awesome-deeplearning-resources</a></li><li><a href=https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/super-cheatsheet-deep-learning.pdf>https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/super-cheatsheet-deep-learning.pdf</a></li><li><a href=https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/>https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/</a></li><li><a href=https://frnsys.com/ai_notes/machine_learning/neural_nets.html>https://frnsys.com/ai_notes/machine_learning/neural_nets.html</a></li><li><a href=https://hackernoon.com/deep-learning-cheat-sheet-25421411e460>https://hackernoon.com/deep-learning-cheat-sheet-25421411e460</a></li><li><a href=https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/>https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/</a></li><li><a href=http://www.computervisionblog.com/2016/12/nuts-and-bolts-of-building-deep.html>http://www.computervisionblog.com/2016/12/nuts-and-bolts-of-building-deep.html</a></li><li><a href=https://kevinzakka.github.io/2016/09/26/applying-deep-learning/>https://kevinzakka.github.io/2016/09/26/applying-deep-learning/</a></li><li><a href=http://www.deepideas.net/deep-learning-from-scratch-theory-and-implementation/>http://www.deepideas.net/deep-learning-from-scratch-theory-and-implementation/</a></li><li>A Brief History of Neural Nets and Deep Learning (2020): <a href=http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/>http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/</a></li><li>A set of educational DL demos applied to the MNIST dataset: <a href=https://github.com/natbusa/deepnumbers>https://github.com/natbusa/deepnumbers</a></li><li>Time Benchmark of models: <a href=https://dawn.cs.stanford.edu/benchmark/>https://dawn.cs.stanford.edu/benchmark/</a></li><li>Deep learning in NNs: An overview: <a href=https://www.sciencedirect.com/science/article/pii/S0893608014002135>https://www.sciencedirect.com/science/article/pii/S0893608014002135</a></li><li>Deep Learning Research Directions: Computational Efficiency: <a href=http://timdettmers.com/2017/08/31/deep-learning-research-directions/>http://timdettmers.com/2017/08/31/deep-learning-research-directions/</a></li><li>A Recipe for Training Neural Networks: <a href=http://karpathy.github.io/2019/04/25/recipe/>http://karpathy.github.io/2019/04/25/recipe/</a></li><li>When to use deep learning<ul><li>Don&rsquo;t use deep learning your data isn&rsquo;t that big: <a href=https://simplystatistics.org/2017/05/31/deeplearning-vs-leekasso/>https://simplystatistics.org/2017/05/31/deeplearning-vs-leekasso/</a></li><li>You can probably use deep learning even if your data isn&rsquo;t that big: <a href=http://beamandrew.github.io/deeplearning/2017/06/04/deep_learning_works.html>http://beamandrew.github.io/deeplearning/2017/06/04/deep_learning_works.html</a></li><li>When not to use deep learning: <a href=http://hyperparameter.space/blog/when-not-to-use-deep-learning/>http://hyperparameter.space/blog/when-not-to-use-deep-learning/</a></li><li>How can I know if DL works better for a specific problem than SVM or random forest?: <a href=https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md>https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md</a></li><li>Using ANNs on small data â€“ Deep Learning vs. Xgboost: <a href=http://maxberggren.se/2017/06/18/deep-learning-vs-xgboost/>http://maxberggren.se/2017/06/18/deep-learning-vs-xgboost/</a></li><li>The limitations of deep learning: <a href=https://blog.keras.io/the-limitations-of-deep-learning.html>https://blog.keras.io/the-limitations-of-deep-learning.html</a></li></ul></li><li>Literature parsing:<ul><li>DeepAI: <a href=https://deepai.org/>https://deepai.org/</a></li><li>Papers with code: <a href=https://paperswithcode.com/>https://paperswithcode.com/</a></li><li>Deep learning monitor: <a href=https://deeplearn.org/>https://deeplearn.org/</a></li><li>GroundAI: <a href=https://www.groundai.com/>https://www.groundai.com/</a></li><li>#CODE Deep Learning Models (Raschka): <a href=https://github.com/rasbt/deeplearning-models>https://github.com/rasbt/deeplearning-models</a></li><li>#CODE Model Zoo: <a href=https://modelzoo.co/>https://modelzoo.co/</a></li></ul></li></ul><h2 id=books>Books</h2><ul><li>#BOOK Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI (Kashani 2022): <a href=https://arxiv.org/abs/2201.00650>https://arxiv.org/abs/2201.00650</a></li><li>#BOOK Physics-based Deep Learning Book (Thuerey 2021): <a href=https://physicsbaseddeeplearning.org/intro.html>https://physicsbaseddeeplearning.org/intro.html</a> ^PBDL</li><li>#BOOK The Principles of Deep Learning Theory: An Effective Theory Approach to Understanding Neural Networks (Roberts 2022): <a href=https://deeplearningtheory.com/PDLT.pdf>https://deeplearningtheory.com/PDLT.pdf</a><ul><li><a href=https://ai.facebook.com/blog/advancing-ai-theory-with-a-first-principles-understanding-of-deep-neural-networks/>https://ai.facebook.com/blog/advancing-ai-theory-with-a-first-principles-understanding-of-deep-neural-networks/</a></li></ul></li><li>#BOOK Deep Learning Book (Goodfellow, 2016 MIT): <a href=https://www.deeplearningbook.org/>https://www.deeplearningbook.org/</a><ul><li>The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular. The online version of the book is now complete and will remain available online for free.</li></ul></li><li>#BOOK DL tutorial (LISA Lab, U Montreal): <a href=http://deeplearning.net/tutorial/>http://deeplearning.net/tutorial/</a></li><li>#BOOK Neural Networks and Deep Learning: <a href=http://neuralnetworksanddeeplearning.com/index.html>http://neuralnetworksanddeeplearning.com/index.html</a></li><li>Deep Learning: Methods and Applications (Li Deng, 2014 NOW)<ul><li><a href=https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/DeepLearning-NowPublishing-Vol7-SIG-039.pdf>https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/DeepLearning-NowPublishing-Vol7-SIG-039.pdf</a></li></ul></li><li>#BOOK Deep Learning with Python (Chollet, 2021 MANNING)<ul><li><a href=https://www.manning.com/books/deep-learning-with-python-second-edition>https://www.manning.com/books/deep-learning-with-python-second-edition</a></li><li>1st edition: <a href=http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf>http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf</a></li></ul></li><li>#BOOK Machine learning yearning (Andrew Ng, 2018): <a href=http://www.mlyearning.org/>http://www.mlyearning.org/</a><ul><li><a href=https://github.com/ajaymache/machine-learning-yearning>https://github.com/ajaymache/machine-learning-yearning</a></li></ul></li><li>#BOOK Dive into Deep Learning (Zhang): <a href=https://d2l.ai/index.html>https://d2l.ai/index.html</a><ul><li>An interactive deep learning book for students, engineers, and researchers. Uses MXNet/Gluon, Pytorch and Tensorflow</li><li>Jupyter notebooks for each section. <a href=https://en.d2l.ai/d2l-en.zip>https://en.d2l.ai/d2l-en.zip</a></li></ul></li><li>#BOOK Introduccion practica con Keras (Torres 2018): <a href=https://torres.ai/deep-learning-inteligencia-artificial-keras/>https://torres.ai/deep-learning-inteligencia-artificial-keras/</a></li><li>#BOOK Technical Book on Deep Learning: <a href=https://github.com/tomepel/Technical_Book_DL>https://github.com/tomepel/Technical_Book_DL</a></li></ul><h2 id=talks>Talks</h2><ul><li>#TALK Deep Learning (Yoshua Bengio, MLSS 2020):<ul><li>Part I: <a href="https://www.youtube.com/watch?v=c_U4THknoHE">https://www.youtube.com/watch?v=c_U4THknoHE</a></li><li>Part II: <a href="https://www.youtube.com/watch?v=PDPdIDihPvc">https://www.youtube.com/watch?v=PDPdIDihPvc</a></li></ul></li><li>#TALK Deep Learning Hardware: Past, Present, and Future (Yann LeCun, ISSCC 2019): <a href="https://www.youtube.com/watch?v=YzD7Z2yRL7Y">https://www.youtube.com/watch?v=YzD7Z2yRL7Y</a></li><li>#TALK Keras, Deep Learning, and the Progress of AI (FranÃ§ois Chollet, Lex Fridman Podcast, 2019): <a href="https://www.youtube.com/watch?v=Bo8MY4JpiXE">https://www.youtube.com/watch?v=Bo8MY4JpiXE</a></li><li>#TALK Deep Learning and the Future of Artificial Intelligence (Yann LeCun, 2018): <a href="https://www.youtube.com/watch?v=RM-Jtc2ryfM&t=5s">https://www.youtube.com/watch?v=RM-Jtc2ryfM&t=5s</a></li><li>#TALK AI Breakthroughs & Obstacles to Progress, Mathematical and Otherwise (Yann LeCun, 2018): <a href="https://www.youtube.com/watch?v=1_KhJv0Em5Y">https://www.youtube.com/watch?v=1_KhJv0Em5Y</a></li><li>#TALK Power & Limits of Deep Learning (Yann Lecun, 2017): <a href="https://www.youtube.com/watch?v=0tEhw5t6rhc">https://www.youtube.com/watch?v=0tEhw5t6rhc</a></li><li>#TALK The Future of Sparsity in Deep Learning (Trevor Gale, Phd student Stanford, 2021): <a href=https://events.rainfocus.com/widget/nvidia/nvidiagtc/sessioncatalog/session/1631029840983001jvzq>https://events.rainfocus.com/widget/nvidia/nvidiagtc/sessioncatalog/session/1631029840983001jvzq</a></li><li>#TALK The Deep End of Deep Learning (Hugo Larochelle, TEDxBoston 2016): <a href="https://www.youtube.com/watch?v=dz_jeuWx3j0">https://www.youtube.com/watch?v=dz_jeuWx3j0</a></li><li>#TALK How deep neural networks work (Brandon Rohrer): <a href="https://www.youtube.com/watch?v=ILsA4nyG7I0">https://www.youtube.com/watch?v=ILsA4nyG7I0</a><ul><li>Simple explanations of DL basics and nice graphics</li></ul></li></ul><h2 id=courses>Courses</h2><ul><li>#COURSE Introduction to Deep Learning (COMP0090, UCL): <a href=https://github.com/YipengHu/COMP0090>https://github.com/YipengHu/COMP0090</a></li><li>#COURSE Full Stack Deep Learning: <a href=https://fullstackdeeplearning.com/>https://fullstackdeeplearning.com/</a><ul><li>Full Stack Deep Learning - Spring 2021: <a href=https://fullstackdeeplearning.com/spring2021/>https://fullstackdeeplearning.com/spring2021/</a><ul><li>Lecture 13: ML Teams and Startups: <a href=https://fullstackdeeplearning.com/spring2021/lecture-13/>https://fullstackdeeplearning.com/spring2021/lecture-13/</a></li></ul></li><li><a href=https://fall2019.fullstackdeeplearning.com/>https://fall2019.fullstackdeeplearning.com/</a><ul><li><a href=https://github.com/full-stack-deep-learning/course-gitbook>https://github.com/full-stack-deep-learning/course-gitbook</a></li></ul></li></ul></li><li>#COURSE Deep Learning (NYU): <a href=https://atcold.github.io/pytorch-Deep-Learning/>https://atcold.github.io/pytorch-Deep-Learning/</a><ul><li><a href=https://github.com/Atcold/pytorch-Deep-Learning>https://github.com/Atcold/pytorch-Deep-Learning</a> (pytorch)</li></ul></li><li>#COURSE Deep Learning (CS230, Stanford): <a href=http://cs230.stanford.edu/>http://cs230.stanford.edu/</a><ul><li>Cheatsheets: <a href=https://github.com/afshinea/stanford-cs-230-deep-learning>https://github.com/afshinea/stanford-cs-230-deep-learning</a></li></ul></li><li>#COURSE Tensorflow for Deep Learning Research (CS20SI, Stanford): <a href=http://web.stanford.edu/class/cs20si/syllabus.html>http://web.stanford.edu/class/cs20si/syllabus.html</a></li><li>#COURSE DeepMind x UCL | Deep Learning Lecture Series 2020: <a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF">https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF</a></li><li>#COURSE Introduction to Deep Learning (6.S191, MIT): <a href=http://introtodeeplearning.com/>http://introtodeeplearning.com/</a></li><li>#COURSE MIT Deep Learning and Artificial Intelligence Lectures: <a href=https://deeplearning.mit.edu/>https://deeplearning.mit.edu/</a><ul><li>Youtube playlist: <a href="https://www.youtube.com/watch?v=0VH1Lim8gL8&list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf">https://www.youtube.com/watch?v=0VH1Lim8gL8&list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf</a></li><li>Deep Learning State of the Art (2020): <a href="https://www.youtube.com/watch?v=0VH1Lim8gL8">https://www.youtube.com/watch?v=0VH1Lim8gL8</a></li></ul></li><li>#COURSE Introduction to Deep Learning (MIT 6.S191): <a href=http://introtodeeplearning.com/>http://introtodeeplearning.com/</a></li><li>#COURSE Intro to Neural Networks and Machine Learning (CSC 321, UToronto): <a href=http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/>http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/</a></li><li>#COURSE Deep Learning nanodegree (Udacity): <a href=https://www.udacity.com/course/deep-learning-nanodegree--nd101>https://www.udacity.com/course/deep-learning-nanodegree--nd101</a><ul><li><a href=https://github.com/udacity/deep-learning-v2-pytorch>https://github.com/udacity/deep-learning-v2-pytorch</a></li><li><a href=https://www.udacity.com/course/deep-learning-pytorch--ud188>https://www.udacity.com/course/deep-learning-pytorch--ud188</a></li></ul></li><li>#COURSE Deep Learning with PyTorch: Zero to GANs (Jovian): <a href=https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans>https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans</a></li><li>#COURSE Fast AI - Practical Deep Learning For Coders: <a href=http://course.fast.ai/>http://course.fast.ai/</a><ul><li>Deep Learning for Coders with fastai and PyTorch: [[AI]] Applications Without a PhD - the book and the course</li><li><a href=https://github.com/fastai/fastbook>https://github.com/fastai/fastbook</a></li></ul></li><li>#COURSE Deep Learning course (U Paris-Saclay): <a href=https://m2dsupsdlclass.github.io/lectures-labs/>https://m2dsupsdlclass.github.io/lectures-labs/</a></li><li>#COURSE Introduction to Machine Learning and Neural Networks (Uniandes): <a href=https://albahnsen.com/courses/applied-deep-learning/>https://albahnsen.com/courses/applied-deep-learning/</a><ul><li><a href=https://github.com/albahnsen/AppliedDeepLearningClass>https://github.com/albahnsen/AppliedDeepLearningClass</a></li></ul></li><li>#COURSE Deep learning specialization (deeplearning.ai, Coursera, Andrew Ng): <a href=https://www.coursera.org/specializations/deep-learning>https://www.coursera.org/specializations/deep-learning</a><ul><li><a href=https://www.deeplearning.ai/deep-learning-specialization/>https://www.deeplearning.ai/deep-learning-specialization/</a></li></ul></li><li>#COURSE Neural Networks (U Sherbrooke): <a href=http://info.usherbrooke.ca/hlarochelle/neural_networks/description.html>http://info.usherbrooke.ca/hlarochelle/neural_networks/description.html</a></li><li>#COURSE The Neural Aesthetic (ITP-NYU): <a href=http://ml4a.github.io/classes/itp-F18/>http://ml4a.github.io/classes/itp-F18/</a></li></ul><h2 id=code>Code</h2><p>State of ML frameworks:</p><ul><li><p><a href=https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/>https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/</a></p></li><li><p><a href=https://towardsdatascience.com/tensorflow-or-pytorch-146f5397278a>https://towardsdatascience.com/tensorflow-or-pytorch-146f5397278a</a></p></li><li><p>#CODE Tensorflow and Keras. See [[Tensorflow, keras]]</p></li><li><p>#CODE Triton: <a href=https://github.com/openai/triton>https://github.com/openai/triton</a></p><ul><li>language and compiler for writing highly efficient custom Deep-Learning primitives</li><li><a href=https://openai.com/blog/triton/>https://openai.com/blog/triton/</a></li><li><a href=https://www.infoq.com/news/2021/08/openAI-triton/>https://www.infoq.com/news/2021/08/openAI-triton/</a></li><li>Triton uses Python as its base. The developer writes code in Python using Tritonâ€™s libraries, which are then JIT-compiled to run on the GPU. This allows integration with the rest of the Python ecosystem, currently the biggest destination for developing machine-learning solutions</li></ul></li><li><p>#CODE MindSpore (Huawei): <a href=https://github.com/mindspore-ai/mindspore>https://github.com/mindspore-ai/mindspore</a> ^huaweimindpore</p><ul><li><a href=https://towardsdatascience.com/program-your-first-neural-network-with-huawei-mindspore-1fc50023e90d>https://towardsdatascience.com/program-your-first-neural-network-with-huawei-mindspore-1fc50023e90d</a></li><li><a href=https://towardsdatascience.com/huaweis-mindspore-a-new-competitor-for-tensorflow-and-pytorch-d319deff2aec>https://towardsdatascience.com/huaweis-mindspore-a-new-competitor-for-tensorflow-and-pytorch-d319deff2aec</a></li><li><a href=https://www.mindspore.cn/en>https://www.mindspore.cn/en</a></li></ul></li><li><p>#CODE Tensorlayer - Deep Learning and Reinforcement Learning Library for Scientists and Engineers: <a href=https://github.com/tensorlayer/tensorlayer>https://github.com/tensorlayer/tensorlayer</a></p><ul><li><a href=http://tensorlayer.org/>http://tensorlayer.org/</a></li></ul></li><li><p>#CODE Elegy - Neural Networks framework based on Jax and inspired by Keras: <a href=https://github.com/poets-ai/elegy>https://github.com/poets-ai/elegy</a></p><ul><li><a href=https://poets-ai.github.io/elegy/>https://poets-ai.github.io/elegy/</a></li><li>See [[Math and stats#^jax]]</li></ul></li><li><p>#CODE PyTorch (Facebook): Tensors and Dynamic neural networks in Python with strong GPU acceleration. <a href=https://github.com/pytorch/pytorch>https://github.com/pytorch/pytorch</a></p><ul><li><a href=http://pytorch.org>http://pytorch.org</a></li><li><a href=https://sagivtech.com/2017/09/19/optimizing-pytorch-training-code/>https://sagivtech.com/2017/09/19/optimizing-pytorch-training-code/</a></li><li>#CODE Pytorch-lightning: <a href=https://pytorchlightning.ai/>https://pytorchlightning.ai/</a><ul><li><a href=https://medium.com/pytorch/introducing-lightning-flash-the-fastest-way-to-get-started-with-deep-learning-202f196b3b98>https://medium.com/pytorch/introducing-lightning-flash-the-fastest-way-to-get-started-with-deep-learning-202f196b3b98</a></li></ul></li><li>#CODE Pytext (Facebook) - A natural language modeling framework based on PyTorch: <a href=https://github.com/facebookresearch/pytext>https://github.com/facebookresearch/pytext</a><ul><li><a href=https://fb.me/pytextdocs>https://fb.me/pytextdocs</a></li><li>PyText is a deep-learning based [[NLP]] modeling framework built on PyTorch</li></ul></li><li>#CODE Pytorch tabular: <a href=https://github.com/manujosephv/pytorch_tabular>https://github.com/manujosephv/pytorch_tabular</a> ^pytorchtab<ul><li><a href=https://deep-and-shallow.com/2021/01/27/pytorch-tabular-a-framework-for-deep-learning-for-tabular-data/>https://deep-and-shallow.com/2021/01/27/pytorch-tabular-a-framework-for-deep-learning-for-tabular-data/</a></li></ul></li></ul></li><li><p>#CODE Paddle (Baidu)- PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice. <a href=https://github.com/PaddlePaddle/Paddle>https://github.com/PaddlePaddle/Paddle</a></p><ul><li><a href=http://www.paddlepaddle.org/>http://www.paddlepaddle.org/</a></li></ul></li><li><p>#CODE Mxnet (Apache): <a href=https://github.com/apache/incubator-mxnet>https://github.com/apache/incubator-mxnet</a></p><ul><li><a href=http://mxnet.io/>http://mxnet.io/</a></li><li>Towards Next Generation Deep Learning Framework: <a href=https://mli.github.io/cvpr17/>https://mli.github.io/cvpr17/</a></li></ul></li><li><p>#CODE Microsoft Cognitive Toolkit (CNTK): <a href=https://github.com/Microsoft/CNTK>https://github.com/Microsoft/CNTK</a></p><ul><li><a href=https://www.microsoft.com/en-us/research/product/cognitive-toolkit/>https://www.microsoft.com/en-us/research/product/cognitive-toolkit/</a></li><li>Microsoft Cognitive Toolkit: A free, easy-to-use, open-source, commercial-grade toolkit that trains deep learning algorithms to learn like the human brain.</li><li>#TALK <a href="https://www.youtube.com/watch?v=9gDDO5ldT-4&feature=youtu.be">https://www.youtube.com/watch?v=9gDDO5ldT-4&feature=youtu.be</a></li></ul></li><li><p>#CODE Neupy - NeuPy is a Tensorflow based python library for prototyping and building neural networks: <a href=https://github.com/itdxer/neupy>https://github.com/itdxer/neupy</a></p><ul><li><a href=http://neupy.com/pages/home.html>http://neupy.com/pages/home.html</a></li></ul></li><li><p>#CODE Chainer - Chainer is a Python-based deep learning framework aiming at flexibility</p><ul><li><a href=https://github.com/chainer/chainer>https://github.com/chainer/chainer</a></li></ul></li><li><p>#CODE PySyft: <a href=https://github.com/OpenMined/PySyft>https://github.com/OpenMined/PySyft</a></p><ul><li>PySyft is a Python library for secure and private Deep Learning. PySyft decouples private data from model training, using Federated Learning, Differential Privacy, and Encrypted Computation (like Multi-Party Computation (MPC) and Homomorphic Encryption (HE)) within the main Deep Learning frameworks like PyTorch and TensorFlow.</li><li>#PAPER A generic framework for privacy preserving deep learning: <a href=https://arxiv.org/abs/1811.04017>https://arxiv.org/abs/1811.04017</a></li></ul></li></ul><h1 id=references>References</h1><ul><li>#PAPER Deep learning (LeCun 2015): <a href=https://www.nature.com/articles/nature14539>https://www.nature.com/articles/nature14539</a> ^dllecun15<ul><li><a href=https://www.researchgate.net/profile/Y_Bengio/publication/277411157_Deep_Learning/links/55e0cdf908ae2fac471ccf0f/Deep-Learning.pdf>https://www.researchgate.net/profile/Y_Bengio/publication/277411157_Deep_Learning/links/55e0cdf908ae2fac471ccf0f/Deep-Learning.pdf</a></li></ul></li><li>#PAPER Deep Neural Decision Forests (Kontschieder 2016): <a href=https://www.ijcai.org/Proceedings/16/Papers/628.pdf>https://www.ijcai.org/Proceedings/16/Papers/628.pdf</a><ul><li>#CODE <a href=https://keras.io/examples/structured_data/deep_neural_decision_forests/>https://keras.io/examples/structured_data/deep_neural_decision_forests/</a></li></ul></li><li>#PAPER On the Origin of Deep Learning (Wang 2017): <a href=https://arxiv.org/abs/1702.07800v4>https://arxiv.org/abs/1702.07800v4</a></li><li>#PAPER Representation Learning on Large and Small Data (Chou 2017): <a href=https://arxiv.org/abs/1707.09873v1>https://arxiv.org/abs/1707.09873v1</a></li><li>#PAPER Deep Learning in Neural Networks: An Overview (Schmidhuber, 2018): <a href=https://arxiv.org/abs/1404.7828>https://arxiv.org/abs/1404.7828</a></li><li>#PAPER Deep Learning as a Mixed Convex-Combinatorial Optimization Problem (Friesen 2018): <a href=https://arxiv.org/abs/1710.11573>https://arxiv.org/abs/1710.11573</a></li><li>#PAPER Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods (Lucas, 2018): <a href=https://ieeexplore.ieee.org/document/8253590>https://ieeexplore.ieee.org/document/8253590</a><ul><li><a href=http://decsai.ugr.es/vip/files/journals/08253590.pdf>http://decsai.ugr.es/vip/files/journals/08253590.pdf</a></li></ul></li><li>#PAPER Neural Tangent Kernel: Convergence and Generalization in Neural Networks (Jacot 2018): <a href=https://arxiv.org/abs/1806.07572#>https://arxiv.org/abs/1806.07572#</a><ul><li><a href=https://www.quantamagazine.org/a-new-link-to-an-old-model-could-crack-the-mystery-of-deep-learning-20211011/>https://www.quantamagazine.org/a-new-link-to-an-old-model-could-crack-the-mystery-of-deep-learning-20211011/</a></li></ul></li><li>#PAPER A Survey of Deep Learning for Scientific Discovery (Raghu & Schmidt, 2020): <a href=https://arxiv.org/abs/2003.11755>https://arxiv.org/abs/2003.11755</a> ^dlscience20</li><li>#PAPER Neural circuit policies enabling auditable autonomy (Lechner 2020): <a href=https://www.nature.com/articles/s42256-020-00237-3>https://www.nature.com/articles/s42256-020-00237-3</a><ul><li>#CODE <a href=https://github.com/mlech26l/keras-ncp>https://github.com/mlech26l/keras-ncp</a></li><li><a href=https://www.csail.mit.edu/news/new-deep-learning-models-require-fewer-neurons>https://www.csail.mit.edu/news/new-deep-learning-models-require-fewer-neurons</a></li><li><a href=https://www.marktechpost.com/2021/10/19/mit-csail-tu-wien-and-ist-researchers-introduce-deep-learning-models-that-require-fewer-neurons/>https://www.marktechpost.com/2021/10/19/mit-csail-tu-wien-and-ist-researchers-introduce-deep-learning-models-that-require-fewer-neurons/</a></li></ul></li><li>#PAPER Implicitly Defined Layers in Neural Networks (Zhang 2020): <a href=https://arxiv.org/abs/2003.01822>https://arxiv.org/abs/2003.01822</a></li><li>#PAPER A Mathematical Principle of Deep Learning: Learn the Geodesic Curve in the Wasserstein Space (Gai 2021): <a href=https://arxiv.org/abs/2102.09235>https://arxiv.org/abs/2102.09235</a></li><li>#PAPER Why is AI hard and Physics simple? (Roberts 2021): <a href=https://arxiv.org/abs/2104.00008>https://arxiv.org/abs/2104.00008</a></li><li>#PAPER Deep Learning for AI (By Yoshua Bengio, Yann Lecun, Geoffrey Hinton, Turing lecture, 2021): <a href=https://dl.acm.org/doi/10.1145/3448250>https://dl.acm.org/doi/10.1145/3448250</a><ul><li><a href=https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltex>https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltex</a></li></ul></li><li>#PAPER Self-Tuning for Data-Efficient Deep Learning (Wang 2021): <a href=https://arxiv.org/abs/2102.12903>https://arxiv.org/abs/2102.12903</a><ul><li>#CODE <a href=https://github.com/thuml/Self-Tuning>https://github.com/thuml/Self-Tuning</a></li><li>#TALK <a href="https://recorder-v3.slideslive.com/#/share?share=40334&s=f7988e61-bece-4a7a-a6ba-3e1a2b49b37b">https://recorder-v3.slideslive.com/#/share?share=40334&s=f7988e61-bece-4a7a-a6ba-3e1a2b49b37b</a></li></ul></li><li>#PAPER Neural circuit policies enabling auditable autonomy (Lechner 2021): <a href=https://www.nature.com/articles/s42256-020-00237-3>https://www.nature.com/articles/s42256-020-00237-3</a><ul><li>#CODE <a href=https://github.com/mlech26l/keras-ncp>https://github.com/mlech26l/keras-ncp</a></li></ul></li><li>#PAPER Uncertainty Baselines: Benchmarks for Uncertainty & Robustness in Deep Learning (Nado 2021): <a href=https://arxiv.org/abs/2106.04015>https://arxiv.org/abs/2106.04015</a><ul><li><a href=https://ai.googleblog.com/2021/10/baselines-for-uncertainty-and.html>https://ai.googleblog.com/2021/10/baselines-for-uncertainty-and.html</a></li></ul></li></ul><h2 id=generalization>Generalization</h2><p>See [[XAI#Interpretability of deep learning models]]</p><ul><li><p><a href=http://www.inference.vc/everything-that-works-works-because-its-bayesian-2/>http://www.inference.vc/everything-that-works-works-because-its-bayesian-2/</a></p></li><li><p>#PAPER Understanding deep learning requires re-thinking generalization (Zhang 2016): <a href=https://arxiv.org/abs/1611.03530>https://arxiv.org/abs/1611.03530</a></p><ul><li><a href=https://blog.acolyer.org/2017/05/11/understanding-deep-learning-requires-re-thinking-generalization/>https://blog.acolyer.org/2017/05/11/understanding-deep-learning-requires-re-thinking-generalization/</a></li><li><a href=https://www.quora.com/Why-is-the-paper-%E2%80%9CUnderstanding-Deep-Learning-Requires-Rethinking-Generalization%E2%80%9D-important>https://www.quora.com/Why-is-the-paper-%E2%80%9CUnderstanding-Deep-Learning-Requires-Rethinking-Generalization%E2%80%9D-important</a></li></ul></li><li><p>#PAPER A Closer Look at Memorization in Deep Networks (Arpit 2017): <a href=https://arxiv.org/abs/1706.05394>https://arxiv.org/abs/1706.05394</a></p></li><li><p>#PAPER Deep nets donâ€™t learn via memorization (Krueger 2017): <a href="https://openreview.net/pdf?id=rJv6ZgHYg">https://openreview.net/pdf?id=rJv6ZgHYg</a></p></li><li><p>#PAPER Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior (Martin 2017): <a href=https://arxiv.org/abs/1710.09553>https://arxiv.org/abs/1710.09553</a></p></li><li><p>#PAPER Ablation Studies in Artificial Neural Networks (Meyes 2019): <a href=https://arxiv.org/abs/1901.08644>https://arxiv.org/abs/1901.08644</a></p></li><li><p>#PAPER Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning (Allen-Zhu 2020): <a href=https://arxiv.org/abs/2012.09816>https://arxiv.org/abs/2012.09816</a></p><ul><li><a href=https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/>https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/</a></li></ul></li><li><p>#PAPER The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers (Nakkiran 2021): <a href=https://arxiv.org/abs/2010.08127>https://arxiv.org/abs/2010.08127</a></p><ul><li><a href=https://ai.googleblog.com/2021/03/a-new-lens-on-understanding.html>https://ai.googleblog.com/2021/03/a-new-lens-on-understanding.html</a></li></ul></li><li><p>#PAPER Predicting trends in the quality of state-of-the-art neural networks without access to training or testing data (Martin 2021): <a href=https://www.nature.com/articles/s41467-021-24025-8>https://www.nature.com/articles/s41467-021-24025-8</a></p></li><li><p>#PAPER Stochastic Training is Not Necessary for Generalization (Geiping 2021): <a href=https://arxiv.org/abs/2109.14119>https://arxiv.org/abs/2109.14119</a></p></li><li><p>#PAPER Underspecification Presents Challenges for Credibility in Modern Machine Learning (D&rsquo;Amour 2021): <a href=https://arxiv.org/abs/2011.03395>https://arxiv.org/abs/2011.03395</a></p><ul><li><a href=https://ai.googleblog.com/2021/10/how-underspecification-presents.html>https://ai.googleblog.com/2021/10/how-underspecification-presents.html</a></li></ul></li><li><p>#PAPER Grokking - Generatlization beyond overfitting on small algorithmic datasets (Power 2022): <a href=https://arxiv.org/abs/2201.02177v1>https://arxiv.org/abs/2201.02177v1</a></p><ul><li>Paper explained: <a href="https://www.youtube.com/watch?v=dND-7llwrpw">https://www.youtube.com/watch?v=dND-7llwrpw</a></li></ul></li></ul><h2 id=regularization>Regularization</h2><ul><li>In general, techniques aimed at reducing overfitting and improve generalization</li><li>Overfit and underfit: <a href=https://www.tensorflow.org/tutorials/keras/overfit_and_underfit>https://www.tensorflow.org/tutorials/keras/overfit_and_underfit</a></li><li><a href=https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036>https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036</a></li><li><a href=https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/>https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/</a></li><li><a href=https://medium.com/intelligentmachines/convolutional-neural-network-and-regularization-techniques-with-tensorflow-and-keras-5a09e6e65dc7>https://medium.com/intelligentmachines/convolutional-neural-network-and-regularization-techniques-with-tensorflow-and-keras-5a09e6e65dc7</a></li></ul><h3 id=data-augmentation>Data augmentation</h3><ul><li><a href=https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html>https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a></li><li><a href=https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/>https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/</a></li><li>#PAPER A survey on Image Data Augmentation for Deep Learning (Shorten 2019): <a href=https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0>https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0</a></li></ul><h3 id=dropout>Dropout</h3><ul><li><p><a href=http://www.cs.toronto.edu/~hinton/absps/dropout.pdf>http://www.cs.toronto.edu/~hinton/absps/dropout.pdf</a></p></li><li><p><a href=https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/>https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/</a></p></li><li><p>12 Main Dropout Methods: Mathematical and Visual Explanation for DNNs, CNNs, and RNNs: <a href=https://towardsdatascience.com/12-main-dropout-methods-mathematical-and-visual-explanation-58cdc2112293>https://towardsdatascience.com/12-main-dropout-methods-mathematical-and-visual-explanation-58cdc2112293</a></p></li><li><p>#PAPER Dropout: A Simple Way to Prevent Neural Networks from Overfitting (Srivastava 2014): <a href=http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf>http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf</a></p></li><li><p>#PAPER Efficient Object Localization Using Convolutional Networks (Tompson 2015): <a href=https://arxiv.org/abs/1411.4280v3>https://arxiv.org/abs/1411.4280v3</a></p><ul><li>Proposed spatial dropout</li></ul></li><li><p>#PAPER Analysis on the Dropout Effect in Convolutional Neural Networks (Park 2017): <a href=https://link.springer.com/chapter/10.1007/978-3-319-54184-6_12>https://link.springer.com/chapter/10.1007/978-3-319-54184-6_12</a></p><ul><li><a href=http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf>http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf</a></li></ul></li><li><p>#PAPER Effective and Efficient Dropout for Deep Convolutional Neural Networks (Cai 2020): <a href=https://arxiv.org/abs/1904.03392>https://arxiv.org/abs/1904.03392</a></p></li></ul><h3 id=normalization>Normalization</h3><ul><li><p>Normalization techniques also improve generalization error, providing some regularization</p></li><li><p>Normalization Techniques in Deep Neural Networks: <a href=https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8>https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8</a></p></li><li><p>Different Types of Normalization in Tensorflow: <a href=https://towardsdatascience.com/different-types-of-normalization-in-tensorflow-dac60396efb0>https://towardsdatascience.com/different-types-of-normalization-in-tensorflow-dac60396efb0</a></p></li><li><p>Normalization in Deep Learning: <a href=https://arthurdouillard.com/post/normalization/>https://arthurdouillard.com/post/normalization/</a></p></li><li><p><a href=https://sebastianraschka.com/faq/docs/scale-training-test.html>https://sebastianraschka.com/faq/docs/scale-training-test.html</a></p></li><li><p>Data normalization/standardization can be used as an alternative (before training) to synch batchnorm (multi-gpu training)</p></li><li><p>Spectral normalization: <a href=https://sthalles.github.io/advanced_gans/>https://sthalles.github.io/advanced_gans/</a></p></li><li><p>#PAPER Normalization Techniques in Training DNNs: Methodology, Analysis and Application (Huang 2020): <a href=https://arxiv.org/abs/2009.12836>https://arxiv.org/abs/2009.12836</a></p></li></ul><h4 id=batchnorm>BatchNorm</h4><ul><li>#PAPER Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (Ioffe 2015): <a href=https://arxiv.org/abs/1502.03167>https://arxiv.org/abs/1502.03167</a><ul><li>#TALK <a href="https://www.youtube.com/watch?v=ZOabsYbmBRM&feature=youtu.be">https://www.youtube.com/watch?v=ZOabsYbmBRM&feature=youtu.be</a></li><li><a href=http://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras>http://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras</a></li><li>Slower convergence w/o BN, BN can be applied on top of standardization</li><li>Synch BatchNorm appears in TF 2.2, for multi-gpu training<ul><li><a href=https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/SyncBatchNormalization>https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/SyncBatchNormalization</a></li></ul></li></ul></li><li>#PAPER Rethinking the Usage of Batch Normalization and Dropout (Chen 2019): <a href=https://arxiv.org/abs/1905.05928>https://arxiv.org/abs/1905.05928</a></li></ul><h2 id=activations>Activations</h2><ul><li><a href=https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html>https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html</a></li><li><a href=https://mlfromscratch.com/activation-functions-explained/#/>https://mlfromscratch.com/activation-functions-explained/#/</a></li><li>RELU: <a href=https://en.wikipedia.org/wiki/Rectifier_(neural_networks)>https://en.wikipedia.org/wiki/Rectifier_(neural_networks)</a><ul><li><a href=https://www.quora.com/What-is-special-about-rectifier-neural-units-used-in-NN-learning>https://www.quora.com/What-is-special-about-rectifier-neural-units-used-in-NN-learning</a></li></ul></li><li><a href=http://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-network>http://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-network</a></li><li><a href=https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions>https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions</a></li></ul><h2 id=losscost-functions>Loss/Cost functions</h2><ul><li>Cross entropy<ul><li><a href=http://neuralnetworksanddeeplearning.com/chap3.html>http://neuralnetworksanddeeplearning.com/chap3.html</a></li><li><a href=https://en.wikipedia.org/wiki/Cross_entropy>https://en.wikipedia.org/wiki/Cross_entropy</a></li><li><a href=http://www.kdnuggets.com/2017/02/gentlest-introduction-tensorflow-part-4.html>http://www.kdnuggets.com/2017/02/gentlest-introduction-tensorflow-part-4.html</a></li></ul></li><li>Perceptual loss, image reconstruction<ul><li><a href=https://arxiv.org/pdf/1511.06409.pdf>https://arxiv.org/pdf/1511.06409.pdf</a> (Learning to Generate Images With Perceptual Similarity Metrics)</li><li>#PAPER Loss Functions for Image Restoration with Neural Networks (Zhao 2018): <a href=https://arxiv.org/abs/1511.08861>https://arxiv.org/abs/1511.08861</a></li><li><a href=https://medium.com/@sanari85/rediscovery-of-ssim-index-in-image-reconstruction-ssim-as-a-loss-function-a1ffef7d2be>https://medium.com/@sanari85/rediscovery-of-ssim-index-in-image-reconstruction-ssim-as-a-loss-function-a1ffef7d2be</a><ul><li>We use three different metric for comparing each different methods such as DSSIM, MSE, and MAE. Structural dissimilarity(DSSIM)[14] is an image distance metric, that corresponds better to the human perception than MAE or RMSE. MeanSquared Error(MSE) measures the average of the squares of the errors that is, the average squared difference between the estimated values and the actual value. Mean AbsoluteError (MAE) is the average distance between each pixel point. <a href=https://arxiv.org/pdf/2001.05372.pdf>https://arxiv.org/pdf/2001.05372.pdf</a></li></ul></li></ul></li><li>Deep learning image enhancement insights on loss function engineering: <a href=https://towardsdatascience.com/deep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7>https://towardsdatascience.com/deep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7</a></li><li>Mean squared logarithmic error<ul><li><a href=https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)>https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)</a></li><li><a href=https://medium.com/@olegrybkin_20684/the-reasonable-ineffectiveness-of-mse-pixel-loss-for-future-prediction-and-what-to-do-about-it-4dca8152355d>https://medium.com/@olegrybkin_20684/the-reasonable-ineffectiveness-of-mse-pixel-loss-for-future-prediction-and-what-to-do-about-it-4dca8152355d</a></li></ul></li></ul><h2 id=optimizers-and-backprop>Optimizers and backprop</h2><ul><li><p>How to use Learning Curves to Diagnose Machine Learning Model Performance: <a href=https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/>https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/</a></p></li><li><p><a href=https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent>https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent</a></p></li><li><p>Keras optimizers: <a href=https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/>https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/</a></p></li><li><p>Adam: <a href=http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/>http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/</a></p></li><li><p>An overview of gradient descent optimization algorithms (2016): <a href=https://ruder.io/optimizing-gradient-descent/index.html#otherrecentoptimizers>https://ruder.io/optimizing-gradient-descent/index.html#otherrecentoptimizers</a></p></li><li><p><a href=https://hackernoon.com/some-state-of-the-art-optimizers-in-neural-networks-a3c2ba5a5643>https://hackernoon.com/some-state-of-the-art-optimizers-in-neural-networks-a3c2ba5a5643</a></p></li><li><p><a href=https://www.jeremyjordan.me/neural-networks-training/>https://www.jeremyjordan.me/neural-networks-training/</a></p></li><li><p><a href=http://colah.github.io/posts/2015-08-Backprop/>http://colah.github.io/posts/2015-08-Backprop/</a></p></li><li><p>Back-propagation - Math Simplified. <a href=https://github.com/DebPanigrahi/Machine-Learning/blob/master/back_prop.ipynb>https://github.com/DebPanigrahi/Machine-Learning/blob/master/back_prop.ipynb</a></p></li><li><p><a href=https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/>https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/</a></p></li><li><p><a href=https://venturebeat.com/2020/12/16/at-neurips-2020-researchers-proposed-faster-more-efficient-alternatives-to-backpropagation/amp/>https://venturebeat.com/2020/12/16/at-neurips-2020-researchers-proposed-faster-more-efficient-alternatives-to-backpropagation/amp/</a></p></li><li><p>#PAPER On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima (Shirish Keshkar 2017): <a href=https://arxiv.org/abs/1609.04836>https://arxiv.org/abs/1609.04836</a></p></li><li><p>#PAPER Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour (Goyal 2018): <a href=https://arxiv.org/abs/1706.02677>https://arxiv.org/abs/1706.02677</a></p></li><li><p>#PAPER Decoupled Weight Decay Regularization (Loshchilov 2018): <a href=https://arxiv.org/abs/1711.05101>https://arxiv.org/abs/1711.05101</a></p><ul><li>AdamW optimizer</li><li>#CODE <a href=https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/AdamW>https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/AdamW</a></li><li><a href=https://www.fast.ai/2018/07/02/adam-weight-decay/>https://www.fast.ai/2018/07/02/adam-weight-decay/</a></li></ul></li><li><p>#PAPER Deep Double Descent: Where Bigger Models and More Data Hurt (Nakkiran 2019): <a href=https://arxiv.org/abs/1912.02292>https://arxiv.org/abs/1912.02292</a></p><ul><li><a href=https://openai.com/blog/deep-double-descent/>https://openai.com/blog/deep-double-descent/</a></li><li><a href=https://medium.com/mlearning-ai/double-descent-8f92dfdc442f>https://medium.com/mlearning-ai/double-descent-8f92dfdc442f</a></li></ul></li><li><p>#PAPER Reconciling modern machine learning practice and the bias-variance trade-off (Belkin 2019): <a href=https://arxiv.org/abs/1812.11118>https://arxiv.org/abs/1812.11118</a></p><ul><li>Paper explained: <a href="https://www.youtube.com/watch?v=ZAW9EyNo2fw">https://www.youtube.com/watch?v=ZAW9EyNo2fw</a></li></ul></li><li><p>#PAPER Deep Double Descent: Where Bigger Models and More Data Hurt (Nakkiran 2020): <a href=https://arxiv.org/abs/1912.02292>https://arxiv.org/abs/1912.02292</a></p><ul><li><a href=https://openai.com/blog/deep-double-descent/>https://openai.com/blog/deep-double-descent/</a></li></ul></li><li><p>#PAPER Descending through a Crowded Valley &ndash; Benchmarking Deep Learning Optimizers (Schmidt 2020): <a href=https://arxiv.org/abs/2007.01547>https://arxiv.org/abs/2007.01547</a></p><ul><li>Paper explained: <a href="https://www.youtube.com/watch?v=DiNzQP7kK-s">https://www.youtube.com/watch?v=DiNzQP7kK-s</a></li></ul></li><li><p>#PAPER Early Stopping in Deep Networks: Double Descent and How to Eliminate it (Heckel 2020): <a href=https://arxiv.org/abs/2007.10099>https://arxiv.org/abs/2007.10099</a></p><ul><li>contrary to model-wise double descent, epoch-wise double descent is not a phenomena tied o over-parameterization</li><li>both under- and overparameterized models can have epoch-wise double descent</li><li>#CODE <a href=https://github.com/MLI-lab/early_stopping_double_descent>https://github.com/MLI-lab/early_stopping_double_descent</a></li></ul></li></ul><h2 id=efficiency-and-performance>Efficiency and performance</h2><ul><li>#PAPER Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better (Menghani 2021): <a href=https://arxiv.org/abs/2106.08962>https://arxiv.org/abs/2106.08962</a><ul><li><a href=https://analyticsindiamag.com/how-to-build-smaller-faster-better-deep-learning-models/>https://analyticsindiamag.com/how-to-build-smaller-faster-better-deep-learning-models/</a></li></ul></li></ul><h2 id=attention>Attention</h2><p>See:
[[Transformers#For NLP]]
[[CNNs#Visual attention]]</p><ul><li>#COURSE Attention and Memory in Deep Learning (DeepMind x UCL | Deep Learning Lectures | 8/12): <a href="https://www.youtube.com/watch?v=AIiwuClvH6k">https://www.youtube.com/watch?v=AIiwuClvH6k</a></li></ul><h2 id=deep-learning-for-multi-dimensional-data>Deep learning for multi-dimensional data</h2><p>See:
[[CNNs#Video segmentation and prediction]]
[[Encoder-decoder networks]]
[[Transformers]]
[[Generative modelling]]</p><ul><li>#PAPER Demystifying Deep Learning in Predictive Spatio-Temporal Analytics: An Information-Theoretic Framework (Tan 2020): <a href=https://arxiv.org/abs/2009.06304>https://arxiv.org/abs/2009.06304</a></li></ul><h2 id=deep-learning-for-tabular-data>Deep learning for tabular data</h2><ul><li><p>An Introduction to Deep Learning for Tabular Data: <a href=https://www.fast.ai/2018/04/29/categorical-embeddings/>https://www.fast.ai/2018/04/29/categorical-embeddings/</a></p></li><li><p>Applying Deep Learning on Tabular Data Using TensorFlow 2.0: <a href=https://pdf.co/blog/deep-learning-on-tabular-data-using-tensorflow-20>https://pdf.co/blog/deep-learning-on-tabular-data-using-tensorflow-20</a></p></li><li><p>#CODE [[#^pytorchtab]]</p></li><li><p>#PAPER Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data (Popov 2019): <a href=https://arxiv.org/abs/1909.06312>https://arxiv.org/abs/1909.06312</a></p></li><li><p>#PAPER TabNet: Attentive Interpretable Tabular Learning (Arik 2020): <a href=https://arxiv.org/abs/1908.07442>https://arxiv.org/abs/1908.07442</a></p></li><li><p>#PAPER Converting tabular data into images for deep learning with convolutional neural networks (Zhu 2021): <a href=https://www.nature.com/articles/s41598-021-90923-y>https://www.nature.com/articles/s41598-021-90923-y</a></p></li><li><p>#PAPER Tabular Data: Deep Learning is Not All You Need (Shwartz-Ziv 2021): <a href=https://arxiv.org/abs/2106.03253>https://arxiv.org/abs/2106.03253</a></p></li><li><p>#PAPER XBNet : An Extremely Boosted Neural Network (Sarkar 2021): <a href=https://arxiv.org/abs/2106.05239>https://arxiv.org/abs/2106.05239</a></p><ul><li>#CODE XBNet: <a href=https://github.com/tusharsarkar3/XBNet>https://github.com/tusharsarkar3/XBNet</a></li><li>Boosted neural network for tabular data</li><li><a href=https://analyticsindiamag.com/guide-to-xbnet-an-extremely-boosted-neural-network/>https://analyticsindiamag.com/guide-to-xbnet-an-extremely-boosted-neural-network/</a></li></ul></li><li><p>#PAPER Revisiting Deep Learning Models for Tabular Data (Gorishniy 2021): <a href=https://arxiv.org/abs/2106.11959>https://arxiv.org/abs/2106.11959</a></p><ul><li>#CODE RDTL (Yandex): <a href=https://github.com/yandex-research/rtdl>https://github.com/yandex-research/rtdl</a></li><li><a href=https://yandex-research.github.io/rtdl/>https://yandex-research.github.io/rtdl/</a></li></ul></li><li><p>#PAPER TABBIE: Pretrained Representations of Tabular Data (Lida 2021): <a href=https://arxiv.org/abs/2105.02584v1>https://arxiv.org/abs/2105.02584v1</a></p></li></ul><h1 id=architectures-and-types-of-models>Architectures and types of models</h1><ul><li>The neural network zoo: <a href=http://www.asimovinstitute.org/neural-network-zoo/>http://www.asimovinstitute.org/neural-network-zoo/</a></li><li>Deep Learning Tips and Tricks cheatsheet: <a href=https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks>https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks</a></li><li>A Visual and Interactive Guide to the Basics of NNs: <a href=https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/>https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/</a></li><li>A Visual And Interactive Look at Basic Neural Network Math: <a href=https://jalammar.github.io/feedforward-neural-networks-visual-interactive/>https://jalammar.github.io/feedforward-neural-networks-visual-interactive/</a></li></ul><h2 id=mlps>[[MLPs]]</h2><h2 id=deep-belief-network>[[Deep belief network]]</h2><h2 id=autoencoders>[[Autoencoders]]</h2><h2 id=cnns>[[CNNs]]</h2><h2 id=rnns>[[RNNs]]</h2><h2 id=capsnets>[[CapsNets]]</h2><h2 id=gans>[[GANs]]</h2><h2 id=bayesian-neural-networks>[[Bayesian neural networks]]</h2><h2 id=gnns>[[GNNs]]</h2><h2 id=residual-and-dense-neural-networks>[[Residual and dense neural networks]]</h2><h2 id=neural-odes>[[Neural ODEs]]</h2><h2 id=fourier-neural-operators>[[Fourier Neural Operators]]</h2><h2 id=multimodal-learning>[[Multimodal learning]]</h2><h2 id=geometric-deep-learning>[[Geometric deep learning]]</h2></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script>async function run(){const{index:a,links:p,content:u}=await fetchData(),j="https://carlgogo.github.io/AIDigitalGarden/AI/Deep-learning/Deep-learning".replace("https://carlgogo.github.io/AIDigitalGarden",""),n=[{"/moc":"#4388cc"}];let h=-1;const m=a=>[...new Set(a.flatMap(a=>[a.source,a.target]))],e=new Set,f=[j||"/","__SENTINEL"];if(h>=0)while(h>=0&&f.length>0){const b=f.shift();if(b==="__SENTINEL")h--,f.push("__SENTINEL");else{e.add(b);const c=a.links[b]||[],d=a.backlinks[b]||[];f.push(...c.map(a=>a.target),...d.map(a=>a.source))}}else m(p).forEach(a=>e.add(a));const g={nodes:[...e].map(a=>({id:a})),links:p.filter(a=>e.has(a.source)&&e.has(a.target))},k=a=>{if(a.id===j||a.id==="/"&&j==="")return"var(--g-node-active)";for(const b of n){const c=Object.keys(b)[0],d=b[c];if(a.id.startsWith(c))return d}return"var(--g-node)"},l=c=>{function d(b,a){b.active||c.alphaTarget(1).restart(),a.fx=a.x,a.fy=a.y}function e(a,b){b.fx=a.x,b.fy=a.y}function f(b,a){b.active||c.alphaTarget(0),a.fx=null,a.fy=null}const a=!0,b=()=>{};return d3.drag().on("start",a?d:b).on("drag",a?e:b).on("end",a?f:b)},c=250,b=document.getElementById("graph-container").offsetWidth,i=d3.forceSimulation(g.nodes).force("charge",d3.forceManyBody().strength(-30)).force("link",d3.forceLink(g.links).id(a=>a.id)).force("center",d3.forceCenter()),d=d3.select('#graph-container').append('svg').attr('width',b).attr('height',c).attr("viewBox",[-b/2,-c/2,b,c]),t=!1;if(t){const a=[{Current:"var(--g-node-active)"},{Note:"var(--g-node)"},...n];a.forEach((a,e)=>{const f=Object.keys(a)[0],g=a[f];d.append("circle").attr("cx",-b/2+20).attr("cy",c/2-30*(e+1)).attr("r",6).style("fill",g),d.append("text").attr("x",-b/2+40).attr("y",c/2-30*(e+1)).text(f).style("font-size","15px").attr("alignment-baseline","middle")})}const r=d.append("g").selectAll("line").data(g.links).join("line").attr("class","link").attr("stroke","var(--g-link)").attr("stroke-width",2).attr("data-source",a=>a.source.id).attr("data-target",a=>a.target.id),s=d.append("g").selectAll("g").data(g.nodes).enter().append("g"),q=s.append("circle").attr("class","node").attr("id",a=>a.id).attr("r",b=>{const c=a.links[b.id]?.length||0,d=a.backlinks[b.id]?.length||0;return 3+(c+d)/4}).attr("fill",k).style("cursor","pointer").on("click",(b,a)=>{window.location.href="https://carlgogo.github.io/AIDigitalGarden"+decodeURI(a.id).replace(/\s+/g,'-')}).on("mouseover",function(g,b){d3.selectAll(".node").transition().duration(100).attr("fill","var(--g-node-inactive)");const d=m([...a.links[b.id]||[],...a.backlinks[b.id]||[]]),e=d3.selectAll(".node").filter(a=>d.includes(a.id)),c=b.id,f=d3.selectAll(".link").filter(a=>a.source.id===c||a.target.id===c);e.transition().duration(200).attr("fill",k),f.transition().duration(200).attr("stroke","var(--g-link-active)"),d3.select(this.parentNode).select("text").raise().transition().duration(200).style("opacity",1)}).on("mouseleave",function(d,b){d3.selectAll(".node").transition().duration(200).attr("fill",k);const a=b.id,c=d3.selectAll(".link").filter(b=>b.source.id===a||b.target.id===a);c.transition().duration(200).attr("stroke","var(--g-link)"),d3.select(this.parentNode).select("text").transition().duration(200).style("opacity",0)}).call(l(i)),o=s.append("text").attr("dx",12).attr("dy",".35em").text(a=>u[decodeURI(a.id).replace(/\s+/g,'-')]?.title||"Untitled").style("opacity",0).style("pointer-events","none").call(l(i)),v=!0;v&&d.call(d3.zoom().extent([[0,0],[b,c]]).scaleExtent([.25,4]).on("zoom",({transform:a})=>{r.attr("transform",a),q.attr("transform",a),o.attr("transform",a)})),i.on("tick",()=>{r.attr("x1",a=>a.source.x).attr("y1",a=>a.source.y).attr("x2",a=>a.target.x).attr("y2",a=>a.target.y),q.attr("cx",a=>a.x).attr("cy",a=>a.y),o.attr("x",a=>a.x).attr("y",a=>a.y)})}run()</script></div></div><div id=contact_buttons><footer><p>Made by Carlos Alberto Gomez Gonzalez using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2022</p><a href=/>Home</a>
<a href=https://carlgogo.github.io>Website</a><a href=https://github.com/carlgogo>Github</a></footer></div></div></body></html>