{
  "/": {
    "title": "AI Digital Garden 🤖🪴",
    "content": "Welcome to my Artificial Intelligence (AI) digital garden, a collection of research notes that I started to complie years ago as my best attempt to become a somewhat functional _information junkie_. In this digital garden, I curate, organize and catalog what I read on my day-to-day life as a researcher in AI and Machine Learning (ML) applied to Earth Sciences. Keeping up with the literature related to AI and ML is ~~impossible~~ quite hard and, although tools like the [Deep Learning Monitor](https://deeplearn.org/) might be of help, the [FOMO](https://en.wikipedia.org/wiki/Fear_of_missing_out) is unavoidable.  \n\nThe concept of a digital garden has been around for quite some time, please [check this great post](https://maggieappleton.com/garden-history) if you want a brief history of digital gardens. The idea of a digital garden is close to that of the [Zettelkasten](https://en.wikipedia.org/wiki/Zettelkasten) note-taking system, or personal knowledge management or building a [second brain](https://fortelabs.co/blog/basboverview/). In short, it is something in between a blog and a wiki; a way to accumulate personal knowledge over time in an explorable space and in a non-linear fashion, while benefiting from fancy features like (bidirectional) links between different topics, and visual graphs and mind maps. There are many tools and workflows you could use to grow your digital garden; [check out this repository](https://github.com/MaggieAppleton/digital-gardeners) full of resources for aspiring gardeners. I personally use two amazing tools: [Obsidian](https://obsidian.md/), for offline management of my garden (in the form of local markdown notes), and [Quartz](https://quartz.jzhao.xyz/) for publishing/sharing its content (the GitHub pages website you are currently visiting). \n\nAs said before, this digital garden is centered around AI but it is [not meant to be a complete](https://nick.groenen.me/notes/digital-garden-notes-may-be-incomplete/) or exhaustive mapping of all the knowledge around AI or ML. It is also not aimed at teaching you anything or to be pedagogical. These are merely my personal research notes, the topics that I have been interested in or that I have come across in my work. Expect broken links and all sort of bugs and errors. That said, feel free to look around, check out the [full list of notes](/AI/), or to use the mind map for an interactive view of the entries of the garden. \n\nMost notes are focused on specific topics (e.g., [Clustering](AI/Unsupervised%20learning/Clustering.md)) but some are broader [maps of content](https://jing.io/garden/MOC/) (e.g., [Deep Learning](AI/Deep%20Learning/Deep%20Learning.md)). The notes are made of common subsections with entries having common tags (e.g., #PAPER or #COURSE):\n\n- Resources: definitions, wikipedia entries, blog posts, non-peer-reviewed articles and other useful resources.\n- Books: well... books (mostly free or open source).\n- Talks: talks, video summaries and video podcasts.\n- Courses: online and free/open courses mostly by recognized universities and institutions.\n- References: peer-review publications and papers.\n- Code: open source code and useful libraries.\n\nThese are some maps of content or important pages you may want to start from:\n\n- [AI](AI/AI.md)\n- [Deep Learning](AI/Deep%20Learning/Deep%20Learning.md)\n- [Machine Learning](AI/Machine%20Learning.md) \n- [Data Science](AI/Data%20Science,%20Data%20Engineering/Data%20Science.md)\n\nI hope you find something useful in this digital garden. Enjoy and use at your own risk!",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/AI": {
    "title": "Artificial Intelligence",
    "content": "## Resources\n- The expression _artificial intelligence_ is an umbrella term encompassing a suite of technologies that can perform complex tasks when acting in conditions of uncertainty, including visual perception, speech recognition, natural language processing, reasoning, learning from data, and a range of optimisation problems.\n- https://en.wikipedia.org/wiki/Artificial_intelligence\n- https://github.com/owainlewis/awesome-artificial-intelligence\n- https://github.com/faktionai/awesome-ai-usecases\n- https://atozofai.withgoogle.com/\n- Francois Chollet - Intelligence and Generalisation (Interview/podcast): https://www.youtube.com/watch?v=J0p_thJJnoo\n- People + AI guidebook (Google): https://pair.withgoogle.com/guidebook/patterns \n- General AI Challenge: https://www.general-ai-challenge.org/\n- AI Index (Stanford): https://aiindex.stanford.edu/report/ \n\t- https://github.com/aimacode\n- AI Playbook: http://aiplaybook.a16z.com/\n- What’s the Difference Between AI, ML, and [[Deep Learning]]?: https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/\n- The current state of machine intelligence 3.0: https://www.oreilly.com/ideas/the-current-state-of-machine-intelligence-3-0\n- The AI takeover is coming. Let's embrace it: https://www.wired.com/2016/12/the-ai-takeover-is-coming-lets-embrace-it/\n- What worries me about AI: https://medium.com/@francois.chollet/what-worries-me-about-ai-ed9df072b704\n- Machine Learning Confronts the Elephant in the Room: https://www.quantamagazine.org/machine-learning-confronts-the-elephant-in-the-room-20180920/\n- AI Experiments: https://aiexperiments.withgoogle.com/ \n- Where will AGI come from? (Karpathy): https://ivenzor.com/wp-content/uploads/2018/07/yconftalk-170902200916.pdf\n- AlphaGo Zero: https://deepmind.com/blog/alphago-zero-learning-scratch/\n\t- https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0\n\n### AI in Science and research\n- The AI revolution in science: applications and new research directions: https://blogs.royalsociety.org/in-verba/2019/08/07/the-ai-revolution-in-science-applications-and-new-research-directions/\n- The AI revolution in scientific research (The Royal Society, The Alan Turing Institute): https://royalsociety.org/-/media/policy/projects/ai-and-society/AI-revolution-in-science.pdf\n- The AI revolution in science: https://www.sciencemag.org/news/2017/07/ai-revolution-science\n- Artificial intelligence in research (Musib 2017): https://science.sciencemag.org/content/357/6346/28\n\n## Events\n- Neural Information Processing Systems Conference (NeurIPS): https://nips.cc/\n\t- Proceedings: http://papers.nips.cc/\n\t- Videos: https://nips.cc/Conferences/2018/Videos\n- International Conference on Machine Learning (ICML): https://icml.cc/\n- International Conference for Learning Representations (ICLR): https://iclr.cc/\n- AI \u0026 Deep Learning Conference (NVIDIA): https://www.nvidia.com/en-us/gtc/\n- AAAI Conference on Artificial Intelligence: http://www.aaai.org/Conferences/conferences.php\n- World summit AI: https://worldsummit.ai/\n\n## References\n- #PAPER The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence (Marcus 2020): https://arxiv.org/abs/2002.06177v3\n\t- https://www.zdnet.com/article/rebooting-ai-deep-learning-meet-knowledge-graphs/\n\t- #TALK AI DEBATE : Yoshua Bengio | Gary Marcus: https://www.youtube.com/watch?v=EeqwFjqFvJA\n\n## Books\n- #BOOK AI Transformation Playbook (Andrew Ng, 2018): https://landing.ai/ai-transformation-playbook/\n- #BOOK The Future of Machine Intelligence (Beyer 2016, O'REILLY): https://www.oreilly.com/library/view/the-future-of/9781492042334/\n- #BOOK Artificial Intelligence - A Modern Approach (Russell \u0026 Norvig, 2010): http://aima.cs.berkeley.edu/\n\t- https://github.com/aimacode\n\t- Javascript visualization (and implementation) of algorithms: http://aimacode.github.io/aima-javascript/\n\n## Courses\n- #COURSE Artificial Intelligence (edX - U Columbia): https://www.edx.org/course/artificial-intelligence-ai-columbiax-csmm-101x-0\n- #COURSE Introduction to Artificial Intelligence (CS 188, Berkeley): https://inst.eecs.berkeley.edu/~cs188/fa18/\n- #COURSE Intro to AI (CS188 , UC Berkeley): http://ai.berkeley.edu/home.html, \n\t- http://ai.berkeley.edu/lecture_videos.html\n- #COURSE Introduction to Artificial Intelligence (ULiege): https://github.com/glouppe/info8006-introduction-to-ai\n- #COURSE Artificial General Intelligence (MIT 6.S099): https://agi.mit.edu/\n- #COURSE Artificial General (MINES Saint-Etienne): https://www.emse.fr/~picard/cours/ai/\n- #COURSE Artificial Intelligence Nanodegree (Udacity): https://www.udacity.com/course/artificial-intelligence-nanodegree--nd889\n- #COURSE Self-Driving Car Engineer (Udacity): https://www.udacity.com/drive\n\t- https://github.com/udacity/self-driving-car\n\t- https://github.com/udacity/self-driving-car-sim\n\t- https://github.com/jessicayung/self-driving-car-nd\n\t- https://github.com/Everhusk/Self-Driving-Car-Engineering\n- #COURSE Deep Learning for Self-Driving Cars (MIT 6.S094): http://selfdrivingcars.mit.edu/\n- #TALK MIT Artificial Intelligence Podcast. https://agi.mit.edu\n- #TALK Building machines that see, learn, and think like people (Tenenbaum): https://www.youtube.com/watch?v=7ROelYvo8f0\n- #TALK The Rise of Artificial Intelligence through Deep Learning (Bengio): https://www.youtube.com/watch?v=uawLjkSI7Mo\n- #TALK Creating human-level AI (Bengio): https://www.youtube.com/watch?v=ZHYXp3gJCaI\n- #TALK A DARPA Perspective on Artificial Intelligence: https://www.youtube.com/watch?time_continue=2\u0026v=-O01G3tSYpU\n- #TALK AI, Deep Learning, and Machine Learning: A Primer. https://a16z.com/2016/06/10/ai-deep-learning-machines/ \n- #TALK Symbolic, Statistical and Causal Artificial Intelligence, MLSS 2020: https://www.youtube.com/watch?v=8staJlMbAig\n\n\n## Related fields and concepts\n\n### Math and Statistics\nSee [Math and Statistics](AI/Math%20and%20Statistics/Math%20and%20Statistics.md)\n\n### Data engineering and computer science\nSee [Data engineering and computer science](AI/Data%20Science,%20Data%20Engineering/Data%20engineering%20and%20computer%20science.md)\n\n### Data Science\nSee [Data Science](AI/Data%20Science,%20Data%20Engineering/Data%20Science.md)\n\n### Machine Learning\nSee [Machine Learning](AI/Machine%20Learning.md)\n\n### Computer vision\nSee [Computer vision](AI/Computer%20Vision/Computer%20vision.md)\n\n### NLP\nSee [NLP](AI/NLP.md)\n\n### Deep Learning\nSee [Deep learning](AI/Deep%20learning/Deep%20learning.md)\n\n### Causality\nSee [Causality](AI/Causality.md)\n\n### Problem Solving and Search\nSee [Problem Solving and Search](AI/Problem%20Solving%20and%20Search.md)\n\n### Automated planning\nSee [Automated planning](AI/Automated%20planning.md)",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Active-learning": {
    "title": "Active learning",
    "content": "## Resources\n* https://en.wikipedia.org/wiki/Active_learning_(machine_learning)\n* Active learning refers to algorithms that take an active role in the selection of which ex-amples are labeled. Active learning assumes that there is an ‘oracle’, such as a human expert, that can be queried to get ground-truth labels for selected unlabeled instances. \n* There are situations in which unlabeled data is abundant but manually labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning. With this approach, there is a risk that the algorithm be overwhelmed by uninformative examples.\n- Overview of Active Learning for Deep Learning: https://jacobgil.github.io/deeplearning/activelearning\n- #PAPER An open source machine learning framework for efficient and transparent systematic reviews (van de Schoot 2021): https://www.nature.com/articles/s42256-020-00287-7\n\t- #CODE https://github.com/asreview/asreview\n\n## References\n- #PAPER Active learning literature survey (Settles 2010): http://burrsettles.com/pub/settles.activelearning.pdf\n- #PAPER Active Learning for Convolutional Neural Networks: A Core-Set Approach (2018): https://openreview.net/forum?id=H1aIuk-RW\n- #PAPER Rethinking deep active learning: Using unlabeled data at model training (Simeoni 2019): https://arxiv.org/abs/1911.08177\n- #PAPER Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds (2020): https://openreview.net/forum?id=ryghZJBKPS \n\n\n### Active learning for anomaly discovery\n- #PAPER Incorporating Expert Feedback into Active Anomaly Discovery (Das 2016): https://ieeexplore.ieee.org/document/7837915\n\t- http://web.engr.oregonstate.edu/~tgd/publications/das-wong-dietterich-fern-emmott-incorporating-expert-feedback-into-active-anomaly-discovery-icdm2016.pdf\n- #PAPER Deep Active Learning for Anomaly Detection (Pimentel 2018): https://arxiv.org/abs/1805.09411",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Anomaly-and-Outlier-Detection": {
    "title": "Anomaly and Outlier Detection",
    "content": "See [Active learning for anomaly discovery](AI/Active%20learning.md#Active%20learning%20for%20anomaly%20discovery)\n\n## Resources\n- Most of the outlier detection approaches belong to [Unsupervised learning](Unsupervised%20learning.md) although it might be framed as a [Semi-supervised learning](Semi-supervised%20learning.md) problem. In data mining, anomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data. Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.\n- https://towardsdatascience.com/density-based-algorithm-for-outlier-detection-8f278d2f7983 \n- https://towardsdatascience.com/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561 \n- Novelty and Outlier Detection: https://scikit-learn.org/stable/modules/outlier_detection.html\n- Comparing anomaly detection algorithms for outlier detection on toy datasets: https://scikit-learn.org/stable/auto_examples/plot_anomaly_comparison.html\n- #TALK Anomaly detection with TensorFlow (VAEs): https://www.youtube.com/watch?v=2K3ScZp1dXQ\n- Local outlier factor: https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py\n- One-class SVM\n\t- https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/one-class-support-vector-machine\n\t- https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py\n  - Z-score\n\t- The z-score or standard score of an observation is a metric that indicates how many standard deviations a data point is from the sample’s mean, assuming a gaussian distribution. This makes z-score a parametric method. \n\t- Z-score is a simple, yet powerful method to get rid of outliers in data if you are dealing with parametric distributions in a low dimensional feature space. For nonparametric problems Dbscan and Isolation Forests can be good solutions.\n- Dbscan\n\t- Density Based Spatial Clustering of Applications with Noise\n\t- Dbscan is a density based clustering algorithm, it is focused on finding neighbors by density (MinPts) on an ‘n-dimensional sphere’ with radius ɛ. A cluster can be defined as the maximal set of 'density connected points' in the feature space.\n\t- Dbscan then defines different classes of points: core, border and outlier points.\n\n  \n## Code\n- #CODE Pyod: https://github.com/yzhao062/pyod\n\t- https://pyod.readthedocs.io/en/latest/\n\t- PyOD is a comprehensive and scalable Python toolkit for detecting outlying objects in multivariate data. This exciting yet challenging field is commonly referred as Outlier Detection or Anomaly Detection.\n - #CODE Anomaly detection (Twitter, for R): https://github.com/twitter/AnomalyDetection\n  \n  \n## References\n- #PAPER Isolation forest (Liu 2008): https://ieeexplore.ieee.org/document/4781136 \n\t- #TALK Unsupervised Anomaly Detection with Isolation Forest - Pydata 2018: https://www.youtube.com/watch?v=5p8B2Ikcw-k\n\t- https://quantdare.com/isolation-forest-algorithm/\n\t- https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py\n\t- https://towardsdatascience.com/outlier-detection-with-isolation-forest-3d190448d45e\n\t- Isolation forest’s basic principle is that outliers are few and far from the rest of the observations. To build a tree (training), the algorithm randomly picks a feature from the feature space and a random split value ranging between the maximums and minimums. This is made for all the observations in the training set. To build the forest a tree ensemble is made averaging all the trees in the forest.\n    - Then for prediction, it compares an observation against that splitting value in a “node”, that node will have two node children on which another random comparisons will be made. The number of “splittings” made by the algorithm for an instance is named: “path length”. As expected, outliers will have shorter path lengths than the rest of the observations.\n- #PAPER Modeling Extreme Events in Time Series Prediction (Ding 2019): http://staff.ustc.edu.cn/~hexn/papers/kdd19-timeseries.pdf\n- #PAPER Bayesian Anomaly Detection and Classification (2019): https://arxiv.org/abs/1902.08627  \n\n\n### DL-based\nSee [GANs for anomaly detection](AI/Deep%20learning/GANs.md#GANs%20for%20anomaly%20detection)\n\n- #PAPER Learning Deep Features for One-Class Classification (Perera 2018): https://arxiv.org/abs/1801.05365\n- #PAPER Deep One-Class Classification (Ruff 2018): http://proceedings.mlr.press/v80/ruff18a.html\n\n#### Code\n- #CODE Anomalib: https://github.com/openvinotoolkit/anomalib\n\t- An anomaly detection library comprising state-of-the-art algorithms and features such as experiment management, hyper-parameter optimization, and edge inference\n\t- https://openvinotoolkit.github.io/anomalib/\n\t- Anomalib is a deep learning library that aims to collect state-of-the-art anomaly detection algorithms for benchmarking on both public and private datasets\n- #CODE Orion - A machine learning library for detecting anomalies in signals: https://github.com/signals-dev/Orion ^oriontfanomalies\n\t- https://signals-dev.github.io/Orion/",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/AutoML": {
    "title": "AutoML",
    "content": "See [Model selection and tuning](Model%20selection%20and%20tuning.md)\n\n## Resources\n- https://en.wikipedia.org/wiki/Automated_machine_learning\n- Automated machine learning (AutoML) is the process of automating the process of applying machine learning to real-world problems. AutoML covers the complete pipeline from the raw dataset to the deployable machine learning model. AutoML was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine learning.\n- Automated machine learning can target various stages of the machine learning process. Steps to automate are:\n\t- Data preparation and ingestion (from raw data and miscellaneous formats)\n\t\t- Column type detection; e.g., boolean, discrete numerical, continuous numerical, or text\n\t\t- Column intent detection; e.g., target/label, stratification field, numerical feature, categorical text feature, or free text feature\n\t\t- Task detection; e.g., binary classification, regression, clustering, or ranking\n\t- Feature engineering\n\t\t- Feature selection\n\t\t- Feature extraction\n\t\t- Meta learning and transfer learning\n\t\t- Detection and handling of skewed data and/or missing values\n\t- Model selection. See [Model selection and tuning](Model%20selection%20and%20tuning.md)\n\t- Hyperparameter optimization of the learning algorithm and featurization\n\t- Pipeline selection under time, memory, and complexity constraints\n\t- Selection of evaluation metrics and validation procedures\n\t- Problem checking\n\t\t- Leakage detection\n\t\t- Misconfiguration detection\n\t- Analysis of results obtained\n\t- User interfaces and visualizations for automated machine learning\n- https://www.automl.org/\n- http://www.kdnuggets.com/2017/01/current-state-automated-machine-learning.html\n- https://medium.com/airbnb-engineering/automated-machine-learning-a-paradigm-shift-that-accelerates-data-scientist-productivity-airbnb-f1f8a10d61f8\n\n\n## Books\n-  #BOOK AutoML: Methods, systems, challenges: https://www.automl.org/book/\n\n\n## Code\n- #CODE FLAML - Fast and Lightweight AutoML: https://github.com/microsoft/FLAML\n\t- FLAML is powered by a new, cost-effective hyperparameter optimization and learner selection method invented by Microsoft Research\n- #CODE EvalML - AutoML library written in python: https://github.com/alteryx/evalml\n\t- https://innovation.alteryx.com/introducing-evalml/\n- #CODE Model Search: https://github.com/google/model_search\n\t- https://ai.googleblog.com/2021/02/introducing-model-search-open-source.html\n- #CODE Auto-sklearn: https://github.com/automl/auto-sklearn\n\t- http://automl.github.io/auto-sklearn/stable/\n\t- Efficient and Robust Automated Machine Learning (Feurer 2015): https://ml.informatik.uni-freiburg.de/papers/15-NIPS-auto-sklearn-preprint.pdf\n\t- http://www.kdnuggets.com/2016/08/winning-automl-challenge-auto-sklearn.html\n- #CODE TPOT: https://github.com/rhiever/tpot\n\t- http://rhiever.github.io/tpot/\n\t- Consider TPOT yourData Science Assistant. TPOT is a Python tool that automatically creates and optimizes ML pipelines using genetic programming\n\t- https://blog.alookanalytics.com/2017/05/25/automate-your-machine-learning/\n- #CODE AutoKeras: https://github.com/keras-team/autokeras\n- #CODE H2O autoML: https://blog.h2o.ai/2017/06/automatic-machine-learning/\n- #CODE Adanet - Fast and flexible AutoML with learning guarantees: https://github.com/tensorflow/adanet \n\t- https://adanet.readthedocs.io\n\t- AdaNet is a lightweight TensorFlow-based framework for automatically learning high-quality models with minimal expert intervention\n- #CODE FEDOT: https://github.com/nccr-itmo/FEDOT\n\t- Automated modeling and machine learning framework\n\t- https://fedot.readthedocs.io/en/latest/\n\n\n## Neural architecture search (NAS)\n- NAS is closely related to hyperparameter optimization and is a subfield of automated machine learning (AutoML).\n- https://en.wikipedia.org/wiki/Neural_architecture_search\n\t- Neural architecture search (NAS) is a technique for automating the design of artificial neural networks (ANN), a widely used model in the field of machine learning. NAS has been used to design networks that are on par or outperform hand-designed architectures. Methods for NAS can be categorized according to the search space, search strategy and performance estimation strategy used:\n\t- The search space defines the type(s) of ANN that can be designed and optimized.\n\t- The search strategy defines the approach used to explore the search space.\n\t- The performance estimation strategy evaluates the performance of a possible ANN from its design (without constructing and training it).\n\n- Literature on NAS: https://www.automl.org/automl/literature-on-neural-architecture-search/\n- #PAPER AdaNet: Adaptive Structural Learning of Artificial Neural Networks (Cortes 2017): http://proceedings.mlr.press/v70/cortes17a.html\n\t- https://ai.googleblog.com/2018/10/introducing-adanet-fast-and-flexible.html?m=1\n- #PAPER Improving Neural Architecture Search Image Classifiers via Ensemble Learning, AdaNas (Macko 2019): https://arxiv.org/abs/1903.06236\n- #PAPER Up to two billion times acceleration of scientific simulations with deep neural architecture search (Kasim 2020): https://arxiv.org/abs/2001.08055\n- #PAPER Neural Architecture Search without Training (Mellor 2020): https://arxiv.org/abs/2006.04647\n\t- Paper explained: https://www.youtube.com/watch?v=a6v92P0EbJc\n- #PAPER Automated Evolutionary Approach for the Design of Composite Machine Learning Pipelines (Nikitin 2021): https://arxiv.org/abs/2106.15397",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Automated-planning": {
    "title": "Automated planning",
    "content": "## Resources\n- AI Planning is a branch of artificial intelligence that concerns the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles. Unlike classical control and classification problems, the solutions are complex and must be discovered and optimized in multidimensional space.\n- A brief overview of AI planning: https://users.aalto.fi/~rintanj1/jussi/planning.html\n- Planning: \n\t- https://www.emse.fr/~picard/cours/ai/chapter-planning-intro.pdf\n\t- https://www.emse.fr/~picard/cours/ai/chapter-planning-space.pdf",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Bayesian-modelling": {
    "title": "Bayesian modelling",
    "content": "See: \n[Monte Carlo methods](AI/Math%20and%20Statistics/Monte%20Carlo%20methods.md)\n[Bayesian neural networks](AI/Deep%20learning/Bayesian%20neural%20networks.md)\n\n\n## Resources\n- https://en.wikipedia.org/wiki/Bayesian_statistics\n- https://en.wikipedia.org/wiki/Bayesian_inference\n- http://brohrer.github.io/how_bayesian_inference_works.html\n- http://willwolf.io/en/2017/02/07/bayesian-inference-via-simulated-annealing/\n- #TALK Bayesian Inference, Shakir Mohamed, MLSS 2020:\n\t- Part I:  https://www.youtube.com/watch?v=x4Y90zPjbq0\n\t- Part II: https://www.youtube.com/watch?v=x4Y90zPjbq0\u0026feature=youtu.be\n\n### Bayesian vs frequentist discussion\n- http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/\n- http://www.fharrell.com/2017/02/my-journey-from-frequentist-to-bayesian.html\n- https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/\n- https://aeon.co/essays/it-s-time-for-science-to-abandon-the-term-statistically-significant\n- http://www.fharrell.com/2017/02/a-litany-of-problems-with-p-values.html?m=1\n\n### Bayes theorem\n- http://blogs.scientificamerican.com/cross-check/bayes-s-theorem-what-s-the-big-deal/\n- http://www.analyticsvidhya.com/blog/2016/06/bayesian-statistics-beginners-simple-english/\n\n### MAP\n- https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation\n- In Bayesian statistics, a maximum a posteriori probability(MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data.It is closely related toFisher's method of maximum likelihood(ML) estimation, but employs an augmented optimization objective which incorporates a prior distribution(that quantifies the additional information available through prior knowledge of a related event) over the quantity one wants to estimate. MAP estimation can therefore be seen as a regularization of ML estimation.\n\n### MLE\n- https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\n- Maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters. MLE can be seen as a special case of the maximum a posteriori estimation (MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized.\n\n### Bayesian network\n- https://en.wikipedia.org/wiki/Bayesian_network\n\n### Variational Bayesian methods\n- See [Normalizing flows](AI/Deep%20learning/Normalizing%20flows.md)\n- Variational Bayesian inference with normalizing flows: a simple example: https://towardsdatascience.com/variational-bayesian-inference-with-normalizing-flows-a-simple-example-1db109d91062\n\t- #CODE https://github.com/fraseriainlewis/towardsdatascience\n\n### MCMC\nSee [Monte Carlo methods#MCMC](AI/Math%20and%20Statistics/Monte%20Carlo%20methods.md#MCMC)\n\n\n## Code\n- #CODE Stan: https://github.com/stan-dev/stan\n\t- http://mc-stan.org\n- #CODE Pymc3 - Probabilistic Programming in Python: http://pymc-devs.github.io/pymc3/\n- #CODE Arviz - Exploratory analysis of Bayesian models with Python: https://arviz-devs.github.io/arviz/\n- #CODE BayesicFitting - A package for model fitting and bayesian evidence calculation: https://github.com/dokester/BayesicFitting\n\n\n## Books\n- #BOOK Think Bayes - Bayesian Statistics Made Simple (Downey 2012): http://greenteapress.com/wp/think-bayes/\n\t- Think Bayes is an introduction to Bayesian statistics using computational methods\n- #BOOK Probabilistic programming and bayesian methods for hackers: http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/\n\t- https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers\n- #BOOK Bayesian Modeling and Computation in Python (Martin 2021, CRC): https://bayesiancomputationbook.com/welcome.html\n\n\n## References\n- #PAPER Bayesian model selection for complex dynamic systems (Mark 2018): https://www.nature.com/articles/s41467-018-04241-5 ^1ef748",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Causality": {
    "title": "Causality",
    "content": "## Resources\n- To Build Truly Intelligent Machines, Teach Them Cause and Effect: https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/\n- Representing uncertain knowledge: https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture5.md\n- Reasoning over time: https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture7.md\n- Making decisions: https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture8.md\n- Causal Analysis Introduction - Examples in Python and PyMC: https://engl.is/causal-analysis-introduction-examples-in-python-and-pymc.html\n- Granger causality: \n\t- https://en.wikipedia.org/wiki/Granger_causality\n\t- The Granger causality test is a statistical hypothesis test for determining whether one time series is useful in forecasting another, first proposed in 1969\n\t- Granger causality is a fundamental technique for causal inference in time series data, commonly used in the social and biological sciences\n- PCMCI:\n\t- https://jakobrunge.github.io/tigramite/#tigramite-pcmci-pcmci\n\t- PCMCI causal discovery for time series datasets. It is a 2-step causal discovery method for large-scale time series datasets. The first step is a condition-selection followed by the MCI conditional independence test.\n\n- #TALK Interview - Causal Reasoning, Counterfactuals, and the Path to AGI (Judea Pearl): https://www.youtube.com/watch?v=pEBI0vF45ic\n- #TALK Causality, Bernhard Schölkopf and Stefan Bauer, MLSS 2020: \n\t- Part I: https://www.youtube.com/watch?v=btmJtThWmhA\u0026feature=youtu.be\n\t\t- https://drive.google.com/file/d/1qlUYuU7wfoD6C8Qo0x4Eyz5aT2k0B_jC/view\n\t- Part II: https://www.youtube.com/watch?v=9DJWJpn0DmU\u0026feature=youtu.be\n\t\t- https://drive.google.com/file/d/1_-bUoyY-Thfqu1ac4EwBSv6cCoS-qtnn/view\n\n\n## Code\n- #CODE Causality - Tools for causal analysis: https://github.com/akelleh/causality\n\t- https://medium.com/@akelleh/causal-inference-with-pandas-dataframes-fc3e64fce5d\n- #CODE CausalImpact (for R): https://google.github.io/CausalImpact/\n- #CODE tfcausalimpact - Google's Causal Impact Algorithm Implemented on Top of TensorFlow Probability: https://github.com/WillianFuks/tfcausalimpact\n\t- https://towardsdatascience.com/implementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126\n\n  \n## References\n- #PAPER Causal inference with multiple time series: principles and problems (2013): https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0613\n- #PAPER Towards a Learning Theory of Cause-Effect Inference (Lopez-Paz 2015): https://arxiv.org/abs/1502.02398\n- #PAPER Unsupervised Discovery of El Nino Using Causal Feature Learning on Microlevel Climate Data (Chalupka 2016): https://arxiv.org/abs/1605.09370\n- #PAPER Comparative Benchmarking of Causal Discovery Techniques (Singh 2017): https://arxiv.org/abs/1708.06246\n- #PAPER A Physics-Based Approach to Unsupervised Discovery of Coherent Structures in Spatiotemporal Systems (Rupe 2017): https://arxiv.org/abs/1709.03184 ^rupe17\n- #PAPER A Primer on Causal Analysis (2018): https://arxiv.org/abs/1806.01488\n- #PAPER DAGs with NO TEARS: Continuous Optimization for Structure Learning (Zheng 2018): https://arxiv.org/abs/1803.01422\n\t- #CODE https://github.com/xunzheng/notears\n- #PAPER Local causal states and discrete coherent structures (Rupe 2018): https://aip.scitation.org/doi/10.1063/1.5021130 ^f00b92\n\t- see [[#^rupe17]]\n- #PAPER Learning Functional Causal Models with Generative Neural Networks (Goudet 2018): https://arxiv.org/abs/1709.05321\n- #PAPER Variable-lag Granger Causality for Time Series Analysis (2019): https://arxiv.org/abs/1912.10829\n- #PAPER Learning Sparse Nonparametric DAGs (Zheng 2020): https://arxiv.org/abs/1909.13189\n\t- #CODE https://github.com/xunzheng/notears\n\t- #CODE https://github.com/jmoss20/notears\n- #PAPER When causal inference meets deep learning (Luo 2020): https://www.nature.com/articles/s42256-020-0218-x\n\t- Learning causal relations, rather than correlations, is a fundamental problem in both statistical [[Machine Learning]] and computer sciences\n\t- Bayesian networks (BNs) can capture causal relations, but learning such a network from data is NP-hard\n\t- Recent work has made it possible to approximate this problem as a continuous optimization task that can be solved efficiently with well-established numerical techniques\n\t- BNs encode the conditional independencies between variables using directed acyclic graphs (DAGs)\n- #PAPER Spacetime Autoencoders Using Local Causal States (Rupe 2020): https://arxiv.org/abs/2010.05451\n\t- #CODE https://github.com/adamrupe/spacetime_autoencoders\n\t- Local causal states are latent representations that capture organized pattern and structure in complex spatiotemporal systems\n\t- We expand their functionality, framing them as space-time autoencoders\n- #PAPER Algorithms for Causal Reasoning in Probability Trees (Genewein 2020): https://arxiv.org/abs/2010.12237\n\t- #CODE https://github.com/deepmind/deepmind-research/tree/master/causal_reasoning\n\t- https://syncedreview.com/2020/10/29/deepmind-introduces-algorithms-for-causal-reasoning-in-probability-trees/\n- #PAPER Off-the-shelf deep learning is not enough, and requires parsimony, Bayesianity, and causality (Vasudevan 2021): https://www.nature.com/articles/s41524-020-00487-0",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Background-subtraction": {
    "title": "Background subtraction",
    "content": "---\n\n## Resources\n- https://en.wikipedia.org/wiki/Foreground_detection\n- https://github.com/murari023/awesome-background-subtraction\n- Foreground detection is one of the major tasks in the field of computer vision and image processing whose aim is to detect changes in image sequences. \n- Background subtraction is any technique which allows an image's foreground to be extracted for further processing (object recognition etc.).\n- Background Subtraction Website (T. Bouwmans): https://sites.google.com/site/thierrybouwmans/background-subtraction",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Computer-vision": {
    "title": "Computer Vision",
    "content": "See \n[CNNs](AI/Deep%20learning/CNNs.md)\n[MLPs#MLPs for vision and language](AI/Deep%20learning/MLPs.md#MLPs%20for%20vision%20and%20language)\n[Transformers#For Computer Vision](AI/Deep%20learning/Transformers.md#For%20Computer%20Vision.md)\n[Generative modelling#Generative models for Image data](AI/Deep%20learning/Generative%20modelling.md#Generative%20models%20for%20Image%20data)\n[GANs](AI/Deep%20learning/GANs.md)\n\n\n## Resources\n- https://github.com/jbhuang0604/awesome-computer-vision\n- Papers with code - computer vision: https://paperswithcode.com/area/computer-vision\n\n## Books\n- #BOOK Image Processing and Acquisition using Python (Chityala 2014): https://www.crcpress.com/Image-Processing-and-Acquisition-using-Python/Chityala-Pudipeddi/p/book/9781466583757\n- #BOOK Computer Vision: A Modern Approach (Forsyth, 2011 PEARSON): https://www.pearson.com/us/higher-education/program/Forsyth-Computer-Vision-A-Modern-Approach-2nd-Edition/PGM111082.html\n\t- https://github.com/yihui-he/computer-vision-tutorial/blob/master/Computer%20Vision%20A%20Modern%20Approach%202nd%20Edition.pdf\n- #BOOK Computer Vision: Models, Learning, and Inference (Prince, 2012 CAMBRIDGE): http://www.computervisionmodels.com/\n- #BOOK Computer vision (chapter): https://d2l.ai/chapter_computer-vision/index.html\n\n## Courses\n- #COURSE Computer vision (CS543/ECE549, UIUC): https://courses.engr.illinois.edu/cs543/sp2015/\n- #COURSE Advances in Computer vision (MIT): http://6.869.csail.mit.edu/fa18/\n- #COURSE Introduction to computer vision (Udacity, Georgia Tech): https://www.udacity.com/course/introduction-to-computer-vision--ud810\n- #COURSE [Deep Learning](AI/Deep%20learning/Deep%20Learning.md) for Computer Vision (UPC TelecomBCN 2016): http://imatge-upc.github.io/telecombcn-2016-dlcv/\n- #COURSE Convolutional Neural Networks for Visual Recognition (CS231n, Stanford): http://cs231n.github.io/\n\t- Pre-version of the course: http://karpathy.github.io/neuralnets/\n\t- Notes (Karpathy): http://cs231n.github.io/\n\t- Videos for each lecture: https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC\n- #COURSE Computer vision (NYU): https://cs.nyu.edu/~fergus/teaching/vision/\n- #COURSE Digital image processing (U Tartu): https://sisu.ut.ee/dev/imageprocessing/avaleht\n- #COURSE Convolutional Neural Networks for Image Recognition (DeepMind x UCL | Deep Learning Lectures)\n\t- https://www.youtube.com/watch?v=shVKhOmT0HE\u0026list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\u0026index=3\u0026t=1s\n\t- https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L3%20-%20UUCLxDeepMind%20DL2020.pdf\n- #COURSE Advanced Models for Computer Vision (DeepMind x UCL | Deep Learning Lectures)\n\t- https://www.youtube.com/watch?v=_aUq7lmMfxo\u0026list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\u0026index=4\n\t- https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L4%20-%20UCLxDeepMind%20DL2020.pdf\n\n\n## Code\n- #CODE Scikit-image. Image processing in Python: https://github.com/scikit-image/scikit-image\n\t- http://scikit-image.org\n- #CODE OpenCV (Open Source Computer Vision Library): https://opencv.org/\n\t- OpenCV is released under a BSD license and hence it’s free for both academic and commercial use. It has C++, Python and Java interfaces and supports Windows, Linux, Mac OS, iOS and Android. OpenCV was designed for computational efficiency and with a strong focus on real-time applications. Written in optimized C/C++, the library can take advantage of multi-core processing. Enabled with OpenCL, it can take advantage of the hardware acceleration of the underlying heterogeneous compute platform.\n\t- https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV\n- #CODE SimpleCV: https://github.com/sightmachine/SimpleCV\n\t- http://simplecv.org/\n\t- SimpleCV is an open source framework for building computer vision applications. With it, you get access to several high-powered computer vision libraries such as OpenCV – without having to first learn about bit depths, file formats, color spaces, buffer management, eigenvalues, or matrix versus bitmap storage. This is computer vision made easy.\n- #CODE Imgaug. Image augmentation for machine learning experiments: https://github.com/aleju/imgaug\n\t- http://imgaug.readthedocs.io\n- #CODE ChainerCV: a Library for Computer Vision in Deep Learning: https://github.com/chainer/chainercv\n\t\t- http://chainercv.readthedocs.io/en/stable/\n\t\t- ChainerCV is a collection of tools to train and run neural networks for computer vision tasks using Chainer\n- #CODE Openface. Free and open source face recognition with deep neural networks. https://cmusatyalab.github.io/openface/\n- #CODE Vision - The torchvision package consists of popular datasets, model architectures, and common image transformations fo CV. \n\t- https://github.com/pytorch/vision\n- #CODE Scenic: https://github.com/google-research/scenic\n\t- https://www.marktechpost.com/2021/10/30/google-research-introduces-scenic-an-open-source-jax-library-for-computer-vision-research/\n\t- A Jax Library for Computer Vision Research and Beyond\n\t- codebase with a focus on research around attention-based models for computer vision\n\n\n## References\n### Deep learning-based CV\nSee: \n[CNNs](AI/Deep%20learning/CNNs.md)\n[GANs](AI/Deep%20learning/GANs.md)\n[Normalizing flows](AI/Deep%20learning/Normalizing%20flows.md)\n[Transformers#For Computer Vision](AI/Deep%20learning/Transformers.md#For%20Computer%20Vision)\n\n- [Deep Learning](AI/Deep%20learning/Deep%20Learning.md) is used in the domain of digital image processing to solve difficult problems (e.g.image colourization, classification, segmentation and  detection). DL methods such as [CNNs](AI/Deep%20learning/CNNs.md) mostly improve  prediction performance using big  data and plentiful computing resources and have pushed the boundaries of what was possible. Problems which were assumed to be unsolvable are now being solved with super-human accuracy. Image classification is a prime example of this. Since being reignited by Krizhevsky, Sutskever and Hinton in 2012, DL has dominated the domain ever since due to a substantially better performance compared to traditional methods.\n- https://github.com/kjw0612/awesome-deep-vision\n- https://github.com/timzhang642/3D-Machine-Learning\n- https://medium.com/@taposhdr/medical-image-analysis-with-deep-learning-i-23d518abf531\n- http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/\n\n- #PAPER Deep Learning for Computer Vision: A Brief Review (Voulodimos 2017): https://www.hindawi.com/journals/cin/2018/7068349/\n- #PAPER Deep Learning vs. Traditional Computer Vision (O'Mahony 2019): https://arxiv.org/abs/1910.13796\n- #PAPER Deep learning encodes robust discriminative neuroimaging representations to outperform standard machine learning (Abrol 2021): https://www.nature.com/articles/s41467-020-20655-6\n- #PAPER Deep learning-enabled medical computer vision (Esteva 2021): https://www.nature.com/articles/s41746-020-00376-2\n- #PAPER Involution: Inverting the Inherence of Convolution for Visual Recognition, a brand new neural operator (Li 2021): https://arxiv.org/abs/2103.06255\n\t- #CODE https://github.com/d-li14/involution\n\t- Paper explained: https://www.youtube.com/watch?v=pH2jZun8MoY\u0026list=WL\u0026index=27\u0026t=641s\n\t- involution is a general-purpose neural primitive that is versatile for a spectrum of deep learning models on different vision tasks\n\t- involution bridges convolution and self-attention in design, while being more efficient and effective than convolution, simpler than self-attention in form\n\t- the proposed involution operator could be leveraged as fundamental bricks to build the new generation of neural networks for visual recognition, powering different deep learning models on several prevalent benchmarks\n- #PAPER Unifying Nonlocal Blocks for Neural Networks (Zhu 2021): https://arxiv.org/abs/2108.02451v3\n\t- #CODE https://github.com/zh460045050/SNL_ICCV2021\n\n\n### Traditional CV techniques\n\n#### Background subtraction\nSee [Background subtraction](AI/Computer%20Vision/Background%20subtraction.md)\n\n#### Geometric transformations\n- https://en.wikipedia.org/wiki/Geometric_transformation\n- https://www.graphicsmill.com/docs/gm/affine-and-projective-transformations.htm\n- https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html\n- http://eeweb.poly.edu/~yao/EL5123/lecture12_ImageWarping.pdf\n\n##### Affine transformations \n- https://en.wikipedia.org/wiki/Affine_transformation\n- Affine transformations are combinations of linear transformations and translations. Properties of affine transformations:\n- Lines map to lines\n- Parallel lines remain parallel\n- Ratios are preserved\n- Closed under composition\n\n##### Projective transformations \n- https://en.wikipedia.org/wiki/Projective_transformation\n- Projective transformations are combos of Affine transformations, and projective warps. Properties of projective transformations:\n- Lines map to lines\n- Parallel lines do not necessarily remain parallel\n- Ratios are not preserved\n- Closed under composition\n- Models change of basis\n- Projective matrix is defined up to a scale (8 DOF)\n\n\n#### Filtering\n- For each pixel we compute a function of local neighborhood and output a new value. Use cases:\n- Enhance images: Denoise, smooth, increase contrast, etc.\n- Extract information from images: Texture, edges, distinctive points, etc.\n- Detect patterns: Template matching\n\nhttps://dsp.stackexchange.com/questions/12684/difference-between-correlation-and-convolution-on-an-image\n\n##### Spatial domain\n- Linear filtering: function is a weighted sum/difference of pixel values (dot products at each position).\n- Convolution and kernels: https://en.wikipedia.org/wiki/Kernel_(image_processing)\n- Kernels visualization: http://setosa.io/ev/image-kernels/\n- http://scikit-image.org/docs/dev/api/skimage.filters.html\n- Examples:\n\t- Box filter. Replaces each pixel with an average of its neighborhood (smoothing effect). https://en.wikipedia.org/wiki/Box_blur\n\t- Sharpening filter. Accentuates differences with local average. \n\t\t- http://northstar-www.dartmouth.edu/doc/idl/html_6.2/Sharpening_an_Image.html\n\t\t- https://en.wikipedia.org/wiki/Box_blur\n\t- Sobel filter. This filter is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. \n\t\t- http://aishack.in/tutorials/sobel-laplacian-edge-detectors/\n\t\t- https://en.wikipedia.org/wiki/Sobel_operator\n\t- Gaussian filter. Smoothing. Remove “high-frequency” components from the image (low-pass filter). https://en.wikipedia.org/wiki/Gaussian_filter\n\t- Median filter. Non linear filter for image smoothing. Robustness to outliers. https://en.wikipedia.org/wiki/Median_filter\n\t- Bilateral filter. A bilateral filter is a non-linear, edge-preserving, and noise-reducing smoothing filter for images. It replaces the intensity of each pixel with a weighted average of intensity values from nearby pixels. https://en.wikipedia.org/wiki/Bilateral_filter\n\t- Laplacian filter. Filtering with a Laplacian operator: \n\t\t- http://aishack.in/tutorials/sobel-laplacian-edge-detectors/\n\t\t- https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.html\n\t\t```\n\t\t  0\t\t1\t\t0\n\t\t  1 \t-4\t\t1\n\t\t  0 \t1\t\t0\n\t\t ```\n  \n##### Frequency domain\n- Fourier transform stores the magnitude and phase at each frequency. The magnitude encodes how much signal there is at a particular frequency whiel the phase encodes spatial information (indirectly). \n- The Convolution Theorem:\n\t- The Fourier transform of the convolution of two functions is the product of their Fourier transforms\n\t- The inverse Fourier transform of the product of two Fourier transforms is the convolution of the two inverse Fourier transforms\n\t- Convolutionin spatial domain is equivalent to multiplicationin frequency domain\n\n\n#### Template matching\n- https://en.wikipedia.org/wiki/Template_matching\n\n##### Template based\n- http://aishack.in/tutorials/template-matching/\n- For templates without strong features, or for when the bulk of the template image constitutes the matching image, a template-based approach may be effective.\n- Cross-correlation. Linear filtering: function is a weighted sum/difference of pixel values (dot products at each position)\n\t- https://en.wikipedia.org/wiki/Cross-correlation\n\t- Convolution and kernels: https://en.wikipedia.org/wiki/Kernel_(image_processing)\n\t- Kernels visualization: http://setosa.io/ev/image-kernels/\n- Using image pyramids: https://en.wikipedia.org/wiki/Pyramid_(image_processing)\n\n\n##### Feature based\n- Feature-based approach relies on the extraction of image features such, i.e. shapes, textures , colors, to match in the target image or frame. This approach is currently achieved by using Neural Networks and [Deep Learning](AI/Deep%20learning/Deep%20Learning.md) classifiers such as VGG, AlexNet, ResNet. Deep Convolutional Neural Networks process the image by passing it through different hidden layers and at each layer produce a vector with classification information about the image. These vectors are extracted from the network and are used as the features of the image. Feature extraction by using Deep Neural Networks is extremely effective and thus is the standard in state of the art template matching algorithms.\n- This method is considered more robust and is state of the art as it can match templates with non-rigid and out of plane transformation, it can match with high background clutter and illumination changes.\n\n#### Feature extraction\nThe Computer Vision Pipeline, Part 4: feature extraction. https://freecontent.manning.com/the-computer-vision-pipeline-part-4-feature-extraction/\n- Feature extraction is a core component of the computer vision pipeline. In fact, the entire deep learning model works around the idea of extracting useful features which clearly define the objects in the image. We’re going to spend a little more time here because it’s important that you understand what a feature is, what a vector of features is, and why we extract features.\n- A feature in [machine learning](AI/Machine%20Learning.md) is an individual measurable property or characteristic of a phenomenon being observed. Features are the input that you feed to your machine learning model to output a prediction or classification. Suppose you want to predict the price of a house, your input features (properties) might include: square_foot, number_of_rooms, bathrooms, etc. and the model will output the predicted price based on the values of your features. Selecting good features that clearly distinguish your objects increases the predictive power of machine learning algorithms.\n\nIn image processing, algorithms are used to detect and isolate various desired portions or shapes (features) of a digitized image or video stream. It is particularly important in the area of optical character recognition. \n- Low-level: Edge detection, Corner detection, Blob detection, Ridge detection, Scale-invariant feature transform,\n- Curvature: Edge direction, changing intensity, autocorrelation\n- Image motion: Motion detection. Area based, differential approach, Optical flow (https://en.wikipedia.org/wiki/Optical_flow)\n- Shape based: Thresholding, Blob extraction, Template matching, Hough transform\n\t- Lines: Circles/ellipses, Arbitrary shapes (generalized Hough transform). Works with any parameterizable feature (class variables, cluster detection, etc..)\n- Flexible methods: Deformable, parameterized shapesActive contours (snakes)\n\n##### Blob detection\n- https://en.wikipedia.org/wiki/Blob_detection\n- In computer vision, blob detection methods are aimed at detecting regions in a digital image that differ in properties, such as brightness or color, compared to surrounding regions. Informally, a blob is a region of an image in which some properties are constant or approximately constant; all the points in a blob can be considered in some sense to be similar to each other.\n- The Laplacian of Gaussian: https://en.wikipedia.org/wiki/Blob_detection#The_Laplacian_of_Gaussian\n- The difference of Gaussians: https://en.wikipedia.org/wiki/Difference_of_Gaussians\n- The determinant of the Hessian: https://en.wikipedia.org/wiki/Blob_detection#The_determinant_of_the_Hessian\n- The hybrid Laplacian and determinant of the Hessian operator (Hessian-Laplace): https://en.wikipedia.org/wiki/Blob_detection#The_hybrid_Laplacian_and_determinant_of_the_Hessian_operator_(Hessian-Laplace)\n- Maximally stable extremal regions (MSER): https://en.wikipedia.org/wiki/Maximally_stable_extremal_regions\n\n##### Edge detection\n- https://en.wikipedia.org/wiki/Template_matching\n- Canny edge detector: https://en.wikipedia.org/wiki/Canny_edge_detector\n\t- The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images.\n\t- The Process of Canny edge detection algorithm can be broken down to 5 different steps:\n\t\t1. Apply Gaussian filter to smooth the image in order to remove the noise\n\t\t2. Find the intensity gradients of the image\n\t\t3. Apply non-maximum suppression to get rid of spurious response to edge detection\n\t\t4. Apply double threshold to determine potential edges\n\t\t5. Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n\t- http://aishack.in/tutorials/canny-edge-detector/\n- Robert cross\n\t- https://en.wikipedia.org/wiki/Roberts_cross\n\t- The Roberts cross operator is used in image processing and computer vision for edge detection. \n\t- As a differential operator, the idea behind the Roberts cross operator is to approximate the gradient of an image through discrete differentiation which is achieved by computing the sum of the squares of the differences between diagonally adjacent pixels.\n- Prewitt operator\n\t- https://en.wikipedia.org/wiki/Prewitt_operator\n\t- The Prewitt operator is used in image processing, particularly within edge detection algorithms. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Prewitt operator is either the corresponding gradient vector or the norm of this vector. The Prewitt operator is based on convolving the image with a small, separable, and integer valued filter in horizontal and vertical directions and is therefore relatively inexpensive in terms of computations like Sobel and Kayyali operators. On the other hand, the gradient approximation which it produces is relatively crude, in particular for high frequency variations in the image.\n- Deriche edge detector\n\t- https://en.wikipedia.org/wiki/Deriche_edge_detector\n\t- The Prewitt operator is used in image processing, particularly within edge detection algorithms. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Prewitt operator is either the corresponding gradient vector or the norm of this vector. The Prewitt operator is based on convolving the image with a small, separable, and integer valued filter in horizontal and vertical directions and is therefore relatively inexpensive in terms of computations like Sobel and Kayyali operators. On the other hand, the gradient approximation which it produces is relatively crude, in particular for high frequency variations in the image.\n\n##### Corner detection\n- https://en.wikipedia.org/wiki/Corner_detection\n- http://aishack.in/tutorials/corner-detection-opencv/\n- Corner detection is an approach used within computer vision systems to extract certain kinds of features and infer the contents of an image.\n- Harris operator: detects corners (patches that have strong gradients in two orthogonal directions). https://en.wikipedia.org/wiki/Harris_Corner_Detector\n- Förstner corner detector: https://en.wikipedia.org/wiki/Corner_detection#The_F%C3%B6rstner_corner_detector\n- The Wang and Brady corner detection algorithm: https://en.wikipedia.org/wiki/Corner_detection#The_Wang_and_Brady_corner_detection_algorithm\n- The SUSAN corner detector: https://en.wikipedia.org/wiki/Corner_detection#The_SUSAN_corner_detector\n- The Trajkovic and Hedley corner detector: https://en.wikipedia.org/wiki/Corner_detection#The_Trajkovic_and_Hedley_corner_detector\n\n##### Feature descriptors\n- Scale-invariant feature transform (SIFT)\n\t- http://aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/\n\t- SIFT keypoints of objects are first extracted from a set of reference images and stored in a database. An object is recognized in a new image by individually comparing each feature from the new image to this database and finding candidate matching features based on Euclidean distance of their feature vectors. From the full set of matches, subsets of keypoints that agree on the object and its location, scale, and orientation in the new image are identified to filter out good matches. The determination of consistent clusters is performed rapidly by using an efficient hash table implementation of the generalised Hough transform. Each cluster of 3 or more features that agree on an object and its pose is then subject to further detailed model verification and subsequently outliers are discarded. Finally the probability that a particular set of features indicates the presence of an object is computed, given the accuracy of fit and number of probable false matches. Object matches that pass all these tests can be identified as correct with high confidence.\n\t- https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html\n\t- There are mainly five steps involved in SIFT algorithm.\n\t\t1. Scale-space Extrema Detection (using DoG)\n\t\t2. Keypoint Localization\n\t\t3. Orientation Assignment\n\t\t4. Keypoint Descriptor\n\t\t5. Keypoint Matching\n- Histogram of oriented gradients (HOG): https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients\n- Speeded up robust features (SURF)\n\t- https://en.wikipedia.org/wiki/Speeded_up_robust_features\n\t- In computer vision, speeded up robust features (SURF) is a patented local feature detector and descriptor. It can be used for tasks such as object recognition, image registration, classification or 3D reconstruction. It is partly inspired by the scale-invariant feature transform (SIFT) descriptor. The standard version of SURF is several times faster than SIFT and claimed by its authors to be more robust against different image transformations than SIFT.\n\n##### Kanade–Lucas–Tomasi (KLT) feature tracker\n- https://en.wikipedia.org/wiki/Kanade%E2%80%93Lucas%E2%80%93Tomasi_feature_tracker\n- In computer vision, the Kanade–Lucas–Tomasi (KLT) feature tracker is an approach to feature extraction. It is proposed mainly for the purpose of dealing with the problem that traditional image registration techniques are generally costly. KLT makes use of spatial intensity information to direct the search for the position that yields the best match. It is faster than traditional techniques for examining far fewer potential matches between the images.\n- Summary of KLT tracking:\n\t- Find a good point to track (harriscorner)\n\t- Use intensity second moment matrix and difference across frames to find displacement\n\t- Iterate and use coarse-to-fine search to deal with larger movements \n\t- When creating long tracks, check appearance of registered patch against appearance of initial patch to find points that have drifted\n\n##### Optical flow\n- https://en.wikipedia.org/wiki/Optical_flow\n- Vector field function of the spatio-temporal image brightness variations \n- #PAPER Large Displacement Optical Flow: https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/brox_cvpr09.pdf",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Image-and-video-captioning": {
    "title": "Image and video captioning",
    "content": "## References\nReview papers: \n- #PAPER A Systematic Literature Review on Image Captioning (Staniute 2019): https://www.mdpi.com/2076-3417/9/10/2024/htm\n- #PAPER Survey of convolutional neural networks for image captioning (Kalra 2020): https://www.tandfonline.com/doi/abs/10.1080/02522667.2020.1715602\n\n- #PAPER Show and Tell: A Neural Image Caption Generator (Vinyals 2015): https://arxiv.org/abs/1411.4555\n- #PAPER Deep Visual-Semantic Alignments for Generating Image Description: http://cs.stanford.edu/people/karpathy/cvpr2015.pdf\n\t- http://cs.stanford.edu/people/karpathy/deepimagesent/\n- #PAPER Mind’s Eye: A Recurrent Visual Representation for Image Caption Generation. http://www.cs.cmu.edu/~xinleic/papers/cvpr15_rnn.pdf\n- #PAPER Sequence to Sequence--Video to Text. http://arxiv.org/abs/1505.00487\n- #PAPER Describing Videos by Exploiting Temporal Structure (Yao 2015): http://arxiv.org/abs/1502.08029\n- #PAPER 3G structure for image caption generation (Yuan 2018): https://arxiv.org/abs/1904.09544",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Image-to-image-translation": {
    "title": "Image-to-image translation",
    "content": "## Resources\n- The task of Image-to-image translation is to learn the mapping from a given image (X) to a specific target image (Y), e.g., mapping grayscale images to RGB images.\n- Learning the mapping from one visual representation to another requires an understanding of underlying features that are shared between these representations, such features are either domain-independent or domain-specific.\n- https://paperswithcode.com/task/image-to-image-translation\n- https://github.com/weihaox/awesome-image-translation\n- Deep Domain Adaptation In Computer Vision: https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f\n\n## References\nReview papers:\n- #PAPER Image-to-Image Translation: Methods and Applications (Pang 2021): https://arxiv.org/abs/2101.08629\n\n\n### CNN-based\nSee [Encoder-decoder networks](AI/Computer%20Vision/Encoder-decoder%20networks.md)\n- Related to the task of supervised semantic segmentation but changing the Y and the loss (MAE, MSE or other reconstruction loss)\n\n\n### GAN-based\nSee [GANs#GANs for representation learning and image synthesis](AI/Deep%20learning/GANs.md#GANs%20for%20representation%20learning%20and%20image%20synthesis)\nReview papers:\n- #PAPER Deep Generative Adversarial Networks for Image-to-Image Translation: A Review (Alotaibi 2020): https://www.mdpi.com/2073-8994/12/10/1705/htm#  ^I2IGANs20\n\t- The powerful ability of deep feature learning to automatically utilize complex and high-level feature representations has significantly advanced the performance of state-of-the-art methods across computer applications\n\t- The underlying structure and distinctive (complex) features are both discovered via deep learning-based methods that can be classified further into discriminative feature-learning algorithms and generative feature-learning algorithms\n\t- Discriminative models focus on the classification-learning process by learning the conditional probability p (x|y) to map input x to class label y. One of the most popular methods used for image feature learning utilizes convolutional neural networks (CNN) for feature extraction and image classification (LeNet, AlexNet, VGGNet, ResNet and other supervised learning algorithms)\n\t- Generative models focus on the data distribution to discover the underlying features from large amounts of data in an unsupervised setting. Such models are able to generate new samples by learning the estimation of the joint probability distribution p (x,y) and predicting y\n\t- The most dominant and efficient deep generative models of recent years have been VAE and GAN. A variational autoencoder learns the underlying probability distribution and generates a new sample that is based on Bayesian inference by maximizing the lower bound of the data’s log-likelihood. In contrast, generative adversarial networks learn data distributions through the adversarial training process based on game theory instead of maximizing the likelihood.\n\t- I2I methods:\n\t\t- Supervised\n\t\t\t- Directional translation (Pix2Pix, StarGAN)\n\t\t\t- Bidirectional translation (BicycleGAN, CEGAN)\n\t\t- Unsupervised\n\t\t\t- Cyclic consistency (CycleGAN, DiscoGAN, DualGAN, QGAN, XGAN)\n\t\t\t- Autoencoder-based (UNIT, BranchGAN)\n\t\t\t- Disentangler representation (MUNIT, DIRT, DosGAN)\n\n#### Paired (supervised) translation \n- #PAPER Image-to-Image Translation with Conditional Adversarial Networks, pix2pix (Isola 2016): https://arxiv.org/abs/1611.07004 ^pix2pix\n\t- Loss function learned by the network itself instead of L2, L1 norms\n\t- UNET generator, CNN discriminator\n\t- Euclidean distance is minimized by averaging all plausible outputs, which causes blurring.  Coming up with loss functions that force the CNN to do what we really want– e.g., output sharp, realistic images – is an open problem and generally requires expert knowledge \n\t- Evaluating the quality of synthesized images is an open and difficult problem. Traditional metrics such as per-pixel mean-squared error do not assess joint statistics of the result, and therefore do not measure the very structure that structured losses aim to capture\n\t- #CODE https://github.com/phillipi/pix2pix\n\t- #CODE https://www.tensorflow.org/tutorials/generative/pix2pix \n\t- #CODE https://github.com/He-Jian/pix2pix-keras\n\t- https://affinelayer.com/pixsrv/\n\t- https://medium.com/deep-math-machine-learning-ai/ch-14-2-pix2pix-gan-and-cycle-gan-55cd84318fb8 \n\t- https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/\n\t- https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n\t- Image-to-Image Translation in Tensorflow: https://affinelayer.com/pix2pix/\n\t- Two minutes papers: https://www.youtube.com/watch?v=u7kQ5lNfUfg\n\t- Paper walkthrough: https://www.youtube.com/watch?v=9SGs4Nm0VR4\n\t- Stochastic inference: \n\t\t- https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/152\n\t\t\t- tried a few ways of adding z to the nets, e.g., adding z to a latent state, concatenating with a latent state, applying dropout, etc. The output tended not to vary much as a function of z\n\t\t\t- see follow up paper by Zhu et al 2017 (BicycleGAN). Shows one way of getting z to actually have a substantial effect\n\t\t- https://machinelearningmastery.com/how-to-implement-pix2pix-gan-models-from-scratch-with-keras/ \n\t\t\t- unlike traditional generator models in the GAN architecture, the U-Net generator does not take a point from the latent space as input. Instead, dropout layers are used as a source of randomness both during training and when the model is used to make a prediction, e.g. generate an image at inference time\n\t\t\t- similarly, batch normalization is used in the same way during training and inference, meaning that statistics are calculated for each batch and not fixed at the end of the training process. This is referred to as instance normalization, specifically when the batch size is set to 1 as it is with the Pix2Pix model\n\t\t\t- \"At inference time, we run the generator net in exactly the same manner as during the training phase. This differs from the usual protocol in that we apply dropout at test time, and we apply batch normalization using the statistics of the test batch, rather than aggregated statistics of the training batch.\"\n\t\t\t- in Keras, layers like Dropout and BatchNormalization operate differently during training and in inference model. We can set the “training” argument when calling these layers to “True” to ensure that they always operate in training-model, even when used during inference\n- #PAPER Toward Multimodal Image-to-Image Translation, BicycleGAN (Zhu 2017): https://arxiv.org/abs/1711.11586 ^bicyclegan\n\t- #CODE https://github.com/junyanz/BicycleGAN\n\t- #CODE https://github.com/clvrai/BicycleGAN-Tensorflow\n\t- #CODE https://github.com/prakashpandey9/BicycleGAN\n\t- Aimed to model a distribution of possible outputs in a conditional generative modeling setting\n\t-  The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. \n\t- Encouraged the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results\n- #PAPER Bayesian Conditional Generative Adverserial Networks (Ehsan Abbasnejad 2017): https://arxiv.org/abs/1706.05477\n- #PAPER Image-to-image translation with conditional GAN (Hu 2018): https://cs230.stanford.edu/projects_spring_2018/reports/8289557.pdf\n- #PAPER High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs (Wang 2018): https://tcwang0509.github.io/pix2pixHD/\n\t- #CODE https://github.com/NVIDIA/pix2pixHD\n\t- https://youtu.be/3AIpPlzM_qs\n- #PAPER StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation (Choi 2018): https://arxiv.org/abs/1711.09020\n\t- #CODE https://github.com/yunjey/stargan\n- #PAPER Reversible GANs for Memory-efficient Image-to-Image Translation (van der Ouderaa 2019): https://arxiv.org/abs/1902.02729\n- #PAPER StarGAN v2: Diverse Image Synthesis for Multiple Domains (Choi 2020): https://arxiv.org/abs/1912.01865\n\t- #CODE https://github.com/clovaai/stargan-v2\n\n\n#### Unpaired (unsupervised) translation\n- #PAPER Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, CycleGAN (Zhu, 2017): https://arxiv.org/abs/1703.10593 \n\t- #TALK https://www.youtube.com/watch?v=Fea4kZq0oFQ \n\t- #CODE https://github.com/clvrai/CycleGAN-Tensorflow\n\t- https://junyanz.github.io/CycleGAN/\n\t- CycleGAN is an approach to training deep convolutional networks for Image-to-Image translation tasks. Unlike other GANs models for image translation tasks, CycleGAN learns a mapping between one image domain and another using an unsupervised approach. This is done by training Generator Networks to learn a mapping from domain X into an image that looks like it came from domain Y (and vice-versa)\n\t- for the generator, residual functions (residual block) are used\n\t- https://medium.com/deep-math-machine-learning-ai/ch-14-2-pix2pix-gan-and-cycle-gan-55cd84318fb8 \n\t- https://towardsdatascience.com/image-to-image-translation-using-cyclegan-model-d58cfff04755\n\t- https://www.tensorflow.org/tutorials/generative/cyclegan \n\t- https://machinelearningmastery.com/cyclegan-tutorial-with-keras/\n\t- https://yanjia.li/gender-swap-and-cyclegan-in-tensorflow-2-0/\n- #PAPER Learning to Discover Cross-Domain Relations with Generative Adversarial Networks (Kim 2017): https://arxiv.org/abs/1703.05192\n\t- #CODE https://github.com/SKTBrain/DiscoGAN\n\t- #CODE https://github.com/clvrai/DiscoGAN-Tensorflow\n\t- This paper introduced an awesome framework for finding one-to-one mapping between two domains in an unsupervised way. The high-level idea is the joint training of two GAN model G1 and G2 in parallel (one for A-\u003eB and the other one for B-\u003eA)\n\t- Besides the adversarial loss, there is also reconstruction loss to ensure the consistency. Specifically, we restrict that G2(G1(A)) = A and G1(G2(B)) = B\n- #PAPER Unsupervised Image-to-Image Translation Networks (Liu 2018): https://arxiv.org/abs/1703.00848\n\t- #CODE https://github.com/mingyuliutw/UNIT/\n\t- https://www.youtube.com/watch?v=dqxqbvyOnMY\u0026feature=youtu.be\n\t- https://medium.com/@theehiproject/unet-unit-for-fast-unsupervised-image2image-translation-using-fastai-e366408eddb4\n- #PAPER MUNIT: Multimodal UNsupervised Image-to-image Translation (Huang 2018): https://arxiv.org/abs/1804.04732\n\t- #CODE https://github.com/NVlabs/MUNIT\n- #PAPER Fixed-point GAN - Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization (Siddiquee 2019): https://arxiv.org/abs/1908.06965 ^fixedpointGAN\n\t- #CODE https://github.com/mahfuzmohammad/Fixed-Point-GAN\n- #PAPER Contrastive Learning for Unpaired Image-to-Image Translation (Park 2020): https://arxiv.org/abs/2007.15651\n\t- https://taesung.me/ContrastiveUnpairedTranslation/\n\t- #CODE https://github.com/taesungp/contrastive-unpaired-translation\n\t- #TALK https://www.youtube.com/watch?v=jSGOzjmN8q0\n- #PAPER Rethinking the Truly Unsupervised Image-to-Image Translation, TUNIT (Baek 2020): https://arxiv.org/abs/2006.06500\n\t- #CODE https://github.com/clovaai/tunit\n\t- Paper explained: https://www.youtube.com/watch?v=sEG8hD64c_Q\n- #PAPER Implicit Pairs for Boosting Unpaired Image-to-Image Translation (Ginger 2020): https://arxiv.org/abs/1904.06913v4\n\n\n### Flow-based\n- #CODE Image-to-image translation with flow-based generative model: https://github.com/yenchenlin/pix2pix-flow\n\n- #PAPER Flow-based Image-to-Image Translation with Feature Disentanglement (Kondo 2019): https://papers.nips.cc/paper/2019/file/ffedf5be3a86e2ee281d54cdc97bc1cf-Paper.pdf\n- #PAPER AlignFlow: Cycle Consistent Learning from Multiple Domains via Normalizing Flows (Grover, 2019): https://arxiv.org/abs/1905.12892\n\t-  A generative modeling framework that models each domain via a normalizing flow\n\t-  The use of normalizing flows allows for\n\t\t- flexibility in specifying learning objectives via adversarial training, maximum likelihood estimation, or a hybrid of the two methods\n\t\t- learning and exact inference of a shared representation in the latent space of the generative model. \n- #PAPER Flow-based Deformation Guidance for Unpaired Multi-Contrast MRI Image-to-Image Translation (Duc Bui 2020): https://arxiv.org/abs/2012.01777v1\n\t- Normalizing flows for unpaired image-to-image translation\n\t- Utilized the temporal information between consecutive slices to provide more constraints to the optimization for transforming one domain to another in un-paired volumetric medical image",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Inpainting": {
    "title": "Inpainting",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Inpainting\n- Inpainting is a conservation process where damaged, deteriorating, or missing parts of an artwork are filled in to present a complete image\n- https://www.nvidia.com/research/inpainting/\n- An Introduction to Image Inpainting using Deep Learning: https://wandb.ai/ayush-thakur/image-impainting/reports/An-Introduction-to-Image-Inpainting-using-Deep-Learning--Vmlldzo3NDU0Nw\n\n\n## References\nReview papers:\n- #PAPER Image inpainting: A review (Elharrouss 2019): https://arxiv.org/abs/1909.06399\n\n### CNN-based\n- #PAPER Feature Learning by Inpainting (Pathak 2016): https://arxiv.org/abs/1604.07379v1\n\t- #CODE https://github.com/pathak22/context-encoder\n- #PAPER Image Inpainting for Irregular Holes Using Partial Convolutions (Liu 2018): https://arxiv.org/abs/1804.07723\n\t- https://nv-adlr.github.io/publication/partialconv-inpainting\n\t- #CODE https://github.com/NVIDIA/partialconv\n\t- #CODE https://github.com/naoto0804/pytorch-inpainting-with-partial-conv\n\t- #CODE https://github.com/MathiasGruber/PConv-Keras\n\t- #CODE Various Keras Layers that can be used with TensorFlow 2.x: https://github.com/mvoelk/keras_layers\n- #PAPER Partial Convolution based Padding (Liu 2018): https://arxiv.org/pdf/1811.11718\n- #PAPER Probabilistic Semantic Inpainting with Pixel Constrained CNNs (Dupont 2019): https://arxiv.org/abs/1810.03728\n\t- #CODE https://github.com/Schlumberger/pixel-constrained-cnn-tf\n- #PAPER A Flexible Deep [[CNNs]] Framework for Image Restoration (2020): https://ieeexplore.ieee.org/document/8820082\n\t- https://www.researchgate.net/profile/Zhi_Jin6/publication/335500109_A_Flexible_Deep_CNN_Framework_for_Image_Restoration/links/5da7c1a9299bf1c1e4c837c3/A-Flexible-Deep-CNN-Framework-for-Image-Restoration.pdf\n- #PAPER Deep learning-Based 3D inpainting of brain MR images (Kwan Kang 2021): https://www.nature.com/articles/s41598-020-80930-w \n\n\n### GAN-based\n- GANs and Missing Data Imputation: https://towardsdatascience.com/gans-and-missing-data-imputation-815a0cbc4ece\n\n- #PAPER VIGAN: Missing View Imputation with Generative Adversarial Networks (Shang 2017): https://arxiv.org/abs/1708.06724\n\t- #CODE https://github.com/chaoshangcs/VIGAN\n- #PAPER Patch-Based Image Inpainting with [[GANs]] (Demir 2018): https://arxiv.org/abs/1803.07422\n- #PAPER GAIN: Missing Data Imputation using [[GANs]] (Yoon 2018): https://arxiv.org/abs/1806.02920\n\t- #CODE https://github.com/jsyoon0823/GAIN\n- #PAPER MisGAN: Learning from Incomplete Data with Generative Adversarial Networks (Li 2019): https://arxiv.org/abs/1902.09599\n- #PAPER CollaGAN : Collaborative GAN for Missing Image Data Imputation (Li 2019): https://arxiv.org/abs/1901.09764\n- #PAPER DeepGIN: Deep Generative Inpainting Network for Extreme Image Inpainting (Li 2020): https://arxiv.org/abs/2008.07173\n\t- #CODE https://github.com/rlct1/DeepGIN\n\t- https://medium.com/analytics-vidhya/review-of-deepgin-deep-generative-inpainting-network-for-extreme-image-inpainting-de5b191562b0\n- #PAPER The image inpainting algorithm used on multi-scale generative adversarial networks and neighbourhood (Mo 2020): https://www.tandfonline.com/doi/full/10.1080/00051144.2020.1821535",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Object-classification-image-recognition": {
    "title": "Object classification, image recognition",
    "content": "See:\n[CNNs](AI/Deep%20learning/CNNs.md)\n[Object detection](AI/Computer%20Vision/Object%20detection.md)\n[Semantic segmentation](AI/Computer%20Vision/Semantic%20segmentation.md)\n[Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n\n## Resources\n- https://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception/\n- https://blog.paralleldots.com/data-science/must-read-path-breaking-papers-about-image-classification/\n\n## References\n- #PAPER AlexNet: ImageNet Classification with Deep Convolutional Neural Networks (2012): https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\n\t- This architecture was one of the first deep networks to push ImageNet Classification accuracy by a significant stride in comparison to traditional methodologies. It is composed of 5 convolutional layers followed by 3 fully connected layers.\n\t- AlexNet, proposed by Alex Krizhevsky, uses ReLu(Rectified Linear Unit) for the non-linear part, instead of a Tanh or Sigmoid function which was the earlier standard for traditional neural networks. Another problem that this architecture solved was reducing the over-fitting by using a Dropout layer after every FC layer.\n- #PAPER Visualizing and Understanding Convolutional Networks (Zeiler and Fergus 2013): https://arxiv.org/abs/1311.2901\n- #PAPER Very Deep Convolutional Networks for Large-Scale Image Recognition, VGG16 (Symonian 2014): https://arxiv.org/abs/1409.1556\n\t- This architecture is from VGG group, Oxford. It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3X3 kernel-sized filters one after another.\n- #PAPER Going Deeper with Convolutions (Szegedy 2015): https://ai.google/research/pubs/pub43022\n\t- GoogLeNet (Inception-V1, 2015)\n\t- http://nicolovaligi.com/history-inception-deep-learning-architecture.html\n\t- GoogLeNet devised a module called inception module that approximates a sparse CNN with a normal dense construction(shown in the figure). Since only a small number of neurons are effective as mentioned earlier, the width/number of the convolutional filters of a particular kernel size is kept small. Also, it uses convolutions of different sizes to capture details at varied scales(5X5, 3X3, 1X1). Another salient point about the module is that it has a so-called bottleneck layer(1X1 convolutions in the figure). It helps in the massive reduction of the computation requirement. Another change that GoogLeNet made, was to replace the fully-connected layers at the end with a simple global average pooling which averages out the channel values across the 2D feature map, after the last convolutional layer. \n- #PAPER Resnet [Residual and dense neural networks#^resnet](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md#%5Eresnet.md)\n- #PAPER Resnext [Residual and dense neural networks#^resnext](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md#%5Eresnext.md)\n- #PAPER Densenet [Residual and dense neural networks#^densenet](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md#%5Edensenet)\n- #PAPER SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and \u003c0.5MB model size (Iandola 2016): https://arxiv.org/abs/1602.07360\n\t- Paper explained: https://www.youtube.com/watch?v=ge_RT5wvHvY \n\t- https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7\n- #PAPER SENets [CNNs#^senets](AI/Deep%20learning/CNNs.MD#%5Esenets)\n- #PAPER Aggregated Residual Transformations for Deep Neural Networks (Xie 2017): https://arxiv.org/abs/1611.05431\n\t- #CODE https://github.com/taki0112/SENet-Tensorflow\n- #PAPER Designing Network Design Spaces (Radosavovic 2020): https://arxiv.org/abs/2003.13678v1\n- #PAPER NFNets. High-Performance Large-Scale Image Recognition Without Normalization (Brock 2021): https://arxiv.org/abs/2102.06171\n\t- #CODE https://github.com/deepmind/deepmind-research/tree/master/nfnets\n\t- https://towardsdatascience.com/deepmind-releases-a-new-state-of-the-art-image-classification-model-nfnets-75c0b3f37312\n- #PAPER Patches Are All You Need? (2021): https://openreview.net/forum?id=TVHS5Y4dNvM\n\t- #CODE https://github.com/tmp-iclr/convmixer\n\t- https://syncedreview.com/2021/10/12/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-121/",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Object-detection": {
    "title": "Object detection",
    "content": "See [Semantic segmentation](AI/Computer%20Vision/Semantic%20segmentation.md)\n \n## Code\n- https://github.com/microsoft/computervision-recipes/tree/master/scenarios/detection\n- #CODE MMdetection: https://github.com/open-mmlab/mmdetection\n\t- OpenMMLab Detection Toolbox and Benchmark (pytorch)\n\t- https://mmdetection.readthedocs.io/\n- #CODE TensorFlow object detection API\n\t- Repository: https://github.com/tensorflow/models/tree/master/research/object_detection\n\t- Model zoo: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n\t- https://medium.com/swlh/train-your-custom-object-detector-with-tensorflow-object-detector-api-65d38dcdf08c\n\t- https://modelzoo.co/model/objectdetection\n- #CODE Detectron2: https://github.com/facebookresearch/detectron2\n\t- Detectron2 is FAIR's next-generation platform for object detection and segmentation\n- #CODE https://github.com/jinwchoi/awesome-action-recognition#object-detection\n- #CODE YOLO: Real-Time Object Detection. https://pjreddie.com/darknet/yolo/\n\n## References\nReview papers:\n- #PAPER Recent Advances in Object Detection in the Age of Deep [CNNs](AI/Deep%20learning/CNNs.md) (Agarwal 2019): https://arxiv.org/abs/1809.03193\n- #PAPER Deep learning for Generic Object Detection: A Survey (Liu 2019): https://arxiv.org/abs/1809.02165v4\n\n\n- #PAPER Multiple Object Recognition with Visual Attention (Ba 2015): http://arxiv.org/abs/1412.7755\n- #PAPER Is object localization for free? – Weakly Supervised Object Recognition with Convolutional Neural Networks (Oquab 2015): \n\t- http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Oquab_Is_Object_Localization_2015_CVPR_paper.pdf\n\t- https://www.di.ens.fr/willow/research/weakcnn/\n- #PAPER DeepLab - Weakly-and semi-supervised learning of a DCNN for semantic image segmentation (Papandreou 2015): http://arxiv.org/abs/1502.02734\n- #PAPER SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation (Badrinarayanan 2016): http://arxiv.org/abs/1511.00561\n- #PAPER SSD. Single Shot MultiBox Detector (Liu 2016): https://arxiv.org/abs/1512.02325\n\t- #BOOK https://d2l.ai/chapter_computer-vision/ssd.html\n- #PAPER YOLO. You Only Look Once: Unified, Real-Time Object Detection (Redmon 2016). https://arxiv.org/abs/1506.02640\n\t- YOLO or You Only Look Once is an object detection algorithm much different from the region based algorithms. In YOLO a single convolutional network predicts the bounding boxes and the class probabilities for these boxes.\n\t- How YOLO works is that we take an image and split it into an SxS grid, within each of the grid we take m bounding boxes. For each of the bounding box, the network outputs a class probability and offset values for the bounding box. The bounding boxes having the class probability above a threshold value is selected and used to locate the object within the image.\n- #PAPER RetinaNet. Focal Loss for Dense Object Detection (Lin 2018): https://arxiv.org/abs/1708.02002\n\t- #CODE https://github.com/fizyr/keras-retinanet\n\t- https://keras.io/examples/vision/retinanet/\n\t- https://towardsdatascience.com/object-detection-on-aerial-imagery-using-retinanet-626130ba2203\n- #PAPER CornerNet: Detecting Objects as Paired Keypoints (Law 2018): https://arxiv.org/abs/1808.01244\n\t- #CODE https://github.com/makalo/CornerNet\n- #PAPER ExtremeNet. Bottom-up Object Detection by Grouping Extreme and Center Points (Zhou 2019): https://arxiv.org/abs/1901.08043\n\t- #CODE https://github.com/xingyizhou/ExtremeNet\n- #PAPER EfficientDet: Scalable and Efficient Object Detection (Tan 2020): https://arxiv.org/pdf/1911.09070.pdf\n\t- #CODE https://github.com/xuannianz/EfficientDet\n\t- Included in the TF object detection API\n- #CODE YOLOX: Exceeding YOLO Series in 2021 (Ge 2021): https://arxiv.org/abs/2107.08430v1\n\t- #CODE https://paperswithcode.com/paper/yolox-exceeding-yolo-series-in-2021\n\nRegion-based CNNs (R-CNNs):\n- https://www.pyimagesearch.com/2020/07/06/region-proposal-object-detection-with-opencv-keras-and-tensorflow/\n- #BOOK Region-based RCNNs: https://d2l.ai/chapter_computer-vision/rcnn.html\n- #PAPER Regional CNN (R-CNN): https://arxiv.org/abs/1311.2524\n\t- The goal of R-CNN is to take in an image, and correctly identify where the main objects (via a bounding box) in the image.\n\t- R-CNN creates these bounding boxes, or region proposals, using a process called Selective Search. \n\t- Once the proposals are created, R-CNN warps the region to a standard square size and passes it through to a modified version of AlexNet (the winning submission to ImageNet 2012 that inspired R-CNN).\n\t- On the final layer of the CNN, R-CNN adds a Support Vector Machine (SVM) that simply classifies whether this is an object, and if so what object. \n- #PAPER Fast R-CNN: https://arxiv.org/abs/1504.08083\n\t- RoI (Region of Interest) Pooling. At its core, RoIPool shares the forward pass of a CNN for an image across its subregions. \n\t- The second insight of Fast R-CNN is to jointly train the CNN, classifier, and bounding box regressor in a single model. \n- #PAPER Faster R-CNN: https://arxiv.org/abs/1506.01497\n\t- The insight of Faster R-CNN was that region proposals depended on features of the image that were already calculated with the forward pass of the CNN (first step of classification).\n\t- So why not reuse those same CNN results for region proposals instead of running a separate selective search algorithm?\n\t- A single CNN is used to both carry out region proposals and classification. This way, only one CNN needs to be trained and we get region proposals almost for free. Faster R-CNN adds a Fully Convolutional Network on top of the features of the CNN creating what’s known as the Region Proposal Network.\n- #PAPER Mask R-CNN (He 2018): https://arxiv.org/abs/1703.06870\n\t- Extending Faster R-CNN for Pixel Level Segmentation\n\t- Mask R-CNN does this by adding a branch to Faster R-CNN that outputs a binary mask that says whether or not a given pixel is part of an object. The branch, as before, is just a Fully Convolutional Network on top of a CNN based feature map. \n\t- But the Mask R-CNN authors had to make one small adjustment to make this pipeline work as expected: Realigning RoIPool to be More Accurate.\n\t- https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46\n\t- https://modelzoo.co/model/mask-r-cnn-keras\n\t- https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Semantic-segmentation": {
    "title": "Semantic segmentation",
    "content": "See:\n[Encoder-decoder networks](AI/Deep%20learning/Encoder-decoder%20networks.md) for image segmentation\n[Object detection](AI/Computer%20Vision/Object%20detection.md)\n\n## Resources\n- https://en.wikipedia.org/wiki/Image_segmentation\n- https://github.com/mrgloom/awesome-semantic-segmentation\n- https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4\n- Overview of semantic image segmentation: https://www.jeremyjordan.me/semantic-segmentation/\n\n## Code\n- #CODE DeepLab2: https://github.com/google-research/deeplab2\n\t- DeepLab2 is a TensorFlow library for deep labeling, aiming to provide a unified and state-of-the-art TensorFlow codebase for dense pixel labeling tasks.\n- #CODE Segmentation models with pretrained backbones (PyTorch): https://github.com/qubvel/segmentation_models\n- #CODE https://www.tensorflow.org/tutorials/images/segmentation\n- #CODE https://github.com/yassouali/pytorch-segmentation\n\n## References\nReview papers:\n- #PAPER Deep learning for cardiac imagesegmentation: A review (2019): https://arxiv.org/abs/1911.03723\n- #PAPER Evolution of Image Segmentation using Deep Convolutional Neural Network: A Survey (Sultana, 2020): https://arxiv.org/abs/2001.0407430\n\n- #PAPER Fully Convolutional Networks for Semantic Segmentation (Long 2015): https://arxiv.org/abs/1411.4038\n- #PAPER CGNet: A Light-weight Context Guided Network for Semantic Segmentation (Wu 2018): https://arxiv.org/abs/1811.08201 ^cgnet\n\t- Context Guided (CG) block learns the joint feature of both local feature and surrounding context, and further improves the joint feature with the global context\n\t- CGNet captures contextual information in all stages of the network and is specially tailored for increasing segmentation accuracy \n\t- CGNet is also elaborately designed to reduce the number of parameters and save memory footprint\n- #PAPER Panoptic-DeepLab: A Simple, Strong, and Fast Baseline for Bottom-Up Panoptic Segmentation (Cheng 2020): https://arxiv.org/abs/1911.10194\n\t- #CODE https://github.com/bowenc0221/panoptic-deeplab\n- #PAPER Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation (Wang 2020): https://arxiv.org/abs/2003.07853\n\t- #CODE https://github.com/csrhddlam/axial-deeplab\n\t- Paper explained: https://www.youtube.com/watch?v=hv3UO3G0Ofo\n- #PAPER Towards infield, live plant phenotyping using a reduced-parameter CNN (Atanbori 2020): https://link.springer.com/article/10.1007%2Fs00138-019-01051-7",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Super-resolution": {
    "title": "Super-resolution",
    "content": "See [Image-to-image translation](AI/Computer%20Vision/Image-to-image%20translation.md)\n\n## Resources\n- https://github.com/ptkin/Awesome-Super-Resolution\n- https://github.com/ChaofWang/Awesome-Super-Resolution\n- https://keras.io/examples/vision/super_resolution_sub_pixel/\n- Image Super-Resolution: A Comprehensive Review (2020): https://blog.paperspace.com/image-super-resolution/ \n- #TALK How Super Resolution Works (2019): https://www.youtube.com/watch?v=KULkSwLk62I\n- #TALK Can you enhance that? Single Image Super Resolution (Pydata 2019): https://www.youtube.com/watch?v=lmUxbRY7H2I\n\n## Code\n- #CODE BasicSR: Open Source Image and Video Restoration Toolbox for Super-resolution, Denoise, Deblurring (Pytorch). https://github.com/xinntao/BasicSR\n\t- It includes EDSR, RCAN, SRResNet, SRGAN, ESRGAN, EDVR, etc\n- #CODE Single Image Super Resolution benchmark (Keras): https://github.com/hieubkset/Keras-Image-Super-Resolution\n\t- EDSR, SRGAN, SRFeat, RCAN, ESRGAN and ERCA (not published)\n- #CODE Single Image Super-Resolution with EDSR, WDSR and SRGAN (Keras): https://github.com/krasserm/super-resolution\n\t- http://krasserm.github.io/2019/09/04/super-resolution/\n\n\n## References\n### Review Papers\n- #PAPER Deep Learning for Single Image Super-Resolution: A Brief Review (2018): https://arxiv.org/abs/1808.03344\n- #PAPER A Deep Journey into Super-resolution: A survey (Anwar 2020): https://arxiv.org/abs/1904.07523\n\t- https://github.com/saeed-anwar/SRsurvey\n- #PAPER Deep Learning for Image Super-resolution: A Survey (Wang 2020): https://arxiv.org/abs/1902.06068 \n- #PAPER NTIRE 2020 Challenge on Perceptual Extreme Super-Resolution: Methods and Results (Zhang 2020): https://arxiv.org/abs/2005.01056\n\t- https://data.vision.ee.ethz.ch/cvl/ntire20/\n\t- Jointly with NTIRE 2020 workshop we have an NTIRE challenge on perceptual extreme super-resolution, that is,the task of super-resolving an LR image to a perceptually pleasant HR image with a magnification factor x16\n- #PAPER A Comprehensive Review of Deep Learning-based Single Image Super-resolution (Bashir 2021): https://arxiv.org/abs/2102.09351\n\n\n### CNN-based\n- #PAPER Image Super-Resolution Using Deep Convolutional Networks, SRCNN (Dong 2015): https://arxiv.org/abs/1501.00092\n\t- #CODE https://github.com/MarkPrecursor/SRCNN-keras\n\t- #CODE https://github.com/yukia18/srcnn-keras\n- #PAPER Accurate Image Super-Resolution Using Very Deep Convolutional Networks (2015): http://arxiv.org/abs/1511.04587\n- #PAPER Deep Networks for Image Super-Resolution with Sparse Prior (Wang 2015): http://www.ifp.illinois.edu/~dingliu2/iccv15/\n\t- http://www.ifp.illinois.edu/~dingliu2/iccv15/iccv15.pdf\n- #PAPER FSRCNN - Accelerating the Super-Resolution Convolutional Neural Network (Dong 2016): https://arxiv.org/abs/1608.00367\n\t- http://mmlab.ie.cuhk.edu.hk/projects/FSRCNN.html\n\t- Uses deconvolution layers (transposed convolution)\n\t- #CODE https://github.com/GeorgeSeif/FSRCNN-Keras\n- #PAPER Deconvolution and Checkerboard Artifacts (Odena 2016): https://distill.pub/2016/deconv-checkerboard/\n\t- Identifies the learned upsample operation (often called deconvolutions) in generative networks as a source of noise\n\t- Overall lesson here is that if you use transposed convolutions, be careful that your kernel size is a multiple of your stride\n\t- However if you use a nearest neighbor or bilinear upsample approach followed by a convolution (termed the ‘resize convolution’) checkerboard artifacts should not appear\n\t- They have more succes with nearest neighbor than with bilinear, possibly because bilinear upsampling smooths away important high frequency signals\n- #PAPER Perceptual Losses for Real-Time Style Transfer and Super-Resolution (Johnson 2016): http://arxiv.org/abs/1603.08155\n\t- http://cs.stanford.edu/people/jcjohns/papers/fast-style/fast-style-supp.pdf\n- #PAPER ESPCN - Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network (Shi 2016): https://arxiv.org/abs/1609.05158\n\t- https://medium.datadriveninvestor.com/review-espcn-real-time-sr-super-resolution-8dceca249350\n\t- #CODE https://keras.io/examples/vision/super_resolution_sub_pixel/\n\t- SubPixelUpscaling implementation here: https://github.com/pavitrakumar78/Anime-Face-GAN-Keras/blob/master/misc_layers.py\n\t- Subpixel convolution is the same as pixel-shuffle: https://nico-curti.github.io/NumPyNet/NumPyNet/layers/pixelshuffle_layer.html\n\t- A drawback of the interpolation upsampling is that upsampling errors are introduced that can be hard to correct sub-sequently\n\t- The idea of pixel shuffling is to rearrange the pixels of multiple low-resolution images, or in this case feature activations, to one high-resolution out-put image by periodic shuffling of the image points. It thus represents a learnable upsampling operation\n\t- Through the constant periodicity, the previous operations of the neural network can learn to distribute content across the feature dimension which is then shuffled to yield the high-resolution output\n\t- This allows to process the image entirely in low-resolution space\n- #PAPER Checkerboard artifact free sub-pixel convolution: A note on sub-pixel convolution, resize convolution and convolution resize (Aitken 2017): https://arxiv.org/abs/1707.02937\n\t- #CODE https://github.com/Golbstein/EDSR-Keras/blob/master/subpixel.py\n- #PAPER EDSR - Enhanced Deep Residual Networks for Single Image Super-Resolution (Lim 2017): https://arxiv.org/abs/1707.02921\n\t- #CODE https://github.com/Golbstein/EDSR-Keras\n\t- #CODE https://github.com/hieubkset/Keras-Image-Super-Resolution\n- #PAPER Pixel Deconvolutional Networks (Gao 2017): https://arxiv.org/abs/1705.06820\n- #PAPER RDN - Residual Dense Network for Image Super-Resolution (Zhang 2018): https://arxiv.org/abs/1802.08797\n\t- #CODE https://github.com/idealo/image-super-resolution\n\t- #CODE https://github.com/hengchuan/RDN-TensorFlow\n- #PAPER WDSR - Wide Activation for Efficient and Accurate ImageSuper-Resolution (Yu 2018): https://arxiv.org/abs/1808.08718\n- #PAPER RecResNet: A Recurrent Residual CNN Architecture for Disparity Map Enhancement (Batsos 2018): https://ieeexplore.ieee.org/document/8490974\n\t- https://mordohai.github.io/public/Batsos_RecResNet18.pdf\n\t- #CODE https://github.com/kbatsos/RecResNet\n- #PAPER RCAN - Image Super-Resolution Using Very Deep Residual Channel Attention Networks (Zhang 2018): https://arxiv.org/abs/1807.02758\n\t- #CODE https://github.com/yulunzhang/RCAN\n- #PAPER Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks (Lai 2018): http://vllab.ucmerced.edu/wlai24/LapSRN/\n- #PAPER Super-Resolution using Convolutional Neural Networks without Any Checkerboard Artifacts (Sugawara 2018): https://arxiv.org/abs/1806.02658v1\n- #PAPER Single Image Super Resolution based on a Modified U-net with Mixed Gradient Loss (Lu, 2019): https://arxiv.org/abs/1911.09428\n- #PAPER Densely Residual Laplacian Super-Resolution (Anwar 2019): https://arxiv.org/abs/1906.12021\n\t- #CODE https://github.com/saeed-anwar/DRLN\n- #PAPER Hyperspectral Image Super-Resolution with 1D–2D Attentional Convolutional Neural Network (Li 2019): https://www.mdpi.com/2072-4292/11/23/2859/htm\n- #PAPER Deep Learning for Multiple-Image Super-Resolution (Kawulok 2019): https://arxiv.org/abs/1903.00440\n- #PAPER RUNet: A Robust UNet Architecture for Image Super-Resolution (Hu 2019): https://openaccess.thecvf.com/content_CVPRW_2019/papers/WiCV/Hu_RUNet_A_Robust_UNet_Architecture_for_Image_Super-Resolution_CVPRW_2019_paper.pdf\n- #PAPER Learned Image Downscaling for Upscaling using Content Adaptive Resampler (Sun 2019): https://arxiv.org/abs/1907.12904\n\t- #CODE https://github.com/sunwj/CAR\n\t- https://paperswithcode.com/paper/learned-image-downscaling-for-upscaling-using\n\t- The proposed resampler network generates content adaptive image resampling kernels that are applied to the original HR input to generate pixels on the downscaled image\n\t- Moreover, a differentiable upscaling (SR) module is employed to upscale the LR result into its underlying HR counterpart\n\t- By back-propagating the reconstruction error down to the original HR input across the entire framework to adjust model parameters, the proposed framework achieves a new state-of-the-art SR performance through upscaling guided image resamplers which adaptively preserve detailed information that is essential to the upscaling\n- #PAPER Image Super-Resolution Using Attention Based DenseNet with Residual Deconvolution (Li 2019): https://arxiv.org/abs/1907.05282\n- #PAPER Meta-SR: A Magnification-Arbitrary Network for Super-Resolution (Hu 2019): https://arxiv.org/abs/1903.00875\n\t- #CODE https://github.com/XuecaiHu/Meta-SR-Pytorch\n\t- #CODE https://github.com/smallsunsun1/Meta-SR/\n\t- #CODE https://github.com/jason71995/meta_sr/\n\t- Continuous, arbitrary scaling\n- #PAPER Pixel Transposed Convolutional Networks (Gao 2019): https://ieeexplore.ieee.org/document/8618415\n\t- The pixel transposed convolutional layer (PixelTCL) is proposed to establish direct relationships among adjacent pixels on the up-sampled feature map\n\t- PixelTCL can largely overcome the checkerboard problem suffered by regular transposed convolutional operations\n- #PAPER A Very Deep Spatial Transformer Towards Robust Single Image Super-Resolution (Jiang 2019): https://ieeexplore.ieee.org/abstract/document/8679959\n- #PAPER ASDN: A Deep Convolutional Network for Arbitrary Scale Image Super-Resolution (Shen 2020): https://arxiv.org/abs/2010.02414v1\n- #PAPER LIIF - Learning Continuous Image Representation with Local Implicit Image Function (Chen 2020): https://arxiv.org/abs/2012.09161\n\t- https://yinboc.github.io/liif/\n\t- #CODE https://github.com/yinboc/liif\n\t- Continuous, arbitrary scaling\n- #PAPER Fixed smooth convolutional layer for avoiding checkerboard artifacts in CNNs (Kinoshita 2020): https://arxiv.org/abs/2002.02117v1\n- #PAPER Efficient Image Super-Resolution Using Pixel Attention (Zhao 2020): https://arxiv.org/abs/2010.01073 ^srwithpixelattention\n\t-  #CODE [CNNs#^tfvisualattention](AI/Deep%20learning/CNNs.md#%5Etfvisualattention)\n\t-  #CODE https://github.com/zhaohengyuan1/PAN\n- #PAPER Dense U-net for super-resolution with shuffle pooling layer (Lu 2021): https://arxiv.org/abs/2011.05490\n- #PAPER OverNet: Lightweight Multi-Scale Super-Resolution with Overscaling Network (Behjati 2021): https://arxiv.org/abs/2008.02382\n\t- https://www.youtube.com/watch?v=_YAn5TaIJfM\n- #PAPER Image Super-Resolution via Iterative Refinement (Saharia 2021): https://arxiv.org/abs/2104.07636\n\t- https://iterative-refinement.github.io/\n\t- SR3 is inspired by recent work on Denoising Diffusion Probabilistic Models (DDPM) and denoising score matching\n\t- SR3 adapts denoising diffusion probabilistic models to conditional image generation and performs super-resolution through a stochastic denoising process\n\t- Inference starts with pure Gaussian noise and iteratively refines the noisy output using a U-Net model trained on denoising at various noise levels\n\t- #CODE https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement\n\n\n### GAN-based\n- #PAPER SRGAN: Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (Ledig 2016): https://arxiv.org/abs/1609.04802\n\t- #CODE https://github.com/idealo/image-super-resolution\n\t- #CODE https://github.com/tensorlayer/srgan\n\t- #CODE https://github.com/leftthomas/SRGAN\n\t- #TALK https://www.youtube.com/watch?v=BXIR_SVCrsE\n\t- First proposed the perceptual loss: content loss + adversarial loss\n\t\t- content loss ensures high-level content is preserved by computing the MSE in the VGG feature-space (instead of pixel image space)\n\t\t- adversarial loss ensures the reconstructed images look real (textures detail)\n\t- Model based on VGG architecture and DCGAN\n- #PAPER Class-Conditional Superresolution with GANs (Chen 2017): http://cs231n.stanford.edu/reports/2017/pdfs/314.pdf \n\t- #CODE https://github.com/vincentschen/cgan-superres\n- #PAPER ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks (Wang 2018): https://arxiv.org/abs/1809.00219\n\t\t- #CODE https://github.com/xinntao/ESRGAN\n- #PAPER tempoGAN: A temporally coherent, volumetric GAN for super-resolution fluid flow (Xie 2018): https://arxiv.org/abs/1801.09710\n- #PAPER Unsupervised Single-Image Super-Resolution with Multi-Gram Loss (Shi 2019): https://www.mdpi.com/2079-9292/8/8/833/htm\n- #PAPER TecoGAN: Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation (Chu 2020): https://ge.in.tum.de/publications/2019-tecogan-chu/\n\t- #CODE https://github.com/thunil/TecoGAN\n\t- Paper explained: https://www.youtube.com/watch?v=MwCgvYtOLS0\n- #PAPER TSRGAN: Generative Adversarial Network for Image Super-Resolution Combining Texture Loss (Jiang 2020): https://www.mdpi.com/2076-3417/10/5/1729/htm\n- #PAPER Residual Channel Attention Generative Adversarial Network for Image Super-Resolution and Noise Reduction (Cai 2020): https://arxiv.org/abs/2004.13674\n- #PAPER Meta-SRGAN - Arbitrary Scale Super-Resolution for Brain MRI Images (Tan 2020): https://arxiv.org/abs/2004.02086\n\t- #CODE https://github.com/pancakewaffles/metasrgan-tutorial/\n- #PAPER MSG-GAN: Multi-Scale Gradients for Generative Adversarial Networks (Karnewar 2020): https://arxiv.org/abs/1903.06048\n- #PAPER MRI Super-Resolution with GAN and 3D Multi-Level DenseNet: Smaller, Faster, and Better (Chen 2020): https://arxiv.org/abs/2003.01217\n- #PAPER Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data (Wnag 2021): https://arxiv.org/abs/2107.10833v1 ^real-esrgan\n\t- #CODE https://github.com/xinntao/Real-ESRGAN\n\t- Super-resolution with a hint of image restoration\n\t- Proposed a high-order degradation modeling process to better simulate complex real-world degradations (blur, downsampling, noise, etc and combinations)\n\n\n### Transformer-based\n- #PAPER Learning Texture Transformer Network for Image Super-Resolution (Yang 2020): https://arxiv.org/abs/2006.04139 ^ttsr\n\t- #CODE https://github.com/researchmm/TTSR\n\t- Texture Transformer Network for Image Super-Resolution (TTSR)\n\t- LR and Ref images are formulated as queries and keys in a transformer, respectively\n\t- The proposed texture transformer consists of a learnable texture extractor which learns a jointly feature embedding for further attention computation and two attention based modules which transfer HR textures from the Ref image. \n\t- Furthermore, the proposed texture transformer can be stacked in a cross-scale way with the proposed CSFI module to learn a more powerful feature representation",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Computer-Vision/Video-segmentation-and-prediction": {
    "title": "Video segmentation and prediction",
    "content": "See: \n[Encoder-decoder networks](AI/Deep%20learning/Encoder-decoder%20networks.md)\n[Deep learning#Deep learning for multi-dimensional data](AI/Deep%20learning/Deep%20learning.md#Deep%20learning%20for%20multi-dimensional%20data)\n[RNNs](AI/Deep%20learning/RNNs.md)\n\n## Resources\n- Spatiotemporal classification and regression\n- Hybrid convolutional and recurrent networks, 3dconv and related approaches\n- https://github.com/jinwchoi/awesome-action-recognition\n- http://blog.qure.ai/notes/deep-learning-for-videos-action-recognition-review\n- https://stackoverflow.com/questions/55926841/convolving-across-channels-in-keras-cnn-conv1d-depthwise-separable-conv-cccp\n- https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\n\n\n## Courses\n- #COURSE [Advanced Models for Computer Vision (DeepMind x UCL | Deep Learning Lectures)](https://www.youtube.com/watch?v=_aUq7lmMfxo\u0026list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\u0026index=4)\n\t- https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L4%20-%20UCLxDeepMind%20DL2020.pdf\n\n\n## References\n- #PAPER Learning Spatiotemporal Features with 3D Convolutional Networks. C3D, 3D CNNs (Tran 2015): https://arxiv.org/abs/1412.0767\n- #PAPER Unsupervised Learning of Video Representations using LSTMs (Srivastava 2016): https://arxiv.org/abs/1502.04681\n- #PAPER Convolutional Gated Recurrent Networks for Video Segmentation (Siam 2016): https://arxiv.org/abs/1611.05435\n\t- Hybrid convolutional and recurrent networks\n- #PAPER LRCN: Long-term Recurrent Convolutional Networks for Visual Recognition and Description (Donahue 2016): https://arxiv.org/abs/1411.4389\n\t- Hybrid convolutional and recurrent networks\n- #PAPER Convolutional Two-Stream Network Fusion for Video Action Recognition (Feichtenhofer 2016): https://arxiv.org/abs/1604.06573\n- #PAPER Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning (Lotter 2016): https://arxiv.org/abs/1605.08104\n\t- https://coxlab.github.io/prednet/\n- #PAPER ContextVP: Fully Context-Aware Video Prediction (Byeon 2018): https://arxiv.org/abs/1710.08518\n\t- http://on-demand.gputechconf.com/gtc/2018/presentation/s8713-fully-context-aware-video-prediction.pdf \n- #PAPER Machine Learning for Spatiotemporal Sequence Forecasting: A Survey (Shi, 2018): https://arxiv.org/abs/1808.06865\n- #PAPER Residual Convolutional LSTM for Tweet Count Prediction (Wei 2018): https://dl.acm.org/doi/fullHtml/10.1145/3184558.3191571\n- #PAPER A Closer Look at Spatiotemporal Convolutions for Action Recognition (Tran 2018): https://arxiv.org/abs/1711.11248\n\t- #CODE https://github.com/facebookresearch/VMZ\n\t- #CODE See Ghadiyaram 2019 below\n\t- #CODE https://github.com/juenkhaw/action_recognition_project\n\t- demonstrate that 3D ResNets significantly outperform 2D ResNets for the same depth when trained and evaluated on large-scale,challenging action recognition benchmarks\n\t- introduce two new forms of spatio temporal convolution that can be viewed as middle grounds between the extremes of 2D (spatial convolution) and full 3D: mixed convolution (MC) and consists in employing 3D convolutions only in the early layers of the network, with 2D convolutions in the top layers, and the R(2+1)D spatiotemporal conv block which explicitly factorizes3D convolution into two separate and successive operations,a 2D spatial convolution and a 1D temporal convolution\n\t- the first advantage is an additional nonlinear rectification between these two operations. This effectively doubles the number of non-linearities compared to a network using full 3D convolutions for the same number of parameters, thus rendering the model capable of representing more complex functions.The second potential benefit is that the decomposition facilitates the optimization, yielding in practice both a lower training loss and a lower testing loss\n- #PAPER Video Classification with Channel-Separated Convolutional Networks (Tran 2019): https://arxiv.org/abs/1904.02811\n\t- #CODE https://github.com/facebookresearch/VMZ\n- #PAPER Dilated 3D Convolutional Neural Networks for Brain MRI Data Classification (Wang 2019): https://ieeexplore.ieee.org/abstract/document/8840843\n- #PAPER Deep Learning for Spatio-Temporal Data Mining: A Survey (Wang 2019): https://arxiv.org/abs/1906.04928\n- #PAPER Large-scale weakly-supervised pre-training for video action recognition (Ghadiyaram 2019): https://arxiv.org/abs/1905.00561\n\t- #CODE https://github.com/microsoft/computervision-recipes/tree/master/scenarios/action_recognition\n- #PAPER Eidetic 3D LSTM A Model for Video Prediction and Beyond, E3D-LSTM (Wang 2019): https://openreview.net/forum?id=B1lKS2AqtX\n\t- #CODE https://github.com/google/e3d_lstm\n- #PAPER Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition (Esat Kalfaoglu 2020): https://arxiv.org/abs/2008.01232\n- #PAPER An Image is Worth 16x16 Words, What is a Video Worth? (Sharir 2021): https://arxiv.org/abs/2103.13915",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/Dask": {
    "title": "Dask",
    "content": "## Resources\n- #TALK Dask for ad hoc distributed computing (Pydata): https://www.youtube.com/watch?v=EEfI-11itn0\n- #TALK Using Dask for Parallel Computing in Python: https://www.youtube.com/watch?v=s4ChP7tc3tA\n- #TALK Parallelizing Scientific Python with Dask | SciPy 2017 Tutorial | James Crist: https://www.youtube.com/watch?v=mbfsog3e5DA\n- http://jcrist.github.io/introducing-dask-searchcv.html\n- Parallel computing with Dask: https://xarray.pydata.org/en/v0.10.1/dask.html\n\n\n## Code\n- #CODE Dask - flexible parallel computing library for analytics: https://github.com/dask/dask\n\t- http://docs.dask.org/en/latest/cheatsheet.html\n- #CODE Dask-Jobqueue - Easily deploy Dask on job queuing systems like PBS, Slurm, MOAB, SGE, LSF, and HTCondor: https://github.com/dask/dask-jobqueue\n\t- https://jobqueue.dask.org/en/latest/\n\t- Scalable interactive analysis workflows using dask on HPC Systems: https://medium.com/pangeo/dask-jobqueue-d7754e42ca53\n- #code Dask-ml - [[Machine learning]] with Dask: https://github.com/dask/dask-ml",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/Data-Science": {
    "title": "Data Science",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Data_science\n- https://github.com/bulutyazilim/awesome-datascience\n- Reproducible Data Analysis in Jupyter (Vanderplas): https://jakevdp.github.io/blog/2017/03/03/reproducible-data-analysis-in-jupyter/\n- Cookiecutter Data Science: https://drivendata.github.io/cookiecutter-data-science/\n- An Executive's Guide To Understanding Cloud-based ML Services: https://www.forbes.com/sites/janakirammsv/2019/01/01/an-executives-guide-to-understanding-cloud-based-machine-learning-services/\n- Why data-driven science is more than just a buzzword: https://sydney.edu.au/news-opinion/news/2017/05/11/Why-data-driven-science-is-more-than-just-a-buzzword.html\n\n### Cheatsheets\n- https://github.com/ml874/Data-Science-Cheatsheet\n- https://github.com/aaronwangy/Data-Science-Cheatsheet\n- https://github.com/FavioVazquez/ds-cheatsheets\n\n### Infographics\n- Data Never Sleeps 3.0: https://www.domo.com/blog/data-never-sleeps-3-0/\n- The Data Science Industry - who does what: https://www.datacamp.com/community/tutorials/data-science-industry-infographic\n- Learn data science infographic: https://www.datacamp.com/community/tutorials/learn-data-science-infographic\n- DS Infographic: http://online.rutgers.edu/resources/infographics/what-can-you-do-with-a-career-in-data-science/\n- Data Science Venn Diagram v2.0: http://www.anlytcs.com/2014/01/data-science-venn-diagram-v20.html\n- Updated DS Venn diagram: http://www.kdnuggets.com/2016/09/new-data-science-venn-diagram.html\n- DS vs STATS vs DATA-ENG: https://www.analyticsvidhya.com/blog/2015/10/job-comparison-data-scientist-data-engineer-statistician/\n\n## References\n- #PAPER Science and data science (Blei 2017): https://www.pnas.org/content/114/33/8689\n- #PAPER 50 Years of Data Science (Donoho 2017): https://www.tandfonline.com/doi/full/10.1080/10618600.2017.1384734\n\t- #TALK 50 Years of Data Science (Donoho)\n\t\t- https://www.youtube.com/watch?v=GUFL-Mf0EWY\n\t\t- https://www.youtube.com/watch?v=E7w-gfFKPf8\n\t\t- https://www.youtube.com/watch?v=QTzNXYcZLbU\n\t\t- https://www.youtube.com/watch?v=BnRRwmeGBgU\n\t- Comments: \n\t\t- https://matloff.wordpress.com/2016/01/23/some-comments-on-donahos-50-years-of-data-science/\n\t\t- https://medium.com/@srowen/what-50-years-of-data-science-leaves-out-2366c9b61d3d\n\t\t- https://www.youtube.com/watch?v=zamQgXDytUA\n\t\t- #TALK Big Data LDN 2016: What “50 Years of Data Science” Leaves Out: https://www.youtube.com/watch?v=zamQgXDytUA\n- #PAPER Theory-guided data science: a new paradigm for scientific discovery from data (Karpatne 2017): https://ieeexplore.ieee.org/document/7959606\n\n\n## Books\n- #BOOK The field guide to DS (Booz Allen Hamilton Inc 2015): https://www.boozallen.com/s/insight/publication/field-guide-to-data-science.html\n\t- https://www.boozallen.com/content/dam/boozallen_site/sig/pdf/publications/2015-field-guide-to-data-science.pdf\n\t- https://github.com/booz-allen-hamilton/The-Field-Guide-to-Data-Science\n- #BOOK [Going pro in data science (Overton 2016, O'REILLY)](https://www.oreilly.com/library/view/going-pro-in/9781492048534/)\n\t- http://ds4100.weebly.com/uploads/8/6/5/9/8659576/going-pro-in-data-science.pdf\n- #BOOK [Weapons of Math Destruction - How big data increases inequality and threatens democracy (O'Neil, 2016)](https://weaponsofmathdestructionbook.com/)\n\t- https://we.riseup.net/assets/404114/Weapons+of+Math+Destruction+Cathy+O%27Neil.pdf\n- #BOOK [Introducing Data Science - Big Data, ML and more, using Python tools (Cielen 2016, MANNING)](https://www.manning.com/books/introducing-data-science)\n\t- http://bedford-computing.co.uk/learning/wp-content/uploads/2016/09/introducing-data-science-machine-learning-python.pdf\n- #BOOK [Mastering Python for Data Science (Madhavan 2015, PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/mastering-python-data-science)\n\t- http://nuovolabs.fauser.edu/~valeria/materiale-didattico/python/Packt.Mastering.Aug.2015.ISBN.1784390151.pdf\n- #BOOK [Python Data Science Handbook (VanderPlas, 2016 OREILLY)](https://jakevdp.github.io/PythonDataScienceHandbook/)\n\t-  http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb\n- #BOOK [Python for Data Analysis 2nd ed (McKinney, 2017 O'REILLY)](http://wesmckinney.com/pages/book.html)\n\t-  https://github.com/wesm/pydata-book\n- #BOOK [Scala for Data Science (Bugnion, 2016 PACKT)](https://www.packtpub.com/big-data-and-business-intelligence/scala-data-science)\n- #BOOK [Scala: Guide for Data Science Professionals (Nicolas, 2017 PACKT)](http://shop.oreilly.com/product/9781787282858.do)\n- #BOOK [R for Data Science (Grolemund 2017 O'REILLY)](http://r4ds.had.co.nz/)\n- #BOOK [Data Science Live Book (in R)](https://livebook.datascienceheroes.com/)\n- #BOOK [R Programming for Data Science (Peng, 2020)](https://bookdown.org/rdpeng/rprogdatascience/)\n- #BOOK [Statistical Inference via Data Science (Ismay 2020)](https://moderndive.com/)\n- #BOOK [Data Science Live Book (Casas 2020)](https://livebook.datascienceheroes.com/)\n- #BOOK Geographic Data Science with Python: https://geographicdata.science/book/intro.html\n- #BOOK Network Data Science: https://bdpedigo.github.io/networks-course/landing.html\n- #BOOK Python Programming for Data Science: https://www.tomasbeuzen.com/python-programming-for-data-science/README.html\n- #BOOK The Data Science Interview Book: https://dipranjan.github.io/dsinterviewqns/intro.html\n- #BOOK Statistics and Data Science: http://theoryandpractice.org/stats-ds-book/intro.html\n\n\n## Courses\n- #COURSE Mathematical Tools for Data Science (NYU Center for Data Science): https://cds.nyu.edu/math-tools/\n- #COURSE Python for Data Science workshop (Paris-Saclay Center for Data Science): https://github.com/paris-saclay-cds/python-workshop\n- #COURSE Data Science (Harvard CS109): http://cs109.github.io/2015/\n- #COURSE Data 8: The Foundations of Data Science (UC Berkeley). http://data8.org/fa16/\n\t-  https://www.inferentialthinking.com/index.html\n- #COURSE Intro to Data Science (Udacity): https://www.udacity.com/course/intro-to-data-science--ud359\n- #COURSE Introduction to Data Science in Python (Coursera, U Michigan): https://www.coursera.org/learn/python-data-analysis\n- #COURSE Data Science in Stratified Healthcare and Precision Medicine (Coursera, U Edinburgh): https://www.coursera.org/learn/datascimed\n- #COURSE Big Data Analytics in Healthcare (Udacity, Georgia Tech): https://eu.udacity.com/course/big-data-analytics-in-healthcare--ud758\n- #TALK Building a Data Science Team with Open Source Tools: https://www.youtube.com/watch?v=mzTlqNTHTmc\n- #TALK Introduction to Python for Data Science (Seabold, PyCon 2018): https://www.youtube.com/watch?v=W4WQi2OIy7o\n\n## ML platforms\n- #CODE Azure (Microsoft): https://azure.microsoft.com/en-gb/\n\t- Azure ML Studio: https://azure.microsoft.com/en-us/services/machine-learning/\n\t- Microsoft Cognitive Services: https://azure.microsoft.com/en-in/services/cognitive-services/\n- #CODE Google Cloud Platform: https://cloud.google.com/\n\t- https://codelabs.developers.google.com/\n\t- https://cloud.google.com/products/ai/\n\t- https://medium.com/google-cloud/jupyter-tensorflow-nvidia-gpu-docker-google-compute-engine-4a146f085f17\n\t- Cloud [[AI]] building blocks: https://cloud.google.com/products/ai/building-blocks/\n\t- Cloud ML Engine: https://cloud.google.com/ml/\n\t\t- Google Cloud Machine Learning platform: https://cloud.google.com/ml-engine/docs/\n\t\t- #TALK Machine Intelligence at Google Scale: Vision/Speech API (Guillaume Laforge): https://www.youtube.com/watch?v=zqWt8oI4gEw\n\t\t- https://www.slideshare.net/matthiasfeys/machine-learning-at-scale-with-google-cloud-platform\n\t\t- https://github.com/Fematich/mlengine-boilerplate\n\t- [[AI]] Hub: https://cloud.google.com/ai-hub/\n\t- Cloud AutoML: https://cloud.google.com/automl/\n- #CODE Amazon web services (AWS): \n\t- https://aws.amazon.com/\n\t- https://github.com/donnemartin/awesome-aws\n\t- ML on AWS: https://aws.amazon.com/machine-learning/\n\t- SageMaker: https://aws.amazon.com/sagemaker/\n\t- [[AI]] on AWS: https://aws.amazon.com/lex/, https://aws.amazon.com/polly, https://aws.amazon.com/rekognition\n- #CODE Watson (IBM): http://www.ibm.com/watson/\n\t- IBM Watson APIs: https://www.ibm.com/watson/developer/\n\t- http://www.datasciencecentral.com/profiles/blogs/ibm-watson-does-your-taxes-question-answering-machine-versus-expe\n\t- https://www.codecademy.com/learn/ibm-watson\n\t- https://www.ibm.com/cloud/watson-studio\n\t- https://www.ibm.com/watson/services/knowledge-studio/\n- #CODE Dataiku DSS: https://www.dataiku.com/\n- #CODE Domino DataLab: https://www.dominodatalab.com/\n- #CODE RapidMiner: https://rapidminer.com/\n- #CODE Knime: https://www.knime.org/knime-analytics-platform\n\n\n## Interactive Computing Environments\n- #CODE [Jupyter](AI/Data%20Science,%20Data%20Engineering/Jupyter.md)\n- #CODE Zepelin: https://zeppelin.apache.org/\n- #CODE Rstudio: https://www.rstudio.com/products/rstudio/\n- #CODE Cauldron: https://github.com/sernst/cauldron\n\t- http://www.unnotebook.com/\n- #CODE Polynote: https://github.com/polynote/polynote\n\t- https://polynote.org/\n- #CODE Google Colaboratory: https://colab.research.google.com/\n\n\n## Related fields\n\n### Math and Statistics\nSee [Math and Statistics](AI/Math%20and%20Statistics/Math%20and%20Statistics.md)\n\n### Machine Learning\nSee [Machine Learning](AI/Machine%20Learning.md)\n\n### Data engineering and Computer Science\nSee [Data engineering and computer science](AI/Data%20Science,%20Data%20Engineering/Data%20engineering%20and%20computer%20science.md)\n\n### Visualization\nSee [Visualization](AI/Data%20Science,%20Data%20Engineering/Visualization.md)",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/Data-engineering-and-computer-science": {
    "title": "Data Engineering and Computer Science",
    "content": "See [MLOps](AI/Data%20Science,%20Data%20Engineering/MLOps.md)\n\n## Resources\n- https://github.com/ossu/computer-science\n- Data engineering role is ensuring uninterrupted flow of data between servers and applications\n- https://www.datacamp.com/community/blog/data-engineering-vs-data-science-infographic#gs.pvMeguY\n- Interaction between ML and CS teams: https://labs.opendoor.com/2017/02/17/two-cultures-of-ml-systems\n- ETL (extract, transform, load): https://en.wikipedia.org/wiki/Extract,_transform,_load\n- Have we bridged the gap between Data Science and DevOps?: https://jaxenter.com/bridge-gap-data-science-devops-134712.html\n\n### Python\n- #COURSE Python in High Performance Computing: https://www.futurelearn.com/courses/python-in-hpc\n- #COURSE Scientific Computing with Python: https://www.freecodecamp.org/learn/scientific-computing-with-python/\n- #COURSE SoloLearn Python 3 Tutorial: https://www.sololearn.com/Course/Python/\n- #COURSE https://www.learneroo.com/modules/65/nodes/366\n- https://github.com/FavioVazquez/ds-cheatsheets/tree/master/Python\n- https://github.com/ujjwalkarn/DataSciencePython\n- Numpy: http://www.labri.fr/perso/nrougier/from-python-to-numpy/\n- Optimizing Python code performance with cProfile: https://blog.alookanalytics.com/2017/03/21/python-profiling-basics/\n- Consistent Python code with Black: https://www.mattlayman.com/blog/2018/python-code-black/\n- Writing proper classes: https://aboucaud.github.io/slides/2016/python-classes\n- Documenting Python code: https://aboucaud.github.io/slides/2016/python-docstrings\n- Compiled C or Fortran to Python: http://people.duke.edu/~ccc14/sta-663/FromCompiledToPython.html\n- Using Python as glue: https://docs.scipy.org/doc/numpy-1.13.0/user/c-info.python-as-glue.html\n- Extending Python with Compiled Code: https://github.com/AstroHackWeek/AstroHackWeek2014/blob/master/day4/ExtendingPython.ipynb\n- Wrapping C/C++ for Python: https://intermediate-and-advanced-software-carpentry.readthedocs.io/en/latest/c++-wrapping.html\n\n### R\n- #BOOK [R para profesionales de los datos: una introducción](https://www.datanalytics.com/libro_r/)\n- #BOOK [Geocomputation with R](https://geocompr.robinlovelace.net/)\n- #BOOK [Efficient R programming](https://csgillespie.github.io/efficientR/)\n- #BOOK [Engineering Production-Grade Shiny Apps](https://engineering-shiny.org/)\n- #BOOK [Advanced R](https://adv-r.hadley.nz/)\n- #BOOK [Hands-On Programming with R](https://rstudio-education.github.io/hopr/)\n- #BOOK [R Packages (Wickham 2020)](https://r-pkgs.org/)\n\n### Julia \n- #TALK https://www.youtube.com/watch?v=AyvyVS6u8AM\n- https://julialang.org/learning/\n\n### Javascript\n- https://www.w3schools.com/js/\n- https://codesandbox.io\n- https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/JavaScript_basics\n- https://dtabio.gitbooks.io/data-science-with-javascript/content/links_and_resources.html\n- http://www.kdnuggets.com/2016/06/top-machine-learning-libraries-javascript.html\n\n### Bash\n- free GNU/Linux Online Terminal and Programming IDE: http://www.webminal.org/\n\n\n### CUDA\n- https://developer.nvidia.com/cuda-education\n- https://dragan.rocks/articles/18/Interactive-GPU-Programming-1-Hello-CUDA\n\n\n## Books\n- #BOOK Problem Solving with Algorithms and Data Structures using Python (Interactive book): https://runestone.academy/runestone/books/published/pythonds/index.html\n- #BOOK Large Scale Machine Learning with Python (Sjandin 2016, PACKT): https://www.packtpub.com/big-data-and-business-intelligence/large-scale-machine-learning-python\n- #BOOK Mining of Massive Datasets (Leskovec, 2014 CAMBRIDGE): http://www.mmds.org/\n- #BOOK Advanced Analytics with Spark (Ryza, 2017 OREILLY): \n\t- http://shop.oreilly.com/product/0636920056591.do\n\t- https://github.com/analystfreakabhi/btb_spark/blob/master/Advanced%20Analytics%20with%20Spark%2C%202nd%20Edition.pdf\n- #BOOK Pandas cookbook (Petrou, 2017 PACKT): packtpub.com/big-data-and-business-intelligence/pandas-cookbook\n\n## Courses\n- #COURSE Data Structures \u0026 Algorithms - Python: https://pythonschool.net/category/data-structures-algorithms.html\n- #COURSE Intro to Hadoop and MapReduce: https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617\n- #COURSE Mining Massive Data Sets (CS246 Stanford): http://web.stanford.edu/class/cs246/\n\t- https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about\n- #COURSE Getting and Cleaning Data (Coursera): https://www.coursera.org/learn/data-cleaning\n- SQL:\n\t- Tutorial and exercises: http://sqlzoo.net\n\t- SQL (basic, intermediate, advanced / pet problems): \n\t\t- https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/\n\t\t- https://github.com/FavioVazquez/ds-cheatsheets/tree/master/SQL\n\n## Code\n- #CODE ABSL.flags - defines a distributed command line system and manual argument parsing: https://abseil.io/docs/python/guides/flags\n- #CODE StreamAlert: https://github.com/airbnb/streamalert\n\t- StreamAlert is a serverless, realtime data analysis framework which empowers you to ingest, analyze, and alert on data from any environment, using datasources and alerting logic you define\n- #CODE Pandas: https://github.com/pandas-dev/pandas\n\t- https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n\t- https://www.youtube.com/watch?v=9d5-Ti6onew\n\t- https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n\t- Merge, Join and concatenate: http://pandas.pydata.org/pandas-docs/stable/merging.html\n\t- SQL for pandas: http://blog.yhat.com/posts/pandasql-intro.html\n\t- Plotting in pandas: http://pandas.pydata.org/pandas-docs/stable/visualization.html\n\t- http://jakevdp.github.io/blog/2017/03/22/group-by-from-scratch/\n\t- Essential Descriptive Statistics in Pandas: https://simplyml.com/essential-descriptive-statistics-in-pandas/\n\t- Selecting Subsets of Data in Pandas:\n\t\t- https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c\n\t\t- https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-39e811c81a0c\n- #CODE Modin - Scale your pandas workflows by changing one line of code: https://github.com/modin-project/modin\n- #CODE Xarray [[Xarray]]\n- #CODE Dora - Exploratory data analysis toolkit for Python: https://github.com/NathanEpstein/Dora\n- #CODE Dedupe - A python library for accurate and scaleable fuzzy matching, record deduplication and entity-resolution: https://github.com/dedupeio/dedupe\n\t- http://blog.districtdatalabs.com/basics-of-entity-resolution\n- #CODE PyTables: https://github.com/PyTables/PyTables, http://www.pytables.org/\n- #CODE H5py: https://github.com/h5py/h5py\n- #CODE Singer - Simple, Composable Open Source ETL: https://www.singer.io/\n- #CODE Docker: https://www.docker.com/\n\t- https://towardsdatascience.com/docker-for-data-science-4901f35d7cf9\n- #CODE Kubernetes - K8s is an open-source system for automating deployment, scaling, and management of containerized applications.\n\t- https://kubernetes.io/\n\t- https://opensource.com/article/19/1/why-data-scientists-love-kubernetes\n\t- https://github.com/Langhalsdino/Kubernetes-GPU-Guide\n\t- https://blog.alexellis.io/kubernetes-in-10-minutes/\n- Big data, distributed computing\n\t- #CODE Ray - A system for parallel and distributed Python that unifies the ML ecosystem. https://github.com/ray-project/ray\n\t\t- https://ray.readthedocs.io/en/latest/\n\t\t- https://ray-project.github.io/\n\t\t- https://ray-project.github.io/2017/10/15/fast-python-serialization-with-ray-and-arrow.html\n\t\t- #TALK Ray: A Distributed Execution Framework for AI | SciPy 2018 | Robert Nishihara: https://www.youtube.com/watch?v=D_oz7E4v-U0\n\t\t- #TALK Ray: A System for Scalable Python and ML |SciPy 2020| Robert Nishihara: https://www.youtube.com/watch?v=XIu8ZF7RSkw\n\t- #CODE Dask [[Dask]]\n\t- #CODE PyGDF - GPU Data Frame: https://github.com/gpuopenanalytics/pygdf\n\t\t- https://devblogs.nvidia.com/parallelforall/goai-open-gpu-accelerated-data-analytics/\n\t- #CODE Apache Hadoop: http://hadoop.apache.org/\n\t\t- The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models.\n\t\t- https://www.quora.com/What-is-the-difference-between-Apache-Spark-and-Apache-Hadoop-Map-Reduce\n\t\t- Intro to Hadoop and MapReduce (Udacity): https://www.youtube.com/playlist?list=PLAwxTw4SYaPkXJ6LAV96gH8yxIfGaN3H-\n\t\t- https://datawanderings.com/2017/01/15/your-first-diy-hadoop-cluster/\n\t\t- http://ruhanixedu.com/blog/interview-question-and-answers/big-data/\n\t- #CODE Ache Spark: https://en.wikipedia.org/wiki/Apache_Spark\n\t\t- http://cacm.acm.org/magazines/2016/11/209116-apache-spark/fulltext\n\t\t- http://www.kdnuggets.com/2015/11/introduction-spark-python.html\n\t\t- https://databricks.com/blog/2018/05/03/benchmarking-apache-spark-on-a-single-node-machine.html\n\t\t- Spark ML: https://pages.databricks.com/definitive-guide-spark.html\n\t\t- #TALK A brief introduction to Distributed Computing with PySpark (Pydata): https://www.youtube.com/watch?v=bJouNc1REno\n\t\t- #TALK Connecting Python To The Spark Ecosystem: https://www.youtube.com/watch?v=niTAJYCEAUM\n\t    - Photon ML (LinkedIn): https://github.com/linkedin/photon-ml\n\t    - http://tech.marksblogg.com/billion-nyc-taxi-rides-spark-2-1-0-emr.html\n\t    - http://ruhanixedu.com/blog/interview-question-and-answers/apache-spark-interview-questions-answers/\n\t    - Text Normalization with Spark: http://www.treselle.com/blog/text-normalization-with-spark-part-1/\n\t    - Spark ML: http://spark.apache.org/docs/latest/ml-guide.html\n\t\t\t- https://www.infoq.com/articles/apache-sparkml-data-pipelines\n\t\t\t- https://commitlogs.com/2017/02/18/serve-spark-ml-model-using-play-framework-and-s3/\n\t\t- MLlib: http://spark.apache.org/mllib/, https://spark.apache.org/docs/latest/ml-guide.html\n\t\t- PySpark: https://spark.apache.org/docs/latest/api/python/index.html\n\t\t- Optimus: https://github.com/ironmussa/Optimus\n\t- #CODE Apache Storm: https://storm.apache.org/\n\t\t- http://zdatainc.com/2014/09/apache-storm-apache-spark/\n\t\t- http://www.collaberatact.com/understanding-hadoop-vs-spark-vs-storm/\n\t- #CODE Apache Arrow: https://arrow.apache.org/\n\t\t- http://wesmckinney.com/blog/apache-arrow-pandas-internals/\n\t- #CODE Blaze: http://blaze.pydata.org/\n\t\t- http://blaze.readthedocs.io/en/latest/index.html\n- SQL:\n\t- #CODE SQLAlchemy. https://www.sqlalchemy.org/\n\t\t- https://github.com/zzzeek/sqlalchemy\n\t- #CODE Pyodbc: https://github.com/mkleehammer/pyodbc\n\t- #CODE ClickHouse: https://clickhouse.yandex/\n- NoSQL:\n\t- Neo4j: https://neo4j.com/product/\n\t- MongoDB: https://en.wikipedia.org/wiki/MongoDB\n\t- PyMongo: https://api.mongodb.com/python/current/\n\t- CouchDB: https://en.wikipedia.org/wiki/CouchDB\n\n\n## Subtopics\n\n### Open datasets (for ML and DS)\n- https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research\n- OpenML (open-source datasets): http://www.openml.org/\n\t- API: https://docs.openml.org/APIs/\n- Awesome Public Datasets (high quality datasets from communities such as academia, education etc): https://github.com/awesomedata/awesome-public-datasets\n- Registry of Open Data on AWS: https://aws.amazon.com/es/public-datasets/?nc1=h_ls\n- http://blog.thedataincubator.com/tag/data-sources/\n- For reinforcement learning algorithms: https://gym.openai.com/\n- Data Is Plural - newsfeed: http://tinyletter.com/data-is-plural/archive\n- A list of publicly available datasets: https://www.datascienceweekly.org/data-science-resources/data-science-datasets\n- Datasets for data mining (ML): http://www.inf.ed.ac.uk/teaching/courses/dme/html/datasets0405.html\n- Greatest Public Datasets for AI/ML: https://medium.com/startup-grind/fueling-the-ai-gold-rush-7ae438505bc2\n- Free TEXT Datasets: https://webhose.io/datasets\n- Open knowledge foundation repository (varied formats and sources): https://datahub.io/dataset\n\n\n### Feature engineering\n- https://en.wikipedia.org/wiki/Feature_engineering\n- Feature engineering is the process of using domain knowledge of the data to create features that make [[machine learning]] algorithms work. It is fundamental to the application of ML, and is both difficult and expensive. The need for manual feature engineering can be obviated by automated [[feature learning]].\n- http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/\n- https://tech.zalando.com/blog/feature-extraction-science-or-engineering/\n\n#### Feature extraction\nSee [Feature learning](AI/Feature%20learning.md) techniques in [Computer vision](AI/Computer%20Vision/Computer%20vision.md).\n\n\n### Data mining\n- http://nbviewer.jupyter.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/tree/master/ipynb/\n- https://www.dataquest.io/course/apis-and-scraping\n\n#### Web scraping\n- https://www.dataquest.io/blog/web-scraping-tutorial-python/\n- http://thiagomarzagao.com/2013/11/12/webscraping-with-selenium-part-1/\n- https://medium.com/@hoppy/how-to-test-or-scrape-javascript-rendered-websites-with-python-selenium-a-beginner-step-by-c137892216aa#.hrjljvffd\n- https://antonio-maiolo.com/2016/12/01/web-crawler-scrapy-crawl-spider-tutorial/\n- http://stackoverflow.com/questions/19021541/scrapy-scrapping-data-inside-a-javascript\n\n#### API\n- A categorized public list of APIs from round the web: https://github.com/abhishekbanthia/Public-APIs\n- A collective list of public JSON APIs for use in web development: https://github.com/toddmotto/public-apis\n- Public APIs: https://public-apis.io/\n\n\n### Databases\n- https://en.wikipedia.org/wiki/Distributed_database\n- ACID (Atomicity, Consistency, Isolation, Durability) : https://en.wikipedia.org/wiki/ACID\n- SQL vs NoSQL: http://dataconomy.com/2014/07/sql-vs-nosql-need-know/\n\n#### SQL\n- https://en.wikipedia.org/wiki/SQL\n- https://en.wikipedia.org/wiki/Relational_database\n- A relational database is a digital database whose organization is based on the relational model of data. \n- https://www.analyticsvidhya.com/blog/2017/01/46-questions-on-sql-to-test-a-data-science-professional-skilltest-solution/\n- Tutorial and exercises: http://sqlzoo.net\n- SQL (basic, intermediate, advanced / pet problems): https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/\n- List of SQL Commands: https://www.codecademy.com/articles/sql-commands\n- JOIN: https://en.wikipedia.org/wiki/Join_(SQL)\n\t- A SQL join clause combines columns from one or more tables in a relational database. It creates a set that can be saved as a table or used as it is. A JOIN is a means for combining columns from one (self-table) or more tables by using values common to each. ANSI-standard SQL specifies five types ofJOIN:INNER,LEFT OUTER,RIGHT OUTER,FULL OUTER and CROSS.\n\t- https://periscopedata.com/blog//how-joins-work.html\n- https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems\n- Python interface\n\t- https://www.tutorialspoint.com/python/python_database_access.htm\n\t- http://www.python-course.eu/sql_python.php\n\t- https://wiki.python.org/moin/DatabaseInterfaces\n\n#### NoSQL\n- https://en.wikipedia.org/wiki/NoSQL\n- Not only SQL: A NoSQL database provides a mechanism for storage and retrieval of data which is modeled in means other than the tabular relations used in relational databases. NoSQL databases are increasingly used in big data and real-time web applications. Many NoSQL stores compromise consistency (in the sense of theCAP theorem) in favor of availability, partition tolerance, and speed. \n- Column: Accumulo, Cassandra, Druid, HBase, Vertica, SAP HANA \n- #TALK GOTO 2012 - Introduction to NoSQL - Martin Fowler: https://www.youtube.com/watch?v=qI_g07C_Q5I\n- Graph: \n\t- A graph database is a database that uses graph structures for semantic queries with nodes, edges and properties to represent and store data. A key concept of the system is the graph (or edge or relationship), which directly relates data items in the store. The relationships allow data in the store to be linked together directly, and in many cases retrieved with a single operation.\n\t- Graph databases employ nodes, edges and properties.\n\t\t- Nodes represent entities/items you might want to keep track of (people, businesses, accounts).\n\t\t- Edges, also known as graphs or relationships, are the lines that connect nodes to other nodes; they represent the relationship between them.\n\t\t- Properties are pertinent information that relate to nodes (sort of keywords).\n\t\t- AllegroGraph, ArangoDB, InfiniteGraph, Apache Giraph, MarkLogic, Neo4J, OrientDB, Virtuoso, Stardog\n\t\t- https://neo4j.com/developer/graph-database/\n- Key-value\n\t- https://en.wikipedia.org/wiki/Key-value_database\n\t- A key-value store, or key-value database, is a data storage paradigm designed for storing, retrieving, and managing associative arrays, a data structure more commonly known today as a dictionary or hash.\n\t- Dictionaries contain a collection of objects, or records, which in turn have many different fields within them, each containing data. These records are stored and retrieved using a key that uniquely identifies the record, and is used to quickly find the data within the database.\n- Document: https://en.wikipedia.org/wiki/Document-oriented_database\n\n### Data munging\n- https://www.coursera.org/learn/data-cleaning\n\n#### Data preparation\n- Data cleansing: Missing data\n\t- https://scikit-learn.org/stable/modules/impute.html\n\t- https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#two\n\t- https://www.quora.com/How-can-I-deal-with-missing-values-in-a-predictive-model\n- Variables encoding: http://pbpython.com/categorical-encoding.html\n- Normalisation, scaling: http://scikit-learn.org/stable/modules/preprocessing.html\n- Outlier detection: https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#three\n\n#### Exploratory data analysis\n- https://www.codementor.io/jadianes/data-science-python-r-exploratory-data-analysis-visualization-du107jjms\n- http://blog.districtdatalabs.com/data-exploration-with-python-2\n- https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/\n\n\n### Big data\n- http://www.datasciencecentral.com/profiles/blogs/25-big-data-terms-you-must-know-to-impress-your-date-or-whoever\n- Architecture of Giants: Data Stacks at Facebook, Netflix, Airbnb, and Pinterest: https://blog.keen.io/architecture-of-giants-data-stacks-at-facebook-netflix-airbnb-and-pinterest-9b7cd881af54\n\n#### MapReduce\n- https://en.wikipedia.org/wiki/MapReduce\n- MapReduce is a programming model and an associated implementation for processing and generating large data sets with a parallel, distributed algorithm on a cluster\n- A MapReduce program is composed of aMap() procedure (method) that performs filtering and sorting (such as sorting students by first name into queues, one queue for each name) and aReduce() method that performs a summary operation (such as counting the number of students in each queue, yielding name frequencies)",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/Distributed-DL": {
    "title": "Distributed Deep learning",
    "content": "## Resources\n- https://d2l.ai/chapter_computational-performance/multiple-gpus.html \n- https://jhui.github.io/2017/03/07/TensorFlow-GPU/ \n- https://www.logicalclocks.com/blog/goodbye-horovod-hello-collectiveallreduce \n- Twelve ways to fool the masses when reporting performance of deep learning workloads: https://htor.inf.ethz.ch/blog/index.php/2018/11/08/twelve-ways-to-fool-the-masses-when-reporting-performance-of-deep-learning-workloads/\n- Distributed Deep Learning 101: Introduction: https://towardsdatascience.com/distributed-deep-learning-101-introduction-ebfc1bcd59d9\n- #TALK ALCF Datascience frameworks: Tensorflow, PyTorch, Keras, and Horovod: https://www.alcf.anl.gov/files/Zheng_SDL_ML_Frameworks_1.pdf\n- #TALK Scaling [[Deep Learning]] for Scientific Workloads on the #1 Summit Supercomputer: https://insidehpc.com/2019/04/scaling-deep-learning-for-scientific-workloads-on-the-1-summit-supercomputer/\n\n## Code\nSee [Tensorflow, keras#Distributed training](Tensorflow,%20keras.md#Distributed%20training)\n\n- #CODE Analytics Zoo: https://github.com/intel-analytics/analytics-zoo\n\t- Distributed Tensorflow, Keras and PyTorch on Apache Spark/Flink \u0026 Ray\n\t- https://analytics-zoo.readthedocs.io/en/latest/index.html\n- #CODE  [Horovod](Horovod.md)\n- #CODE Colossal-AI: A Unified Deep Learning System for Large-Scale Parallel Training: https://github.com/hpcaitech/colossalai\n\t- See [[#^colossalai]]\n\t-  https://www.marktechpost.com/2021/10/31/researchers-introduce-colossal-ai-a-pytorch-based-deep-learning-system-for-large-scale-parallel-training/\n\n## References\n- #PAPER Evaluation of Deep Learning Frameworks over Different HPC Architectures (Shams 2017): https://www.ibm.com/university/power/images/EvaluationofDeepLearningFrameworksoverDifferentHPCArchitectures.pdf\n- #PAPER Deep Learning at 15PF: Supervised and Semi-Supervised Classification for Scientific Data (Kurth 2017): https://arxiv.org/abs/1708.05256\n- #PAPER Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis (Tal Ben-Nun and Torsten Hoefler 2018): http://arxiv.org/abs/1802.09941 ^bennun18\n\t- #TALK Hoefler 2018: https://www.youtube.com/watch?v=xtxxLWZznBI\n\t- #TALK Hoefler 2020: https://www.youtube.com/watch?v=uNzQ1vvJ82c\n\t- #TALK Ben-Nun 2020: https://www.youtube.com/watch?v=N5uIFSVR7jE\n- #PAPER Mesh-TensorFlow: Deep Learning for Supercomputers (Shazeer 2018): https://arxiv.org/abs/1811.02084v1 ^f86598\n\t- #TALK https://www.youtube.com/watch?v=HgGyWS40g-g\n\t- #CODE Mesh-TensorFlow: https://github.com/tensorflow/mesh\n\t\t- Go beyond data-parallel training\n\t\t- More sophisticated parallel computations (big models that do not fit on one device)\n- #PAPER GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism (Huang 2019): http://arxiv.org/abs/1811.06965\n- #PAPER A Quantitative Study of Deep Learning Training on Heterogeneous Supercomputers (Han 2019): https://ieeexplore.ieee.org/document/8890993\n\t- http://people.cs.vt.edu/~butta/docs/cluster2019-DL.pdf\n- #PAPER Channel and filter parallelism for large-scale CNN training (Dryden 2019): https://dl.acm.org/doi/10.1145/3295500.3356207\n\t- https://ndryden.com/data/papers/sc2019-chanfilt.pdf\n- #PAPER Improving Strong-Scaling of CNN Training by Exploiting Finer-Grained Parallelism (Dryden 2019): http://arxiv.org/abs/1903.06681\n- #PAPER Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training (Li 2019): http://arxiv.org/abs/1811.03619\n- #PAPER Scalable Deep Learning on Distributed Infrastructures: Challenges, Techniques and Tools (Mayer 2019): http://arxiv.org/abs/1903.11314\n- #PAPER Performance Analysis of Deep Learning Workloads on Leading-edge Systems (Ren 2019): https://www.osti.gov/biblio/1571428-performance-analysis-deep-learning-workloads-leading-edge-systems\n- #PAPER TensorFlow on State-of-the-Art HPC Clusters: A Machine Learning use Case (Ramirez-Gargallo 2019): https://ieeexplore.ieee.org/document/8752892 ^ramirez19\n\t- https://core.ac.uk/download/pdf/196280993.pdf \n\t- Compared MN4, Power9 and Dibona HPC clusters. Only CPUs compared (Power9 GPUs are not evaluated)\n- #PAPER Exascale Deep Learning for Scientific Inverse Problems (Laanait 2019): http://arxiv.org/abs/1909.11150\n- #PAPER ZeRO: memory optimizations toward training trillion parameter models (Rajbhandari 2019): https://arxiv.org/abs/1910.02054\n\t- #CODE DeepSpeed: https://github.com/microsoft/DeepSpeed\n\t\t- DeepSpeed is a deep learning optimization library that makes distributed training easy, efficient, and effective. For pytorch\n\t\t- www.deepspeed.ai/\n\t- https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/\n- #PAPER Towards a Scalable and Distributed Infrastructure for Deep Learning Applications (Hasheminezhad 2020): https://arxiv.org/abs/2010.03012\n\t- Phylanx Deep Learning Framework\n\t- Good comparison with respect to SOTA\n\t- Phylanx provides a high-productivity debugable Python-based interactive interface, JetLag: https://github.com/STEllAR-GROUP/JetLag\n\t- Tests only on CPU. Does it support GPUs?\n- #PAPER Distributed Training of Deep Learning Models: A Taxonomic Perspective (Langer 2020): https://arxiv.org/abs/2007.03970\n- #PAPER Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training (Bian 2021): https://arxiv.org/abs/2110.14883 ^colossalai",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/Horovod": {
    "title": "Horovod",
    "content": "## References\n- #PAPER Horovod: fast and easy distributed deep learning in TensorFlow (Sergeev 2018): http://arxiv.org/abs/1802.05799 \n\t- #CODE https://github.com/horovod/horovod \n\t- https://horovod.readthedocs.io/en/latest/keras.html \n\t- https://horovod.readthedocs.io/en/stable/tensorflow.html\n\t- https://eng.uber.com/horovod/\n\t- Horovod is a distributed training framework for TensorFlow, Keras, PyTorch, and MXNet. The goal of Horovod is to make distributed [[Deep Learning]] fast and easy to use. Horovod is hosted by the LF AI Foundation (Linux Foundation AI). Horovod implements all-reduce operations into the back-propagation computation to average the computed gradients and allow the distributed scaling among multiple GPUs. Based on Baidu ring allreduce: http://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/ \n\t- Not straightforward from Jupyterlab: https://github.com/horovod/horovod/issues/622. Possible solution - Ipyparallel:\n\t\t- Interactive Distributed Deep Learning with Jupyter Notebooks: https://sc18.supercomputing.org/proceedings/tech_poster/poster_files/post206s2-file3.pdf\n\t\t- https://github.com/sparticlesteve/cori-intml-examples \n\n## Examples\n- https://github.com/horovod/horovod/tree/master/examples\n- https://horovod.readthedocs.io/en/stable/running_include.html\n- https://github.com/horovod/tutorials/blob/master/fashion_mnist/README.md \n- Distributed Deep Learning with Horovod (Jordi Torres): https://towardsdatascience.com/distributed-deep-learning-with-horovod-2d1eea004cb2\n- https://towardsdatascience.com/a-quick-guide-to-distributed-training-with-tensorflow-and-horovod-on-amazon-sagemaker-dae18371ef6e \n- with SLURM on the BSC-P9 cluster: https://towardsdatascience.com/distributed-deep-learning-with-horovod-2d1eea004cb2\n- With SLURM workload manager. See paper [[Distributed DL#^ramirez19]]\n- Example with SLURM: http://www.idris.fr/eng/jean-zay/gpu/jean-zay-gpu-hvd-tf-multi-eng.html",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/Jupyter": {
    "title": "Jupyter",
    "content": "## Resources\n- #CODE Jupyter: https://github.com/jupyter\n\t- #CODE Jupyterlab: https://github.com/jupyterlab/jupyterlab \n\t- #CODE Jupyter(hub): https://jupyter.org/hub \n\t- #CODE Jupyterlite: https://github.com/jupyterlite\n\t\t- https://blog.jupyter.org/jupyterlite-jupyter-%EF%B8%8F-webassembly-%EF%B8%8F-python-f6e2e41ab3fa\n- #CODE Papermill - Parameterize, execute, and analyze notebooks: https://github.com/nteract/papermill\n- #CODE Beaker kernels and extensions: http://beakerx.com/\n- Juypterbook - Books with Jupyter: https://jupyterbook.org/intro.html\n- [Executing notebooks from the command line](https://nbconvert.readthedocs.io/en/latest/execute_api.html#executing-notebooks-from-the-command-line \"Permalink to this headline\")\n\t- `$ jupyter nbconvert --to notebook --inplace --ExecutePreprocessor.timeout=None --execute mynotebook.ipynb`\n\n## Jupyter in HPC\n- High-level scripting languages such as Python, R and Julia, have become the go-to choices in the world of Data Science and ML/AI. Project Jupyter exists to develop open-source software, open-standards, and services for interactive computing across dozens of programming languages. For instance, the Jupyter Notebook is an open-source web-app that allows users to write portable documents containing executable code, narrative text, and equations, and to visualize the results of running the code directly in the web browser. The name comes from a combination of the three core programming languages of Jupyter (Julia, Python and R) though Jupyter is not limited to these languages.  \n- Tools in the Jupyter ecosystem are designed in a modular fashion, and behave similarly on a researcher's laptop, a high-performance computing center, or the cloud. As a result, Jupyter technologies have been widely adopted across a spectrum of scientific disciplines, including Earth Sciences (Perez et al. 2019).  \n- JupyterHub brings the power of notebooks to groups of users. It gives users access to computational environments and resources without burdening the users with installation and maintenance tasks. These are a few examples of JupyterHub systems running on supercomputing systems: \n\t- University Corporation for Atmospheric Research (UCAR, https://jupyterhub.ucar.edu/)  \n\t- CSCS, ETH Zurich (https://jupyter.cscs.ch/hub/login) \n\t- CHPC, University of Utah (https://www.chpc.utah.edu/documentation/software/jupyterhub.php#hub, http://notebook.chpc.utah.edu/) \n\t- Minesota supercomputing institute (https://www.msi.umn.edu/content/msi-beta) \n- A common denominator of these computing platforms is that they allow the interactive execution of Jupyter tools on HPC systems over multiple nodes. The user is offered to choose the job configuration options in order to allocate the resources to be used to run Jupyter: account, number of nodes, access to GPUs, wall-clock time, etc.  \n- Interactive supercomputing with Jupyter lab: https://www.cscs.ch/publications/news/2019/interactive-supercomputing-with-jupyterlab/\n\n- #PAPER Jupyter as common technology platform for interactive HPC services (Milligan 2018): https://arxiv.org/abs/1807.09929\n- #PAPER Jupyter meets the Earth: Enabling discovery in geoscience through interactive computing at scale (Perez 2019): https://zenodo.org/record/3369939 \n- #PAPER Interactive Supercomputing with Jupyter (Thomas 2021): https://authorea.com/doi/full/10.22541/au.161230518.84458221 ^thomas21hpcjupyter\n\n\n## Ipython\n- Save interactive ipython session: `%history -f /tmp/history.py`",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/MLops": {
    "title": "ML Ops",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/MLOps\n- Set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently. The word is a compound of \"machine learning\" and the continuous development practice of DevOps in the software field\n- https://github.com/GokuMohandas/MadeWithML\n- https://github.com/visenger/awesome-mlops\n- https://github.com/EthicalML/awesome-production-machine-learning\n\n## Code\n### Experiment tracking\n- https://neptune.ai/blog/best-ml-experiment-tracking-tools\n- #CODE Weights \u0026 Biases: https://docs.wandb.com/\n\t- Library that -helps you keep track of your machine learning projects. Use our tool to log hyperparameters and output metrics from your runs, then visualize and compare results and quickly share findings with your colleagues.\n- #CODE Aim: https://github.com/aimhubio/aim\n\t- The open-source tool for ML experiment comparison\n\t- https://aimstack.io/\n- #CODE ClearML: https://github.com/allegroai/clearml\n\t- https://clear.ml/\n\n### Workflow managers\n- #CODE MLFlow: https://github.com/mlflow/mlflow/ \n\t- An open source platform for the machine learning lifecycle. https://mlflow.org\n- #CODE Airflow: Apache Airflow - A platform to programmatically author, schedule, and monitor workflows. https://github.com/apache/airflow\n\t- http://nerds.airbnb.com/airflow/\n\t- https://medium.com/datasd/why-data-automation-matters-4391d59e1952\n- #CODE Luigi (Spotify): https://github.com/spotify/luigi\n\t- https://luigi.readthedocs.io/en/latest/\n- #CODE Azkaban: https://github.com/azkaban/azkaban\n\t- https://azkaban.github.io/\n- #CODE Clipper\t- A low-latency prediction-serving system. http://clipper.ai\n- #CODE PredictionIO: https://predictionio.apache.org",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/Tensorflow-keras": {
    "title": "Tensorflow, Keras",
    "content": "## Code\n- #CODE Tensorflow (Google): https://github.com/tensorflow/tensorflow\n\t- http://playground.tensorflow.org/\n\t- https://cloud.google.com/blog/big-data/2016/07/understanding-neural-networks-with-tensorflow-playground\n\t- https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc#.dg41ldof5\n\t- https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0\n\t- Tensorflow 2.0: models migration and new design: https://pgaleone.eu/tensorflow/gan/2018/11/04/tensorflow-2-models-migration-and-new-design/\n\t- http://planspace.org/20170404-how_not_to_program_the_tensorflow_graph/\n- #CODE TF Similarity: https://github.com/tensorflow/similarity\n\t- https://blog.tensorflow.org/2021/09/introducing-tensorflow-similarity.html\n\t- Metric learning is different from traditional classification as it's objective is different. The model learns to minimize the distance between similar examples and maximize the distance between dissimilar examples, in a supervised or self-supervised fashion\n- #CODE TF Probability: https://github.com/tensorflow/probability\n\t- Probabilistic reasoning and statistical analysis in TensorFlow\n\t- https://www.tensorflow.org/probability\n- #CODE TF Decision Forests: https://github.com/tensorflow/decision-forests\n\t- A collection of state-of-the-art algorithms for the training, serving and interpretation of Decision Forest models in Keras\n\t- https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html\n\t- https://towardsdatascience.com/tensorflow-decision-forests-train-your-favorite-tree-based-models-using-keras-875d05a441f\n\t- Decision forests in TF: https://www.youtube.com/watch?v=5qgk9QJ4rdQ\n- #CODE TF Datasets: https://github.com/tensorflow/datasets\n- #CODE TF Agents: https://github.com/tensorflow/agents\n\t- A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning\n- #CODE TF Recommenders: https://github.com/tensorflow/recommenders \n\t- Library for building recommender system models using TensorFlow.\n- #CODE TF Graphics: https://github.com/tensorflow/graphics\n\t- Differentiable Graphics Layers for TensorFlow\n- #CODE TF Ranking: https://github.com/tensorflow/ranking\n\t- Learning to Rank in TensorFlow\n- #CODE Tensorboard: https://github.com/tensorflow/tensorboard\n\t- https://tensorboard.dev/\n\t- https://www.tensorflow.org/tensorboard/get_started (use as a jupyterlab magic)\n- #CODE Tensorflow.js: https://www.tensorflow.org/js/\n- #CODE TF On Spark: https://github.com/yahoo/TensorFlowOnSpark\n- #CODE Sonnet: https://github.com/deepmind/sonnet\n\t- https://deepmind.com/blog/open-sourcing-sonnet/\n- #CODE seq2seq: https://github.com/google/seq2seq\n- #CODE Tensor2Tensor: https://github.com/tensorflow/tensor2tensor\n\t- https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html\n- #CODE Graph Nets - Build Graph Nets in Tensorflow: https://github.com/deepmind/graph_nets\n\t- https://arxiv.org/abs/1806.01261\n- TF Graph Visualizer: http://idl.cs.washington.edu/papers/tfgraph/\n- #CODE Tensorpack - It's Yet Another TF high-level API, with speed, and flexibility built together. https://github.com/tensorpack/tensorpack\n- #CODE Cleverhans - A library for benchmarking vulnerability to adversarial examples: https://github.com/tensorflow/cleverhans\n\t- http://karpathy.github.io/2015/03/30/breaking-convnets/\n\t- https://blog.openai.com/adversarial-example-research/\n\n\n## Keras\n- #CODE Keras: https://github.com/keras-team/keras \n\t- Keras is a deep learning API written in Python, running on top of the machine learning platform Tensorflow\n\t- http://keras.io/\n\t- https://keras.io/getting_started/intro_to_keras_for_researchers/\n\t- Modern Keras design patterns: https://www.youtube.com/watch?v=FCz9m4T0DI0\n- #CODE AutoKeras - Auto-Keras is an open source software library for automated machine learning (AutoML): https://github.com/keras-team/autokeras\n\t- http://autokeras.com/\n\t- #PAPER Auto-Keras: An Efficient Neural Architecture Search System (Jin 2019): https://arxiv.org/abs/1806.10282\n\t- https://towardsdatascience.com/autokeras-the-killer-of-googles-automl-9e84c552a319\n\n\n## Distributed training\n- https://missinglink.ai/guides/tensorflow/tensorflow-distributed-training-introduction-tutorials/ \n- TF.Distribute\n\t- https://www.tensorflow.org/guide/distributed_training \n\t- https://www.tensorflow.org/guide/gpu\n\t- https://keras.io/guides/distributed_training/\n\t- #TALK Inside TensorFlow: tf.data + tf.distribute: https://www.youtube.com/watch?v=ZnukSLKEw34\n- Numpy to tf.record: https://gist.github.com/swyoon/8185b3dcf08ec728fb22b99016dd533f\n- https://www.tensorflow.org/tutorials/distribute/keras \n- https://www.tensorflow.org/tutorials/distribute/custom_training \n- https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#scrollTo=9iagoTBfijUz \n- Train a Neural Network on multi-GPU with TensorFlow (Jordi Torres): https://towardsdatascience.com/train-a-neural-network-on-multi-gpu-with-tensorflow-42fa5f51b8af\n- Multinode example: https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md\n- MultiWorkerMirroredStrategy:\n\t- https://www.tensorflow.org/api_docs/python/tf/distribute/MultiWorkerMirroredStrategy (after TF v2)\n\t- https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy\n\t- https://blog.tensorflow.org/2020/12/whats-new-in-tensorflow-24.html (TF v2.4)\n\t- https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras \n\t- https://github.com/tensorflow/tensorflow/issues/36094\n- https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/SlurmClusterResolver \n- https://lambdalabs.com/blog/tensorflow-2-0-tutorial-05-distributed-training-multi-node/ \n\nData lazy loading: \n- Tf.data:\n\t- https://www.tensorflow.org/api_docs/python/tf/data/Dataset \n\t- https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator\n\t- https://www.tensorflow.org/tutorials/distribute/input\n- Tensorflow data netcdf, MATEX tensorflow (seems to be abandoned) :https://github.com/matex-org/matex/wiki/DataSet-Reader",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/Visualization": {
    "title": "Visualization",
    "content": "## Resources\n- https://github.com/fasouto/awesome-dataviz\n- http://keshif.me/demo/VisTools\n- The visualization universe: http://visualizationuniverse.com/\n\t- http://visualizationuniverse.com/charts/\n- Dataviz project: https://datavizproject.com/\n- UW Interactive Data Lab: http://idl.cs.washington.edu/\n- Flowing Data Tutorials: https://flowingdata.com/category/tutorials/\n- http://www.coolinfographics.com/blog/2017/1/10/digital-marketing-tools-landscape.html\n- https://www.analyticsvidhya.com/blog/2015/09/infographic-tools-data-visualization/\n- https://visme.co/blog/examples-data-visualizations/\n- https://towardsdatascience.com/3rd-wave-data-visualization-824c5dc84967\n- What's so hard about histograms?: https://tinlizzie.org/histograms/\n- Dataviz tools: http://visualizationuniverse.com/tools/\n- Data visualization tools and books: https://keshif.me/demo/VisTools\n- Python data viz tools: http://blog.yhat.com/posts/python-data-viz-landscape.html\n- Dataviz.tools: A curated guide to the best tools, resources and technologies for data viz. http://dataviz.tools/\n- Dashboard design (how-to): http://www.designyourway.net/blog/inspiration/showcase-of-beautiful-dashboard-ui-designs/    \n- Python Data Visualization 2018 (Anaconda)\n\t1. Why So Many Libraries?: https://www.anaconda.com/blog/developer-blog/python-data-visualization-2018-why-so-many-libraries/\n\t2. Moving Toward Convergence: https://www.anaconda.com/blog/developer-blog/python-data-visualization-moving-toward-convergence/\n\t3. Where Do We Go From Here?: https://www.anaconda.com/blog/developer-blog/python-data-visualization-2018-where-do-we-go-from-here/\n\n## Books\n- Dataviz books: http://visualizationuniverse.com/books/?sortBy=volume\u0026sortDir=desc\n- #BOOK [Fundamentals of Data Visualization (Wilke 2020)](https://clauswilke.com/dataviz/)\n- #BOOK [Data Visualization (Healy 2020)](https://socviz.co/)\n- #BOOK [R Graphics Cookbook, 2nd edition](https://r-graphics.org/)\n\n## Courses\n- #COURSE Information Visualization (CS 465, Middlebury): http://www.cs.middlebury.edu/~candrews/archive/infovis_s14/\n- #COURSE [Data Visualization (CSE512, U Washington)](http://courses.cs.washington.edu/courses/cse512/14wi/)\n\t- https://github.com/uwdata/d3-tutorials\n- #COURSE Data Science: Visualization (Harvard-edX): https://www.edx.org/course/data-science-visualization-harvardx-ph125-2x\n- #COURSE Reading and interpreting data (Khan academy): https://www.khanacademy.org/math/pre-algebra/pre-algebra-math-reasoning\n- #TALK 23 Visualizations and When to Use Them in 30 Minutes: https://www.youtube.com/watch?v=RG_BKQRbJZw\n- #TALK The Python Visualization Landscape (Vanderplas, Pycon 2017): \n\t- https://www.youtube.com/watch?v=FytuB8nFHPQ\n\t- https://us.pycon.org/2017/schedule/presentation/616/\n- #TALK Everything we know about how humans interpret graphics (Elliot 2016): https://www.youtube.com/watch?v=s0J6EDvlN30\n- #TALK Constructive Code Review (Rose, PyCon 2017): https://www.youtube.com/watch?v=iNG1a--SIlk\n\n## Code\n- #CODE Matplotlib: https://matplotlib.org/\n\t- http://nbviewer.jupyter.org/github/cs109/content/blob/master/lec_03_statistical_graphs.ipynb\n- #CODE Seaborn: http://seaborn.pydata.org/\n- #CODE Bokeh: https://github.com/bokeh/bokeh\n- #CODE Plotly: https://github.com/plotly\n\t- https://github.com/plotly/plotly.js\n\t- http://blog.yhat.com/posts/visualize-nba-pipelines.html\n- #CODE Lightning: http://lightning-viz.org/\n\t- Lightning is a data-visualization server providing API-based access to reproducible, web-based, interactive visualizations\n\t- https://github.com/lightning-viz/lightning-python\n- #CODE Perspective: https://jpmorganchase.github.io/perspective/\n- #CODE D3.js: https://d3js.org/\n\t- http://chimera.labs.oreilly.com/books/1230000000345/index.html\n\t- https://github.com/d3/d3/wiki/Tutorials\n\t- https://blog.datazar.com/the-best-resources-when-learning-d3-js-7da4ba0a783e#.oyw1gyxzz\n\t- https://learningd3.com/\n\t- https://learningd3.com/blog/generative-art/\n\t- http://blog.thedataincubator.com/2015/08/embedding-d3-in-an-ipython-notebook/\n\t- https://datawanderings.com/2017/01/29/data-visualisation-from-scratch-with-d3-js-part-1-canvas-setup/\n\t- D3 Tips and Tricks: https://leanpub.com/D3-Tips-and-Tricks\n\t- Blocks - database of examples: https://bl.ocks.org/\n\t- Building a storytelling scroller with D3: http://vallandingham.me/scroller.html\n\t- Interactive Data Visualization for the Web: http://chimera.labs.oreilly.com/books/1230000000345/index.html\n\t- https://www.analyticsvidhya.com/blog/2017/08/visualizations-with-d3-js/\n\t- PykCharts.js: https://github.com/pykih/PykCharts.js\n\t- dc.js: https://dc-js.github.io/dc.js/\n- #CODE deck.gl (Uber) - deck.gl is a WebGL-powered framework for visual exploratory data analysis of large datasets: https://eng.uber.com/deck-gl-framework/\n- #CODE Visdom (Facebook) - A flexible tool for creating, organizing, and sharing visualizations of live, rich data. Supports Torch and Numpy: https://github.com/facebookresearch/visdom\n- #CODE Vega: https://github.com/vega/vega\n\t- https://github.com/vega/vega-lite\n\t- https://github.com/vega/voyager\n\t- https://github.com/vega/lyra\n- #CODE Altair: https://altair-viz.github.io/\n\t- #TALK Jake VanderPlas - Exploratory Data Visualization with Vega, Vega-Lite, and Altair - PyCon 2018. https://www.youtube.com/watch?v=ms29ZPUKxbU\n- #CODE Bqplot (Bloomberg) - Plotting library for IPython/Jupyter Notebooks: https://github.com/bloomberg/bqplot\n\t- #TALK PyData Ann Arbor: Dhruv Madeka | Interactive Data Visualization in Jupyter Notebook Using bqplot: https://www.youtube.com/watch?v=wJS4S0WB4Jw\n- #CODE Chartify (Spotify): https://github.com/spotify/chartify/\n\t- https://labs.spotify.com/2018/11/15/introducing-chartify-easier-chart-creation-in-python-for-data-scientists/\n\t- Chartify is a Python library that makes it easy for data scientists to create charts.\n- #CODE ggplot2 (for R): http://ggplot2.org/\n- Graphs, networks:\n\t- #CODE NetworkX: https://networkx.github.io/\n\t- #CODE Gephi: https://gephi.org/\n\t- #CODE Graph-tool: https://graph-tool.skewed.de/\n\t- #CODE igraph: http://igraph.org/\n\t- #CODE Graphviz: http://www.graphviz.org/\n- Dashboards (webapps):\n\t- #CODE Dash - Interactive, reactive web apps in pure python: https://plot.ly/products/dash\n\t\t- https://medium.com/@plotlygraphs/introducing-dash-5ecf7191b503\n\t\t- #TALK Dash - A New Framework for Building User Interfaces for Technical Computing | SciPy 2017 | Chris Par: https://www.youtube.com/watch?v=sea2K4AuPOk\n\t- #CODE Redash: https://redash.io/\n\t- #CODE Superset:  http://airbnb.io/projects/superset/\n\t\t- https://medium.com/airbnb-engineering/caravel-airbnb-s-data-exploration-platform-15a72aa610e5\n\t\t- https://indatalabs.com/blog/data-strategy/open-source-data-visualization-tool-superset\n\t- #CODE Shiny (for R)\n\t\t- https://shiny.rstudio.com/\n\t\t- http://www.htmlwidgets.org/\n\t- #CODE Pyxley - Python helpers for building dashboards using Flask and React: \n\t\t- https://github.com/stitchfix/pyxley\n\t\t- http://multithreaded.stitchfix.com/blog/2015/07/16/pyxley/\n\t- #CODE Spyre: https://github.com/adamhajari/spyre\n\t- #CODE Bowtie: http://bowtie-py.readthedocs.io/en/latest/\n\t- #CODE Stackimpact-python: https://stackimpact.com\n- #CODE PyViz: https://github.com/pyviz\n\t- HoloViews: https://holoviews.org/\n\t- Panel: https://panel.pyviz.org/\n\t- Datashader: http://datashader.org\n\t - GeoViews: http://geoviews.org/ \n\t - Hvplot: https://hvplot.pyviz.org/\n- #CODE Ipyvolume: https://ipyvolume.readthedocs.io/en/latest/\n- #CODE Vaex: https://vaex.io/",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Data-Science-Data-Engineering/Xarray": {
    "title": "Xarray",
    "content": "## Code\n- #code Xarray - N-D labeled arrays and datasets in Python: https://github.com/pydata/xarray\n\t- #PAPER Xarray - N-D labeled Arrays and Datasets in Python (Hoyer 2017): https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/\n\t- http://xarray.pydata.org/en/stable/why-xarray.html\n\t- Breaking up arrays up into chunks for fun and science with Xarray and Dask: https://www.youtube.com/watch?v=0dO-iC16xUo\n- #CODE [Dask](AI/Data%20Science,%20Data%20Engineering/Dask.md)",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Deep-learning/Autoencoders": {
    "title": "Autoencoders",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Autoencoder\n- Dimensionality Reduction: https://www.cs.toronto.edu/~hinton/science.pdf\n- The classical approach for unsupervised learning using neural networks. The basic version consists of a Multilayer Perceptron (MLP) where the input and output layer have the same size and a smaller hidden layer is trained to recover the input. Once trained, the output from the hidden layer corresponds to data representation that can be useful for clustering, dimensionality reduction, improving supervised classification and even for data compression.\n- https://blog.keras.io/building-autoencoders-in-keras.html\n- https://blog.insightdatascience.com/isee-removing-eyeglasses-from-faces-using-deep-learning-d4e7d935376f\n- https://github.com/nanopony/keras-convautoencoder\n\n\n## References\n- #PAPER Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion (Vincent 2010): https://www.jmlr.org/papers/v11/vincent10a.html\n- #PAPER Adversarial Autoencoders with Constant-Curvature Latent Manifolds (Grattarola 2018): https://arxiv.org/abs/1812.04314\n- #PAPER Image-To-Image Translation Using a Cross-Domain Auto-Encoder and Decoder (Yoo 2019): https://www.mdpi.com/2076-3417/9/22/4780/htm \n\t- Early image-to-image translation methods used convolutional neural networks (CNN), which learn to minimize the loss of a pixel value between the source domain image and the target domain image but had the limitation of failing to produce more photorealistic images \n\t- Unlike other approaches… our method is not limited to a specific task, nor do we rely on predefined relationships between the source and target domains. Our method can be applied to make a general-domain solution for many image-to-image translation tasks. \n\n\n### VAEs\n- Variational autoencoders are generative models. Traditional autoencoders that just do reconstruction don’t have an obvious generative interpretation. There are some cases in between, like denoising autoencoders, where it is possible to construct a Markov chain that uses the autoencoder to sample from the data distribution, but the autoencoder doesn’t give direct explicit access to an estimate of the density or the ability to sample directly.\n- VAE is a type of autoencoder with added constraints on the encoded representations being learned. More precisely, it is an autoencoder that learns a latent variable model for its input data. So instead of letting your neural network learn an arbitrary function, you are learning the parameters of a probability distribution modeling your data. If you sample points from this distribution, you can generate new input data samples: a VAE is a \"generative model\".\n- Variational Autoencoders Explained: http://kvfrans.com/variational-autoencoders-explained/\n- Intuitively understanding VAEs: https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf\n- An Intuitive Comparison of Autoencoders with Variational Autoencoders: https://thilospinner.com/towards-an-interpretable-latent-space/\n- http://blog.fastforwardlabs.com/post/148842796218/introducing-variational-autoencoders-in-prose-and\n- Arxiv insights. Variational Autoencoders: https://www.youtube.com/watch?v=9zKuYvjFFS8\n- From Autoencoder to Beta-VAE: https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html\n\n- #PAPER Auto-Encoding Variational Bayes (Kingma 2014): https://arxiv.org/abs/1312.6114\n- #PAPER An Introduction to Variational Autoencoders (Kingma 2019): https://arxiv.org/abs/1906.02691\n- #PAPER NVAE: A Deep Hierarchical Variational Autoencoder (Vahdat 2020): https://arxiv.org/abs/2007.03898\n\t- Paper explained: https://www.youtube.com/watch?v=x6T1zMSE4Ts",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Deep-learning/Bayesian-neural-networks": {
    "title": "Bayesian Neural Networks (BNNs)",
    "content": "## Resources\n- Bayesian Neural Network tutorial: http://edwardlib.org/tutorials/bayesian-neural-network\n- Bayesian Deep Learning - NeurIPS Workshop: http://bayesiandeeplearning.org/ \n- Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe [[AI]]. https://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai/\n- Making Your Neural Network Say “I Don’t Know” — Bayesian NNs using Pyro and PyTorch: https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd\n- Building a Bayesian deep learning classifier: https://towardsdatascience.com/building-a-bayesian-deep-learning-classifier-ece1845bc09\n- Physics - a Gateway to Bayesian Deep Learning: https://github.com/henripal/sgld\n- [Bayesian deep learning with Fastai : how not to be uncertain about your uncertainty!](https://towardsdatascience.com/bayesian-deep-learning-with-fastai-how-not-to-be-uncertain-about-your-uncertainty-6a99d1aa686e)\n\t- BNNs are a way to add uncertainty handling in our models. The idea is simple, instead of having deterministic weights that we learn, we instead learn the parameters of a random variable which we will use to sample our weights during forward propagation. Then, to learn the parameters, we will use backpropagation, sometimes with a little trick to make our parameters differentiable.\n\t- Dropout is a way to make your Neural Networks Bayesian almost for free, and to use it during inference you just have to keep the Dropout, and sample several models, this is called MC Dropout.\n- MC Dropout: https://datascience.stackexchange.com/questions/44065/what-is-monte-carlo-dropout\n\t- normal dropout (only at training time) serves as a regularization to avoid overfitting. During test time, dropout is not applied; instead, all nodes/connections are present, but the weights are adjusted accordingly (e.g. multiplied by the keep ratio, which is 1 - dropout_ratio). Such a model during test time can be understood as a *average* of an ensemble of neural networks.\n\t- Notice that for normal dropout, at test time the prediction is *deterministic*. Without other source of randomness, given one test data point, the model will always predict the same label or value.\n\t- For *Monte Carlo dropout*, the dropout is applied at both training and test time. At test time, the prediction is no longer deterministic, but depending on which nodes/links you randomly choose to keep. Therefore, given a same datapoint, your model could predict different values each time.\n\t- The primary goal of MC dropout is to generate random predictions and interpret them as samples from a probabilistic distribution. \n- #TALK Estimacion de la Incertidumbre en Redes Neuronales (Valdenegro): https://mvaldenegro.github.io/files/DSRP-meetup-NeurIPS-2020-incertidumbre-redes-neuronales.pdf\n\n\n## Code\n- #CODE Pyro (Uber) - Deep universal probabilistic programming with Python and PyTorch: https://github.com/uber/pyro  \n\t\t- http://pyro.ai\n\t\t- http://eng.uber.com/pyro\n- #CODE Blitz - Bayesian Layers in Torch Zoo: https://github.com/piEsposito/blitz-bayesian-deep-learning\n- #CODE Edwardlib - Edward is a Python library for probabilistic modeling, inference, and criticism\n\t- https://theintelligenceofinformation.wordpress.com/2017/06/02/pydata-london-2017-bayesian-deep-learning-talk-by-andrew-rowan/\n\t- #TALK https://www.youtube.com/watch?v=I09QVNrUS3Q\n\t- http://willwolf.io/2017/06/15/random-effects-neural-networks/\n- #CODE TensorFlow Probability: https://www.tensorflow.org/probability/\n\t- https://towardsdatascience.com/bayesian-neural-networks-with-tensorflow-probability-fbce27d6ef6\n- #CODE keras-uncertainty: https://github.com/mvaldenegro/keras-uncertainty\n\t- Monte Carlo Dropout (MC-Dropout)\n\t- Deep Ensembles\n\n\n## References\n- #PAPER Dropout as a Bayesian Approximation:Representing Model Uncertainty in Deep Learning (Gal 2016): https://arxiv.org/abs/1506.02142\n- #PAPER Bayesian Neural Networks (Mullachery, 2018): https://arxiv.org/abs/1801.07710\n- #PAPER Deep Sub-Ensembles for Fast Uncertainty Estimation in Image Classification (Valdenegro-Toro): https://arxiv.org/abs/1910.08168\n- #PAPER Bayesian Recurrent Neural Networks (Fortunato 2019): https://arxiv.org/abs/1704.02798\n- #PAPER Bayesian Deep Learning and a Probabilistic Perspective of Generalization (Gordon Wilson, 2020): https://arxiv.org/abs/2002.08791\n\t- https://github.com/izmailovpavel/understandingbdl\n- #PAPER Hands-on Bayesian Neural Networks - a Tutorial for [[Deep Learning]] Users (Jospin 2020): https://arxiv.org/abs/2007.06823\n- #PAPER DropConnect is effective in modeling uncertainty of Bayesian deep networks (Mobiny 2021): https://www.nature.com/articles/s41598-021-84854-x\n\t- #CODE https://github.com/hula-ai/mc_dropconnect\n- #PAPER Epistemic Neural Networks (Osband 2021): https://arxiv.org/abs/2107.08924\n\t- #CODE https://github.com/deepmind/enn\n\t- https://syncedreview.com/2021/07/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-69/",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Deep-learning/CNNs": {
    "title": "Convolutional Neural Networks (CNNs)",
    "content": "## Resources\n- https://github.com/kjw0612/awesome-deep-vision\n- https://en.wikipedia.org/wiki/Convolutional_neural_network\n- In [deep learning](deep%20learning.md), a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks, based on their shared-weights architecture and translation invariance characteristics. \n- CNNs: https://d2l.ai/chapter_convolutional-neural-networks/index.html\n- Convolutional Neural Networks cheatsheet: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\n- http://cs231n.github.io/convolutional-networks/\n- http://cs231n.github.io/understanding-cnn/\n- https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/\n* Best deep CNN architectures and their principles: from AlexNet to EfficientNet: https://theaisummer.com/cnn-architectures/\n\n### Convolutions\n- Understanding convolutions: http://colah.github.io/posts/2014-07-Understanding-Convolutions/\n- An Introduction to different Types of Convolutions in DL: https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d\n- https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215\n- https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d\n- Depthwise separable convolution: https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\n- https://stackoverflow.com/questions/42883547/intuitive-understanding-of-1d-2d-and-3d-convolutions-in-convolutional-neural-n \n- https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807\n- Convolutions Over Volumes (channels): https://www.youtube.com/watch?v=KTB_OFoAQcc \n\n## Code \n- #CODE Keras Layers (for TensorFlow 2.x): https://github.com/mvoelk/keras_layers\n- #CODE Model Zoo - Discover open source deep learning code and pretrained models: https://modelzoo.co/\n- #CODE https://github.com/microsoft/computervision-recipes\nChannel/visual attention:\n- #CODE Visual-attention-tf: https://github.com/vinayak19th/Visual_attention_tf ^tfvisualattention\n\t- Pixel Attention\n\t- Channel Attention (CBAM)\n\t- Efficient Channel Attention\n- #CODE Convolution Variants: https://github.com/JinLi711/Convolution_Variants ^kerasconvvariants\n\t- Attention Augmented (AA) Convolution Layer\n\t- Mixed Depthwise Convolution Layer\n\t- Drop Block\n\t- Efficient Channel Attention (ECA) Layer\n\t- Convolutional Block Attention Module (CBAM) Layer\n\n\n## References\n- #PAPER A guide to convolution arithmetic for deep learning (Dumoulin, 2016): https://arxiv.org/abs/1603.07285\n\t- #CODE https://github.com/vdumoulin/conv_arithmetic\n- #PAPER Xception: Deep Learning with Depthwise Separable Convolutions (Chollet 2017): https://arxiv.org/abs/1610.02357\n- #PAPER 3D Depthwise Convolution: Reducing Model Parameters in 3D Vision Tasks (Ye 2018): https://arxiv.org/abs/1808.01556\n- #PAPER Making Convolutional Networks Shift-Invariant Again (Zhang 2019): https://arxiv.org/pdf/1904.11486v2\n- #PAPER A Survey of the Recent Architectures of Deep Convolutional Neural Networks (Khan 2020): https://arxiv.org/abs/1901.06032v7\n- #PAPER Revisiting Spatial Invariance with Low-Rank Local Connectivity (Elsayed 2020): https://arxiv.org/abs/2002.02959\n\t- #CODE https://github.com/google-research/google-research/tree/master/low_rank_local_connectivity\n- #THESIS/PHD Multi-modal Medical Image Processing with Applications in HybridX-ray/Magnetic Resonance Imaging (Stimpel 2021): https://opus4.kobv.de/opus4-fau/frontdoor/deliver/index/docId/15697/file/Dissertation_Bernhard_Stimpel.pdf\n- #PAPER Involution: Inverting the Inherence of Convolution for Visual Recognition (Li 2021): https://arxiv.org/abs/2103.06255\n\t- #CODE https://github.com/d-li14/involution\n\t- #CODE https://github.com/PrivateMaRyan/keras-involution2Ds\n\t- Paper explained: https://www.youtube.com/watch?v=pH2jZun8MoY\n- #PAPER Convolutional Conditional Neural Processes (Gordon 2020): https://arxiv.org/abs/1910.13556 ^convcondneuralproc\n\t- #CODE https://github.com/cambridge-mlg/convcnp\n\t- https://yanndubs.github.io/Neural-Process-Family/reproducibility/ConvCNP.html\n- #PAPER Non-deep Networks (Goyal 2021): https://arxiv.org/abs/2110.07641\n\t- #CODE https://paperswithcode.com/paper/non-deep-networks-1?from=n19\n\t- use parallel subnetworks instead of stacking one layer after another. This helps effectively reduce depth while maintaining high performance\n* #PAPER ConvNext: A ConvNet for the 2020s (Liu 2022): https://arxiv.org/abs/2201.03545 ^convnext\n\t* #CODE https://github.com/facebookresearch/ConvNeXt\n\t* #CODE https://github.com/bamps53/convnext-tf/\n\t* Paper explained: \n\t\t* https://www.youtube.com/watch?v=WvKsMI4Iemk\u0026t=330s\n\t\t* https://www.youtube.com/watch?v=idiIllIQOfU\u0026list=WL\u0026index=55\n\t\t* https://www.youtube.com/watch?v=QqejV0LNDHA\n\t* https://twitter.com/papers_daily/status/1481937771732566021\n\t* ConvNeXt essentially takes a ResNet and gradually \"modernizes\" it to discover components that contribute to performance gains. ConvNeXt applies several tricks like larger kernels, layer norm, fewer activation functions, separate downsampling layers to name a few. \n\t* These results show that hybrid models are promising and that different components can still be optimized further and composed more effectively to improve the overall model on a wide range of vision tasks.\n\n\n### Channel/Visual attention\n - #PAPER Squeeze-and-Excitation Networks, SENets (Hu 2017): https://arxiv.org/abs/1709.01507 ^senets\n\t- Features can incorporate global context\n\t- Since SENet only revolves around providing channel attention by using dedicated global feature descriptors, which in this case is Global Average Pooling (GAP), there is a loss of information and the attention provided is point-wise. This means that all pixels are mapped in the spatial domain of a feature map uniformly, and thus not discriminating between important or class-deterministic pixels versus those which are part of the background or not containing useful information.\n\t- Thus, the importance/need for spatial attention is justified to be coupled with channel attention. One of the prime examples of the same is CBAM (published at ECCV 2018) [[CNNs#^cbam]]\n\t- #CODE https://github.com/hujie-frank/SENet\n\t- #CODE https://github.com/yoheikikuta/senet-keras\n\t- https://blog.paperspace.com/channel-attention-squeeze-and-excitation-networks/\n\t- https://programmerclick.com/article/4934219785/\n - #PAPER CBAM: Convolutional Block Attention Module (Woo 2018): https://arxiv.org/abs/1807.06521 ^cbam\n\t -  #CODE https://kobiso.github.io//research/research-CBAM/\n\t -  #CODE [[#^kerasconvvariants]], [[#^tfvisualattention]]\n\t -  https://medium.com/visionwizard/understanding-attention-modules-cbam-and-bam-a-quick-read-ca8678d1c671\n- #PAPER ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks (Wang 2020): https://arxiv.org/abs/1910.03151\n\t-  #CODE [[#^tfvisualattention]]\n\t- this paper proposes an Efficient Channel Attention (ECA) module, which only involves a handful of parameters while bringing clear performance gain\n\t- proposed a local cross-channel interaction strategy without dimensionality reduction, which can be efficiently implemented via 1D convolution\n- #PAPER [[Super-resolution#^srwithpixelattention]]\n\n\n### 1x1 convolutions\n- 1x1 convolutions: https://d2l.ai/chapter_convolutional-neural-networks/channels.html#times-1-convolutional-layer\n- 1x1 convolutions: https://www.youtube.com/watch?v=qVP574skyuM\n- Networks in Networks and 1x1 Convolutions: https://www.youtube.com/watch?v=vcp0XvDAX68\n- https://iamaaditya.github.io/2016/03/one-by-one-convolution/\n- https://towardsdatascience.com/1x1-convolution-5219bbc09027\n- https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578\n- https://machinelearningmastery.com/introduction-to-1x1-convolutions-to-reduce-the-complexity-of-convolutional-neural-networks/\n\t- A convolutional layer with a 1×1 filter is used at any point in a CNN to control the number of feature maps. It's often referred to as a projection operation or projection layer, or even a feature map or channel pooling layer\n\n\n## Subtopics and applications\n### Sequence (time series) modelling\n- #PAPER An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling (Bai 2018): https://arxiv.org/abs/1803.01271\n  - Temporal convolutional networks (TCN)\n  - #CODE https://github.com/philipperemy/keras-tcn\n  - Implementing Temporal Convolutional Networks: https://medium.com/the-artificial-impostor/notes-understanding-tensorflow-part-3-7f6633fcc7c7\n\t  - The most important component of TCNs is dilated causal convolution. “Causal” simply means a filter at time step t can only see inputs that are no later than t. The point of using dilated convolution is to achieve larger receptive field with fewer parameters and fewer layers. \n\t  - A residual block stacks two dilated causal convolution layers together, and the results from the final convolution are added back to the inputs to obtain the outputs of the block. \n  - Temporal convolutional networks for sequence modeling: https://dida.do/blog/temporal-convolutional-networks-for-sequence-modeling\n- #PAPER Convolutions Are All You Need (For Classifying Character Sequences) (Wood-doughty 2018): https://www.aclweb.org/anthology/W18-6127/\n- #PAPER InceptionTime: Finding AlexNet for time series classification (Fawaz 2021): https://link.springer.com/article/10.1007/s10618-020-00710-y\n\t- #CODE https://github.com/hfawaz/InceptionTime\n\t- https://arxiv.org/abs/1909.04939\n\n\n### Object classification, image recognition\nSe [Object classification, image recognition](Object%20classification,%20image%20recognition.md)\n\n### Semantic segmentation\nSee [Semantic segmentation](Semantic%20segmentation.md) \n\n### Object detection\nSee [Object detection](Object%20detection.md) \n\n### Video segmentation and prediction\nSee [Video segmentation and prediction](Video%20segmentation%20and%20prediction.md)\n\n### Image and video captioning\nSee [Image and video captioning](Image%20and%20video%20captioning.md)\n\n### Image-to-image translation\nSee [Image-to-image translation](Image-to-image%20translation.md)\n\n### Super-resolution \nSee [Super-resolution#CNN-based](Super-resolution.md#CNN-based)\n\n### Inpainting\nSee [Inpainting#CNN-based](Inpainting.md#CNN-based)\n\n### Background subtraction, foreground detection\nSee [Background subtraction#CNN based](Background%20subtraction.md#CNN%20based)\n\n### Edge detection\n- #PAPER DeepEdge: A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection: http://arxiv.org/pdf/1412.1123\n- #PAPER DeepContour: A Deep Convolutional Feature Learned by Positive-Sharing Loss for Contour Detection. http://mc.eistar.net/UpLoadFiles/Papers/DeepContour_cvpr15.pdf\n\n\n### Human pose estimation and activity recognition\n- https://en.wikipedia.org/wiki/Activity_recognition\n- https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/\n- https://github.com/cbsudux/awesome-human-pose-estimation\n- https://github.com/topics/human-pose-estimation\n- https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/\n\n- #PAPER Fast Human Pose Estimation: https://arxiv.org/abs/1811.05419\n- #PAPER Convolutional pose machines: https://arxiv.org/abs/1602.00134\n- #PAPER Human activity recognition with smartphone sensors using deep learning neural networks: https://www.sciencedirect.com/science/article/abs/pii/S0957417416302056\n\n\n### Motion detection, tracking\n- #PAPER Optical Flow (FlowNet): http://arxiv.org/pdf/1504.06852\n\n\n### Deconvolution\n- #PAPER Deep Convolutional Neural Network for Image Deconvolution (Xu 2014): http://lxu.me/projects/dcnn/",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Deep-learning/CapsNets": {
    "title": "Capsule Neural networks (CapsNets)",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Capsule_neural_network\n- A Capsule Neural Network (CapsNet) is a machine learning system that is a type of artificial neural network (ANN) that can be used to better model hierarchical relationships. The approach is an attempt to more closely mimic biological neural organization.\n- The main failure of CNNs is that they do not carry any information about the relative relationships between features (CNNs since they are based on the convolution operation applied to scalar values).\n- Capsules introduce a new building block that can be used in deep learning to better model relationships inside the network. The key to this richer feature representation is the use of vectors rather than scalars.\n- A capsule is an abstract idea of having a group of neurons with an activity vector that contains more information about the object. There are many ways to implement this. Hinton et al chose one particular way to implement this, which allows using “dynamic routing”. \n- https://towardsdatascience.com/a-simple-and-intuitive-explanation-of-hintons-capsule-networks-b59792ad46b1\n- https://towardsdatascience.com/capsule-neural-networks-are-here-to-finally-recognize-spatial-relationships-693b7c99b12\n- https://towardsdatascience.com/capsule-neural-networks-part-2-what-is-a-capsule-846d5418929f\n- https://www.freecodecamp.org/news/understanding-capsule-networks-ais-alluring-new-architecture-bdb228173ddc/\n\n## References\n- #PAPER Dynamic Routing Between Capsules (Sabour 2017): https://arxiv.org/abs/1710.09829\n\t- #CODE https://github.com/XifengGuo/CapsNet-Keras\n- #PAPER Capsule Networks – A survey (Mensah 2019): https://www.sciencedirect.com/science/article/pii/S1319157819309322",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Deep-learning/Deep-belief-network": {
    "title": "Deep belief network",
    "content": "## Resources\n- In machine learning, a deep belief network (DBN) is a generative graphical model, or alternatively a type of deep neural network, composed of multiple layers of latent variables(\"hidden units\"), with connections between the layers but not between units within each layer. DBNs can be viewed as a composition of simple, unsupervised networks such as restricted Boltzmann machines (RBMs) or autoencoders, where each sub-network's hidden layer serves as the visible layer for the next.\n- #TALK Deep Belief Nets (Hinton): https://www.cs.toronto.edu/~hinton/nipstutorial/nipstut3.pdf\n- Deep-Belief Networks: https://wiki.pathmind.com/deep-belief-network\n\t- A deep-belief network can be defined as a stack of restricted Boltzmann machines, in which each RBM layer communicates with both the previous and subsequent layers. The nodes of any single layer don’t communicate with each other laterally.\n\t- This stack of RBMs might end with a a Softmax layer to create a classifier, or it may simply help cluster unlabeled data in an unsupervised learning scenario.\n\t- With the exception of the first and final layers, each layer in a deep-belief network has a double role: it serves as the hidden layer to the nodes that come before it, and as the input (or “visible”) layer to the nodes that come after. It is a network built of single-layer networks.\n\t- Deep-belief networks are used to recognize, cluster and generate images, video sequences and motion-capture data. A continuous deep-belief network is simply an extension of a deep-belief network that accepts a continuum of decimals, rather than binary data. They were introduced by Geoff Hinton and his students in 2006.",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Deep-learning/Deep-learning": {
    "title": "Deep Learning (DL)",
    "content": "## Resources\n- DL is a branch of [Machine Learning](AI/Machine%20Learning.md) and [AI](AI/AI.md) based on a set of algorithms that attempt to model high level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear transformations.\n- DL uses huge neural networks with many layers of processing units, taking advantage of advances in computing power and improved training techniques to learn complex patterns in large amounts of data. \n- https://github.com/ChristosChristofidis/awesome-deep-learning\n- https://github.com/endymecy/awesome-deeplearning-resources\n- https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/\n- A Quick Introduction to Neural Networks: https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/\n- https://kevinzakka.github.io/2016/09/26/applying-deep-learning/\n- http://www.deepideas.net/deep-learning-from-scratch-theory-and-implementation/\n- A Brief History of Neural Nets and Deep Learning (2020): http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/\n- Time Benchmark of models: https://dawn.cs.stanford.edu/benchmark/\n- A Recipe for Training Neural Networks: http://karpathy.github.io/2019/04/25/recipe/\n\n### DL news aggregators\n- DeepAI:  https://deepai.org/\n- Papers with code: https://paperswithcode.com/\n- Deep learning monitor: https://deeplearn.org/\n\n### Cheatsheets\n- https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/super-cheatsheet-deep-learning.pdf\n\n### When to use and not to use deep learning\n- When and When Not to Use Deep Learning: https://blog.dataiku.com/when-and-when-not-to-use-deep-learning\n- You can probably use deep learning even if your data isn't that big: http://beamandrew.github.io/deeplearning/2017/06/04/deep_learning_works.html\n- When not to use deep learning: http://hyperparameter.space/blog/when-not-to-use-deep-learning/\n- Using ANNs on small data – Deep Learning vs. Xgboost: http://maxberggren.se/2017/06/18/deep-learning-vs-xgboost/\n- The limitations of deep learning: https://blog.keras.io/the-limitations-of-deep-learning.html\n\n\n## Books\n- #BOOK Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI (Kashani 2022): https://arxiv.org/abs/2201.00650\n- #BOOK Physics-based Deep Learning Book (Thuerey 2021): https://physicsbaseddeeplearning.org/intro.html ^PBDL\n- #BOOK The Principles of DL Theory: An Effective Theory Approach to Understanding Neural Networks (Roberts 2022): https://deeplearningtheory.com/PDLT.pdf\n\t- https://ai.facebook.com/blog/advancing-ai-theory-with-a-first-principles-understanding-of-deep-neural-networks/\n- #BOOK Deep Learning Book (Goodfellow, 2016 MIT): https://www.deeplearningbook.org/\n\t- The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular\n- #BOOK DL tutorial (LISA Lab, U Montreal): http://deeplearning.net/tutorial/\n- #BOOK Deep Learning with Python (Chollet, 2021 MANNING): https://www.manning.com/books/deep-learning-with-python-second-edition\n\t- 1st edition: http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf\n- #BOOK Machine learning yearning (Andrew Ng, 2018): https://freecomputerbooks.com/Machine-Learning-Yearning.html\n\t- https://github.com/ajaymache/machine-learning-yearning\n- #BOOK Dive into Deep Learning (Zhang): https://d2l.ai/index.html\n\t- An interactive deep learning book for students, engineers, and researchers. Uses MXNet/Gluon, Pytorch and Tensorflow\n\t- Jupyter notebooks for each section: https://en.d2l.ai/d2l-en.zip\n- #BOOK Introduccion practica con Keras (Torres 2018): https://torres.ai/deep-learning-inteligencia-artificial-keras/\n- #BOOK Neural Networks and Deep Learning: http://neuralnetworksanddeeplearning.com/index.html\n\n\n## Talks\n- #TALK Deep Learning (Yoshua Bengio, MLSS 2020): \n\t- Part I: https://www.youtube.com/watch?v=c_U4THknoHE\n\t- Part II: https://www.youtube.com/watch?v=PDPdIDihPvc\n- #TALK Deep Learning Hardware: Past, Present, and Future (Yann LeCun, ISSCC 2019): https://www.youtube.com/watch?v=YzD7Z2yRL7Y\n- #TALK Keras, Deep Learning, and the Progress of AI (François Chollet, Lex Fridman Podcast, 2019): https://www.youtube.com/watch?v=Bo8MY4JpiXE\n- #TALK Deep Learning and the Future of Artificial Intelligence (Yann LeCun, 2018): https://www.youtube.com/watch?v=RM-Jtc2ryfM\u0026t=5s\n- #TALK AI Breakthroughs \u0026 Obstacles to Progress, Mathematical and Otherwise (Yann LeCun, 2018): https://www.youtube.com/watch?v=1_KhJv0Em5Y\n- #TALK Power \u0026 Limits of Deep Learning (Yann Lecun, 2017): https://www.youtube.com/watch?v=0tEhw5t6rhc\n- #TALK The Future of Sparsity in Deep Learning (Trevor Gale, Phd student Stanford, 2021): https://events.rainfocus.com/widget/nvidia/nvidiagtc/sessioncatalog/session/1631029840983001jvzq\n- #TALK The Deep End of Deep Learning (Hugo Larochelle, TEDxBoston 2016): https://www.youtube.com/watch?v=dz_jeuWx3j0\n- #TALK How deep neural networks work (Brandon Rohrer): https://www.youtube.com/watch?v=ILsA4nyG7I0\n\t- Simple explanations of DL basics and nice graphics\n\n\n## Courses\n- #COURSE Introduction to Deep Learning (COMP0090, UCL): https://github.com/YipengHu/COMP0090 \n- #COURSE Full Stack Deep Learning: https://fullstackdeeplearning.com/\n\t- Full Stack Deep Learning - Spring 2021: https://fullstackdeeplearning.com/spring2021/\n\t\t- Lecture 13: ML Teams and Startups: https://fullstackdeeplearning.com/spring2021/lecture-13/\n\t- https://fall2019.fullstackdeeplearning.com/\n\t\t- https://github.com/full-stack-deep-learning/course-gitbook\n- #COURSE Deep Learning (NYU): https://atcold.github.io/pytorch-Deep-Learning/\n\t- https://github.com/Atcold/pytorch-Deep-Learning (pytorch)\n- #COURSE Deep Learning (CS230, Stanford): http://cs230.stanford.edu/\n\t- Cheatsheets: https://github.com/afshinea/stanford-cs-230-deep-learning\n- #COURSE Tensorflow for Deep Learning Research (CS20SI, Stanford): http://web.stanford.edu/class/cs20si/syllabus.html\n- #COURSE DeepMind x UCL | Deep Learning Lecture Series 2020: https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF\n- #COURSE Introduction to Deep Learning (6.S191, MIT): http://introtodeeplearning.com/\n- #COURSE MIT Deep Learning and Artificial Intelligence Lectures: https://deeplearning.mit.edu/\n\t- Youtube playlist: https://www.youtube.com/watch?v=0VH1Lim8gL8\u0026list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf\n\t- Deep Learning State of the Art (2020): https://www.youtube.com/watch?v=0VH1Lim8gL8\n- #COURSE Introduction to Deep Learning (MIT 6.S191): http://introtodeeplearning.com/\n- #COURSE Intro to Neural Networks and Machine Learning (CSC 321, UToronto): http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/\n- #COURSE Deep Learning nanodegree (Udacity): https://www.udacity.com/course/deep-learning-nanodegree--nd101\n\t- https://github.com/udacity/deep-learning-v2-pytorch\n\t- https://www.udacity.com/course/deep-learning-pytorch--ud188\n- #COURSE Deep Learning with PyTorch: Zero to GANs (Jovian): https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans\n- #COURSE Fast AI - Practical Deep Learning For Coders: http://course.fast.ai/\n\t- Deep Learning for Coders with fastai and PyTorch: [[AI]] Applications Without a PhD - the book and the course\n\t- https://github.com/fastai/fastbook\n- #COURSE Deep Learning course (U Paris-Saclay): https://m2dsupsdlclass.github.io/lectures-labs/\n- #COURSE Introduction to Machine Learning and Neural Networks (Uniandes): https://albahnsen.com/courses/applied-deep-learning/\n\t- https://github.com/albahnsen/AppliedDeepLearningClass\n- #COURSE Deep learning specialization (deeplearning.ai, Coursera, Andrew Ng): https://www.coursera.org/specializations/deep-learning\n\t- https://www.deeplearning.ai/deep-learning-specialization/\n- #COURSE Neural Networks (U Sherbrooke): http://info.usherbrooke.ca/hlarochelle/neural_networks/description.html\n- #COURSE The Neural Aesthetic (ITP-NYU): http://ml4a.github.io/classes/itp-F18/\n\n\n## Code\nState of ML frameworks: \n- https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/\n- https://towardsdatascience.com/tensorflow-or-pytorch-146f5397278a\n\n- #CODE [Tensorflow, keras](AI/Data%20Science,%20Data%20Engineering/Tensorflow,%20keras.md)\n- #CODE Triton: https://github.com/openai/triton\n\t- language and compiler for writing highly efficient custom Deep-Learning primitives\n\t- https://openai.com/blog/triton/\n\t- https://www.infoq.com/news/2021/08/openAI-triton/\n\t- Triton uses Python as its base. The developer writes code in Python using Triton’s libraries, which are then JIT-compiled to run on the GPU. This allows integration with the rest of the Python ecosystem, currently the biggest destination for developing machine-learning solutions\n- #CODE MindSpore (Huawei): https://github.com/mindspore-ai/mindspore ^huaweimindpore\n\t- https://towardsdatascience.com/program-your-first-neural-network-with-huawei-mindspore-1fc50023e90d\n\t- https://towardsdatascience.com/huaweis-mindspore-a-new-competitor-for-tensorflow-and-pytorch-d319deff2aec\n\t- https://www.mindspore.cn/en\n- #CODE Tensorlayer - Deep Learning and Reinforcement Learning Library for Scientists and Engineers: https://github.com/tensorlayer/tensorlayer\n\t- http://tensorlayer.org/\n- #CODE Elegy - Neural Networks framework based on Jax and inspired by Keras: https://github.com/poets-ai/elegy\n\t- https://poets-ai.github.io/elegy/\n\t- See [Mathematical Optimization](AI/Math%20and%20Statistics/Mathematical%20Optimization.md) JAX\n- #CODE PyTorch (Facebook): Tensors and Dynamic neural networks in Python with strong GPU acceleration. https://github.com/pytorch/pytorch\n\t- http://pytorch.org\n\t- https://sagivtech.com/2017/09/19/optimizing-pytorch-training-code/\n\t- #CODE Pytorch-lightning: https://pytorchlightning.ai/\n\t\t- https://medium.com/pytorch/introducing-lightning-flash-the-fastest-way-to-get-started-with-deep-learning-202f196b3b98\n\t- #CODE Pytext (Facebook) - A natural language modeling framework based on PyTorch: https://github.com/facebookresearch/pytext \n\t\t- https://fb.me/pytextdocs\n\t\t- PyText is a deep-learning based [NLP](AI/NLP.md) modeling framework built on PyTorch\n\t- #CODE Pytorch tabular: https://github.com/manujosephv/pytorch_tabular ^pytorchtab\n\t\t- https://deep-and-shallow.com/2021/01/27/pytorch-tabular-a-framework-for-deep-learning-for-tabular-data/\n- #CODE Paddle (Baidu): https://github.com/PaddlePaddle/Paddle\n\t- http://www.paddlepaddle.org/\n\t- PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice\n- #CODE Mxnet (Apache): https://github.com/apache/incubator-mxnet\n\t- http://mxnet.io/\n\t- Towards Next Generation Deep Learning Framework: https://mli.github.io/cvpr17/\n- #CODE Microsoft Cognitive Toolkit (CNTK): https://github.com/Microsoft/CNTK\n\t- https://www.microsoft.com/en-us/research/product/cognitive-toolkit/\n\t- Microsoft Cognitive Toolkit: A free, easy-to-use, open-source, commercial-grade toolkit that trains deep learning algorithms to learn like the human brain.\n\t- #TALK https://www.youtube.com/watch?v=9gDDO5ldT-4\u0026feature=youtu.be\n- #CODE Neupy - NeuPy is a Tensorflow based python library for prototyping and building neural networks: https://github.com/itdxer/neupy\n\t- http://neupy.com/pages/home.html\n- #CODE Chainer - Chainer is a Python-based deep learning framework aiming at flexibility\n\t- https://github.com/chainer/chainer\n- #CODE Neural Network Console (Sony): https://dl.sony.com/\n- #CODE PySyft: https://github.com/OpenMined/PySyft\n\t- PySyft is a Python library for secure and private Deep Learning. \n\t- PySyft decouples private data from model training, using Federated Learning, Differential Privacy, and Encrypted Computation (like Multi-Party Computation (MPC) and Homomorphic Encryption (HE)) within the main Deep Learning frameworks like PyTorch and TensorFlow.\n\t- #PAPER A generic framework for privacy preserving deep learning: https://arxiv.org/abs/1811.04017\n- #CODE Deep cognition: https://deepcognition.ai/\n\n\n## References\n- #PAPER Deep learning in NNs: An overview (Schmidhuber 2015): https://www.sciencedirect.com/science/article/pii/S0893608014002135\n- #PAPER Deep learning (LeCun 2015): https://www.nature.com/articles/nature14539 ^dllecun15\n\t- https://www.researchgate.net/profile/Y_Bengio/publication/277411157_Deep_Learning/links/55e0cdf908ae2fac471ccf0f/Deep-Learning.pdf\n- #PAPER Deep Neural Decision Forests (Kontschieder 2016): https://www.ijcai.org/Proceedings/16/Papers/628.pdf\n\t- #CODE https://keras.io/examples/structured_data/deep_neural_decision_forests/\n- #PAPER On the Origin of Deep Learning (Wang 2017): https://arxiv.org/abs/1702.07800v4 \n- #PAPER Representation Learning on Large and Small Data (Chou 2017): https://arxiv.org/abs/1707.09873v1\n- #PAPER Deep Learning in Neural Networks: An Overview (Schmidhuber, 2018): https://arxiv.org/abs/1404.7828\n- #PAPER Deep Learning as a Mixed Convex-Combinatorial Optimization Problem (Friesen 2018): https://arxiv.org/abs/1710.11573\n- #PAPER Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods (Lucas, 2018): https://ieeexplore.ieee.org/document/8253590\n\t- http://decsai.ugr.es/vip/files/journals/08253590.pdf\n- #PAPER Neural Tangent Kernel: Convergence and Generalization in Neural Networks (Jacot 2018): https://arxiv.org/abs/1806.07572#\n\t- https://www.quantamagazine.org/a-new-link-to-an-old-model-could-crack-the-mystery-of-deep-learning-20211011/\n- #PAPER A Survey of Deep Learning for Scientific Discovery (Raghu \u0026 Schmidt, 2020): https://arxiv.org/abs/2003.11755 ^dlscience20\n- #PAPER Neural circuit policies enabling auditable autonomy (Lechner 2020): https://www.nature.com/articles/s42256-020-00237-3\n\t- #CODE https://github.com/mlech26l/keras-ncp\n\t- https://www.csail.mit.edu/news/new-deep-learning-models-require-fewer-neurons\n\t- https://www.marktechpost.com/2021/10/19/mit-csail-tu-wien-and-ist-researchers-introduce-deep-learning-models-that-require-fewer-neurons/\n- #PAPER Implicitly Defined Layers in Neural Networks (Zhang 2020): https://arxiv.org/abs/2003.01822\n- #PAPER A Mathematical Principle of Deep Learning: Learn the Geodesic Curve in the Wasserstein Space (Gai 2021): https://arxiv.org/abs/2102.09235\n- #PAPER Why is AI hard and Physics simple? (Roberts 2021): https://arxiv.org/abs/2104.00008\n- #PAPER Deep Learning for AI (By Yoshua Bengio, Yann Lecun, Geoffrey Hinton, Turing lecture, 2021): https://dl.acm.org/doi/10.1145/3448250\n\t- https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltex\n- #PAPER Self-Tuning for Data-Efficient Deep Learning (Wang 2021): https://arxiv.org/abs/2102.12903\n\t- #CODE https://github.com/thuml/Self-Tuning\n\t- #TALK https://recorder-v3.slideslive.com/#/share?share=40334\u0026s=f7988e61-bece-4a7a-a6ba-3e1a2b49b37b\n- #PAPER Neural circuit policies enabling auditable autonomy (Lechner 2021): https://www.nature.com/articles/s42256-020-00237-3\n\t- #CODE https://github.com/mlech26l/keras-ncp\n- #PAPER Uncertainty Baselines: Benchmarks for Uncertainty \u0026 Robustness in Deep Learning (Nado 2021): https://arxiv.org/abs/2106.04015\n\t- https://ai.googleblog.com/2021/10/baselines-for-uncertainty-and.html\n\n\n### Generalization\nSee [XAI#Interpretability of deep learning models](AI/XAI.md#Interpretability%20of%20deep%20learning%20models)\n- http://www.inference.vc/everything-that-works-works-because-its-bayesian-2/\n\n- #PAPER Understanding deep learning requires re-thinking generalization (Zhang 2016): https://arxiv.org/abs/1611.03530\n\t- https://blog.acolyer.org/2017/05/11/understanding-deep-learning-requires-re-thinking-generalization/\n\t- https://www.quora.com/Why-is-the-paper-%E2%80%9CUnderstanding-Deep-Learning-Requires-Rethinking-Generalization%E2%80%9D-important\n- #PAPER A Closer Look at Memorization in Deep Networks (Arpit 2017): https://arxiv.org/abs/1706.05394\n- #PAPER Deep nets don’t learn via memorization (Krueger 2017): https://openreview.net/pdf?id=rJv6ZgHYg\n- #PAPER Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior (Martin 2017): https://arxiv.org/abs/1710.09553\n- #PAPER Ablation Studies in Artificial Neural Networks (Meyes 2019): https://arxiv.org/abs/1901.08644\n- #PAPER Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning (Allen-Zhu 2020): https://arxiv.org/abs/2012.09816\n\t- https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/\n- #PAPER The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers (Nakkiran 2021): https://arxiv.org/abs/2010.08127\n\t- https://ai.googleblog.com/2021/03/a-new-lens-on-understanding.html\n- #PAPER Predicting trends in the quality of state-of-the-art neural networks without access to training or testing data (Martin 2021): https://www.nature.com/articles/s41467-021-24025-8\n- #PAPER Stochastic Training is Not Necessary for Generalization (Geiping 2021): https://arxiv.org/abs/2109.14119\n- #PAPER Underspecification Presents Challenges for Credibility in Modern Machine Learning (D'Amour 2021): https://arxiv.org/abs/2011.03395\n\t- https://ai.googleblog.com/2021/10/how-underspecification-presents.html\n- #PAPER Grokking - Generatlization beyond overfitting on small algorithmic datasets (Power 2022): https://arxiv.org/abs/2201.02177v1\n\t- Paper explained: https://www.youtube.com/watch?v=dND-7llwrpw\n\n\n### Regularization\n- In general, techniques aimed at reducing overfitting and improve generalization\n- Overfit and underfit: https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\n- https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036\n- https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/\n- https://medium.com/intelligentmachines/convolutional-neural-network-and-regularization-techniques-with-tensorflow-and-keras-5a09e6e65dc7\n\n#### Data augmentation\n- https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n- https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n- #PAPER A survey on Image Data Augmentation for Deep Learning (Shorten 2019): https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0\n\n#### Dropout\n- http://www.cs.toronto.edu/~hinton/absps/dropout.pdf\n- https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/\n- 12 Main Dropout Methods: Mathematical and Visual Explanation for DNNs, CNNs, and RNNs: https://towardsdatascience.com/12-main-dropout-methods-mathematical-and-visual-explanation-58cdc2112293\n\n- #PAPER Dropout: A Simple Way to Prevent Neural Networks from Overfitting (Srivastava 2014): http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf\n- #PAPER Efficient Object Localization Using Convolutional Networks (Tompson 2015): https://arxiv.org/abs/1411.4280v3\n\t- Proposed spatial dropout\n- #PAPER Analysis on the Dropout Effect in Convolutional Neural Networks (Park 2017): https://link.springer.com/chapter/10.1007/978-3-319-54184-6_12\n\t- http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf\n- #PAPER Effective and Efficient Dropout for Deep Convolutional Neural Networks (Cai 2020): https://arxiv.org/abs/1904.03392\n\n\n#### Normalization\n- Normalization techniques also improve generalization error, providing some regularization\n- Normalization Techniques in Deep Neural Networks: https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8\n- Different Types of Normalization in Tensorflow: https://towardsdatascience.com/different-types-of-normalization-in-tensorflow-dac60396efb0\n- Normalization in Deep Learning: https://arthurdouillard.com/post/normalization/\n- https://sebastianraschka.com/faq/docs/scale-training-test.html \n- Data normalization/standardization can be used as an alternative (before training) to synch batchnorm (multi-gpu training)\n- Spectral normalization: https://sthalles.github.io/advanced_gans/\n\n- #PAPER Normalization Techniques in Training DNNs: Methodology, Analysis and Application (Huang 2020): https://arxiv.org/abs/2009.12836\n\n##### BatchNorm\n- #PAPER  Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (Ioffe 2015): https://arxiv.org/abs/1502.03167\n\t- #TALK https://www.youtube.com/watch?v=ZOabsYbmBRM\u0026feature=youtu.be\n\t- http://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras\n\t- Slower convergence w/o BN, BN can be applied on top of standardization \n\t- Synch BatchNorm appears in TF 2.2, for multi-gpu training \n\t\t- https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/SyncBatchNormalization \n- #PAPER Rethinking the Usage of Batch Normalization and Dropout (Chen 2019): https://arxiv.org/abs/1905.05928\n\n### Activations\n- https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html\n- https://mlfromscratch.com/activation-functions-explained/#/\n- RELU: https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n\t- https://www.quora.com/What-is-special-about-rectifier-neural-units-used-in-NN-learning\n- http://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-network\n- https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions\n\n### Loss/Cost functions\n- Cross entropy\n\t- http://neuralnetworksanddeeplearning.com/chap3.html\n\t- https://en.wikipedia.org/wiki/Cross_entropy\n\t- http://www.kdnuggets.com/2017/02/gentlest-introduction-tensorflow-part-4.html\n- Perceptual loss, image reconstruction\n\t- https://arxiv.org/pdf/1511.06409.pdf (Learning to Generate Images With Perceptual Similarity Metrics) \n\t- #PAPER Loss Functions for Image Restoration with Neural Networks (Zhao 2018): https://arxiv.org/abs/1511.08861\n\t- https://medium.com/@sanari85/rediscovery-of-ssim-index-in-image-reconstruction-ssim-as-a-loss-function-a1ffef7d2be \n\t\t- We use three different metric for comparing each different methods such  as  DSSIM,  MSE,  and  MAE.  Structural  dissimilarity(DSSIM)[14]  is  an  image  distance  metric,  that  corresponds better to the human perception than MAE or RMSE. MeanSquared  Error(MSE)  measures  the  average  of  the  squares of the errors that is, the average squared difference between the  estimated  values  and  the  actual  value.  Mean  AbsoluteError  (MAE)  is  the  average  distance  between  each  pixel point. https://arxiv.org/pdf/2001.05372.pdf \n- Deep learning image enhancement insights on loss function engineering: https://towardsdatascience.com/deep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7\n- Mean squared logarithmic error \n\t- https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle) \n\t- https://medium.com/@olegrybkin_20684/the-reasonable-ineffectiveness-of-mse-pixel-loss-for-future-prediction-and-what-to-do-about-it-4dca8152355d \n\n### Optimizers and backpropagation\n- How to use Learning Curves to Diagnose Machine Learning Model Performance: https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\n- https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent\n- Keras optimizers: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/ \n- Adam: http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n- An overview of gradient descent optimization algorithms (2016): https://ruder.io/optimizing-gradient-descent/index.html#otherrecentoptimizers \n- https://hackernoon.com/some-state-of-the-art-optimizers-in-neural-networks-a3c2ba5a5643 \n- https://www.jeremyjordan.me/neural-networks-training/\n- http://colah.github.io/posts/2015-08-Backprop/\n- Back-propagation - Math Simplified. https://github.com/DebPanigrahi/Machine-Learning/blob/master/back_prop.ipynb\n- https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n- https://venturebeat.com/2020/12/16/at-neurips-2020-researchers-proposed-faster-more-efficient-alternatives-to-backpropagation/amp/\n\n- #PAPER On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima (Shirish Keshkar 2017): https://arxiv.org/abs/1609.04836\n- #PAPER Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour (Goyal 2018): https://arxiv.org/abs/1706.02677\n- #PAPER Decoupled Weight Decay Regularization (Loshchilov 2018): https://arxiv.org/abs/1711.05101\n\t- AdamW optimizer\n\t- #CODE https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/AdamW\n\t- https://www.fast.ai/2018/07/02/adam-weight-decay/\n- #PAPER Deep Double Descent: Where Bigger Models and More Data Hurt (Nakkiran 2019): https://arxiv.org/abs/1912.02292\n\t- https://openai.com/blog/deep-double-descent/\n\t- https://medium.com/mlearning-ai/double-descent-8f92dfdc442f\n- #PAPER Reconciling modern machine learning practice and the bias-variance trade-off (Belkin 2019): https://arxiv.org/abs/1812.11118\n\t- Paper explained: https://www.youtube.com/watch?v=ZAW9EyNo2fw\n- #PAPER Deep Double Descent: Where Bigger Models and More Data Hurt (Nakkiran 2020): https://arxiv.org/abs/1912.02292\n\t- https://openai.com/blog/deep-double-descent/\n- #PAPER Descending through a Crowded Valley -- Benchmarking Deep Learning Optimizers (Schmidt 2020): https://arxiv.org/abs/2007.01547\n\t- Paper explained: https://www.youtube.com/watch?v=DiNzQP7kK-s\n- #PAPER Early Stopping in Deep Networks: Double Descent and How to Eliminate it (Heckel 2020): https://arxiv.org/abs/2007.10099\n\t- contrary to model-wise double descent, epoch-wise double descent is not a phenomena tied o over-parameterization\n\t- both under- and overparameterized models can have epoch-wise double descent \n\t- #CODE https://github.com/MLI-lab/early_stopping_double_descent\n\n\n### Efficiency and performance\n- #PAPER Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better (Menghani 2021): https://arxiv.org/abs/2106.08962\n\t- https://analyticsindiamag.com/how-to-build-smaller-faster-better-deep-learning-models/\n\n### Attention\nSee: \n[Transformers#For NLP](AI/Deep%20learning/Transformers.md#For%20NLP)\n[CNNs#Channel/Visual attention](/AI/Deep%20learning/CNNs.md#Channel/Visual%20attention)\n\n- #COURSE Attention and Memory in Deep Learning (DeepMind x UCL | Deep Learning Lectures | 8/12): https://www.youtube.com/watch?v=AIiwuClvH6k\n\n### Deep learning for multi-dimensional data\nSee:\n[Video segmentation and prediction](AI/Computer%20Vision/Video%20segmentation%20and%20prediction.md)\n[Encoder-decoder networks](AI/Deep%20learning/Encoder-decoder%20networks.md)\n[Transformers](AI/Deep%20learning/Transformers.md)\n[Generative modelling](AI/Deep%20learning/Generative%20modelling.md)\n\n- #PAPER Demystifying Deep Learning in Predictive Spatio-Temporal Analytics: An Information-Theoretic Framework (Tan 2020): https://arxiv.org/abs/2009.06304\n\n### Deep learning for tabular data\n- An Introduction to Deep Learning for Tabular Data: https://www.fast.ai/2018/04/29/categorical-embeddings/\n- Applying Deep Learning on Tabular Data Using TensorFlow 2.0: https://pdf.co/blog/deep-learning-on-tabular-data-using-tensorflow-20\n- #CODE See Pytorch tabular [[#^pytorchtab]]\n- #PAPER Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data (Popov 2019): https://arxiv.org/abs/1909.06312\n- #PAPER TabNet: Attentive Interpretable Tabular Learning (Arik 2020): https://arxiv.org/abs/1908.07442\n- #PAPER Converting tabular data into images for deep learning with convolutional neural networks (Zhu 2021): https://www.nature.com/articles/s41598-021-90923-y\n- #PAPER Tabular Data: Deep Learning is Not All You Need (Shwartz-Ziv 2021): https://arxiv.org/abs/2106.03253\n- #PAPER XBNet: An Extremely Boosted Neural Network (Sarkar 2021): https://arxiv.org/abs/2106.05239\n\t- #CODE XBNet: https://github.com/tusharsarkar3/XBNet\n\t- Boosted neural network for tabular data\n\t- https://analyticsindiamag.com/guide-to-xbnet-an-extremely-boosted-neural-network/\n- #PAPER Revisiting Deep Learning Models for Tabular Data (Gorishniy 2021): https://arxiv.org/abs/2106.11959\n\t- #CODE RDTL (Yandex): https://github.com/yandex-research/rtdl\n\t- https://yandex-research.github.io/rtdl/\n- #PAPER TABBIE: Pretrained Representations of Tabular Data (Lida 2021): https://arxiv.org/abs/2105.02584v1\n\n\n## Architectures and model types\n- The neural network zoo: http://www.asimovinstitute.org/neural-network-zoo/\n- Deep Learning Tips and Tricks cheatsheet: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks\n- A Visual and Interactive Guide to the Basics of NNs: https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/\n- A Visual And Interactive Look at Basic Neural Network Math: https://jalammar.github.io/feedforward-neural-networks-visual-interactive/\n- #CODE Model Zoo: https://modelzoo.co/\n- #CODE Deep Learning Models (Raschka): https://github.com/rasbt/deeplearning-models\n\n\n### MLPs\nSee [MLPs](AI/Deep%20learning/MLPs.md)\n\n### Deep belief network\nSee [Deep belief network](AI/Deep%20learning/Deep%20belief%20network.md)\n\n### Autoencoders\nSee [Autoencoders](AI/Deep%20learning/Autoencoders.md)\n\n### CNNs\nSee [CNNs](AI/Deep%20learning/CNNs.md)\n\n### RNNs\nSee [RNNs](AI/Deep%20learning/RNNs.md)\n\n### CapsNets\nSee [CapsNets](AI/Deep%20learning/CapsNets.md)\n\n### GANs\nSee [GANs](AI/Deep%20learning/GANs.md)\n\n### Bayesian neural networks\nSee [Bayesian neural networks](AI/Deep%20learning/Bayesian%20neural%20networks.md)\n\n### GNNs\nSee [GNNs](AI/Deep%20learning/GNNs.md)\n\n### Residual and dense neural networks\nSee [Residual and dense neural networks](AI/Deep%20learning/Residual%20and%20dense%20neural%20networks.md)\n\n### Neural ODEs\nSee [Neural ODEs](AI/Deep%20learning/Neural%20ODEs.md)\n\n### Fourier Neural Operators\nSee [Fourier Neural Operators](AI/Deep%20learning/Fourier%20Neural%20Operators.md)\n\n### Multimodal learning\nSee [Multimodal learning](AI/Deep%20learning/Multimodal%20learning.md)\n\n### Geometric deep learning\nSee [Geometric deep learning](AI/Deep%20learning/Geometric%20deep%20learning.md)\n\n### GFlowNets\nSee [GFlowNets](AI/Deep%20learning/GFlowNets.md)",
    "lastmodified": "2022-03-10T09:30:02.069584671Z",
    "tags": null
  },
  "/AI/Deep-learning/Encoder-decoder-networks": {
    "title": "Encoder-decoder networks",
    "content": "## Resources\n- Very common models for semantic segmentation tasks\n- [Deep learning](AI/Deep%20learning/Deep%20learning.md)] architectures composed of two paths, an encoding and a decoding one. [Autoencoders](AI/Deep%20learning/Autoencoders.md)] are similar but unsupervised (reconstructions loss)\n- U-NETs are a type of encoder-decoder [CNNs](AI/Deep%20learning/CNNs.md)] model with skipped connections trained in a [Supervised learning](AI/Supervised%20Learning/Supervised%20learning.md)] context for image segmentation and related tasks\n- https://www.slideshare.net/PetteriTeikariPhD/multiphoton-vasculature-segmentation-5-unet\n\n\n## References\n- #PAPER U-Net: Convolutional Networks for Biomedical Image Segmentation (Ronneberger 2015): https://arxiv.org/abs/1505.04597 \n\t- https://towardsdatascience.com/review-u-net-biomedical-image-segmentation-d02bf06ca760 \n\t- https://github.com/karolzak/keras-unet \n\t- https://tuatini.me/practical-image-segmentation-with-unet/ \n\t- https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/unet.py \n\t- diagram example: https://www.researchgate.net/publication/323302730/figure/fig1/AS:596310398881793@1519182886358/U-Net-architecture-consisted-with-convolutional-encoding-and-decoding-units-that-take.png \n- #PAPER 3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation (Cicek 2016): https://arxiv.org/abs/1606.06650\n\t- https://towardsdatascience.com/review-3d-u-net-volumetric-segmentation-medical-image-segmentation-8b592560fac1 \n- #PAPER V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation (Milletari 2016): https://arxiv.org/abs/1606.04797\n\t- https://towardsdatascience.com/review-v-net-volumetric-convolution-biomedical-image-segmentation-aa15dbaea974 \n- #PAPER Volumetric ConvNets with Mixed Residual Connections for Automated Prostate Segmentation from 3D MR Images, 3D UNET+Resnet (Yu 2017): https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14719\n\t- https://towardsdatascience.com/review-3d-u-net-resnet-volumetric-convolutions-long-short-residual-connections-biomedical-3a7da3f98dae\n- #PAPER Automatic 3D Cardiovascular MR Segmentation with Densely-Connected Volumetric ConvNets, DenseVoxNet (Yu 2017): https://arxiv.org/abs/1708.00573 \n\t- https://medium.com/@sh.tsang/review-densevoxnet-volumetric-brain-segmentation-biomedical-image-segmentation-9136bb6128dd \n- #PAPER Road Extraction by Deep Residual U-Net, ResUNET (Zhang 2017): https://arxiv.org/abs/1711.10684\n\t- https://github.com/nikhilroxtomar/Deep-Residual-Unet\n- #PAPER Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation (Alom 2018): https://www.researchgate.net/publication/323302730_Recurrent_Residual_Convolutional_Neural_Network_based_on_U-Net_R2U-Net_for_Medical_Image_Segmentation\n- #PAPER UNet++: A Nested U-Net Architecture for Medical Image Segmentation (Zhou 2018): https://arxiv.org/abs/1807.10165\n\t- https://medium.com/@sh.tsang/review-unet-a-nested-u-net-architecture-biomedical-image-segmentation-57be56859b20 \n- #PAPER H-DenseUNet: Hybrid Densely Connected UNet for Liver and Tumor Segmentation from CT Volumes (Li 2018): https://arxiv.org/abs/1709.07330  \n\t- https://medium.com/@sh.tsang/review-h-denseunet-2d-3d-denseunet-for-intra-inter-slice-features-biomedical-image-f3e526e81fe7 \n\t- #CODE https://github.com/xmengli999/H-DenseUNet/\n- #PAPER Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation, DeepLabv3+ (Chen 2018): https://arxiv.org/abs/1802.02611\n\t- #CODE https://github.com/ChoiDM/pytorch-deeplabv3plus-3D \n- #PAPER ResUNet-a: a deep learning framework for semantic segmentation of remotely sensed data (Diakogiannis 2019): https://arxiv.org/abs/1904.00592\n- #PAPER ResUNet++: An Advanced Architecture for Medical Image Segmentation (Jha 2019): https://arxiv.org/abs/1911.07067\n- #PAPER M-Net: U-Net with Multi-stream Feature Fusion and Multi-scale Dilated Convolutions (Fu 2019): https://ieeexplore.ieee.org/document/8864993 \n\t- https://www.researchgate.net/publication/336455527_M-Net_A_Novel_U-Net_with_Multi-stream_Feature_Fusion_and_Multi-scale_Dilated_Convolutions_for_Bile_Ducts_and_Hepatolith_Segmentation_September_2019 \n- #PAPER Channel-Unet: A Spatial Channel-Wise Convolutional Neural Network for Liver and Tumors Segmentation (Chen 2019): https://www.frontiersin.org/articles/10.3389/fgene.2019.01110/full\n- #PAPER Bi-Directional ConvLSTM U-Net with Densely Connected Convolutions (Azad 2019): https://arxiv.org/abs/1909.00166\n    - #CODE https://github.com/rezazad68/BCDU-Net/blob/master/Retina%20Blood%20Vessel%20Segmentation/models.py\n- #PAPER LSTM-UNET - Microscopy Cell Segmentation via Convolutional LSTM Networks (Arbelle 2019): https://arxiv.org/abs/1805.11247\n\t#CODE https://github.com/arbellea/LSTM-UNet\n- #PAPER USE-Net: incorporating Squeeze-and-Excitation blocks into U-Net for prostate zonal segmentation of multi-institutional MRI datasets (Rundo 2019): https://arxiv.org/abs/1904.08254\n- #PAPER Evaluation of Multi-Slice Inputs to Convolutional Neural Networks for Medical Image Segmentation (Vu 2019): https://arxiv.org/abs/1912.09287\n- #PAPER Making a Case for 3D Convolutions for Object Segmentation in Videos (Mahadevan 2020): https://arxiv.org/abs/2008.11516\n\t- proposed a simple and fast network architecture consisting entirely of 3D  convolutions that is capable of effectively learning spatio-temporal features\n\t- used a 3D ResNet pretrained for video action classification as an encoder, and a novel decoder architecture inspired by existing 2D convolutional networks\n- #PAPER nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation (Isensee 2020): https://www.nature.com/articles/s41592-020-01008-z\n\t- https://www.sciencedaily.com/releases/2020/12/201207112253.htm\n\t- #CODE https://github.com/MIC-DKFZ/nnUNet\n- #PAPER MCNN, Multi-resolution convolutional neural networks for inverse problems (Wang 2020): https://www.nature.com/articles/s41598-020-62484-z\n\t- #CODE https://github.com/fengwang/MCNN\n\t- #CODE https://github.com/fengwang/mcnn-demo/tree/master/demo",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/Fourier-Neural-Operators": {
    "title": "Fourier Neural Operator",
    "content": "## References\n- #PAPER Fourier Neural Operator for Parametric Partial Differential Equations (Li 2020): https://arxiv.org/abs/2010.08895\n\t- #CODE https://github.com/zongyi-li/fourier_neural_operator\n\t- https://zongyi-li.github.io/blog/2020/fourier-pde/\n\t- https://www.technologyreview.com/2020/10/30/1011435/ai-fourier-neural-network-cracks-navier-stokes-and-partial-differential-equations/\n\t- Function approximation in Fourier space instead of a the Euclidian (with conventional convolutions)\n\t- Paper explained: https://www.youtube.com/watch?v=IaS72aHrJKE",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/GANs": {
    "title": "Generative Adversarial Networks (GANs)",
    "content": "## Resources\n- A GAN consists of two networks; a generator (G) and a discriminator (D), given a set of training examples, G will generate outputs and D will classify them as either being from the same distribution as the training examples or not. In doing so D is optimized so as to be able to discriminate between examples from the training example and from the generator network which in turn is optimized to fool D into classifying its output as being drawn from the training examples. After such training G can now generate samples with properties very similar to those of the training examples. GANs tend to be devilishly hard to train. \n- List of papers and other on Generative Adversarial Networks: https://github.com/pshams55/GAN-Case-Study\n- Generative Adversarial Networks: https://spectra.pub/ml/gans\n- #TALK GANs for Good - A Virtual Expert Panel by DeepLearning.AI: https://www.youtube.com/watch?v=9d4jmPmTWmc\n- Generative adversarial networks: https://deepgenerativemodels.github.io/notes/gan/ \n- Generative adversarial networks for beginners: https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners\n- Intuitive explanation of GANs. Subtypes. https://tryolabs.com/blog/2016/12/06/major-advancements-deep-learning-2016/\n- https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-1-Generative-Adversarial-Nets\n- http://www.openias.org/hybrid-generative-discriminative\n- http://edwardlib.org/tutorials/gan\n- Play with GANs in your browser: https://poloclub.github.io/ganlab/\n- Do GANs actually do distribution learning?: http://www.offconvex.org/2017/07/06/GANs3/\n- The GAN Zoo - A list of all named GANs! https://deephunt.in/the-gan-zoo-79597dc8c347\n- Advances in Generative Adversarial Networks: https://beyondminds.ai/advances-in-generative-adversarial-networks-gans/ ^advancesingans\n\t- Drawbacks of using GANs: Mode collapse, Convergence, Quality evaluation, Metrics\n\t- Techniques for Improving Performance:\n\t\t- Alternative Loss Functions: One of the most popular fixes to the shortcomings of GANs is the Wasserstein GAN. It essentially replaces the Jensen Shannon divergence of conventional GANs with the Earth Mover distance (Wasserstein-1 distance or EM distance)\n\t\t- Two Timescale Update Rule (TTUR): In this method, we use a different learning rate for the discriminator and the generator. Typically, a slower update rule is used for the generator and a faster update rule is used for the discriminator\n\t\t- Gradient Penalty: In the paper [GANs#^wgangp](AI/Deep%20learning/GANs.md#%5Ewgangp), a simple gradient penalty was introduced which is added to the loss function to avoid exploding vanishing gradients and optimization issues (caused by weight clipping)\n\t\t- Spectral Normalization: weight normalization technique that is typically used on the Discriminator to enhance the training process\n\t\t- Unrolling and Packing: http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/\n\t\t- Stacking GANs: use multiple GANs placed consecutively, where each GAN solves an easier version of the problem.  For instance, FashionGAN used two GANs to perform localized image translation. Progressive GANs (ProGANs) can generate high quality images of excellent resolution.\n\t\t- Relativistic GANs: Conventional GANs measure the probability of the generated data being real. Relativistic GANs measure the probability of the generated data being “more realistic” than the real data. We can measure this “relative realism” using an appropriate distance measure, as mentioned in the RGAN [GANs#^190c58](AI/Deep%20learning/GANs.md#%5E190c58) paper\n\t\t- Self Attention Mechanism [GANs#^sagan](AI/Deep%20learning/GANs.md#%5Esagan):  The authors of Self Attention GANs claim that convolutions used for generating images look at information that are spread locally. That is, they miss out on relationships that span globally due to their restrictive receptive field. Self-Attention Generative Adversarial Network allows attention-driven, long-range dependency modeling for image generation tasks. \n\t\t- Miscellaneous Techniques: Feature Matching, Mini Batch Discrimination, Historical Averaging, One-sided Label Smoothing, Virtual Batch Normalization. See [GANs#^improvedgans](AI/Deep%20learning/GANs.md#%5Eimprovedgans)\n\n## Courses\n- #COURSE Generative Adversarial Networks ( DeepMind x UCL | Deep Learning Lectures | 9/12): https://www.youtube.com/watch?v=wFsI2WqUfdA\u0026t=850s\n\n## Code\n- #CODE Keras-GAN - Collection of Keras implementations of GANs: https://github.com/eriklindernoren/Keras-GAN\n- #CODE Pytorch-GAN - Collection of Pytorch implementations of GANs: https://github.com/eriklindernoren/PyTorch-GAN\n- #CODE Generative models in Tensorflow and Pytorch: https://github.com/wiseodd/generative-models\n- #CODE Tensorflow generative model collection: https://github.com/hwalsuklee/tensorflow-generative-model-collections\n- #CODE ydata-synthetic: https://github.com/ydataai/ydata-synthetic\n\t- This repository contains material related with GANs for synthetic data generation, in particular regular tabular data and time-series\n\n\n## References\nReview papers:\n- #PAPER A Survey on Generative Adversarial Networks: Variants, Applications,and Training (Jabbar 2020): https://arxiv.org/abs/2006.05132\n- #PAPER A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications (Gui 2020): https://arxiv.org/abs/2001.06937\n\n- #PAPER Generative Adversarial Networks (Goodfellow 2014): http://arxiv.org/abs/1406.2661\n\t- Paper explained: https://www.youtube.com/watch?v=eyxmSmjmNS0\n- #PAPER GAN to convert text descriptions into images (Reed 2016): https://arxiv.org/abs/1605.05396\n- #PAPER Unsupervised representation learning with GANs (Radford 2016): https://arxiv.orga/abs/1511.06434v2\n\t- Although GANs were already introduced in 2014 by Ian Goodfellow, it wasn't until the publication of this paper detailing a deep convolutional architecture (DCGAN) that GANs really took off \n\t- https://www.tensorflow.org/tutorials/generative/dcgan\n\t- https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8\n\t- #CODE https://github.com/tensorflow/models/blob/master/research/slim/nets/dcgan.py\n- #PAPER Deconvolution and Checkerboard Artifacts (Odena 2016): https://distill.pub/2016/deconv-checkerboard/\n- #PAPER InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets (Chen 2016): https://arxiv.org/abs/1606.03657\n\t- https://wiseodd.github.io/techblog/2017/01/29/infogan/\n- #PAPER Checkerboard artifact free sub-pixel convolution: A note on sub-pixel convolution, resize convolution and convolution resize (Aitken 2017): https://arxiv.org/abs/1707.02937\n- #PAPER Wasserstein GAN (Arjovsky 2017): https://arxiv.org/abs/1701.07875\n\t- From GAN to Wasserstein GAN: https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html#wasserstein-gan-wgan \n- #PAPER Improved Training of Wasserstein GANs (Gulrajani 2017): https://arxiv.org/abs/1704.00028 ^wgangp\n- #PAPER Bayesian GAN (Saatchi 2017): https://arxiv.org/abs/1705.09558\n\t- #CODE https://github.com/andrewgordonwilson/bayesgan\n- #PAPER WaterGAN: Unsupervised Generative Network to Enable Real-time Color Correction of Monocular Underwater Images (Li 2017): https://arxiv.org/abs/1702.07392 \n- #PAPER A Style-Based Generator Architecture for Generative Adversarial Networks, StyleGAN (Karras 2018): https://arxiv.org/abs/1812.04948 \n\t- #TALK https://youtu.be/kSLJriaOumA \n\t- #CODE https://github.com/NVlabs/stylegan \n\t- FFHQ: https://github.com/NVlabs/ffhq-dataset \n- #PAPER The relativistic discriminator: a key element missing from standard GAN (Jolicoeur-Martineau 2018): https://arxiv.org/abs/1807.00734 ^190c58\n- #PAPER From GAN to WGAN (Wenb 2019): https://arxiv.org/abs/1904.08994\n- #PAPER Time Series Simulation by Conditional Generative Adversarial Net (Fu 2019): https://arxiv.org/abs/1904.11419\n- #PAPER HoloGAN: Unsupervised learning of 3D representations from natural images (Nguyen-Phuoc 2019): https://arxiv.org/abs/1904.01326 \n\t- https://www.monkeyoverflow.com/#/hologan-unsupervised-learning-of-3d-representations-from-natural-images/ \n\t- #TALK https://www.youtube.com/watch?v=z2DnFOQNECM\n- #PAPER Implicit competitive regularization in GANs (Schafer 2020): https://arxiv.org/abs/1910.05852\n- #PAPER Training Generative Adversarial Networks with Limited Data (Karras 2020): https://arxiv.org/abs/2006.06676\n- #PAPER Gradient-Guided Dynamic Efficient Adversarial Training (Waag 2021): https://arxiv.org/abs/2103.03076\n\t- #CODE https://github.com/locuslab/fast_adversarial\n\t- The goal of DEAT is to improve adversarial training while maintaining effectiveness. It begins by training one batch replay and gradually increases it during training\n\t- This method reduces large amount of computation when doing backpropagation and consequently achieves a more efficient training paradigm\n\n\n## Subtopics\n\n### GANs for super-resolution\nSee [Super-resolution#GAN-based](AI/Computer%20Vision/Super-resolution.md#GAN-based)\n\n\n### GANs for missing data, imputation and inpainting\nSee [Inpainting#GAN-based](AI/Computer%20Vision/Inpainting.md#GAN-based)\n\n\n### Image-to-image translation. Conditional GANs\nSee [Image-to-image translation#GAN-based](AI/Computer%20Vision/Image-to-image%20translation.md#GAN-based)\n\n\n### GANs for spatio-temporal data generation\n- #PAPER COT-GAN: Generating Sequential Data via Causal Optimal Transport (Xu 2020): https://arxiv.org/abs/2006.08571\n- #PAPER SPATE-GAN: Improved Generative Modeling of Dynamic Spatio-Temporal Patterns with an Autoregressive Embedding Loss (Klemmer 2021): https://arxiv.org/abs/2109.15044# ^spate-gan\n\t- #CODE https://github.com/konstantinklemmer/spate-gan\n\n\n### GANs for representation learning and image synthesis \n- #PAPER Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks, Laplacian GAN (Denton 2015): https://arxiv.org/abs/1506.05751\n- #PAPER Adversarial feature learning, BiGAN (Donahue 2017): https://arxiv.org/abs/1605.09782\n- #PAPER Large Scale Adversarial Representation Learning, BigBiGAN (Donahue 2019): https://arxiv.org/abs/1907.02544\n- #PAPER Large Scale GAN Training for High Fidelity Natural Image Synthesis, BigGAN (Brock 2019): https://arxiv.org/abs/1809.11096\n- #PAPER Self-Attention GANs, SAGAN (Zhang 2019): https://arxiv.org/abs/1805.08318 ^sagan\n\t- #CODE https://github.com/brain-research/self-attention-gan\n- #PAPER In-domain GAN Inversion for Real Image Editing (Zhu 2020): https://genforce.github.io/idinvert/\n\t- Paper explained: https://www.youtube.com/watch?v=2qMw8sOsNg0\n- #PAPER High-Fidelity Generative Image Compression (Mentzer 2020): https://arxiv.org/abs/2006.09965\n\t- https://hific.github.io/\n- #PAPER Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications (Liu 2020): https://arxiv.org/abs/2008.02793\n- #PAPER Image Synthesis with Adversarial Networks: a Comprehensive Survey and Case Studies (Shamsolmoali 2020): https://arxiv.org/abs/2012.13736\n- #PAPER Cross-Modal Contrastive Learning for Text-to-Image Generation (Zhang 2021): https://arxiv.org/abs/2101.04702\n\t- https://ai.googleblog.com/2021/05/cross-modal-contrastive-learning-for.html\n\t- text-to-image generation by learning to maximize the mutual information between image and text using inter-modal (image-text) and intra-modal (image-image) contrastive losses\n- #PAPER TriGAN: image-to-image translation for multi-source domain adaptation (Roy 2021): https://link.springer.com/article/10.1007/s00138-020-01164-4\n\t- approach for multi-source domain adaptation (MSDA) based on generative adversarial networks\n- #PAPER Sketch Your Own GAN (Wang 2021): https://arxiv.org/abs/2108.02774\n- #PAPER Instance-Conditioned GAN (Casanova 2021): https://arxiv.org/abs/2109.05070\n\t- #CODE https://paperswithcode.com/paper/instance-conditioned-gan?from=n17\n\n\n### Semi-supervised GANs\n- #PAPER Improved Techniques for Training GANs (Saliman 2016): https://arxiv.org/abs/1606.03498 ^improvedgans\n\t- https://towardsdatascience.com/semi-supervised-learning-with-gans-9f3cb128c5e\n\t- https://hjweide.github.io/semi-supervised-dcgan\n- #PAPER Semi-Supervised Learning with Generative Adversarial Networks (Odena 2016): https://arxiv.org/abs/1606.01583\n\t- #CODE https://github.com/tryambak2019/SGAN\n- #PAPER Semi and Weakly Supervised Semantic Segmentation Using Generative Adversarial Network (Suoly 2017): https://arxiv.org/abs/1703.09695\n- #PAPER Semi-supervised Learning in Generative Adversarial Networks, review (2018): https://farzadab.github.io/assets/projects/pdf/Review__SSL_in_GANs.pdf\n    - The GAN framework can be integrated with almost any available neural network classifier in order to make use of unlabeled data\n\n\n### Few/one-shot learning GANs \nSee [One, few-shot learning#Few one-shot learning GANs](AI/One,%20few-shot%20learning.md#Few%20one-shot%20learning%20GANs)\n\n\n### GANs for anomaly detection\n- #PAPER A Survey on GANs for Anomaly Detection (Di Mattia 2019): https://arxiv.org/abs/1906.11632 \n- #PAPER TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks (Geiger 2020): https://arxiv.org/abs/2009.07769\n\t- #CODE [[#^oriontfanomalies]]\n\t- https://analyticsindiamag.com/hands-on-guide-to-tadgan-with-python-codes/",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/GFlowNets": {
    "title": "GFlowNets",
    "content": "## Talks\n- #TALK GFlowNets for generative active learning | Amazon Science: https://www.youtube.com/watch?v=2s_GtmofbyU\n- #TALK Prof. YOSHUA BENGIO - GFlowNets, Consciousness \u0026 Causality (Podcast, discussion): https://www.youtube.com/watch?v=M49TMqK5uCE\n- #TALK Confiance.ai Day 2021 - Yoshua Bengio, Director, Mila : GFlowNets for Generative Active Learning: https://www.youtube.com/watch?v=Ww9c9u_nTjQ\n\n## References\n- #PAPER GFlowNet Foundations (Bengio 2021): https://arxiv.org/abs/2111.09266\n\t- Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function\n- #PAPER Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation (Bengio 2021): https://arxiv.org/abs/2106.04399\n\t- #CODE https://github.com/GFNOrg/gflownet\n\t- http://folinoid.com/w/gflownet/",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/GNNs": {
    "title": "Graph neural networks (GNNs)",
    "content": "## Resources\n- Graph Neural networks (GNNs) are being widely adopted for diverse applications and domains. This is in part due to their effectiveness on complex data structures, improved performance and scalability, and availability of approaches\n- A Gentle Introduction to Graph Neural Networks: https://distill.pub/2021/gnn-intro/\n- Must read papers on GNNs: https://github.com/thunlp/GNNPapers\n- Time Series Forecasting with Graph Convolutional Neural Network: https://towardsdatascience.com/time-series-forecasting-with-graph-convolutional-neural-network-7ffb3b70afcf\n- https://medium.com/dair-ai/an-illustrated-guide-to-graph-neural-networks-d5564a551783\n\n## Talks\n- #TALK Intro to graph neural networks (ML Tech Talks, Deepmind): https://www.youtube.com/watch?v=8owQBFAHw7E\n\n## Code\n- #CODE DGL - Deep graph library: https://github.com/dmlc/dgl\n\t- https://www.dgl.ai/\n- #CODE Pytorch geometric: https://github.com/rusty1s/pytorch_geometric\n- #CODE Spektral - Graph Neural Networks with Keras and Tensorflow 2: https://github.com/danielegrattarola/spektral\n- #CODE Deep Graph Library (DGL) - Python package built to ease deep learning on graph, on top of existing DL frameworks. \n\t- https://github.com/dmlc/dgl\n\t- http://dgl.ai\n\t- It makes implementing graph neural networks (including Graph Convolution Networks, TreeLSTM, and many others) easy while maintaining high computation efficiency.\n- #CODE DIG: A Turnkey Library for Diving into Graph Deep Learning Research: https://github.com/divelab/DIG\n- #CODE PyTorch Geometric Temporal: https://github.com/benedekrozemberczki/pytorch_geometric_temporal\n\t- A Temporal Extension Library for PyTorch Geometric\n\n## References\n- #PAPER Structured Sequence Modeling with Graph Convolutional Recurrent Networks (Seo 2016): https://arxiv.org/abs/1612.07659\n\t- Graph Convolutional Recurrent Network (GCRN)\n- #PAPER Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting (Yu 2018): https://arxiv.org/abs/1709.04875 \n- #PAPER Dynamic Spatial-Temporal Graph Convolutional Neural Networks for Traffic Forecasting (Diao 2019): https://www.aaai.org/ojs/index.php/AAAI/article/view/3877\n- #PAPER A Comprehensive Survey on Graph Neural Networks (Wu 2019): https://arxiv.org/abs/1901.00596\n- #PAPER Graph Neural Networks: A Review of Methods and Applications (Zhou 2019): https://arxiv.org/abs/1812.08434\n- #PAPER Graph Neural Networks for Decentralized Controllers (Gama 2020): https://arxiv.org/abs/2003.10280 \n- #PAPER Learning to Simulate Complex Physics with Graph Networks (Sanchez-Gonzalez 2020): https://arxiv.org/abs/2002.09405\n\t- Two minute papers: https://www.youtube.com/watch?v=2Bw5f4vYL98\n- #PAPER DeepSphere: a graph-based spherical CNN (Defferrard 2020): https://arxiv.org/abs/2012.15000 ^deepsphere\n\t- #CODE https://github.com/deepsphere\n- #PAPER VQ-GNN: A Universal Framework to Scale up Graph Neural Networks using Vector Quantization (Ding 2021): https://arxiv.org/abs/2110.14363\n- #PAPER Nested Graph Neural Networks (Zhang 2021): https://arxiv.org/abs/2110.13197\n\t- #CODE https://paperswithcode.com/paper/nested-graph-neural-networks?from=n19\n- #PAPER A Heterogeneous Graph Based Framework for Multimodal Neuroimaging Fusion Learning (Shi 2021): https://arxiv.org/abs/2110.08465\n\t- #CODE https://paperswithcode.com/paper/a-heterogeneous-graph-based-framework-for?from=n19",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/Generative-modelling": {
    "title": "Generative modeling",
    "content": "## Resources\n- Generative models: https://openai.com/blog/generative-models/ \n- Deep Generative Models: https://www.cs.toronto.edu/~slwang/generative_model.pdf\n- Taxonomy of Generative Models: https://christineai.blog/taxonomy/\n\n## Courses\n- #COURSE Deep Generative Modeling: VAEs and GANs (MIT 6.S191): https://www.youtube.com/watch?v=rZufA635dq4\u0026t=1062s\n\n\n### Autoencoders\nSee [Autoencoders#VAEs](Autoencoders.md#VAEs)\n\n### GANs\nSee [[GANs]]\n\n### Normalizing flows\nSee [Normalizing flows](Normalizing%20flows.md)\n\n### Generative models for Image data\nSee:\n[Image-to-image translation](Image-to-image%20translation.md)\n[Image-to-image translation#GAN-based](Image-to-image%20translation.md#GAN-based)\n[GANs#GANs for representation learning and image synthesis](GANs.md#GANs%20for%20representation%20learning%20and%20image%20synthesis)\n[Transformers#For Computer Vision](Transformers.md#For%20Computer%20Vision)\n\n- #PAPER Video Pixel Networks (Kalchbrenner 2016): https://arxiv.org/abs/1610.00527\n- #PAPER Pixel RNNs - Pixel Recurrent Neural Networks (van den Oord 2016): https://arxiv.org/abs/1601.06759\n\t- Pixel-RNN presents a novel architecture with recurrent layers and residual connections that predicts pixels across the vertical and horizontal axes. The architecture models the joint distribution of pixels as a product of conditional distributions of horizontal and diagonal pixels. The model achieves state-of-the-art in the generation of natural images.\n\t- https://medium.com/a-paper-a-day-will-have-you-screaming-hurray/day-4-pixel-recurrent-neural-networks-1b3201d8932d\n\t- https://christineai.blog/pixelcnn-and-pixelrnn/\n- #PAPER Conditional Image Generation with PixelCNN Decoders (van den Oord 2016): https://arxiv.org/abs/1606.05328\n\t-  https://medium.com/a-paper-a-day-will-have-you-screaming-hurray/day-5-conditional-image-generation-with-pixelcnn-decoders-a8fc68b103a2\n\t-  #CODE https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/PixelCNN\n\t-  #CODE https://keras.io/examples/generative/pixelcnn/\n- #PAPER PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications (Salimans 2017): https://arxiv.org/abs/1701.05517\n\t- #CODE https://github.com/openai/pixel-cnn\n\t- https://openreview.net/forum?id=BJrFC6ceg\u0026noteId=Bkc_sOZ4l\n- #PAPER FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models (Grathwohl 2018): https://arxiv.org/abs/1810.01367 \n- #PAPER Generating Realistic Geology Conditioned on Physical Measurements with Generative Adversarial Networks (Dupont 2018): http://arxiv.org/abs/1802.03065 ^dupont18\n\t- Using G and D we want to generate realistic images conditioned on a set of known pixels\n\t- Total loss is a combination of a Prior loss (high score of generated images from D) and a Contexet loss (generated image should match the known pxs)\n\t- For the Context loss, a mask is used with smoothing\n- #PAPER Parametric generation of conditional geological realizations using generative neural networks (Chan 2019): https://link.springer.com/article/10.1007%2Fs10596-019-09850-7 ^chan19\n- #PAPER Parametrization of Stochastic Inputs Using Generative Adversarial Networks With Application in Geology (Chan 2020): https://www.frontiersin.org/articles/10.3389/frwa.2020.00005/full ^chan20\n- #PAPER Generative Models as Distributions of Functions (Dupont 2021): https://arxiv.org/abs/2102.04776\n\t- Generative models are typically trained on grid-like data such as images (tied to the underlying grid resolution)\n\t- Instead of discretized grids, they parametrized individual data points by continuous functions over which they learned distributions --\u003e generative models\n\t- Coordinate and feature pairs are treated as point clouds (sets with underlying notion of distance). Leveraged the PointConv framekwork \n\t- Their model can learn rich distributions of functions independently of data type and resolution. Application to [[Super-resolution]]\n- #PAPER Score-Based Generative Modeling through Stochastic Differential Equations (Song 2021): https://arxiv.org/abs/2011.13456v2\n\t- #CODE https://paperswithcode.com/paper/score-based-generative-modeling-through-1\n- #PAPER Diffusion Models Beat GANs on Image Synthesis (Dhariwal 2021): https://arxiv.org/abs/2105.05233v3\n\t- #CODE https://github.com/openai/guided-diffusion\n\t- Diffusion models are a class of likelihood-based models that have shown to produce high-quality images with desired properties such as distribution coverage and easy scalability. These models generate samples by gradually removing noise from a signal. Previous research has shown that they improve reliably with increased compute. The proposed method brings improvements to diffusions models that have worked for GANs, such as improved model architecture and a scheme to trade off diversity for quality. The proposed diffusion model achieves several state-of-the-art results, surpassing GANs on several metrics and datasets",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/Geometric-deep-learning": {
    "title": "Geometric deep learning",
    "content": "## Talks and courses\n- #TALK Geometric Deep Learning: The Erlangen Programme of ML (M Bronstein, ICLR 2021 Keynote): https://www.youtube.com/watch?v=w6Pw4MOzMuo\n- #COURSE Geometric Deep Learning: https://geometricdeeplearning.com/lectures/\n\n## References\nReview papers:\n- #PAPER Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges (Bronstein 2021): https://arxiv.org/abs/2104.13478",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/MLPs": {
    "title": "Multilayer perceptrons (MLPs)",
    "content": "## Resources\n- A multilayer perceptron (MLP) is a feed forward artificial neural network model that maps sets of input data onto a set of appropriate outputs. An MLP consists of multiple layers of nodes in a directed graph, with each layer fully connected to the next one. Except for the input nodes, each node is a neuron (or processing element) with a non linear activation function. \n- MLP utilizes a supervised learning technique called back propagation for training the network\n- MLP is a modification of the standard linear perceptron and can distinguish data that is not linearly separable\n- Multilayer Perceptron (MLP) vs Convolutional Neural Network in Deep Learning: https://medium.com/data-science-bootcamp/multilayer-perceptron-mlp-vs-convolutional-neural-network-in-deep-learning-c890f487a8f1\n\n## Code\n- #CODE MLP for MNIST: https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py\n- #CODE Sklearn MLP implementation: \n\t- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n\t- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\n\n\n## Perceptron\n- History of the Perceptron: https://medium.com/@Jaconda/a-concise-history-of-neural-networks-2070655d3fec\n- https://www.neuraldesigner.com/blog/perceptron-the-main-component-of-neural-networks\n- https://fr.mathworks.com/help/nnet/ug/perceptron-neural-networks.html\n- http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/\n- http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html\n\n\n## MLPs for vision and language\n- #PAPER MLP-Mixer: An all-MLP Architecture for Vision (Tolstikhin 2021): https://arxiv.org/abs/2105.01601v2\n\t- #CODE https://paperswithcode.com/paper/mlp-mixer-an-all-mlp-architecture-for-vision?from=n9\n\t- CNNs are widely regarded as the go-to model for dealing with computer vision tasks. Attention-based architectures have also emerged as promising approaches that produce good performance on a variety of vision tasks. Despite this trend and the successes of attention and CNN architectures, this paper proposes a simple alternative architecture, MLP-Mixer, based on multi-layer perceptions, that produces competitive results on image classification benchmarks\n\t- MLP-Mixer contains two types of layers. One layer of MLPs applied independently to image patches and another layer of MLPs applied across patches. These layers achieve the effect of mixing per-location features and mixing spatial information, respectively \n\t- MLP-Mixer achieves competitive results on the ImageNet benchmark\n- #PAPER RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition (Ding 2021): https://arxiv.org/abs/2105.01883v1\n\t- #CODE https://github.com/DingXiaoH/RepMLP\n- #PAPER ResMLP: Feedforward networks for image classification with data-efficient training (Touvron 2021): https://arxiv.org/abs/2105.03404\n- #PAPER Pay Attention to MLPs (Liu 2021): https://arxiv.org/abs/2105.08050v2\n\t- #CODE https://paperswithcode.com/paper/pay-attention-to-mlps?from=n10\n\t- https://www.infoq.com/news/2021/10/google-mlp-vision-language/\n\t- Researchers at Google Brain have announced Gated Multi-Layer Perceptron (gMLP), a deep-learning model that contains only basic multi-layer perceptrons\n\t- gMLP aims to show that these simplified architectures can perform as well as Transformers on key vision and language applications. According to the authors, the results and comparisons show that attention is not critical for Vision Transformers\n\t- In fine-tuning tasks, gMLP can close the gap on Transformers by simply making the model substantially larger\n\t- gMLP can scale as well as Transformers over increased data and compute\n- #PAPER MAXIM: Multi-Axis MLP for Image Processing (Tu 2022): https://arxiv.org/abs/2201.02973v1\n\t- #CODE https://paperswithcode.com/paper/maxim-multi-axis-mlp-for-image-processing?from=n23",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/Multimodal-learning": {
    "title": "Multimodal learning",
    "content": "## Resources\n- General-purpose neural networks capable of handling diverse inputs and output tasks\n- Multimodal Deep Learning: https://multimodal-dl.mpi-inf.mpg.de/\n\n## Code\n- #CODE Pykale (in pytorch): https://github.com/pykale/pykale\n\t- [[#^pykale]]\n\n## References\nReview papers:\n- #PAPER Recent Advances and Trends in Multimodal Deep Learning: A Review (Summaira 2021): https://arxiv.org/abs/2105.11087\n\n- #PAPER Multi-modal Transformer for Video Retrieval (Gabeur 2020): https://arxiv.org/abs/2007.10639\n- #PAPER DALL-E - Creating Images from Text (Ramesh 2021): https://openai.com/blog/dall-e/ ^dall-e\n\t- https://www.technologyreview.com/2021/01/05/1015754/avocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense/\n\t- Blogpost explained: https://www.youtube.com/watch?v=j4xgkjWlfL4\n\t- #CODE https://github.com/EleutherAI/DALLE-mtf\n\t- Multi-modal text and speech\n\t- DALL-E mini: https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA\n- #PAPER Perceiver: General Perception with Iterative Attention (Jaegle 2021): https://arxiv.org/abs/2103.03206\n\t- https://www.zdnet.com/article/googles-supermodel-deepmind-perceiver-is-a-step-on-the-road-to-an-ai-machine-that-could-process-everything/\n\t- Multi-model with image, audio, video, 3d point clouds\n- #PAPER PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python (Lu 2021): https://arxiv.org/abs/2106.09756v1 ^pykale\n- #PAPER Perceiver IO: A General Architecture for Structured Inputs \u0026 Outputs (Jaegle 2021): https://arxiv.org/abs/2107.14795v2\n\t- #CODE https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for\n- #PAPER VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text (Akbari 2021): https://arxiv.org/abs/2104.11178v2\n\t- #CODE https://paperswithcode.com/paper/vatt-transformers-for-multimodal-self\n\t- VATT is trained to learn multimodal representations from unlabeled data using Transformer architectures\n- #PAPER NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion (Wu 2021): https://arxiv.org/abs/2111.12417v1\n\t- #CODE https://paperswithcode.com/paper/nuwa-visual-synthesis-pre-training-for-neural\n\t- Paper explained: https://www.youtube.com/watch?v=InhMx1h0N40\u0026list=WL\u0026index=50\n\t- NÜWA consists of an adaptive encoder that takes either text or visual input, and a pre-trained decoder shared by 8 visual tasks\n\t- 3D Nearby Attention mechanism (3DNA) is proposed to reduce computational complexity and improve visual quality of results, by considering the locality characteristics for both spatial and temporal axes to better deal with the nature of the visual data",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/Neural-ODEs": {
    "title": "Neural Ordinary Differential Equations",
    "content": "## Resources\n- https://github.com/Zymrael/awesome-neural-ode\n- Understanding Neural ODE's: https://jontysinai.github.io/jekyll/update/2019/01/18/understanding-neural-odes.html\n- Neural Ordinary Differential Equations and Dynamics Models: https://medium.com/@ml.at.berkeley/neural-ordinary-differential-equations-and-dynamics-models-1a4277fbb80\n\t- ODEs are often used to describe the time derivatives of a physical situation, referred to as the dynamics. Knowing the dynamics allows us to model the change of an environment, like a physics simulation, unlocking the ability to take any starting condition and model how it will change. With Neural ODEs, we don’t define explicit ODEs to document the dynamics, but learn them via ML.\n\t- Strong connection with [[Residual and dense neural networks]]. Why do residual layers help networks achieve higher accuracies and grow deeper? Firstly, skip connections help information flow through the network by sending the hidden state, h(t), along with the transformation by the layer, f(h(t)), to layer t+1, preventing important information from being discarded by f. Secondly, residual layers can be stacked, forming very deep networks.\n\t- However, ResNets still employ many layers of weights and biases requiring much time and data to train. On top of this, the backpropagation algorithm on such a deep network incurs a high memory cost to store intermediate values.\n\t- Continuous depth ODENets are evaluated using black box ODE solvers, but first the parameters of the model must be optimized via gradient descent. To do this, we need to know the gradient of the loss with respect to the parameters, or how the loss function depends on the parameters in the ODENet.\n\t- In deep learning, backpropagation is the workhorse for finding this gradient, but this algorithm incurs a high memory costs to store the intermediate values of the network. On top of this, the sheer number of chain rule applications produces numerical error. Since an ODENet models a differential equation, these issues can be circumvented using sensitivity analysis methods developed for calculating gradients of a loss function with respect to the parameters of the system producing its input.\n\n\n## References\n- #PAPER Neural Ordinary Differential Equations (TQ Chen 2018): https://arxiv.org/abs/1806.07366\n\t- #CODE https://github.com/JSeam2/Neural-Ordinary-Differential-Equations\n\t- #CODE https://github.com/jason71995/Keras_ODENet\n\t- Neural Ordinary Differential Equations - Best Paper Awards NeurIPS 2018: https://www.youtube.com/watch?v=V6nGT0Gakyg\n\t- https://towardsdatascience.com/paper-summary-neural-ordinary-differential-equations-37c4e52df128\n\t- https://braindump.jethro.dev/posts/neural_ode/\n\t- https://msurtsukov.github.io/Neural-ODE/\n\t- https://github.com/msurtsukov/neural-ode/blob/master/Neural%20ODEs.ipynb\n\t- https://www.youtube.com/watch?v=jltgNGt8Lpg\n- #PAPER Augmented Neural ODEs (Dupont 2019): https://arxiv.org/abs/1904.01681\n- #PAPER Differential Bayesian Neural Nets (Look 2020): https://arxiv.org/abs/1912.00796\n\t- Neural Ordinary Differential Equations (N-ODEs) are a powerful building block for learning systems, which extend residual networks to a continuous-time dynamical system. Propose a Bayesian version of N-ODEs that enables well-calibrated quantification of prediction uncertainty, while maintaining the expressive power of their deterministic counterpart.\n- #THESIS/MSC Generative Modeling with Neural Ordinary Differential Equations (2019): https://uwspace.uwaterloo.ca/bitstream/handle/10012/15354/Dockhorn_Tim.pdf\n- #PAPER Universal Differential Equations for Scientific Machine Learning (Rackauckas 2020): https://arxiv.org/abs/2001.04385\n\t- https://www.stochasticlifestyle.com/how-to-train-interpretable-neural-networks-that-accurately-extrapolate-from-small-data/\n- #PAPER Neural Differential Equations for Single Image Super-Resolution (Le Scao 2020): https://arxiv.org/pdf/2005.00865\n- #PAPER Liquid Time-constant Networks (Hasani 2020): https://arxiv.org/abs/2006.04439\n\t- #TALK https://www.youtube.com/watch?v=IlliqYiRhMU\n\t- #CODE https://github.com/raminmh/liquid_time_constant_networks\n\t- https://news.mit.edu/2021/machine-learning-adapts-0128",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/Normalizing-flows": {
    "title": "Normalizing flows",
    "content": "## Resources\n- Normalizing flow models are generative models, i.e. they infer the underlying probability distribution of an observed dataset. With that distribution we can do a number of interesting things, namely sample new realistic points and query probability densities.\n- https://github.com/janosh/awesome-normalizing-flows\n- Flow-based Deep Generative Models: https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html\n- https://deepgenerativemodels.github.io/notes/flow/ \n- http://akosiorek.github.io/ml/2018/04/03/norm_flows.html \n\n- #TALK Introduction to Normalizing Flows (ECCV2020 Tutorial): https://www.youtube.com/watch?v=u3vVyFVU_lI\n\n\n## Code\n- #CODE Normalizing Flows in JAX: https://github.com/ChrisWaites/jax-flows\n- #CODE NuX - Normalizing Flows using JAX: https://github.com/Information-Fusion-Lab-Umass/NuX\n\n\n## References\nReview papers:\n- #PAPER Normalizing Flows: An Introduction and Review of Current Methods (Kobyzev 2020): https://arxiv.org/abs/1908.09257\n\n- #PAPER NICE: Non-linear Independent Components Estimation (Dinh 2015): https://arxiv.org/abs/1410.8516\n- #PAPER Glow: Generative Flow with Invertible 1x1 Convolutions (Kingma 2018): https://arxiv.org/abs/1807.03039\n\t- https://openai.com/blog/glow/\n\t- #CODE https://github.com/openai/glow\n\n\n### Image-to-image translation\nSee [Image-to-image translation#Flow-based](Image-to-image%20translation.md#Flow-based)",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/RNNs": {
    "title": "Recurrent Neural Networks (RNNs)",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Recurrent_neural_network\n- https://github.com/kjw0612/awesome-rnn\n- Recurrent Neural Networks cheatsheet: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n- Tensorflow, DL and RNNs without a PhD: https://docs.google.com/presentation/d/e/2PACX-1vRouwj_3cYsmLrNNI3Uq5gv5-hYp_QFdeoan2GlxKgIZRSejozruAbVV0IMXBoPsINB7Jw92vJo2EAM/pub?slide=id.p\n- http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n- http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html\n- http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n- http://www.kdnuggets.com/2017/04/build-recurrent-neural-network-tensorflow.html\n- https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0\n- https://www.kaggle.com/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru\n- https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n- 4 Sequence Encoding Blocks You Must Know Besides RNN/LSTM in Tensorflow: https://hanxiao.github.io/2018/06/24/4-Encoding-Blocks-You-Need-to-Know-Besides-LSTM-RNN-in-Tensorflow/\n- When Recurrent Models Don't Need to be Recurrent (recurrent vs feed-forward models): http://www.offconvex.org/2018/07/27/approximating-recurrent/\n\n\n## References\n- #PAPER Neural Turing Machines (Graves 2014): http://arxiv.org/abs/1410.5401\n- #PAPER Attention and Augmented Recurrent Neural Networks (Olah 2016): http://distill.pub/2016/augmented-rnns/\n- #PAPER Engineering Extreme Event Forecasting at Uber with Recurrent Neural Networks (Laptev 2017): https://eng.uber.com/neural-networks/\n- #PAPER Deep and Confident Prediction for Time Series at Uber (Zhu 2017): https://arxiv.org/abs/1709.01907\n\t- https://eng.uber.com/neural-networks-uncertainty-estimation/ \n\t- introduced a new end-to-end Bayesian neural network (BNN) architecture that more accurately forecasts time series predictions and uncertainty estimations at scale\n- #PAPER Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau 2016): https://arxiv.org/abs/1409.0473\n\t- https://medium.com/datadriveninvestor/attention-in-rnns-321fbcd64f05\n\t\n\n### Long Short-Term Memory (LSTM)\n- https://en.wikipedia.org/wiki/Long_short-term_memory\n- One of the most innovative works in the NLP space is LSTMs and their variations e.g. GRU \n- With a basic RNN cell, we see a massive drop in performance when it comes to long sequences and the network needs to remember patterns which have occurred way at the beginning to infer things correctly at a current time step. And this is because of exploding and vanishing gradients.\n- Then came Sepp Hochreiter and Jürgen Schmidhuber and invented LSTMs, which can remember information from the way past and also selectively forget stuff that is not required.\n- There are several architectures of LSTM units. A common architecture is composed of a cell (the memory part of the LSTM unit) and three \"regulators\", usually called gates, of the flow of information inside the LSTM unit: an input gate, an output gate and a forget gate. Some variations of the LSTM unit do not have one or more of these gates or maybe have other gates (for instance, GRUs do not have an output gate).\n- The Forget gate decides what is relevant to keep from prior steps. The input gate decides what information is relevant to add from the current step. The output gate determines what the next hidden state should be.\n- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n- http://machinelearningmastery.com/tune-lstm-hyperparameters-keras-time-series-forecasting/\n- http://machinelearningmastery.com/use-features-lstm-networks-time-series-forecasting/\n- http://blog.echen.me/2017/05/30/exploring-lstms/\n- https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4\n- https://rubikscode.net/2018/03/19/understanding-long-short-term-memory-networks-lstms/\n- https://eli.thegreenplace.net/2018/minimal-character-based-lstm-implementation/\n\n- #PAPER Long Short-Term Memory (Hochreiter 1997): https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735\n- #PAPER IndyLSTMs: Independently Recurrent LSTMs (Gonnet 2019): https://arxiv.org/abs/1903.08023\n\t- Independently Recurrent Long Short-term Memory cells (IndyLSTMs) differ from regular LSTM cells in that the recurrent weights are not modeled as a full matrix, but as a diagonal matrix, i.e.\\ the output and state of each LSTM cell depends on the inputs and its own output/state, as opposed to the input and the outputs/states of all the cells in the layer. The number of parameters per IndyLSTM layer, and thus the number of FLOPS per evaluation, is linear in the number of nodes in the layer, as opposed to quadratic for regular LSTM layers, resulting in potentially both smaller and faster models. IndyLSTMs, despite their smaller size, consistently outperform regular LSTMs both in terms of accuracy per parameter, and in best accuracy overall. We attribute this improved performance to the IndyLSTMs being less prone to overfitting.\n- #PAPER Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks (Staudemeyer 2019): https://arxiv.org/abs/1909.09586\n\n\n### Gated recurrent units (GRU): \n- https://en.wikipedia.org/wiki/Gated_recurrent_unit \n- https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be\n- GRU (Gated Recurrent Unit) aims to solve the vanishing gradient problem which comes with a standard recurrent neural network. GRU can also be considered as a variation on the LSTM. GRU’s got rid of the cell state and used the hidden state to transfer information. It also only has two gates, a reset gate and update gate. \n- The update gate acts similar to the forget and input gate of an LSTM. It decides what information to throw away and what new information to add.\n- The reset gate is another gate is used to decide how much past information to forget.\n\t\n\n### Reservoir computing\n- https://en.wikipedia.org/wiki/Reservoir_computing\n- Reservoir computing is a framework for computation derived from recurrent neural network theory that maps input signals into higher dimensional computational spaces through the dynamics of a fixed, non-linear system called a reservoir. After the input signal is fed into the reservoir, which is treated as a \"black box,\" a simple readout mechanism is trained to read the state of the reservoir and map it to the desired output.\n\n#### Echo state networks (ESN)\n- https://en.wikipedia.org/wiki/Echo_state_network\n- The ESN is a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity)\n\n- #PAPER Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication (Jaeger 2004): https://pubmed.ncbi.nlm.nih.gov/15064413/\n\t- #CODE https://github.com/cknd/pyESN\n- #PAPER Design of deep echo state networks (Gallicchio 2018): https://www.sciencedirect.com/science/article/pii/S0893608018302223\n\t- #CODE https://github.com/lucapedrelli/DeepESN\n- #PAPER Using Machine Learning to Replicate Chaotic Attractors and Calculate Lyapunov Exponents from Data (Pathak 2017): https://arxiv.org/abs/1710.07313\n- #PAPER Model-Free Prediction of Large Spatiotemporally Chaotic Systems from Data: A Reservoir Computing Approach (Pathak 2018): https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.024102\n- #PAPER Wind Power Forecasting Based on Echo State Networks and Long Short-Term Memory (Lopez 2018): https://www.mdpi.com/1996-1073/11/3/526/htm\n\t- ESN + LSTM\n- #PAPER Comparison between DeepESNs and gatedRNNs on multivariate time-series prediction (Gallicchio 2019): https://arxiv.org/abs/1812.11527\n- #PAPER Deep Echo State Network (DeepESN): A Brief Survey (Gallicchio 2020): https://arxiv.org/abs/1812.11527\t\n- #PAPER Comparison of Recurrent Neural Networks for Wind Power Forecasting (Lopez 2020): https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7297597/#CR12\n\t- ESN + LSTM",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/Residual-and-dense-neural-networks": {
    "title": "Residual and dense neural networks",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Residual_neural_network\n- Training and investigating Residual Nets: http://torch.ch/blog/2016/02/04/resnets.html\n\n\n## References\n- #PAPER Deep Residual Learning for Image Recognition, Resnet-50 (He 2015): http://arxiv.org/abs/1512.03385 ^resnet\n\t- #CODE https://github.com/raghakot/keras-resnet\n\t- https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\n\t- Explained paper: https://www.youtube.com/watch?v=GWt6Fu05voI\n\t- Deep convolutional neural networks have led to a series of breakthroughs for image classification. Many other visual recognition tasks have also greatly benefited from very deep models. So, over the years there is a trend to go more deeper, to solve more complex tasks and to also increase /improve the classification/recognition accuracy. But, as we go deeper; the training of neural network becomes difficult and also the accuracy starts saturating and then degrades also. Residual Learning tries to solve both these problems.\n\t- What is Residual Learning?\n\t\t- In general, in a deep convolutional neural network, several layers are stacked and are trained to the task at hand. The network learns several low/mid/high level features at the end of its layers. In residual learning, instead of trying to learn some features, we try to learn some residual. Residual can be simply understood as subtraction of feature learned from input of that layer. ResNet does this using shortcut connections (directly connecting input of nth layer to some (n+x)th layer. It has proved that training this form of networks is easier than training simple deep convolutional neural networks and also the problem of degrading accuracy is resolved.\n\t\t- The architecture is similar to the VGGNet consisting mostly of 3X3 filters. From the VGGNet, shortcut connection as described above is inserted to form a residual network.\n- #PAPER Aggregated Residual Transformations for Deep Neural Networks, ResNeXt (Xie 2016): https://arxiv.org/abs/1611.05431 ^resnext\n- #PAPER Densely Connected Convolutional Networks, DenseNet (Huang 2016): https://arxiv.org/abs/1608.06993 ^densenet\n\t- #CODE https://github.com/liuzhuang13/DenseNet\n\t- #BOOK DenseNet: https://d2l.ai/chapter_convolutional-modern/densenet.html\n\t- For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages such as alleviating the vanishing-gradient problem, strengthening the feature propagation, encouraging feature reuse, and substantially reducing the number of parameters. DenseNets outperformed ResNets whilst requiring less memory and computation to achieve high performance.\n\t- https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803\n\t- In DenseNet, each layer obtains additional inputs from all preceding layers and passes on its own feature-maps to all subsequent layers. Concatenation is used (while element-wise addition for ResNets). Each layer is receiving a “collective knowledge” from all preceding layers. \n\t- https://arthurdouillard.com/post/densenet/\n- #PAPER Wide Residual Networks (Zagoruyko 2016): https://arxiv.org/abs/1605.07146\n\t- #CODE https://github.com/szagoruyko/wide-residual-networks\n- #PAPER Residual Attention Network for Image Classification (Wang 2017): https://arxiv.org/abs/1704.06904\n\t- Residual Attention Network, a convolutional neural network using attention mechanism which can incorporate with state-of-art feed forward network architecture in an end-to-end training fashion. The attention residual learning is used to train very deep Residual Attention Networks which can be easily scaled up to hundreds of layers.\n- #PAPER ResNet strikes back: An improved training procedure in timm (Wightman 2021): https://arxiv.org/abs/2110.00476\n\t- Paper explained: https://www.youtube.com/watch?v=Gl0s0GDqN3c",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Deep-learning/Transformers": {
    "title": "Transformers",
    "content": "## Resources\n- https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/ (from RNNs with attention to Transformers)\n- https://analyticsindiamag.com/a-complete-learning-path-to-transformers/\n- https://analyticsindiamag.com/transformers-for-vision-7-works-that-indicate-fusion-is-the-future-of-ai/\n\n## Code\n- #CODE Transformers: https://github.com/huggingface/transformers\n- #CODE Xformers: https://github.com/facebookresearch/xformers\n\n\n## For NLP\n- #PAPER Attention is all you need (Vaswani 2017): https://arxiv.org/abs/1706.03762\n\t- https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\n\t- Paper explained: https://www.youtube.com/watch?v=iDulhoQ2pro\n\t- The Transformer is a novel neural network architecture based on a self-attention mechanism that is well suited for language understanding. \n\t- It outperforms both recurrent and convolutional models on academic English to German and English to French translation benchmarks. On top of higher translation quality, the Transformer requires less computation to train and is a much better fit for modern machine learning hardware, speeding up training by up to an order of magnitude.\n\t- Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing. If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. \n\t- The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n\t- http://jalammar.github.io/illustrated-transformer/\n\t- Attention is all you need, attentional neural network models (Łukasz Kaiser): https://www.youtube.com/watch?v=rBCqOTEfxvg\n\t- LSTM is dead, long live Transformers: https://sea-adl.org/2019/12/03/lstm-is-dead-long-live-transformers/\n- #PAPER Tensor2tensor (Vaswani 2018): https://arxiv.org/abs/1803.07416\n\t- Tensor2Tensor, or T2T for short, is a library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research. T2T is actively used and maintained by researchers and engineers within the Google Brain team and a community of users. We're eager to collaborate with you too, so feel free to open an issue on GitHub or send along a pull request (see our contribution doc). You can chat with us on Gitter and join the T2T Google Group.\n\t- It includes the reference implementation of the state-of-the-art Transformer model.\n- #PAPER Improving Language Understanding by Generative Pre-Training, GPT (Radford 2018): https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf\n\t- https://openai.com/blog/language-unsupervised/\n- #PAPER Language Models are Unsupervised Multitask Learners, GPT-2 (Radford 2018): https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\n\t- #CODE https://github.com/openai/gpt-2\n\t- https://openai.com/blog/better-language-models/\n\t- Paper explained\n\t\t- https://www.youtube.com/watch?v=u1_qMdb0kYU\n\t\t- https://www.youtube.com/watch?v=UULqu7LQoHs\n\t\t- https://www.youtube.com/watch?v=8ypnLjwpzK8\n- #PAPER BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin 2019): https://arxiv.org/abs/1810.04805\n\t- #CODE TensorFlow code and pre-trained models for BERT. https://github.com/google-research/bert\n\t- Paper explained: https://www.youtube.com/watch?v=-9evrZnBorM\n\t- BERT as a service: https://github.com/hanxiao/bert-as-service\n- #PAPER Language Models are Few-Shot Learners, GPT-3 (Brown 2020): https://arxiv.org/abs/2005.14165\n\t- Paper explained: \n\t\t- https://www.youtube.com/watch?v=SY5PvZrJhLE\n\t\t-  https://www.youtube.com/watch?v=_x9AwxfjxvE\n- #PAPER It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners (Schick 2020): https://arxiv.org/abs/2009.07118\n\t- #CODE https://github.com/timoschick/pet\n\t- https://www.infoq.com/news/2020/10/training-exceeds-gpt3/\n- #PAPER Rethinking Attention with Performers (Choromanski 2020): https://arxiv.org/abs/2009.14794\n\t- https://syncedreview.com/2020/10/02/google-cambridge-deepmind-alan-turing-institutes-performer-transformer-slashes-compute-costs/\n\t- https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html\n\t- #CODE https://github.com/google-research/google-research/tree/master/performer/fast_self_attention\n\t- Paper explained: https://www.youtube.com/watch?v=xJrKIPwVwGM\n- #PAPER SqueezeBERT: What can computer vision teach NLP about efficient neural networks? (Iandola 2020): https://arxiv.org/abs/2006.11316\n\t- #TALK From SqueezeNet to SqueezeBERT: Developing Efficient Deep Neural Networks. https://www.youtube.com/watch?v=kPMaEYSywdI\n\t- https://www.microsoft.com/en-us/research/video/from-squeezenet-to-squeezebert-developing-efficient-deep-neural-networks/\n- #PAPER FNet: Mixing Tokens with Fourier Transforms (Lee-Thorp 2021): https://arxiv.org/abs/2105.03824\n\t- https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/\n\t- #CODE https://paperswithcode.com/paper/fnet-mixing-tokens-with-fourier-transforms?from=n10\n\t- Transformer architectures can be massively sped up, with limited accuracy costs, by replacing self-attention sublayers with linear transformations that \"mix\" input tokens\n- #PAPER Optimizing Deeper Transformers on Small Datasets (Xu 2021): https://arxiv.org/abs/2012.15355\n- #PAPER Infinity-former: Infinite Memory Transformer: https://arxiv.org/abs/2109.00301\n\t- Paper explained: https://www.youtube.com/watch?v=0JlB9gufTw8\n\n\n## For Computer Vision\n- #PAPER Spatial Transformer Networks (Jaderberg 2016): https://arxiv.org/abs/1506.02025\n\t-  the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, result-ing in state-of-the-art performance on several benchmarks, and for a number of classes of transformations\n\t-  https://www.youtube.com/watch?v=6NnearestOQC_fl1hQ\n\t-  #CODE https://github.com/oarriaga/paz/tree/master/examples/spatial_transfomer_networks\n- #PAPER Image Transformer (Parmar 2018): https://arxiv.org/abs/1802.05751\n- #PAPER Generative Pretraining from Pixels (Chen 2020): https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf ^imagegpt\n\t- https://openai.com/blog/image-gpt/ \n\t- #CODE https://github.com/openai/image-gpt\n\t- Paper explained: https://www.youtube.com/watch?v=YBlNQK0Ao6g\n\t- https://www.youtube.com/watch?v=7rFLnQdl22c\n- #PAPER DETR - End-to-End Object Detection with Transformers (Carion 2020): https://arxiv.org/abs/2005.12872 \n\t- #CODE https://paperswithcode.com/paper/end-to-end-object-detection-with-transformers\n- #PAPER Taming Transformers for High-Resolution Image Synthesis (Esser 2020): https://arxiv.org/abs/2012.09841v1 ^tamingtransformers\n\t- https://compvis.github.io/taming-transformers/\n\t- https://github.com/CompVis/taming-transformers\n\t- https://www.marktechpost.com/2020/12/28/a-new-method-to-code-inductive-image-biases-into-models-using-cnn-and-transformers/\n- #PAPER ViT - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (2020): https://openreview.net/forum?id=YicbFdNTTy\n\t- While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer can perform very well on image classification tasks when applied directly to sequences of image patches\n\t- Paper explained: https://www.youtube.com/watch?v=TrdevFK_am4\n\t- #CODE https://github.com/google-research/vision_transformer\n\t- #CODE https://keras.io/examples/vision/image_classification_with_vision_transformer/\n\t- #CODE https://github.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples\n- #PAPER Training data-efficient image transformers \u0026 distillation through attention (Touvron 2021): https://arxiv.org/abs/2012.12877\n\t- #CODE https://github.com/facebookresearch/deit\n\t- Propose a competitive convolution-free transformer by training on Imagenet only\n\t- Introduced a teacher-student strategy specific to transformers. It relies on a distillation token ensuring that the student learns from the teacher through attention\n\t- https://ai.facebook.com/blog/data-efficient-image-transformers-a-promising-new-technique-for-image-classification/\n- #PAPER PVT - Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions (Wang 2021): https://arxiv.org/abs/2102.12122 ^pvt\n\t- #CODE https://paperswithcode.com/paper/pyramid-vision-transformer-a-versatile\n\t- #CODE https://github.com/wangermeng2021/PVT-tensorflow2\n\t- PVT inherits the advantages from both CNN and Transformer, making it a unified backbone in various vision tasks without convolutions by simply replacing CNN backbones\n- #PAPER Vision Transformers for Dense Prediction (Ranftl 2021): https://arxiv.org/abs/2103.13413v1\n\t- #CODE https://paperswithcode.com/paper/vision-transformers-for-dense-prediction\n\t- Model with an encoder-decoder design, leveraging the vision transformer (ViT) as the building block of the encoder\n\t- The representations produced by the transformer are reassembled into image-like feature representations at various resolutions and are progressively combined into the final dense prediction using a convolutional decoder \n\t- The transformer downsamples operations and keeps a representation with a constant dimensionality throughout the processing stages while keeping a global receptive field at every stage\n\t- These properties allows DPT to provide fine-grained and globally coherent predictions as compared to fully-convolutional networks\n- #PAPER Understanding Robustness of Transformers for Image Classification (Bhojanapalli 2021): https://arxiv.org/abs/2103.14586v1\n- #PAPER Medical Transformer: Gated Axial-Attention for Medical Image Segmentation (Valanarasu 2021): https://arxiv.org/abs/2102.10662\n\t- #CODE https://github.com/jeya-maria-jose/Medical-Transformer\n\t- https://analyticsindiamag.com/guide-to-medical-transformer-attention-for-medical-image-segmentation/\n\t- Trains with less data thanks to the Gated Axial-Attention model which extends the existing architectures by introducing an additional control mechanism in the self-attention module\n\t- To train the model effectively on medical images, we propose a Local-Global training strategy (LoGo) which further improves the performance. Specifically, we operate on the whole image and patches to learn global and local features, respectively\n- #PAPER TransGAN: Two Transformers Can Make One Strong GAN (Jiang 2021): https://arxiv.org/abs/2102.07074v2\n\t- #CODE https://paperswithcode.com/paper/transgan-two-transformers-can-make-one-strong\n\t-  first pilot study in building a GAN completely free of convolutions, using only pure transformer-based architectures\n- #PAPER Gansformer - Generative Adversarial Transformers (Hudson 2021): https://arxiv.org/abs/2103.01209v2\n\t- #CODE https://paperswithcode.com/paper/generative-adversarial-transformers\n- #PAPER TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation (Chen 2021): https://arxiv.org/abs/2102.04306v1\n\t- #CODE https://paperswithcode.com/paper/transunet-transformers-make-strong-encoders\n\t- due to the intrinsic locality of convolution operations, U-Net generally demonstrates limitations in explicitly modeling long-range dependency\n\t- TransUNet merits both Transformers and U-Net, as a strong alternative for medical image segmentation\n\t- transformer encodes tokenized image patches from a convolution neural network (CNN) feature map as the input sequence for extracting global contexts\n\t- on the other hand, the decoder upsamples the encoded features which are then combined with the high-resolution CNN feature maps to enable precise localization\n- #PAPER Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Liu 2021): https://arxiv.org/abs/2103.14030\n\t- #CODE https://github.com/microsoft/Swin-Transformer\n\t- #CODE https://github.com/rishigami/Swin-Transformer-TF\n\t- #CODE https://github.com/yingkaisha/keras-vision-transformer\n\t- Swin Transformer serves as a general-purpose backbone for computer vision. Works for tasks such as image classification, object detection and semantic segmentation\n\t- involves a hierarchical Transformer whose representation is computed through a shifted windowing mechanism which limits the self-attention computation to non-overlapping local windows while still allowing for cross-window connection\n\t- the benefits of this hierarchical architecture are greater efficiency and flexibility to model at various scales. In addition, this model has linear computational complexity with respect to image size\n- #PAPER How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers (Steiner 2021): https://arxiv.org/abs/2106.10270v1\n\t- Results show that models using a combination of AugReg (model regularization) and increased compute can attain similar performance as models trained on an order of magnitude more training data\n\t- ViT models of various sizes, trained on ImageNet-21k, match or outperform counterparts trained on a larger dataset (JFT-300M)\n\t- #CODE https://paperswithcode.com/paper/how-to-train-your-vit-data-augmentation-and\n- #PAPER Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning (Kossen 2021): https://arxiv.org/abs/2106.02584v1\n\t- #CODE https://paperswithcode.com/paper/self-attention-between-datapoints-going?from=n11\n\t- Authors challenge a common assumption underlying most supervised deep learning: that a model makes a prediction depending only on its parameters and the features of a single input\n\t- Introduced a general-purpose deep learning architecture that takes as input the entire dataset instead of processing one datapoint at a time\n\t- The approach uses self-attention to reason about relationships between datapoints explicitly, which can be seen as realizing non-parametric models using parametric attention mechanisms\n- #PAPER Segmenter: Transformer for Semantic Segmentation (Strudel 2021): https://arxiv.org/abs/2105.05633\n- #PAPER Do Vision Transformers See Like Convolutional Neural Networks (Raghu 2021): https://arxiv.org/abs/2108.08810\n\t- Paper explained: https://www.youtube.com/watch?v=rk9bhIRInC0\n- #PAPER DECIMER 1.0: deep learning for chemical image recognition using transformers (Rajan 2021): https://jcheminf.biomedcentral.com/articles/10.1186/s13321-021-00538-8\n- #PAPER Multiscale Vision Transformers (Fan 2021): https://arxiv.org/abs/2104.11227\n\t- #CODE  https://github.com/facebookresearch/SlowFast\n\t- https://ai.facebook.com/blog/multiscale-vision-transformers-an-architecture-for-modeling-visual-data/\n- #PAPER Swin Transformer V2: Scaling Up Capacity and Resolution (Liu 2021): https://arxiv.org/abs/2111.09883v1\n\t- #CODE https://paperswithcode.com/paper/swin-transformer-v2-scaling-up-capacity-and\n- #PAPER Transformers in Medical Imaging: A Survey (Shamshad 2022): https://arxiv.org/abs/2201.09873v1\n\t- #CODE https://paperswithcode.com/paper/transformers-in-medical-imaging-a-survey?from=n24\n\t- https://github.com/fahadshamshad/awesome-transformers-in-medical-imaging\n\n\n\n### Self-supervised vision transformers\n- Self-Supervised Learning in Vision Transformers: https://towardsdatascience.com/self-supervised-learning-in-vision-transformers-30ff9be928c\n- #PAPER SiT: Self-supervised vIsion Transformer (Atito 2021): https://arxiv.org/abs/2104.03602\n- #PAPER DINO - Emerging Properties in Self-Supervised Vision Transformers (Caron 2021): https://arxiv.org/abs/2104.14294\n\t- https://towardsdatascience.com/on-dino-self-distillation-with-no-labels-c29e9365e382\n\n\n### Vision transformers with convolutions\n- #PAPER CeiT - Incorporating Convolution Designs into Visual Transformers (Yan 2021): https://arxiv.org/abs/2103.11816v1\n\t- #CODE https://paperswithcode.com/paper/incorporating-convolution-designs-into-visual\n\t- CeiT combines the advantages of CNNs in extracting low-level features, strengthening locality, and the advantages of Transformers in establishing long-range dependencies\n- #PAPER CvT: Introducing Convolutions to Vision Transformers (Wu 2021): https://arxiv.org/abs/2103.16302v1\n\t- #CODE https://paperswithcode.com/paper/cvt-introducing-convolutions-to-vision\n- #PAPER Escaping the Big Data Paradigm with Compact Transformers (Hassani 2021): https://arxiv.org/abs/2104.05704 ^cctransformer\n\t- Compact Convolutional Transformer (CCT)\n\t- #CODE https://github.com/SHI-Labs/Compact-Transformers\n\t- #CODE https://keras.io/examples/vision/cct/\n\t- ViTs (or a typical Transformer-based architecture) do not have well-informed inductive biases (such as convolutions for processing images)\n\t- Attempt to combine the benefits of convolution and the benefits of Transformers in a single network architecture\n\t- These benefits include parameter-efficiency, and self-attention to process long-range and global dependencies (interactions between different regions in an image)\n- #PAPER CvT: Introducing Convolutions to Vision Transformers (Wu 2021): https://arxiv.org/abs/2103.15808\n\t- #CODE https://github.com/leoxiaobin/CvT\n\t- Convolutional vision Transformers (CvT) improves ViT in performance and efficienty by introducing convolutions into ViT to yield the best of both disignes\n\t- This is accomplished through two primary modifications: a hierarchy of Transformers containing a new convolutional token embedding, and a convolutional Transformer block leveraging a convolutional projection\n\t- These changes introduce desirable properties of convolutional neural networks (CNNs) to the ViT architecture (e.g. shift, scale, and distortion invariance) while maintaining the merits of Transformers (e.g. dynamic attention, global context, and better generalization)\n- #PAPER Combining EfficientNet and Vision Transformers for Video Deepfake Detection (Coccomini 2021): https://arxiv.org/abs/2107.02612\n\t- Vision Transformers or Convolutional Neural Networks? Both!: https://towardsdatascience.com/vision-transformers-or-convolutional-neural-networks-both-de1a2c3c62e4\n- #PAPER Early Convolutions Help Transformers See Better (Xiao 2021): https://arxiv.org/abs/2106.14881\n\t- https://syncedreview.com/2021/07/06/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-55/\n\t- replacing the ViT patchify stem with a standard convolutional stem in early visual processing results in marked improvements in terms of optimizer stability and final model accuracy\n- #PAPER ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases (d'ascoli 2021): https://arxiv.org/abs/2103.10697\n\t- #CODE https://github.com/facebookresearch/convit\n\t- https://ai.facebook.com/blog/computer-vision-combining-transformers-and-convolutional-neural-networks/\n- #PAPER CMT: Convolutional Neural Networks Meet Vision Transformers (Guo 2021): https://arxiv.org/abs/2107.06263\n- #PAPER CoAtNet: Marrying Convolution and Attention for All Data Sizes (Dai 2021): https://arxiv.org/abs/2106.04803\n\t- https://ai.googleblog.com/2021/09/toward-fast-and-accurate-neural.html\n- #PAPER UniFormer: Unifying Convolution and Self-attention for Visual Recognition (Li 2022): https://arxiv.org/abs/2201.09450v1\n\t- #CODE https://paperswithcode.com/paper/uniformer-unifying-convolution-and-self?from=n24\n- #PAPER Convolutional Xformers for Vision (Jeevan 2022): https://arxiv.org/abs/2201.10271v1\n\t- #CODE https://arxiv.org/abs/2201.10271v1\n\n\n## Multi-modal transformers\nSee [Multimodal learning](AI/Deep%20learning/Multimodal%20learning.md)\n\n## For RL\nSee [Reinforcement learning#^decisiontransformer](AI/Reinforcement%20learning.md#%5Edecisiontransformer)",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Feature-learning": {
    "title": "Feature learning",
    "content": "## Resources\n- In machine learning, feature learning or representation learning is a set of techniques that allows a system to automatically discover the representations needed for feature detection or classification from raw data. This replaces manual feature engineering and allows a machine to both learn the features and use them to perform a specific task.\n- https://en.wikipedia.org/wiki/Feature_learning\n\n## Unsupervised case\n- Dictionary learning\n- Autoencoders\n- ICA\n- Matrix factorization\n\n## Supervised case\n- Deep supervised models (Multilayer perceptron, Supervised netural networks) are able to learn automatically features from data.",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Forecasting": {
    "title": "Forecasting",
    "content": "See: \n[Time Series analysis](Time%20Series%20analysis.md)\n[Regression](Regression.md)\n[RNNs](RNNs.md)\n[CNNs#Sequence time series modelling](CNNs.md#Sequence%20time%20series%20modelling)\n[Transformers#For NLP](Transformers.md#For%20NLP)\n\n## Resources\n- https://en.wikipedia.org/wiki/Forecasting\n- Microsoft - Time Series Forecasting Best Practices \u0026 Examples: https://github.com/microsoft/forecasting\n- Forecasting with a Time Series Model using Python: \n\t- https://www.bounteous.com/insights/2020/09/15/forecasting-time-series-model-using-python-part-one/\n\t- https://www.bounteous.com/insights/2020/09/15/forecasting-time-series-model-using-python-part-two/\n- https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775\n- https://towardsdatascience.com/automl-for-time-series-advanced-approaches-with-fedot-framework-4f9d8ea3382c\n\n## Code\n- #CODE Darts: https://github.com/unit8co/darts\n\t- https://unit8co.github.io/darts/\n\t- Python library for easy manipulation and forecasting of time series. It contains a variety of models, from classics such as ARIMA, Prophet,  deep neural networks (NBEATS, RNNs, Transformers)\n\t- https://towardsdatascience.com/darts-swiss-knife-for-time-series-forecasting-in-python-f37bb74c126\n- #CODE Prophet (Facebook): https://github.com/facebook/prophet\n\t- https://facebook.github.io/prophet/\n\t- Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data.\n\t- https://research.fb.com/prophet-forecasting-at-scale/\n\t- http://blog.fastforwardlabs.com/2017/03/22/prophet.html\t\n- #CODE NeuralProphet: https://github.com/ourownstory/neural_prophet\n\t- https://ourownstory.github.io/neural_prophet/\n\t- A simple forecasting model based on Neural Networks in PyTorch\n- #CODE Hcrystalball: https://github.com/heidelbergcement/hcrystalball\n\t- Library that unifies the API for most commonly used libraries and modeling techniques for time-series forecasting in Python\n- #CODE AtsPy: Automated Time Series Forecasting in Python: https://github.com/firmai/atspy\n- #CODE Greykite (Linkedin): https://github.com/linkedin/greykite\n\t- https://linkedin.github.io/greykite/\n\t- A flexible, intuitive and fast forecasting library\n- #CODE Scalecast: https://github.com/mikekeith52/scalecast\n\t- https://towardsdatascience.com/introducing-scalecast-a-forecasting-library-pt-1-33b556d9b019\n- #CODE Skforecast: https://github.com/JoaquinAmatRodrigo/skforecast\n\t\n\n## Books\n- #BOOK Forescasting: principles and practice (Hyndman 2018, R): https://otexts.com/fpp2/\n\n\n## References\n- #PAPER Time Series Forecasting With Deep Learning: A Survey (Lim 2020): https://arxiv.org/abs/2004.13408\n- #PAPER A flexible forecasting model for production systems (Hosseini 2021): https://arxiv.org/abs/2105.01098\n- #PAPER An Experimental Review on Deep Learning Architectures for Time Series Forecasting (Lara-Benitez 2021): https://arxiv.org/abs/2103.12057",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Learning-to-rank": {
    "title": "Learning to rank",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Learning_to_rank\n- Learning to rank or machine-learned ranking (MLR) is the application of machine learning, typically supervised, semi-supervised or [reinforcement learning](reinforcement%20learning.md), in the construction of ranking models for information retrieval systems. Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model's purpose is to rank, i.e. produce a permutation of items in new, unseen lists in a way which is \"similar\" to rankings in the training data in some sense.\n\n### Ordinal regression (classification)\n- https://en.wikipedia.org/wiki/Ordinal_regression\n- OR (also called \"ordinal classification\" or “ranking learning”) is a type of [regression](regression.md) analysis used for predicting an ordinal variable, i.e. a variable whose value exists on an arbitrary scale where only the relative ordering between different values is significant. It can be considered an intermediate problem between regression and classification.\n- http://stackoverflow.com/questions/3495157/ordinal-classification-packages-and-algorithms\n- http://stats.idre.ucla.edu/r/dae/ordinal-logistic-regression/\n\n## Code\n- #CODE Adarank: https://github.com/rueycheng/AdaRank\n- #CODE Pyltr - LambdaMART: https://github.com/jma127/pyltr\n- #CODE Mord - Ordinal Regression in Python: https://github.com/fabianp/mord\n\t- https://pythonhosted.org/mord/\n\t- http://fa.bianp.net/blog/2013/logistic-ordinal-regression/\n\n## References\n### DL-based ranking\n- #PAPER TF-Ranking: Scalable TensorFlow Library for Learning-to-Rank (Kumar Pasumarthi 2019): https://research.google/pubs/pub48160/\n\t- #CODE https://github.com/tensorflow/ranking\n\t- New Keras-based TF-Ranking version: https://ai.googleblog.com/2021/07/advances-in-tf-ranking.html",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Machine-Learning": {
    "title": "Machine Learning",
    "content": "## Resources\n- Machine learning identifies patterns using statistical learning and computers by unearthing boundaries in data sets. \n- Awesome ML: https://github.com/josephmisiti/awesome-machine-learning\n- Machine Learning Research Articles: https://deepai.org/publications/statistics-machine-learning/1\n- Rules of ML (Google): https://developers.google.com/machine-learning/rules-of-ml/\n- Jason's Machine Learning 101 (Google): https://www.youtube.com/watch?v=JpTYbmpoHT0\n\t- https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/preview\n- Machine Learning Glossary (Google): https://developers.google.com/machine-learning/glossary/\n- ML Resources (MIT student): https://sgfin.github.io/learning-resources/\n- Machine Learning \u0026 Deep Learning Tutorials: https://github.com/ujjwalkarn/Machine-Learning-Tutorials/\n- A visual introduction to machine learning: http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n- How to pick an algo (mind map): http://i.imgur.com/HnRwlce.png\n- ML Algorithms: Strengths and Weaknesses: https://elitedatascience.com/machine-learning-algorithms\n- A friendly introduction to linear algebra for ML (ML Tech Talks): https://www.youtube.com/watch?v=LlKAna21fLE\n- Naive/homemade implementations\n\t- https://github.com/trekhleb/homemade-machine-learning\n\t- https://github.com/anhquan0412/basic_model_scratch\n\t- https://github.com/rushter/MLAlgorithms\n\t- https://github.com/ahmedbesbes/Neural-Network-from-scratch\n\t- https://github.com/eriklindernoren/ML-From-Scratch\n- Best practices for ML engineering (Google): http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf\n- https://github.com/GokuMohandas/practicalAI\n- https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471\n- http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/\n- Recommendation System Algorithms: https://blog.statsbot.co/recommendation-system-algorithms-ba67f39ac9a3\n\n### Cheatsheets and notes\n- https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/super-cheatsheet-machine-learning.pdf\n- https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks\n- ML-AI guide: https://csinva.io/blog/compiled_notes/_build/html//intro.html\n\n## References\n- #PAPER Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence (Raschka 2020): https://arxiv.org/abs/2002.04803\n\n\n## Books\n- #BOOK The elements of statistical learning (Hastie 2015, SPRINGER): https://web.stanford.edu/~hastie/ElemStatLearn/\n- #BOOK An Introduction to Statistical Learning (James 2013, SPRINGER): http://www-bcf.usc.edu/~gareth/ISL/\n\t- https://github.com/JWarmenhoven/ISLR-python\n-  #BOOK Recommender Systems - The Textbook (Aggarwal, 2016 SPRINGER): http://charuaggarwal.net/Recommender-Systems.pdf\n-  #BOOK Mathematics for ML (Deisenroth, 2018 CAMBRIDGE): https://mml-book.github.io/\n-  #BOOK Introduction to Machine Learning with Python - A Guide for Data Scientists (Muller, 2016 O'REILLY)\n\t\t- https://www.academia.edu/42736911/Introduction_to_Machine_Learning_with_Python_A_Guide_for_Data_Scientists\n\t\t- https://github.com/amueller/introduction_to_ml_with_python\n- #BOOK Machine Learning for Dummies (Hurwitz, 2018 WILEY-IBM): https://www-01.ibm.com/common/ssi/cgi-bin/ssialias?htmlfid=IMM14209USEN\n- #BOOK Python Machine Learning (Raschka 2015, PACKT)\n\t\t- http://diggerdnepr.ddns.net/wp-content/uploads/2019/02/python-machine-learning-2nd.pdf\n\t\t- https://github.com/rasbt/python-machine-learning-book\n- #BOOK Mastering Machine Learning with scikit-learn (Hackeling 2014, PACKT): https://www.packtpub.com/big-data-and-business-intelligence/mastering-machine-learning-scikit-learn\n- #BOOK Designing Machine Learning Systems with Python (Julian 2016, PACKT): https://www.packtpub.com/big-data-and-business-intelligence/designing-machine-learning-systems-python\n- #BOOK Evaluating Machine Learning Models (Zheng 2015, OREILLY): https://www.oreilly.com/ideas/evaluating-machine-learning-models\n- #BOOK Introduction to Machine Learning Interviews Book: https://huyenchip.com/ml-interviews-book/\n\n## Courses\n- #COURSE Machine Learning (CS229, Stanford): http://cs229.stanford.edu/\n\t- Lecture notes: https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf\n\t- Cheat sheets: https://github.com/afshinea/stanford-cs-229-machine-learning\n- #COURSE Machine Learning (Coursera-Stanford): https://www.coursera.org/learn/machine-learning\n- #COURSE Machine Learning Crash Course with TensorFlow APIs (Google): https://developers.google.com/machine-learning/crash-course/\n- #COURSE Data Mining and Machine Learning (STAT 365/665, Yale): http://euler.stat.yale.edu/~tba3/stat665/\n- #COURSE Applied machine learning (U Columbia): https://github.com/amueller/applied_ml_spring_2017\n- #COURSE L'apprentissage face à la malédiction de la grande dimension (College de France): https://www.college-de-france.fr/site/stephane-mallat/course-2017-2018.htm\n- #COURSE The Machine Learning Summer School, MLSS Tubingen 2020 (virtual): http://mlss.tuebingen.mpg.de/2020/\n\t- https://www.youtube.com/channel/UCBOgpkDhQuYeVVjuzS5Wtxw/videos\n\n## Code \n- #CODE Benchmarks of ML libraries: https://github.com/szilard/benchm-ml\n- #CODE Scikit-learn: https://github.com/scikit-learn/scikit-learn\n\t- http://scikit-learn.org/stable/\n\t- Contrib packages: https://github.com/scikit-learn-contrib\n\t- #TALK PyData tutorial by Sebastian Raschka: https://www.youtube.com/watch?v=9fOWryQq9J8\n\t- #CODE scikit-plot: http://scikit-plot.readthedocs.io/en/stable/Quickstart.html\n\t- #CODE Lightning - Large-scale linear classification, [Regression](Regression.md) and ranking ([Learning to rank](Learning%20to%20rank.md)) in Python: http://contrib.scikit-learn.org/lightning/\n- #CODE mlinsights: https://github.com/sdpython/mlinsights/\n\t- http://www.xavierdupre.fr/app/mlinsights/helpsphinx/notebooks/piecewise_linear_regression.html\n- #CODE PyCaret: https://github.com/pycaret/pycaret\n\t- https://pycaret.org/\n\t- PyCaret is an open-source, low-code machine learning library in Python that automates machine learning workflows\n\t- PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, LightGBM, CatBoost, spaCy, Optuna, Hyperopt, Ray, and many more\n\t- PyCaret \u003e= 2.2 provides the option to use GPU for select model training and hyperparameter tuning\n- #CODE Hypertools: https://github.com/ContextLab/hypertools\n\t-  A python toolbox for visualizing and manipulating high-dimensional data\n\t- http://hypertools.readthedocs.io/en/latest/\n\t- https://github.com/ContextLab/hypertools-paper-notebooks\n\t- http://blog.kaggle.com/2017/04/10/exploring-the-structure-of-high-dimensional-data-with-hypertools-in-kaggle-kernels/\n- #CODE PySAL: Python Spatial Analysis Library Meta-Package: https://github.com/pysal/pysal\n\t- http://pysal.org/pysal/\n- #CODE MLxtend - A library of extension and helper modules for Python's data analysis and machine learning libraries: http://rasbt.github.io/mlxtend/\n- #CODE H2O: https://github.com/h2oai/\n\t- http://www.h2o.ai/\n\t- https://github.com/h2oai/h2o-3\n\t- https://github.com/h2oai/h2o4gpu\n\t- https://github.com/h2oai/h2o-tutorials\n\t- #TALK Getting started with H2O on Python (pydata): https://www.youtube.com/watch?v=OYJYl8egLQs\n\t- http://www.jowanza.com/post/156015716294/why-h2o-sparkling-water\n\t- https://github.com/h2oai/h2o-3/tree/master/h2o-py/demos\n- #CODE Dlib (C++ with python interface): http://dlib.net/\n- #CODE Shogun: http://shogun-toolbox.org/\n- #CODE Vowpal Wabbit - ML system which pushes the frontier of machine learning with techniques such as online, hashing, allreduce, reductions, learning2search, active, and interactive learning.\n\t- https://github.com/JohnLangford/vowpal_wabbit\n\t- http://hunch.net/~vw/\n\t- https://github.com/JohnLangford/vowpal_wabbit/wiki\n- #CODE DMTK (Microsoft):  https://github.com/Microsoft/DMTK\n\t- http://www.dmtk.io/\n\t- Light LDA - Scalable, fast, and lightweight system for large-scale topic modeling: http://www.dmtk.io\n- #CODE RAPIDS - GPU data science. https://github.com/rapidsai, https://rapids.ai/\n\t- #CODE cuML - RAPIDS Machine Learning Library: https://github.com/rapidsai/cuml\n\t- #CODE cuspatial - CUDA-accelerated GIS and spatiotemporal algorithms: https://github.com/rapidsai/cuspatial\n\t- #CODE cuSignal - RAPIDS Signal Processing Library: https://github.com/rapidsai/cusignal\n\t- #CODE cuGraph - RAPIDS Graph Analytics Library: https://github.com/rapidsai/cugraph\n\t- #CODE cuDF - GPU DataFrame Library: https://github.com/rapidsai/cudf\n- #CODE Daal4Py: https://github.com/IntelPython/daal4py ^4d4f07\n\t- Python API to Intel(R) oneAPI Data Analytics Library that allows for fast usage of the framework suited for Data Scientists or Machine Learning users\n- #CODE CuPy - NumPy-like API accelerated with CUDA. https://github.com/cupy/cupy\n\t- https://cupy.chainer.org/\n\t- https://docs-cupy.chainer.org/en/stable/\n\t- https://docs-cupy.chainer.org/en/stable/tutorial/\n- #CODE ArrayFire: https://github.com/arrayfire/arrayfire-python\n\t- ArrayFire is a high performance library for parallel computing with an easy-to-use API. It enables users to write scientific computing code that is portable across CUDA, OpenCL and CPU devices. This project provides Python bindings for the ArrayFire library.\n\t- https://arrayfire.com/\n- #CODE TuriCreate (Apple)\n\t- TuriCreate simplifies the development of custom machine learning models. You don't have to be a machine learning expert to add recommendations, object detection, image classification, image similarity or activity classification to your app.\n\t- https://github.com/apple/turicreate#documentation\n\t- https://developer.apple.com/videos/play/wwdc2018/712/\n- #CODE ThunderSVM - A Fast SVM Library on GPUs and CPUs: https://github.com/zeyiwen/thundersvm\n- #CODE PyGAM - Generalized Additive Models in Python: \n\t- https://pygam.readthedocs.io\n\t- https://github.com/dswah/pyGAM\n- #CODE SurPRISE - A Python scikit for building and analyzing recommender systems: http://surpriselib.com\n- #CODE Facets: https://github.com/PAIR-code/facets\n\t- visualizations for understanding and analyzing machine learning datasets: Facets Overview and Facets Dive. The visualizations are implemented as Polymer web components, backed by Typescript code and can be easily embedded into Jupyter notebooks or webpages\n\t- https://pair-code.github.io/facets/\n- #CODE PyCM: https://github.com/sepandhaghighi/pycm\n\t- PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters\n\t- http://www.pycm.ir/\n\n## Subtopics\n\n### Feature selection\nSee [Feature selection](AI/Supervised%20Learning/Feature%20selection.md)]\n\n### Explainable AI\nSee [XAI](AI/XAI.md)]\n\n### Feature learning\nSee [Feature learning](AI/Feature%20learning.md)]\n\n### Anomaly and Outlier Detection\nSee [Anomaly and Outlier Detection](AI/Anomaly%20and%20Outlier%20Detection.md)\n\n### Time Series analysis and forecasting\nSee [Time Series analysis](AI/Time%20Series%20analysis.md)] and [Forecasting](AI/Forecasting.md)]\n\n### AutoML\nSee [AutoML](AI/AutoML.md)]\n\n### Deep Learning\nSee [Deep learning](AI/Deep%20learning/Deep%20learning.md)\n\n### Reinforcement learning\nSee [Reinforcement learning](AI/Reinforcement%20learning.md)]\n\n### Unsupervised learning\nSee [Unsupervised learning](AI/Unsupervised%20learning/Unsupervised%20learning.md)\n\n### Supervised learning\nSee [Supervised learning](AI/Supervised%20Learning/Supervised%20learning.md)\n\n### Weakly-supervised learning\nSee [Weakly-supervised learning](AI/Weakly-supervised%20learning.md). It includes these topics: [Semi-supervised learning](AI/Semi-supervised%20learning.md), [Active learning](AI/Active%20learning.md)] and [Transfer learning](AI/Transfer%20learning.md)]\n\n### One, few-shot learning\nSee [One, few-shot learning](AI/One,%20few-shot%20learning.md)]\n\n### Self-supervised learning\nSee [Self-supervised learning](AI/Self-supervised%20learning.md)]\n\n### Probabilistic machine learning\nSee [Probabilistic machine learning](AI/Probabilistic%20machine%20learning.md)]\n\n### Learning to rank and ordinal regression\nSee [Learning to rank](AI/Learning%20to%20rank.md)\n\n### Generative modelling\nSee [Generative modelling](AI/Deep%20learning/Generative%20modelling.md)",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Math-and-Statistics/Distances": {
    "title": "Distances",
    "content": "## Resources\n- Anscombe dataset: http://datascienceplus.com/the-importance-of-data-visualization/\n- Distance = 1 - Similarity \n- Having a set of points (space), a distance d is a function d(x,y) that takes 2 point in the space and produces a real number. It must satisfy 4 axioms:\n\t1. d(x,y)\u003e=0, no negative distances\n\t2. d(x,y)=0 if and only if x=y, positive distances except the from a point to itself\n\t3. d(x,y) = d(y,x), distance is symmetric \n\t4. d(x,y) \u003c= d(x,z)+d(z,y), the triangle inequality says that to travel from x to y, we cannot obtain any benefit if we are forced to travel via some particular third point z. \n- http://www.benfrederickson.com/distance-metrics/ (notebook kind of post using pandas, d3)\n- https://github.com/andrecosta90/distance-similarity-measures\n\n### Minkowski\n- The Minkowski distance is the generalized Lp -norm of the difference. \n- Lp-norm is the distance d defined as: d = (sum|x_i - y_i|^p)^1/p \n\n### Euclidean\n- Same as L2-norm (Lp-norm when p=2)\n- Most familiar distance measure, defined as the square root of the sum of the square distances: d = sqrt(sum((x_i - y_i)^2)\n- An equivalent to the L2-norm is the Squared Euclidean distance or sum of squared difference (SSD). This is the fundamental metric in least squares problems and linear algebra. It’s very sensitive to outliers (because of the square). The Mean Squared Error (MSE) is the normalized version of the SSD. \n\n### Manhattan\n- https://en.wikipedia.org/wiki/Taxicab_geometry\n- Same as L1-norm (Lp-norm when p=1)\n- Also known as Taxicab norm and SAD\n- Distance defined as the sum of the absolute differences of the coordinates: d = sum(|x_i - y_i|)\n- In solving an underdetermined system of linear equations, the regularisation term for the parameter vector is expressed in terms of the-norm (taxicab geometry) of the vector. This approach appears in the signal recovery framework called compressed sensing.\n- The Mean-Absolute Error (MAE) is a normalized version of the SAD: d_MAE(x,y) = d_SAD(x,y)/n = 1/n sum(|x_i - y_i|)\n\n### Cosine\n- The cosine distance contains the dot product scaled by the product of the Euclidean distances from the origin. It represents the angular distance of two vectors while ignoring their scale. \n\n### Jaccard\n- The Jaccard distance, is a measure of how _dissimilar_ two sets are. It is the complement of the Jaccard index and can be found by subtracting the Jaccard Index from 100%\n- https://en.wikipedia.org/wiki/Jaccard_index\n\n### Hamming\n- The hamming distance represents the number of entries in the two sample vectors which are different. It is a fundamental distance measure in information theory but less relevant in non-integer numerical problems. \n\n### Pearson\n- The Pearson distance is a correlation distance based on Pearson's product-momentum correlation coefficient of the two sample vectors. Since the correlation coefficient falls between [-1, 1], the Pearson distance lies in [0, 2] and measures the linear relationship between the two vectors. \nd_pearson(x,y) = 1 - Correlation(x,y)",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Math-and-Statistics/Linear-Algebra": {
    "title": "Linear Algebra",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Linear_algebra\n- The Matrix Cookbook (Brandt 2012): https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf\n- Stanford, Linear algebra refresher: https://stanford.edu/~shervine/teaching/cme-102/linear-algebra\n- Stanford CS229, algebra and calculus refresher: \n\t- https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf\n\t- http://cs229.stanford.edu/section/cs229-linalg.pdf\n- http://people.duke.edu/~ccc14/sta-663/LinearAlgebraReview.html\n- https://www.khanacademy.org/math/linear-algebra\n- http://nbviewer.jupyter.org/github/relopezbriega/relopezbriega.github.io/blob/master/downloads/LinearAlgebraPython.ipynb\n\n### Matrix decompositions\n- https://en.wikipedia.org/wiki/Matrix_decomposition\n- http://people.duke.edu/~ccc14/sta-663/LinearAlgebraMatrixDecompWithSolutions.html\n- http://hameddaily.blogspot.be/2016/12/simple-matrix-factorization-with.html\n- https://sites.google.com/site/igorcarron2/matrixfactorizations\n- http://blog.ethanrosenthal.com/2017/06/20/matrix-factorization-in-pytorch/\n- https://tryolabs.com/blog/introduction-to-recommender-systems/\n- Alternating Least-squares\n\t- Fast Python Collaborative Filtering for Implicit Datasets: https://github.com/benfred/implicit\n\t- Recommender system using matrix factorization (SVD, ALS): http://www.benfrederickson.com/matrix-factorization/\n- Eigen decomposition: \n\t- https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix\n\t- http://setosa.io/ev/eigenvectors-and-eigenvalues/\n- LU decomposition: https://en.wikipedia.org/wiki/LU_decomposition\n- QR decomposition: https://en.wikipedia.org/wiki/QR_decomposition\n\n#### SVD\n- Singular Value Decomposition: https://en.wikipedia.org/wiki/Singular_value_decomposition\n- https://mathworld.wolfram.com/SingularValueDecomposition.html\n- Geometric explanation of SVD and applications: http://www.ams.org/publicoutreach/feature-column/fcarc-svd\n- Singular Value Decomposition as Simply as Possible: https://gregorygundersen.com/blog/2018/12/10/svd/\n- https://jeremykun.com/2016/04/18/singular-value-decomposition-part-1-perspectives-on-linear-algebra/\n- #TALK SVD (MIT, Gilbert Strang): https://www.youtube.com/watch?v=mBcLRGuAFUk\n- #TALK Singular Value Decomposition (SVD): Mathematical Overview: https://www.youtube.com/watch?v=nbBvuuNVfco\n\n##### Randomized Singular Value Decomposition\n- https://gregorygundersen.com/blog/2019/01/17/randomized-svd/\n- Fast Randomized SVD (Meta/Facebook research): https://research.facebook.com/blog/2014/09/fast-randomized-svd/\n- #TALK Randomized Singular Value Decomposition (SVD): https://www.youtube.com/watch?v=fJ2EyvR85ro\n\n## Code\n- #CODE Nimfa: https://github.com/marinkaz/nimfa\n- #CODE Pymf: https://github.com/cthurau/pymf\n- #CODE Tensorly - fast and simple Python library for tensor learning: \n\t- https://tensorly.github.io/stable/home.html\n\t- http://tensorly.org/stable/modules/api.html#module-tensorly.decomposition\n\t- https://github.com/JeanKossaifi/tensorly-notebooks/blob/master/02_tensor_decomposition/cp_decomposition.ipynb\n- #CODE Eigen - Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms: http://eigen.tuxfamily.org/index.php?title=Main_Page\n\n\n## Books\n- #BOOK Templates for the Solution of Algebraic Eigenvalue Problems (Bai, Demmel 2000): https://www.cs.ucdavis.edu/~bai/ET/contents.html\n- #BOOK High Dimensional Data Analysis 2020 (HDA2020): https://statomics.github.io/HDA2020/index.html\n\n\n## References\n- #PAPER Singular value decomposition and least squares solutions (Golub \u0026 Reinsch 1970): https://link.springer.com/article/10.1007/BF02163027\n\t- http://people.duke.edu/~hpgavin/SystemID/References/Golub+Reinsch-NM-1970.pdf",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Math-and-Statistics/Math-and-Statistics": {
    "title": "Math and Statistics",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Portal:Mathematics\n- https://en.wikipedia.org/wiki/Mathematics\n- Statistics cheatsheet: https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-statistics\n- https://github.com/rouseguy/intro2stats\n- Stanford-cs-229 ML, probability and stats refresher: https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-probabilities-statistics.pdf\n- https://www.khanacademy.org/math/statistics-probability\n- http://christopherroach.com/articles/statistics-for-hackers/\n- Trigonometry refresher: https://stanford.edu/~shervine/teaching/cme-102/trigonometry\n\n## Books\n- #BOOK Essential Mathematics and Statistics for Science (Currell 2009, WILEY): https://www.wiley.com/en-us/Essential+Mathematics+and+Statistics+for+Science%2C+2nd+Edition-p-9780470694480\n\t- http://www.stewartschultz.com/statistics/books/Essential%20Mathematics.pdf\n- #BOOK Think Stats - Exploratory Data Analysis in Python (Downey 2014): https://greenteapress.com/wp/think-stats-2e/\n\t- Think Stats is an introduction to Probability and Statistics for Python programmers\n- #BOOK An Introduction to Statistics with Python (Haslwanter, 2015 6 SPRINGER): https://www.springer.com/fr/book/9783319283159\n\t- Applications in the life sciences\n\t- https://es.scribd.com/document/338198132/An-Introduction-to-Statistics-With-Python-With-Applications-in-the-Life-Sciences\n- #BOOK Statistical Thinking for the 21st Century (Poldrack 2018): http://statsthinking21.org/index.html\n\t- R language\n- #BOOK Jupyter Guide to Linear Algebra: https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/intro.html\n\n## Courses\n- #COURSE Statistical inference for data science: https://www.coursera.org/learn/statistical-inference\n\t- https://leanpub.com/LittleInferenceBook\n\t- Coursera Inference Version 3: https://www.youtube.com/playlist?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- #COURSE Probability and Statistics (Stanford online): https://lagunita.stanford.edu/courses/course-v1:OLI+ProbStat+Open_Jan2017/about\n- #COURSE Modern Applied Statistics: Elements of Statistical Learning (Statistics 315a, Stanford): http://statweb.stanford.edu/~tibs/stat315a/\n- #TALK Statistics in Python (Varoquaux 2015 Euroscipy): https://www.youtube.com/watch?v=yaSgoGLXKOg\n\n## Code\n- #CODE Numpy: https://numpy.org/\n\t- #PAPER Array programming with NumPy (Harris 2020): https://www.nature.com/articles/s41586-020-2649-2\n- #CODE Scipy: https://www.scipy.org/\n- #CODE Statsmodels: http://www.statsmodels.org/\n- #CODE PyLops: https://github.com/PyLops/pylops\n\t- https://pylops.readthedocs.io/en/latest/index.html\n\t- Python library is inspired by the MATLAB Spot – A Linear-Operator Toolbox project\n- #CODE Bayesian bootstrap: https://github.com/lmc2179/bayesian_bootstrap\n\n### A/B testing\n- #CODE Bootstrapped (Facebook) - Generate Bootstrapped confidence intervals for A/B testing: https://github.com/facebookincubator/bootstrapped\n- #CODE Sixpack: https://github.com/sixpack/sixpack\n- #CODE Expan (Zalando) - A Python library for statistical analysis of randomised control trials (A/B tests): \n\t- https://github.com/zalando/expan\n\t- #TALK https://www.youtube.com/watch?v=furJxiZlo6w\n- #CODE Proctor (Indeed): \n\t- https://github.com/indeedeng/proctor\n\t- http://opensource.indeedeng.io/proctor/\n\n\n## Subtopics\n### Calculus\n- Calculus refresher: https://stanford.edu/~shervine/teaching/cme-102/calculus\n- Ordinary Differential Equations\n\t- https://stanford.edu/~shervine/teaching/cme-102/cheatsheet-first-ode\n\t- https://stanford.edu/~shervine/teaching/cme-102/cheatsheet-second-ode\n\t- https://stanford.edu/~shervine/teaching/cme-102/cheatsheet-applications\n- Stanford-cs-229 ML, algebra and calculus refresher: https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf\n- https://scipy-latinamerica.github.io/revista.io/blog/2018/10/20/introduccion-al-calculo-con-python/\n- https://www.khanacademy.org/math/multivariable-calculus\n\n- #COURSE Calculus introductory courses (MIT): https://ocw.mit.edu/high-school/mathematics/\n\t- Single Variable Calculus (18.01SC): https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010\n\t- Multivariable Calculus (18.02SC): https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010\n\t- Highlights of calculus (Strang): https://ocw.mit.edu/resources/res-18-005-highlights-of-calculus-spring-2010\n\n### Linear Algebra\nSee [Linear Algebra](AI/Math%20and%20Statistics/Linear%20Algebra.md)\n\n\n### Distances\nSee [Distances](AI/Math%20and%20Statistics/Distances.md)\n\n\n### Descriptive stats\n- https://en.wikipedia.org/wiki/Descriptive_statistics\n- http://debrouwere.org/2017/02/01/unlearning-descriptive-statistics/\n\n#### Correlation and dependance\n- https://www.datascience.com/blog/introduction-to-correlation-learn-data-science-tutorials\n- https://en.wikipedia.org/wiki/Correlation_and_dependence\n- Correlation is a statistical measure that describes the association between random variables. Why is correlation a useful metric?\n\t- Correlation can help in predicting one quantity from another\n\t- Correlation can (but often does not, as we will see in some examples below) indicate the presence of a causal relationship\n\t- Correlation is used as a basic quantity and foundation for many other modeling techniques\n- Types:\n\t- Pearson’s Correlation: \n\t\t- Pearson is the most widely used correlation coefficient. Pearson correlation measures the linear association between continuous variables. In other words, this coefficient quantifies the degree to which a relationship between two variables can be described by a line. Raw observations are centered by subtracting their means and re-scaled by a measure of standard deviations.\n\t\t- Ro_X,Y = E[(X - mu_X)(Y - mu_Y)] / simga_X sigma_Y\n\t\t- numerator  -\u003e covariance\n\t\t- Dividing the covariance between two variables by the product of standard deviations ensures that correlation will always fall between -1 and 1 (much easier to interpret)\n\t- Spearman's Correlation:\n\t\t- Spearman's rank correlation coefficient can be defined as a special case of Pearson ρapplied to ranked (sorted) variables. Rather than comparing means and variances, Spearman's coefficient looks at the relative order of values for each variable. The formula for Spearman's coefficient looks very similar to that of Pearson, with the distinction of being computed on ranks instead of raw scores. \n\t- Kendall's Tau:\n\t\t- Also based on variable ranks, however, unlike Spearman's coefficient, Kendall’s tau does not take into account the difference between ranks— only directional agreement.\n- Covariance (matrix)\n\t- https://en.wikipedia.org/wiki/Covariance\n\t- In probability theory and statistics, covariance is a measure of the joint variability of two random variables. The sign of the covariance therefore shows the tendency in the linear relationship between the variables. The magnitude of the covariance is not easy to interpret. The normalized version of the covariance, the correlation coefficient, however, shows by its magnitude the strength of the linear relation. \n\t- In multidimensional case: covariance matrix. https://en.wikipedia.org/wiki/Covariance_matrix\n- Correlation \u0026 Causation \n\t- https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation\n\t- \"Correlation does not imply causation\" is a phrase used in statistics to emphasize that a correlation between two variables does not imply that one causes the other. Spurious statistical associations can be found in a multitude of quantities, simply due to chance.\n\t- Often, a relationship may appear to be causal through high correlation due to some unobserved variables. For example, the number of grocery stores in a city can be strongly correlated with the number of ice cream creameries. However, there is an obvious hidden variable here— the population size of the city.\n\t- https://medium.com/@akelleh/a-technical-primer-on-causality-181db2575e41#.4csn3na8j\n\t- https://www.khanacademy.org/math/probability/scatterplots-a1/creating-interpreting-scatterplots/v/correlation-and-causality\n\t- Also, weak or no correlation does not imply lack of association. Correlation is only one data summary statistic that by no means tells the complete story of relationships in the data.\n\n\n### Experimental design\nSee [Active learning](AI/Active%20learning.md)\n- Coursera - data scientist's toolbox: https://www.youtube.com/watch?v=vSXOJnGNtM4\n- Good experiment: replication, measure variability, generalise to the problem, transparent\n- Confounding variable - strategies: randomization, stratifying \n- Prediction is not and inference. Both are important and depend on the problem. Prediction is more challenging that inference. For prediction there are key quantities (metrics): sensitivity, specificity, positive predictive value, negative predictive value, accuracy\n\n#### A/B testing\nSee [A B testing](#code#A%20B%20testing)\n- https://en.wikipedia.org/wiki/A/B_testing\n- In marketing and business intelligence, A/B testing is a term for a randomized experiment with two variants, A and B, which are the control and variation in the controlled experiment. A/B testing is a form of statistical hypothesis testing with two variants leading to the technical term, two-sample hypothesis testing, used in the field of statistics. Other terms used for this method include bucket tests and split-run testing.\n- https://www.optimizely.com/ab-testing/\n- https://www.wired.com/2012/04/ff_abtesting/\n- http://data36.com/ab-testing-5-rules/\n- https://www.udacity.com/course/ab-testing--ud257\n- https://tech.okcupid.com/the-pitfalls-of-a-b-testing-in-social-networks/\n- https://www.quora.com/What-kind-of-A-B-testing-questions-should-I-expect-in-a-data-scientist-interview-and-how-should-I-prepare-for-such-questions\n- http://www.kdnuggets.com/2017/05/must-know-key-issues-problems-ab-testing.html\n\n#### Multi-armed bandit\n- http://blog.actblue.com/2015/04/29/the-multi-armed-bandit-new-and-much-improved-ab-testing-tools-2/\n- https://conversionxl.com/bandit-tests/\n- https://support.google.com/analytics/answer/2844870?hl=en\n- https://vwo.com/blog/multi-armed-bandit-algorithm/\n\n### Statistical Inference\n- https://en.wikipedia.org/wiki/Statistical_inference\n- https://www.youtube.com/watch?v=WkOinijQmPU\u0026feature=youtu.be\u0026list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/\n- Statistical inference : the process of generating conclusions about a population from a noisy sample. Without statistical inference we’re simply living within our data. With statistical inference, we’re trying to generate new knowledge. The use of probability models as the connection between our data and a populations represents the most effective way to obtain inference.\n- Question to answer: Are the statistics calculated on a small sample representative of the ones of the whole population?\n- http://www.datasciencecentral.com/profiles/blogs/the-death-of-the-statistical-test-of-hypothesis\n\n#### Frequentist inference\n- https://en.wikipedia.org/wiki/Frequentist_inference\n- Statistical Hypothesis testing: http://youtu.be/Wqvx6_12ZMs?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-hypothesis-testing\n\t- Hypothesis testing is concerned with making decisions using data. \n\t- To make decisions using data, we need to characterize the kinds of conclusions we can make. Classical hypothesis testing is concerned with deciding between two decisions (things get much harder if there’s more than two). The first, a null hypothesis is specified that represents the status quo. This hypothesis is usually labeled, H_0. This is what we assume by default. The alternative or research hypothesis is what we require evidence to conclude. This hypothesis is usually labeled H_a, or sometimes H_1 (or some other number other than 0). So to reiterate, the null hypothesis is assumed true and statistical evidence is required to reject it in favor of a research or alternative hypothesis\t\n\t- t-test\n\t\t- http://www.cs.cornell.edu/~asampson/blog/statsmistakes.html\n\t\t- https://www.quora.com/What-is-an-intuitive-explanation-of-the-t-test-in-hypothesis-testing\n\t\t- https://medium.freecodecamp.org/the-t-distribution-a-key-statistical-concept-discovered-by-a-beer-brewery-dbfdc693184\n\t- z-test\n\t- f-test\n- Confidence intervals\n\t- http://youtu.be/u85aQ0mtiZ8?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-confidence-intervals\n\t- Confidence intervals are methods for quantifying uncertainty in our estimates. The fact that the interval has width characterizes that there is randomness that prevents us from getting a perfect estimate.\n\t- t-confidence intervals\n\t\t- http://youtu.be/pHXrDMjzyYg?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-t-confidence-intervals\n- Null hypothesis\n\t- https://en.wikipedia.org/wiki/Null_hypothesis\n\t- The term \"null hypothesis\" is a general statement or default position that there is no relationship between two measured phenomena, or no association among groups.\n\t- H_0 is generally assumed to be true until evidence indicates otherwise.\n- P-value\n\t- https://en.wikipedia.org/wiki/P-value\n\t- A p-value is the probability that, using a given statistical model, the statistical summary (such as the sample mean difference between two compared groups) would be the same as or more extreme than the actual observed results, when the null hypothesis is true.\n\t- After choosing the models H_0, H_1 and a threshold value alpha for p (the significance level of the test, traditionally 5% or 1%), if the p-value is less than or equal to alpha, the test suggests that the observed data is inconsistent with the null hypothesis, so the null hypothesis must be rejected. However, that does not prove that the tested hypothesis is true. When the p-value is calculated correctly, this test guarantees that the Type I error rate is at most alpha. For typical analysis, using the standard alpha= 0.05 cutoff, the null hypothesis is rejected when p\u003c .05 and not rejected when p\u003e .05. \n\t- The p-value does not, in itself, support reasoning about the probabilities of hypotheses but is only a tool for deciding whether to reject the null hypothesis (it can only provide evidence against a hypothesis).\n\t- http://youtu.be/Ky68x_7iK6c?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-p-values\n\t- P-values are the most common measure of statistical significance. Their ubiquity, along with concern over their interpretation and use makes them controversial among statisticians.\n\t- http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values\n\t- A P value is the probability of obtaining an effect at least as extreme as the one in your sample data, assuming the truth of the null hypothesis.\n\t- For example, suppose that a vaccine study produced a P value of 0.04. This P value indicates that if the vaccine had no effect, you’d obtain the observed difference or more in 4% of studies due to random sampling error. \n\t- P values address only one question: how likely are your data, assuming a true null hypothesis? It does not measure support for the alternative hypothesis.\n\t- http://machinelearningmastery.com/use-statistical-significance-tests-interpret-machine-learning-results/\n\t- https://www.nature.com/news/big-names-in-statistics-want-to-shake-up-much-maligned-p-value-1.22375\n- Statistical Power\n\t- https://en.wikipedia.org/wiki/Statistical_power\n\t- #TALK Statistical power:\n\t\t- http://youtu.be/-TsBOLiW4rQ?list=PLpl-gQkQivXiB1mGyzLrUjzsblmQsLtkzJ\n\t\t- http://youtu.be/GRS2b1aedmk?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-power\n\t- Power is the probability of rejecting the null hypothesis when it is false. Ergo, power (as its name would suggest) is a good thing; you want more power. A type II error (a bad thing, as its name would suggest) is failing to reject the null hypothesis when it’s false; the probability of a type II error is usually called Beta. Note Power = 1 - Beta.\n- Effect size: https://en.wikipedia.org/wiki/Effect_size\n- Goodness of fit: https://en.wikipedia.org/wiki/Goodness_of_fit\n\t- Chi squared: https://en.wikipedia.org/wiki/Chi-squared_test\n\n### Bootstrap and permutation tests\n- http://youtu.be/0hNQx9nagq4?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-bootstrap-and-resampling\n- The bootstrap is a tremendously useful tool for constructing confidence intervals and calculating standard errors for difficult statistics. That’s the bootstrap principle: investigate the sampling distribution of a statistic by simulating repeated realizations from the observed distribution.\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-permutation-tests\n- Consider comparing means between the group. However, let’s use the calculate the distribution of our statistic under a null hypothesis that the labels are irrelevant (exchangeable). This is a handy way to create a null distribution for our test statistic by simply permuting the labels over and over and seeing how extreme our data are with respect to this permuted distribution. \n- The procedure would be as follows: \n\t- consider a data from with count and spray,\n\t- permute the spray (group) labels,\n\t- recalculate the statistic (such as the difference in means),\n\t- calculate the percentage of simulations where the simulated statistic was more extreme (toward the alternative) than the observed.\n\n#### Bayesian bootstrap\nSee [Code](#Code)\n- http://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/\n\n### Probability theory\nSee [Probability Theory](AI/Math%20and%20Statistics/Probability%20Theory.md)\n\n### Bayesian modelling\nSee [Bayesian modelling](AI/Bayesian%20modelling.md)\n\n### Monte Carlo methods\nSee [Monte Carlo methods](AI/Math%20and%20Statistics/Monte%20Carlo%20methods.md)\n\n### Mathematical Optimization\nSee [Mathematical Optimization](AI/Math%20and%20Statistics/Mathematical%20Optimization.md)\n\n### Time series analysis\nSee [Time Series analysis](Time%20Series%20analysis.md)\n\n### Regression analysis\nSee [Regression](AI/Supervised%20Learning/Regression.md)\n- https://en.wikipedia.org/wiki/Regression_analysis\n- Regression analysis is widely used for prediction and forecasting, where its use has substantial overlap with the field of [Machine Learning](AI/Machine%20Learning.md)\n\n### Compressed sensing\n- https://en.wikipedia.org/wiki/Compressed_sensing\n- Compressed sensing(also known as compressive sensing, compressive sampling, or sparse sampling) is a signal processing technique for efficiently acquiring and reconstructing a signal, by finding solutions to underdetermined linear systems. This is based on the principle that, through optimization, the sparsity of a signal can be exploited to recover it from far fewer samples than required by the Shannon-Nyquist sampling theorem.\n- There are two conditions under which recovery is possible: \n\t- Sparsity, which requires the signal to be sparse in some domain. \n\t- Incoherence, which is applied through the isometric property which is sufficient for sparse signals\n- https://calculatedcontent.com/2012/12/28/foundations-theory-of-compressed-sensing/amp/\n\n#### Nyquist theorem\n- https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem\n- In the field of digital signal processing, the sampling theorem is a fundamental bridge between continuous-time signals(often called \"analog signals\") and discrete-time signals(often called \"digital signals\"). It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.\n\n#### Matching pursuit\n- https://en.wikipedia.org/wiki/Matching_pursuit\n- Matching pursuit (MP) is asparse approximation algorithm which involves finding the \"best matching\" projections of multidimensional data onto the span of an over-complete (i.e., redundant) dictionary D.\n- Orthogonal Matching Pursuit\n\t- Extension of MP: after every step, all the coefficients extracted so far are updated, by computing the orthogonal projection of the signal onto the set of atoms selected so far. This can lead to better results than standard MP, but requires more computation.\n\t- http://scikit-learn.org/stable/auto_examples/linear_model/plot_omp.html",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Math-and-Statistics/Mathematical-Optimization": {
    "title": "Mathematical Optimization",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Mathematical_optimization\n- A birds-eye view of optimization algorithms (Pedregosa): http://fa.bianp.net/teaching/2018/eecs227at/\n- http://people.duke.edu/~ccc14/sta-663/BlackBoxOptimization.html\n- http://www.benfrederickson.com/numerical-optimization/ (notebook kind of post with python, d3)\n- http://www.kdnuggets.com/2016/12/hard-thing-about-deep-learning.html\n- https://www.neuraldesigner.com/blog/5_algorithms_to_train_a_neural_network\n- Why Momentum works: http://distill.pub/2017/momentum/\n\n### Heuristics\n- A heuristic is any algorithm which is not guaranteed (mathematically) to find the solution, but which is nevertheless useful in certain practical situations.\n- Genetic algorithms\n\t- https://en.wikipedia.org/wiki/Genetic_algorithm\n\t- Metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms(EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on bio-inspired operators such as mutation, crossover and selection.\n- Nelder–Mead method\n\t- https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method\n\t- The Nelder–Mead method or downhill simplex method or amoeba method is a commonly applied numerical method used to find the minimum or maximum of an objective function in a multidimensional space. It is applied to nonlinear optimization problems for which derivatives may not be known. However, the Nelder–Mead technique is a heuristic search method that can converge to non-stationary points on problems that can be solved by alternative methods.\n\t- The method uses the concept of a simplex, which is a special polytope of n+ 1 vertices in n dimensions. Examples of simplices include a line segment on a line, a triangle on a plane, a tetrahedron in three-dimensional space and so forth. The method approximates a local optimum of a problem with n variables when the objective function varies smoothly and is unimodal.\n\t- Nelder–Mead in n dimensions maintains a set of n+1test points arranged as a simplex. It then extrapolates the behavior of the objective function measured at each test point, in order to find a new test point and to replace one of the old test points with the new one, and so the technique progresses. The simplest approach is to replace the worst point with a point reflected through the centroid of the remaining n points. If this point is better than the best current point, then we can try stretching exponentially out along this line. On the other hand, if this new point isn't much better than the previous value, then we are stepping across a valley, so we shrink the simplex towards a better point.\n\n### Iterative methods\nThe iterative methods used to solve problems of nonlinear programming differ according to whether they evaluate Hessians, gradients, or only function values.\n- Gradient descent\n\t- https://en.wikipedia.org/wiki/Gradient_descent\n\t- Gradient descent is a first-order iterative optimization algorithm. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or of the approximate gradient) of the function at the current point. Gradient descent is also known as steepest descent, or the method of steepest descent.\n\t- An overview of gradient descent optimization algorithms: http://ruder.io/optimizing-gradient-descent/index.html\n\t- https://towardsdatascience.com/gradient-descent-demystified-bc30b26e432a\n\t- https://www.jeremyjordan.me/gradient-descent/\n- Conjugate gradient method: https://en.wikipedia.org/wiki/Conjugate_gradient_method\n- Interior point method: https://en.wikipedia.org/wiki/Interior_point_method\n\n\n## Code\n- #CODE Nevergrad (Facebook) - A Python toolbox for performing gradient-free optimization: https://code.fb.com/ai-research/nevergrad/\n- #CODE scikit-optimize: https://scikit-optimize.github.io/\n- #CODE GPflowOpt - library for Bayesian Optimization with GPflow: https://gpflowopt.readthedocs.io/en/latest/index.html \n- #CODE JAX: https://github.com/google/jax ^jax\n\t- JAX is Autograd and XLA, brought together for high-performance machine learning research. It can automatically differentiate native Python and NumPy functions\n\t- #TALK JAX: Accelerated Machine Learning Research | SciPy 2020 | VanderPlas: https://www.youtube.com/watch?v=z-WSrQDXkuM\n\t- https://towardsdatascience.com/deep-learning-with-jax-and-elegy-c0765e3ec31a\n\t- #TALK Machine Learning with JAX - From Zero to Hero: https://www.youtube.com/watch?v=SstuvS-tVc0",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Math-and-Statistics/Monte-Carlo-methods": {
    "title": "Monte Carlo methods",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Monte_Carlo_method\n\n### Sequential Monte Carlo (SMC or particle filter)\n- Particle filters or Sequential Monte Carlo (SMC) methods are a set of Monte Carlo algorithms used to solve filtering problems arising in signal processing and Bayesian statistical inference. The filtering problem consists of estimating the internal states in dynamical systems when partial observations are made, and random perturbations are present in the sensors as well as in the dynamical system. The objective is to compute the posterior distributions of the states of some Markov process, given some noisy and partial observations.\n\n### Markov Process\n- https://en.wikipedia.org/wiki/Markov_chain\n- https://en.wikipedia.org/wiki/Markov_property\n- A stochastic process has the Markov property if the conditional probability distribution of future states of the process (conditional on both past and present states) depends only upon the present state, not on the sequence of events that preceded it. A process with this property is called a Markov process.\n- Markov Chains Explained Visually: http://setosa.io/ev/markov-chains/\n\n#### Hidden Markov Model (HMM)\n- https://en.wikipedia.org/wiki/Hidden_Markov_model\n- Hidden Markov Model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (i.e. hidden) states.\n- HMM is a Markov chain for which the state is only partially observable. In other words, observations are related to the state of the system, but they are typically insufficient to precisely determine the state. Several well-known algorithms for hidden Markov models exist. \n- https://www.quora.com/What-is-a-hidden-Markov-Model-HMM-and-how-can-it-be-used-in-speech-recognition\n- https://www.quora.com/Why-do-we-use-Hidden-Markov-Models-for-speech-recognition\n- http://scikit-learn.sourceforge.net/stable/modules/hmm.html\n- https://github.com/hmmlearn/hmmlearn\n- http://hmmlearn.readthedocs.io/en/latest/tutorial.html#available-models\n\n### MCMC\n- MCMC methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by recording states from the chain\n- https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo\n\n### Nested Sampling\n- https://en.wikipedia.org/wiki/Nested_sampling_algorithm\n- The nested sampling algorithm is a computational approach to the problem of comparing models in Bayesian statistics. \n\n\n## Code\n- A list of Python-based MCMC packages. Also here’s a nice list of MCMC algorithms: https://gabriel-p.github.io/pythonMCMC/\n- #CODE Sampyl - MCMC samplers for Bayesian estimation in Python, including Metropolis-Hastings, NUTS, and Slice: http://mcleonard.github.io/sampyl/\n- #CODE emcee: http://dan.iel.fm/emcee/current/\n- #CODE UltraNest - A Pythonic implementation of the Nested Sampling integration algorithm for Bayesian model comparison and parameter estimation\n\t- https://johannesbuchner.github.io/UltraNest/\n\t- https://johannesbuchner.github.io/UltraNest/testsuite/",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Math-and-Statistics/Probability-Theory": {
    "title": "Probability Theory",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Probability_theory\n- https://stanford.edu/~shervine/teaching/cme-106/key-concepts\n- A visual introduction to probability and statistics: http://students.brown.edu/seeing-theory/\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-probability\n- Probability forms the foundation for almost all treatments of statistical inference. Probability is a law that assigns numbers to the long run occurrence of random phenomena after repeated unrelated realizations\n- http://nbviewer.jupyter.org/url/norvig.com/ipython/Probability.ipynb\n- https://en.wikipedia.org/wiki/Probability_interpretations\n- https://en.wikipedia.org/wiki/Bayesian_probability\n- The Coursera Statistical Inference class: http://youtu.be/oTERv_vrmJM?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- Monty Hall problem: https://en.wikipedia.org/wiki/Monty_Hall_problem\n- Coded in Python: https://github.com/cs109/2015lab1/blob/master/hw0.ipynb\n- Cheatsheets:\n\t- https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-probability\n\t- Probability Cheatsheet (Chen): \n\t\t- http://www.wzchen.com/probability-cheatsheet/\n\t\t- This is an 10-page probability cheatsheet compiled from Harvard's Introduction to Probability course, taught by Joe Blitzstein (@stat110). The probability formula sheet summarizes important probability probability concepts, formulas, and distributions, with figures, examples, and stories.\n\t- Review of Probability Theory (CS229 Stanford)\n\t\t- http://cs229.stanford.edu/section/cs229-prob.pdf\t\n\t\t- http://cs229.stanford.edu/section/cs229-prob-slide.pdf\n\n#### Random variables\n- http://youtu.be/Shzt9uZ8BII?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-random-variables\n- Random variable is a numerical outcome of an experiment. The random variables that we study will come in two varieties, discrete or continuous. Discrete random variables are random variables that take on only a countable number of possibilities. Mass functions will assign probabilities that they take specific values. Continuous random variable can conceptually take any value on the real line or some subset of the real line and we talk about the probability that they lie within some range. Densities will characterize these probabilities.\n- For all of these kinds of random variables, we need convenient mathematical functions to model the probabilities of collections of realizations. These functions, called mass functions and densities, take possible values of the random variables, and assign the associated probabilities. These entities describe the population of interest.\n- PDF - probability density function\n\t- https://en.wikipedia.org/wiki/Probability_density_function\n\t- http://youtu.be/mPe0Us4VYDM?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-probability-density-functions\n\t- A probability density function (pdf), is a function associated with a continuous random variable. Because of the peculiarities of treating measurements as having been recorded to infinite decimal expansions, we need a different set of rules. This leads us to the central dogma of probability density functions: Areas under PDFs correspond to probabilities for that random variable. \n\t- A PDF, or density of a continuous random variable, is a function, whose value at any given sample (or point) in the sample space(the set of possible values taken by the random variable) can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample.\n\t- The PDF is used to specify the probability of the random variable falling within a particular range of values, as opposed to taking on any one value.\n\n#### Conditional probability\n- http://youtu.be/u6AH6qsSVA4?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-conditional-probability\n- Conditioning is a central subject in statistics. If we are given information about a random variable, it changes the probabilities associated with it. For example, the probability of getting a one when rolling a (standard) die is usually assumed to be one sixth. If you were given the extra information that the die roll was an odd number (hence 1, 3 or 5) then conditional on this new information, the probability of a one is now one third.\n- http://setosa.io/ev/conditional-probability/\n\n#### Independance\n- https://en.wikipedia.org/wiki/Independence_(probability_theory)\n- http://youtu.be/MY1EfrR1ZUs?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-independence\n- Statistical independence of events is the idea that the events are unrelated. Consider successive coin flips. Knowledge of the result of the first coin flip tells us nothing about the second.\n- The important principle is that probabilities of independent things multiply! This has numerous consequences, including the idea that we shouldn’t multiply non-independent probabilities.\n- IID samples : https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables\n\t- IID - Independent and identically distributed \n\t- In probability theory and statistics, a sequence or other collection of random variables is independent and identically distributed(i.i.d.) if each random variable has the same probability distribution as the others and all are mutually independent.\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-iid-random-variables\n\t- Random variables are said to be independent and identically distributed (iid) if they are independent and all are drawn from the same population. The reason iid samples are so important is that they are a model for random samples. This is a default starting point for most statistical inferences.\n  \n#### Common distributions\n- https://stanford.edu/~shervine/teaching/cme-106/distribution-tables\n- https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-some-common-distributions\n- Normal distribution: http://efavdb.com/normal-distributions/\n- Bernoulli\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-bernoulli-distribution\n\t- TheBernoulli distribution arises as the result of a binary outcome, such as a coin flip.\n- Normal\n\t- http://youtu.be/dUTWvKa0Leo?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-normal-distribution\n\t- The normal distribution is easily the handiest distribution in all of statistics. It can be used in an endless variety of settings. Moreover, as we’ll see later on in the course, sample means follow normal distributions for large sample sizes.\n\t- The normal distribution only requires two numbers to characterize it, mean and variance.\n- Poisson\n\t- http://youtu.be/ZPLZg7qz4xE?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n\t- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-poisson-distribution\n\t- The Poisson distribution is used to model counts. It is perhaps only second to the normal distribution usefulness. In fact, the Bernoulli, binomial and multinomial distributions can all be modeled by clever uses of the Poisson.\n\t- The Poisson distribution is especially useful for modeling unbounded counts or counts per unit of time (rates). Like the number of clicks on advertisements, or the number of people who show up at a bus stop. There is also a deep connection between the Poisson distribution and popular models for so-called event-time data.\n\n#### Expected value\n- https://en.wikipedia.org/wiki/Expected_value\n- In probability theory, the expected value of a random variable, intuitively, is the long-run average value of repetitions of the experiment it represents.\n- Less roughly, the law of large numbers states that the arithmetic mean of the values almost surely converges to the expected value as the number of repetitions approaches infinity. The expected value is also known as the expectation, mathematical expectation, EV, average, mean value, mean, or first moment.\n- Expected values: http://youtu.be/zljxRbu6jyc?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-expected-values\n- Expected values characterize a distribution. The most useful expected value, the mean, characterizes the center of a density or mass function. Another expected value summary, the variance, characterizes how spread out a density is. Yet another expected value calculation is the skewness, which considers how much a density is pulled toward high or low values.\n\n#### Central limit theorem\n- https://en.wikipedia.org/wiki/Central_limit_theorem\n- http://youtu.be/FAIyVHmniK0?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ\n- https://leanpub.com/LittleInferenceBook/read#leanpub-auto-the-central-limit-theorem\n- CLT is one of the most important theorems in statistics. For our purposes, the CLT states that the distribution of averages of iid variables becomes that of a standard normal as the sample size increases.\n\n#### Kullback-Leibler Divergence\n- https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n- https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained\n\n\n## Books\n- #COURSE Introduction to Probability and Statistics (MIT): https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/NLP": {
    "title": "Natural Language Processing (NLP)",
    "content": "---\n\n## Resources\n- NLP is a branch of data science that consists of systematic processes for analyzing, understanding, and deriving information from the text data in a smart and efficient manner. By utilizing NLP and its components, one can organize the massive chunks of text data, perform numerous automated tasks and solve a wide range of problems such as – automatic summarization, machine translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation etc.\n- https://en.wikipedia.org/wiki/Natural_language_processing\n- A Computer Science field connected to Artificial Intelligence and Computational Linguistics which focuses on interactions between computers and human language and a machine’s ability to understand, or mimic the understanding of human language\n- https://github.com/keon/awesome-nlp\n- The most important NLP highlights of 2018: https://github.com/omarsar/nlp_highlights\n- NLP - Udemy ML: https://github.com/jmportilla/Udemy",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/One-few-shot-learning": {
    "title": "One, few-shot learning",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/One-shot_learning\n- One-shot learning is an object categorization problem, found mostly in computer vision. Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of samples/images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training samples/images.\n- https://medium.com/sap-machine-learning-research/deep-few-shot-learning-a1caa289f18\n- https://sorenbouma.github.io/blog/oneshot/\n- https://github.com/Goldesel23/Siamese-Networks-for-One-Shot-Learning\n- Zero-Shot Visual Imitation: https://pathak22.github.io/zeroshot-imitation/\n- #TALK Neural Networks - One Shot Learning: https://www.youtube.com/watch?v=r8LLorRACPM\n\n\n## Code\n- #CODE LibFewShot: https://github.com/rl-vig/libfewshot\n\t- #PAPER LibFewShot: A Comprehensive Library for Few-shot Learning (Li 2021): https://arxiv.org/abs/2109.04898\n\t- LibFewShot: A Comprehensive Library for Few-shot Learning (pytorch)\n\n## References\n- #PAPER Siamese Neural Networks for One-shot Image Recognition (Koch 2015): http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf\n\t- Few-Shot learning has seen great progress over the last years. A classic approach is based on metric learning using Siamese neural networks.\n\t- #CODE https://sorenbouma.github.io/blog/oneshot/\n- #PAPER One-Shot Imitation Learning (Duan 2017): https://arxiv.org/abs/1703.07326\n- #PAPER One-shot texture segmentation (Ustyuzhaninov 2018): https://arxiv.org/abs/1807.02654\n\t- We solve the task of one-shot texture segmentation in three steps. First, we compute embeddings of an input image and a reference patch; second, we search for the reference texture in the embedding space to produce a rough segmentation mask; and, finally, we employ a decoding network to produce the output segmentation.\n- #PAPER One-shot instance segmentation (Michaelis 2018): https://arxiv.org/abs/1811.11507 \n\t- We tackle one-shot visual search by example for arbitrary object categories: Given an example image of a novel reference object, find and segment all object instances of the same category within a scene. To address this problem, we propose Siamese Mask R-CNN. \n\t- It extends Mask R-CNN by a Siamese backbone encoding both reference image and scene, allowing it to target detection and segmentation towards the reference category.\n- #PAPER FIGR: Few-shot Image Generation with Reptile (Clouatre 2019): https://arxiv.org/abs/1901.02199\n- #PAPER Generalizing from a Few Examples: A Survey on Few-Shot Learning (Wang 2020): https://arxiv.org/abs/1904.05046\n- #PAPER 'Less Than One'-Shot Learning: Learning N Classes From M \u003c N Samples (Sucholutsky 2020): https://arxiv.org/abs/2009.08449\n\t- https://www.technologyreview.com/2020/10/16/1010566/ai-machine-learning-with-tiny-data/\n\t- [[AI]] model able to accurately recognize more objects than the number of examples it was trained on\n\t- The trick, was to create images that blend multiple digits together and then feed them into an [[AI]] model with hybrid, or “soft,” labels\n\n\n### Few/one-shot learning GANs \n- #PAPER MetaGAN: An Adversarial Approach to Few-Shot Learning (Zhang 2018). https://papers.nips.cc/paper/7504-metagan-an-adversarial-approach-to-few-shot-learning\n- #PAPER SinGAN: Learning a Generative Model from a Single Natural Image, SinGAN (Rott Shaham, ICCV 2019 Best Paper): https://arxiv.org/abs/1905.01164 \n\t-  Paper explained: https://www.youtube.com/watch?v=-f8sz8AExdc \n\t-  Paper explained: https://www.youtube.com/watch?v=Xc9Rkbg6IZA\n- #PAPER DAWSON: A Domain Adaptive Few Shot Generation Framework (Liang 2020). https://arxiv.org/abs/2001.00576\n- #PAPER LARGE: Latent-Based Regression through GAN Semantics (Nitzan 2021): https://arxiv.org/abs/2107.11186\n\t- #CODE https://github.com/YotamNitzan/LARGE",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Probabilistic-machine-learning": {
    "title": "Probabilistic machine learning",
    "content": "See:\n[Bayesian neural networks](AI/Deep%20learning/Bayesian%20neural%20networks.md)\n[Bayesian modelling](AI/Bayesian%20modelling.md)\n[GFlowNets](AI/Deep%20learning/GFlowNets.md)\n\n\n## Resources\n- https://en.wikipedia.org/wiki/Graphical_model\n\n## References\n- #BOOK Probabilistic Graphical Models: Principles and Techniques (Koller, 2009 MIT): http://pgm.stanford.edu/ \n- #PAPER Probabilistic machine learning and artificial intelligence (Ghahramani 2015): https://www.nature.com/articles/nature14541\n\n## Courses\n- #COURSE Introductory course on probabilistic graphical models: https://ermongroup.github.io/cs228-notes/",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Problem-Solving-and-Search": {
    "title": "Problem Solving and Search",
    "content": "## Resources\n- Solving problems by searching: https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture2.md\n- Problem solving and search: https://www.emse.fr/~picard/cours/ai/chapter03.pdf\n- Constraint satisfaction problems:\n\t- Constraint satisfaction problems (CSPs) are mathematical questions defined as a set of objects whose state must satisfy a number of constraints or limitations. CSPs represent the entities in a problem as a homogeneous collection of finite constraints over variables, which is solved by constraint satisfaction methods. CSPs are the subject of intense research in both artificial intelligence and operations research, since the regularity in their formulation provides a common basis to analyze and solve problems of many seemingly unrelated families. \n\t- Constraint satisfaction problems: https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture3.md\n\t- Constraint satisfaction problems: https://www.emse.fr/~picard/cours/ai/chapter06.pdf\n- Adversarial Search\n\t- Games and adversarial search: https://glouppe.github.io/info8006-introduction-to-ai/?p=lecture4.md\n\t- Adversarial search: https://www.emse.fr/~picard/cours/ai/chapter05.pdf",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Reinforcement-learning": {
    "title": "Reinforcement learning",
    "content": "## Resources\n- Reinforcement learning is the task of learning what actions to take, given a certain situation/environment, so as to maximize a reward signal. The interesting difference between supervised and reinforcement learning is that this reward signal simply tells you whether the action (or input) that the agent takes is good or bad. It doesn’t tell you anything about what the best action is. Contrast this to CNNs where the corresponding label for each image input is a definite instruction of what the output should be for each input.  Another unique component of RL is that an agent’s actions will affect the subsequent data it receives. For example, an agent’s action of moving left instead of right means that the agent will receive different input from the environment at the next time step.\n- https://en.wikipedia.org/wiki/Reinforcement_learning\n- Curriculum for Reinforcement Learning: https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html\n- Andrej Karpathy's introduction to RL: http://karpathy.github.io/2016/05/31/rl/\n- Evolution strategies vs RL: https://blog.openai.com/evolution-strategies/\n\t- https://github.com/openai/evolution-strategies-starter\n- Reinforcement learning derivations (math): http://www.alexirpan.com/rl-derivations/\n- Introduction to various RL algos: https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287\n- Q-learning: https://en.wikipedia.org/wiki/Q-learning\n- Temporal differencing (TD) learning  is a prediction-based machine learning method. \n\t- It has primarily been used for the reinforcement learning problem, and is said to be \"a combination ofMonte Carlo ideas and dynamic programming (DP) ideas.\" \n\t- TD resembles a Monte Carlo method because it learns by sampling the environment according to some policy, and is related to dynamic programming techniques as it approximates its current estimate based on previously learned estimates (a process known as bootstrapping). The TD learning algorithm is related to the temporal difference model of animal learning. As a prediction method, TD learning considers that subsequent predictions are often correlated in some sense.\n\t- TD-Lambda: This algorithm was famously applied by Gerald Tesauro to createTD-Gammon, a program that learned to play the game of backgammon at the level of expert human players. The lambda parameter refers to the trace decay parameter, with 0\u003c= lambda \u003c=1. Higher settings lead to longer lasting traces; that is, a larger proportion of credit from a reward can be given to more distant states and actions when lambda is higher, with lambda=1 producing parallel learning to Monte Carlo RL algorithms.\n- SARSA: https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action\n\n\n## Courses, talks and books\n- #COURSE Reinforcement Learning (UCL): https://www.davidsilver.uk/teaching/\n\t- Videos: https://www.youtube.com/watch?v=2pWv7GOvuf0\u0026list=PLzuuYNsE1EZAXYR4FJ75jcJseBmo4KQ9-\n- #COURSE CS294-112 Deep Reinforcement Learning Sp17: https://www.youtube.com/playlist?list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX\n- #COURSE Practical Reinforcement Learning (Yandex): https://github.com/yandexdataschool/Practical_RL\n- #COURSE [Tutorial: Introduction to Reinforcement Learning](https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W3D2_BasicReinforcementLearning/student/W3D2_Tutorial1.ipynb)\n- #TALK Deep Learning and Reinforcement Learning Summer School, Toronto 2018: http://videolectures.net/DLRLsummerschool2018_toronto/\n- #TALK Deep RL Bootcamp: https://sites.google.com/view/deep-rl-bootcamp/lectures\t  \n- #BOOK Deep Reinforcement Learning (2020 SPRINGER): https://www.springer.com/gp/book/9789811540943\n\t- https://deepreinforcementlearningbook.org/\n\n\n## Code\n- #CODE Acme: a research framework for reinforcement learning: https://github.com/deepmind/acme\n- #CODE Deep Reinforcement Learning Model ZOO: https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement_learning\n- #CODE Open.ai Gym - A toolkit for developing and comparing reinforcement learning algorithms. https://github.com/openai/gym\n\t- https://gym.openai.com/\n\t- #PAPER http://arxiv.org/abs/1606.01540\n- #CODE Horizon (Facebook) - The first open source reinforcement learning platform for large-scale products and services. https://github.com/facebookresearch/Horizon\n- #CODE Keras-rl - Deep Reinforcement Learning for Keras: https://github.com/keras-rl/keras-rl\n- #CODE TRFL (pronounced \"truffle\") is a library built on top of TensorFlow that exposes several useful building blocks for implementing Reinforcement Learning agents. https://github.com/deepmind/trfl/\n- #CODE Surreal - Open-Source Distributed Reinforcement Learning Framework by Stanford Vision and Learning Lab. https://github.com/SurrealAI/surreal\n\t- https://surreal.stanford.edu\n- #CODE Tensorforce - Tensorforce is an open-source deep reinforcement learning framework, with an emphasis on modularized flexible library design and straightforward usability for applications in research and practice. \n\t- https://github.com/tensorforce/tensorforce\n\t- https://reinforce.io/blog/introduction-to-tensorforce/\n- #CODE Tensorlayer: https://github.com/tensorlayer/tensorlayer\n\t- Deep Learning and Reinforcement Learning Library for Scientists and Engineers\n\t- https://tensorlayer.readthedocs.io/en/latest/index.html\n\n\n## References\n### Deep RL\n- Spinning Up as a Deep RL Researcher: https://spinningup.openai.com/en/latest/spinningup/spinningup.html\n\nReview papers:\n- #PAPER A Brief Survey of Deep Reinforcement Learning (Arulkumaran 2017): https://arxiv.org/abs/1708.05866\n\t- Many of the successes in DRL have been based on scaling up prior work in RL to high-dimensional problems. This is due to the learning of low-dimensional feature representations and the powerful function approximation properties of neural networks. By means of representation learning, DRL can deal efficiently with the curse of dimensionality, unlike tabular and traditional non-parametric methods.\n\t- https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-2-Reinforcement-Learning\n- #PAPER An Introduction to Deep Reinforcement Learning (Fancois-Lavet 2018): https://arxiv.org/abs/1811.12560\n- #PAPER Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems (Levine 2020): https://arxiv.org/abs/2005.01643\n\n- #PAPER DQN: Human-level control through Deep Reinforcement Learning (Mnih 2015): https://deepmind.com/research/dqn/\n\t- https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf\n- #PAPER Learning to Optimize (Li 2016): https://arxiv.org/abs/1606.01885\n\t- Learning to Optimize with Reinforcement Learning: https://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/\n- #PAPER Deep Recurrent Q-Learning for Partially Observable MDPs (Hausknecht 2017): https://arxiv.org/abs/1507.06527\n- #PAPER Neural Episodic Control (Pritzel 2017): https://arxiv.org/abs/1703.01988\n\t- Deep reinforcement learning methods attain super-human performance in a wide range of environments. Such methods are grossly inefficient, often taking orders of magnitudes more data than humans to achieve reasonable performance\n\t- Neural Episodic Control: a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them. \n\t- The agent uses a semi-tabular representation of the value function: a buffer of past experience containing slowly changing state representations and rapidly updated estimates of the value function\n\t- https://www.technologyreview.es/s/6656/olvidese-del-aprendizaje-profundo-el-nuevo-enfoque-de-google-funciona-mucho-mejor\n\t- Explanation of Neural Episodic Control: https://rylanschaeffer.github.io/content/research/neural_episodic_control/main.html\n- #PAPER Supervising strong learners by amplifying weak experts (Christiano 2018): https://arxiv.org/abs/1810.08575\n\t- Learning Complex Goals with Iterated Amplification: https://blog.openai.com/amplifying-ai-training/\n- #PAPER MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model (Schrittwieser 2019): https://deepmind.com/research/publications/MasterinModel\n\t- https://medium.com/dataseries/deepminds-muzero-is-one-of-the-most-important-deep-learning-systems-ever-created-347442a6793g-Atari-Go-Chess-and-Shogi-by-Planning-with-a-Learned-\n- #PAPER Decision Transformer: Reinforcement Learning via Sequence Modeling (Chen 2021): https://arxiv.org/abs/2106.01345v1 ^decisiontransformer\n\t- #CODE https://paperswithcode.com/paper/decision-transformer-reinforcement-learning\n\t- Paper explained: https://www.youtube.com/watch?v=-buULmf7dec\n- #PAPER Reward is enough (Silver 2021): https://www.sciencedirect.com/science/article/pii/S0004370221000862\n\t- https://towardsdatascience.com/reward-is-enough-ml-paper-review-e448ee0a6092\n\t- From the authors of “Attention is all you need”, this paper proposes an intriguing hypothesis that incentivizing AI agents with reward is enough to achieve General Artificial Intelligence\n\t- \"General intelligence, of the sort possessed by humans and perhaps also other animals, may be defined as the ability to flexibly achieve a variety of goals in different contexts. According to our hypothesis, general intelligence can instead be understood as, and implemented by, maximising a singular reward in a single, complex environment4\"",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Self-supervised-learning": {
    "title": "Self-supervised learning",
    "content": "## Resources\n- https://github.com/jason718/awesome-self-supervised-learning\n- https://hackernoon.com/self-supervised-learning-gets-us-closer-to-autonomous-learning-be77e6c86b5a\n- Self-Supervised Representation Learning: https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html\n- Self-Supervised Vision Models (2021, Dr. Ishan Misra - FAIR): https://www.youtube.com/watch?v=EXJmodhu4_4\n- Self-supervised learning: The dark matter of intelligence: https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/\n\t- The general technique of self-supervised learning is to predict any unobserved or hidden part (or property) of the input from any observed or unhidden part of the input\n\t- Blog post explained: https://www.youtube.com/watch?v=Ag1bw8MfHGQ\u0026t=6s\n\t\n \n## Code\n- #CODE VISSL: https://github.com/facebookresearch/vissl\n\t- FAIR's library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images\n- #CODE Solo-learn: https://github.com/vturrisi/solo-learn\n\t- A library of self-supervised methods for unsupervised visual representation learning powered by PyTorch Lightning\n\t- Methods available: Barlow Twins, BYOL, DeepCluster V2, DINO, MoCo V2+, NNCLR, ReSSL, SimCLR + Supervised Contrastive Learning, SimSiam, Swav, VICReg, W-MSE\n\t- https://arxiv.org/abs/2108.01775v2\n- #CODE Lightly: https://github.com/lightly-ai/lightly\n\t- A python library for self-supervised learning on images\n- #CODE OpenSelfSup: https://github.com/open-mmlab/OpenSelfSup\n\t- Self-Supervised Learning Toolbox and Benchmark\n- #CODE Curator: https://github.com/spaceml-org/Self-Supervised-Learner\n\t- A No-Code, Self-Supervised Learning and Active Labeling Tool to Create Labeled Image Datasets from Petabyte-Scale Imagery\n\n\n## References\n- #PAPER Self-Supervised Learning of Pretext-Invariant Representations (Misra 2019): https://arxiv.org/abs/1912.01991\n- #PAPER A Framework For Contrastive Self-Supervised Learning And Designing A New Approach (Falcon 2020): https://arxiv.org/abs/2009.00104\n\t- https://towardsdatascience.com/a-framework-for-contrastive-self-supervised-learning-and-designing-a-new-approach-3caab5d29619\n- #PAPER RegNet - Designing Network Design Spaces (Radosavovic 2020): https://arxiv.org/abs/2003.13678v1\n- #PAPER Transferable Visual Words: Exploiting the Semantics of Anatomical Patterns for Self-supervised Learning (Haghighi 2021): https://arxiv.org/abs/2102.10680\n- #PAPER Instance Localization for Self-supervised Detection Pretraining (Yang 2021): https://arxiv.org/abs/2102.08318\n- #PAPER Supervised Contrastive Learning (Khosla 2021): https://arxiv.org/abs/2004.11362\n\t- #CODE https://github.com/google-research/google-research/tree/master/supcon\n\t- #CODE https://keras.io/examples/vision/supervised-contrastive-learning/\n\t- extended the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information\n\t- clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Semi-supervised-learning": {
    "title": "Semi-supervised learning",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Semi-supervised_learning\n- Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data).\n- In contrast (to active learning), semi-supervised learning attempts to automatically exploit unlabeled data in addition to labeled data to improve learning performance, where no human intervention is assumed. \n- https://deepai.org/machine-learning-glossary-and-terms/semi-supervised-learning\n- https://scikit-learn.org/stable/modules/label_propagation.html\n\n## Code\n- #CODE TorchSSL: https://github.com/TorchSSL/TorchSSL\n\t- A PyTorch-based Toolbox for Semi-Supervised Learning\n\n## References\n- #PAPER Semi-Supervised Learning Literature Survey (2008): http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf\n- #PAPER Learning Loss Functions for Semi-supervised Learning via Discriminative Adversarial Networks (Nogueira Dos Santos 2017): https://arxiv.org/abs/1707.02198\n- #PAPER Semi-Supervised Learning with Normalizing Flows (Izmailov, 2019): https://arxiv.org/abs/1912.13025\n\t- #CODE https://github.com/izmailovpavel/flowgmm\n- #PAPER Self-training with Noisy Student improves ImageNet classification (Xie 2020): https://arxiv.org/abs/1911.04252\n\t- Paper explained: https://www.youtube.com/watch?v=q7PjrmGNx5A\n\t- Noisy Student Training, a semi-supervised learning approach that works well even when labeled data is abundant. Noisy Student Training extends the idea of self-training and distillation with the use of equal-or-larger student models and noise added to the student during learning. On ImageNet, we first train an EfficientNet model on labeled images and use it as a teacher to generate pseudo labels for 300M unlabeled images. We then train a larger EfficientNet as a student model on the combination of labeled and pseudo labeled images. We iterate this process by putting back the student as the teacher. During the learning of the student, we inject noise such as dropout, stochastic depth, and data augmentation via RandAugment to the student so that the student generalizes better than the teacher.\n\t- #CODE https://github.com/google-research/noisystudent\n- #PAPER Big Transfer (BiT):General Visual Representation Learning (Kolesnikov 2020): https://arxiv.org/abs/1912.11370\n\t- Paper explained: https://www.youtube.com/watch?v=k1GOF2jmX7c\n- #PAPER Towards a Deeper Understanding of Adversarial Losses (Dong 2020): https://arxiv.org/abs/1901.08753",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Class-imbalance": {
    "title": "Class imbalance",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis\n- http://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation\n- http://www.alfredo.motta.name/cross-validation-done-wrong/\n- http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/\n- http://www.chioka.in/class-imbalance-problem/\n- http://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html\n- https://svds.com/learning-imbalanced-classes/\n\t- Conventional algorithms are often biased towards the majority class because their loss functions attempt to optimize quantities such as error rate, not taking the data distribution into consideration. Result: a trivial classifier that classifies every example as the majority class.\n\n## Code\n- #CODE Imbalanced-learn: https://github.com/scikit-learn-contrib/imbalanced-learn \n\t- https://imbalanced-learn.readthedocs.io/en/stable/\n\t- https://imbalanced-learn.readthedocs.io/en/stable/api.html\n- #CODE Smote_variants: https://github.com/analyticalmindsltd/smote_variants\n\t- http://smote-variants.readthedocs.io/\n\t-  The package implements 85 variants of the Synthetic Minority Oversampling Technique (SMOTE). Besides the implementations, an easy to use model selection framework is supplied to enable the rapid evaluation of oversampling techniques on unseen datasets. \n\n## Approaches\n### Resampling\n- Balance the training dataset\n- #PAPER Survey of resampling techniques for improving classification performance in unbalanced datasets (More 2016): https://arxiv.org/abs/1608.06048\n\n#### Oversampling\n- #PAPER SMOTE: Synthetic Minority Over-sampling Technique (Chaula 2002): https://jair.org/index.php/jair/article/view/10302\n\t- There are a number of methods available to oversample a dataset used in a typical classification problem (using a classification algorithm to classify a set of images, given a labelled training set of images). The most common technique is known as SMOTE. \n\t- https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n- #PAPER ADASYN: Adaptive synthetic sampling approach for imbalanced learning (He 2008): https://ieeexplore.ieee.org/document/4633969\n\t- https://sci2s.ugr.es/keel/pdf/algorithm/congreso/2008-He-ieee.pdf\n\t- ADASYN builds on the methodology of SMOTE, by shifting the importance of the classification boundary to those minority classes which are difficult. ADASYN uses a weighted distribution for different minority class examples according to their level of difficulty in learning, where more synthetic data is generated for minority class examples that are harder to learn.\n\n#### Undersampling\n- Down-sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm. The most common heuristic for doing so is resampling without replacement.\n- https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n- Cluster. Cluster centroids is a method that replaces cluster of samples by the cluster centroid of a K-means algorithm, where the number of clusters is set by the level of undersampling.\n- Tomek links. Tomek links remove unwanted overlap between classes where majority class links are removed until all minimally distanced nearest neighbor pairs are of the same class. Tomek links are pairs of instances of opposite classes who are their own nearest neighbors. Tomek’s algorithm looks for such pairs and removes the majority instance of the pair.\n\t- Classification of Imbalance Data using Tomek Link (T-Link) Combined with Random Under-sampling (RUS) as a Data Reduction Method: https://pdfs.semanticscholar.org/6ec4/18f9071f3a96d5548e87e34be3665703119e.pdf\n- Throw away minority examples and switch to an anomaly detection framework\n\n### Adjust the class importance or the metric\n- At the algorithm level, or after: Adjust the class weight (misclassification costs), adjust the decision threshold. Many machine learning toolkits have ways to adjust the “importance” of classes (classifiers that take an optional class_weight). \n- Change the metric. \n\t- Evaluating the classifier: Accuracy is not a good metric for imbalanced classes!!\n\t- Use a ROC curve\n\t- Don’t get hard classifications (labels) from your classifier (via score or predict). Instead, get probability estimates via proba or predict_proba\n\t- No matter what you do for training, always test on the natural (stratified) distribution your classifier is going to operate upon. Seesklearn.cross_validation.StratifiedKFold\n\t- For a singe metric (value): AUC, F1 (harmonic mean of precision and recall), Cohen’s Kappa (evaluation statistic that takes into account how much agreement would be expected by chance)\n\t- https://medium.com/towards-data-science/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba\n\t- http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\n\t- The following performance measures that can give more insight into the accuracy of the model than traditional classification accuracy:\n\t\t- Confusion Matrix: A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned).\n\t\t- Precision: A measure of a classifiers exactness.\n\t\t- Recall: A measure of a classifiers completeness\n\t\t- F1 Score (or F-score): A weighted average of precision and recall.\n\t\t- Kappa (or Cohen’s kappa): Classification accuracy normalized by the imbalance of the classes in the data.\n\t\t- ROC Curves: Like precision and recall, accuracy is divided into sensitivity and specificity and models can be chosen based on the balance thresholds of these values.\n\n### Cost-sensitive training\n- Cost-Sensitive Training. For this tactic we use penalized learning algorithms that increase the cost of classification mistakes on the minority class. A popular algorithm for this technique is Penalized-SVM. During training, we can use the argument class_weight='balanced'  to penalize mistakes on the minority class by an amount proportional to how under-represented it is.\n\n### Select or create a suitable algorithm\n- Create new algorithm for the imbalanced classes situation, or use one which handles the data imbalance\n- #PAPER Boosting/bagging. Comparing Boosting and Bagging Techniques With Noisy and Imbalanced Data (Khoshgoftaar 2010): https://ieeexplore.ieee.org/document/5645694?arnumber=5645694\n\t- The experiments show that the bagging techniques generally outperform boosting, and hence in noisy data environments, bagging is the preferred method for handling class imbalance.",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Classification": {
    "title": "Classification",
    "content": "---\n\n## Resources\n- https://github.com/jmportilla/Udemy",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Ensemble-learning": {
    "title": "Ensemble learning",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Ensemble_learning\n- In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. By analogy, ensemble techniques have been used also in [[unsupervised learning]] scenarios, for example in consensus clustering or in anomaly or [[AI/Anomaly and Outlier Detection]]\n- In general, ensembling is a technique of combining two or more algorithms of similar or dissimilar types called base learners. This is done to make a more robust system (improving generalizability / robustness over a single estimator) which incorporates the predictions from all the base learners.\n- http://scikit-learn.org/stable/modules/ensemble.html\n- http://mlwave.com/kaggle-ensembling-guide/\n- https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n- http://www.datasciencecentral.com/profiles/blogs/improving-predictions-with-ensemble-model\n- http://www.kdnuggets.com/2016/11/data-science-basics-intro-ensemble-learners.html\n- https://medium.com/diogo-menezes-borges/ensemble-learning-when-everybody-takes-a-guess-i-guess-ec35f6cb4600\n- https://blog.statsbot.co/ensemble-learning-d1dcd548e936\n- How to Reduce Variance in the Final DL Model With a Horizontal Voting Ensemble: https://machinelearningmastery.com/horizontal-voting-ensemble/\n\n### Bagging\n- With bootstrap aggregating (Bagging) we build models of smaller datasets by sampling with replacement. The results of these bootstrap samples are then aggregated, using majority voting (equal weighting of models)\n- See [Random Forest](Random%20Forest.md)\n\n### Boosting\nSee [Gradient boosting](Gradient%20boosting.md)\n- Same as bagging but operates via weighted voting. Algorithm proceeds iteratively (one tries to reduce the bias of the combined estimator); new models are influenced by previous ones. E.g. AdaBoost (Adaptive Boosting) and LogitBoost\n- https://en.wikipedia.org/wiki/AdaBoost\n\n### Stacking\n- uses a meta learner (as opposed to bagging/boosting which use voting schemes)\n- It consists in training multiple learners/algorithms (as opposed to bagging/boosting which train a single learner).  Each learner uses a subset of data. \n- A \"combiner\" is trained on a validation set. This combiner can be any ensemble technique, but logistic regression is often found to be an adequate and simple algorithm to perform this combining.\n- http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/\n- https://machinelearningmastery.com/ensemble-methods-for-deep-learning-neural-networks/",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Feature-selection": {
    "title": "Feature selection",
    "content": "See [Regression#Regularized regression](Regression.md#Regularized%20regression)\n\n## Resources\n- https://en.wikipedia.org/wiki/Feature_selection\n- http://machinelearningmastery.com/an-introduction-to-feature-selection/\n- http://scikit-learn.org/stable/modules/feature_selection.html\n- Removing features with low variance: http://scikit-learn.org/stable/modules/feature_selection.html#removing-features-with-low-variance\n- Univariate feature selection: http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\n- Recursive feature elimination: http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination\n- Regularization: \n\t- http://scikit-learn.org/stable/modules/feature_selection.html#l1-based-feature-selection\n\t- https://en.wikipedia.org/wiki/Regularization_(mathematics)\n\t- Penalized regression has been applied widely across many research disciplines, but it is a great fit for business data with many columns, even data sets with more columns than rows, and for data sets with a lot of correlated variables. L1/LASSO penalties drive unnecessary regression parameters to zero, selecting a small, representative subset of regression parameters for the regression model while avoiding potential multiple comparison problems that arise in forward, backward, and stepwise variable selection. Tikhonov/L2/ridge penalties help preserve parameter estimate stability, even when many correlated variables exist in a wide data set or important predictor variables are correlated. It’s also important to know penalized regression techniques don’t always create confidence intervals, t-statistics, or p-values for regression parameters. These types of measures are typically only available through iterative methods or bootstrapping that can require extra computing time.\n\t- https://www.quora.com/What-is-regularization-in-machine-learning\n\t- The loss function is penalized by adding an L1 or L2 norm of the weights vector W (the vector of the learned parameters in the linear regression):\n\t\t- L(X,Y) + lambda N(W), where N is either the L1, L2 or any other norm.\n\t\t- This helps avoiding overfitting and performs fetuses selection for the case of the L1 regularization. Lambda can be chosen by cross-validation. \n- Tree-based methods\n\t- Random forest, extra trees. Feature importances with forests of trees: http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n\t- XGBoost, Feature importance and why it’s important: \n\t\t- http://datawhatnow.com/feature-importance/\n\t\t- http://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/\n\t\t- Importance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity (Gini index) used to select the split points or another more specific error function. The feature importances are then averaged across all of the the decision trees within the model.\n\n## Books\n- #BOOK Feature Engineering and Selection: A Practical Approach for Predictive Models (Kuhn 2018): http://www.feat.engineering/index.html\n\n## Code \n- #CODE Scikit-feature: https://github.com/jundongl/scikit-feature\n\t- http://featureselection.asu.edu/\n- #CODE Feature-selector - Feature selector is a tool for dimensionality reduction of machine learning datasets.\n\t- Methods: Missing Values, Single Unique Values, Collinear Features, Zero Importance Features, Low Importance Features\n    - https://github.com/WillKoehrsen/feature-selector/blob/master/Feature%20Selector%20Usage.ipynb\n    - https://towardsdatascience.com/a-feature-selection-tool-for-machine-learning-in-python-b64dd23710f0",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Gaussian-Process": {
    "title": "Gaussian Process",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Gaussian_process\n- In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i.e. every finite linear combination of them is normally distributed. The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.\n- A machine-learning algorithm that involves a Gaussian process uses lazy learning and a measure of the similarity between points (the kernel function) to predict the value for an unseen point from training data. The prediction is not just an estimate for that point, but also has uncertainty information—it is a one-dimensional Gaussian distribution (which is the marginal distribution at that point).\n- http://scikit-learn.org/stable/modules/gaussian_process.html\n- A Practical Guide to Gaussian Processes: https://drafts.distill.pub/gp/ \n- A Visual Exploration of Gaussian Processes\n\t- https://www.jgoertler.com/visual-exploration-gaussian-processes/\n\t- https://blog.dominodatalab.com/fitting-gaussian-process-models-python/\n- Gaussian processes: http://krasserm.github.io/2018/03/19/gaussian-processes/\n\n## Code\n- #CODE GPy: https://github.com/SheffieldML/GPy\n- #CODE GPyTorch: https://github.com/cornellius-gp/gpytorch\n\t- https://gpytorch.ai/\n- #CODE GPFlow: https://github.com/GPflow/GPflow\n\t- https://gpflow.readthedocs.io/en/master/intro.html\n- #CODE GPflux: https://github.com/secondmind-labs/GPflux\n\t- GPflux uses the mathematical building blocks from GPflow and marries these with the powerful layered deep learning API provided by Keras. \n\t- https://secondmind-labs.github.io/GPflux/tutorials.html\n\n\n## Books and review papers\n- #BOOK Bayesian Optimization Book (Garnett 2021): https://bayesoptbook.com/\n- #PAPER An Intuitive Tutorial to Gaussian Processes Regression (Wang 2021): https://arxiv.org/abs/2009.10862\n- #PAPER Deep Gaussian Processes: A Survey (Jakkala 2021): https://arxiv.org/abs/2106.12135\n\n\n## References\n- #PAPER Gaussian Processes for Machine Learning (Rasmussen and Williams 2006): http://www.gaussianprocess.org/gpml/\n\t- http://www.gaussianprocess.org/gpml/chapters/RW.pdf\n- #PAPER Convolutional Gaussian Processes (van der Wilk 2017): https://arxiv.org/abs/1709.01894\n\t- #CODE https://gpflow.readthedocs.io/en/master/notebooks/advanced/convolutional.html\n- #PAPER Deep convolutional Gaussian processes (Blomqvist 2018): https://arxiv.org/abs/1810.03052\n\t- #CODE https://github.com/kekeblom/DeepCGP\n\t- https://github.com/kekeblom/DeepCGP/blob/master/notebooks/Inspect.ipynb\n- #PAPER Gaussian processes meet NeuralODEs: A Bayesian framework for learning the dynamics of partially observed systems from scarce and noisy data (Aziz Bhouri 2021): https://arxiv.org/abs/2103.03385\n\t- #CODE https://github.com/PredictiveIntelligenceLab/GP-NODEs",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Gradient-boosting": {
    "title": "Gradient boosting",
    "content": "See [Ensemble learning](Ensemble%20learning.md)\n\n## Resources\n- Outperforms Random Forests and AdaBoost. RF is easier to tune and less prone to overfitting\n- http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html\n- http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html\n- https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/\n- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n\n## Code\n- #CODE Xgboost: https://github.com/dmlc/xgboost\n\t- Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library, for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Flink and DataFlow\n\t- https://xgboost.readthedocs.org/\n\t- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n- #CODE Light GBM: https://github.com/microsoft/LightGBM\n\t- a very high-performance gradient boosting tree framework (supporting GBDT, GBRT, GBM, and MART), and its distributed implementation. Part of DMTK (Microsoft)\n\t- https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/\n\t- https://www.techleer.com/articles/489-lightgbm-a-light-gradient-boosting-machine/\n- #CODE CatBoost: https://github.com/catboost/catboost/\n\t- https://catboost.ai/\n\t- https://catboost.ai/docs/\n\t- A fast, scalable, high performance Gradient Boosting on Decision Trees library, used for ranking, classification, regression and other machine learning tasks for Python, R, Java, C++. Supports computation on CPU and GPU\n\t- CatBoost vs. Light GBM vs. XGBoost: https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db\n- #CODE https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n\n\n## References\n- #PAPER Probabilistic Gradient Boosting Machines for Large-Scale Probabilistic Regression (Sprangers 2021): https://arxiv.org/abs/2106.01682v2\n\t- #CODE https://paperswithcode.com/paper/probabilistic-gradient-boosting-machines-for?from=n11",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Model-selection-and-tuning": {
    "title": "Model selection and tuning",
    "content": "See:  \n[AutoML](AI/AutoML.md)\n[Data engineering and computer science](AI/Data%20Science,%20Data%20Engineering/Data%20engineering%20and%20computer%20science.md)\n\n\n## Resources\n- Model selection and evaluation: https://scikit-learn.org/stable/model_selection.html\n\n## Code\nSee [MLOps](AI/Data%20Science,%20Data%20Engineering/MLOps.md)\n- #CODE Optuna - A hyperparameter optimization framework: https://github.com/optuna/optuna\n\t- https://optuna.org/\n- #CODE Yellowbrick. Visual analysis and diagnostic tools to facilitate machine learning model selection: http://www.scikit-yb.org/en/latest/\n- #CODE Tune-sklearn: https://github.com/ray-project/tune-sklearn\n\t- Tune-sklearn is a drop-in replacement for Scikit-Learn’s model selection module (GridSearchCV, RandomizedSearchCV) with cutting edge hyperparameter tuning techniques\n- #CODE Talos. Hyperparameter Optimization for Keras Models: https://autonomio.github.io/docs_talos/#introduction\n- #CODE Hyperopt. Distributed Asynchronous Hyperparameter Optimization in Python: http://hyperopt.github.io/hyperopt\n\t- Hyperparameter optimization for neural networks: https://github.com/hyperopt/hyperopt-nnet\n\t- Hyperopt-sklearn: http://hyperopt.github.io/hyperopt-sklearn/\n\t- #CODE Hyperas- Keras + Hyperopt: A very simple wrapper for convenient hyperparameter optimization: https://github.com/maxpumperla/hyperas\n\t\t- http://maxpumperla.github.io/hyperas/\n- #CODE Hyperband - A Novel Bandit-Based Approach to Hyperparameter Optimization: https://github.com/zygmuntz/hyperband\n\t- #PAPER https://arxiv.org/abs/1603.06560\n\t- http://fastml.com/tuning-hyperparams-fast-with-hyperband/\n\n## Bias-variance trade-off\n- Problem of minimizing two sources of errors that prevent a supervised learning algorithm from generalizing beyond the training set:\n\t- High bias  -\u003e  underfitting\n\t- High variance  -\u003e  overfitting\n- Validation curves: plotting scores to evaluate models: https://scikit-learn.org/stable/modules/learning_curve.html\n- https://www.quora.com/How-would-you-explain-the-bias-variance-tradeoff-to-a-five-year-old\n- http://scott.fortmann-roe.com/docs/BiasVariance.html\n- http://scott.fortmann-roe.com/docs/MeasuringError.html\n- https://elitedatascience.com/bias-variance-tradeoff\n- Overfitting: https://en.wikipedia.org/wiki/Overfitting\n\t- https://www.quora.com/What-is-an-intuitive-explanation-of-overfitting\n\t- https://www.quora.com/How-can-I-avoid-overfitting\n\t- https://www.quora.com/How-do-we-detect-overfitting-and-under-fitting-in-Machine-Learning\n\n## Cross-validation\n- Cross-validation\n\t- Train, test and validation: https://machinelearningmastery.com/difference-test-validation-datasets/\n\t- http://scikit-learn.org/stable/modules/cross_validation.html (also about train, test, validation)\n\t- http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n\t- https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html\n\t- https://blog.dataiku.com/model-sucks-evaluating-models-validation-set-infographic\n\t- Making Predictive Models Robust: Holdout vs Cross-Validation: https://www.kdnuggets.com/2017/08/dataiku-predictive-model-holdout-cross-validation.html\n\t- How to Train a Final ML Model: http://machinelearningmastery.com/train-final-machine-learning-model/\n\t- http://nbviewer.jupyter.org/github/cs109/content/blob/master/lec_10_cross_val.ipynb\n- Hyperparameter optimization: https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)\n- Tuning the hyper-parameters of an estimator: https://scikit-learn.org/stable/modules/grid_search.html",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Random-forest": {
    "title": "Random forest",
    "content": "See [Ensemble learning](Ensemble%20learning.md)\n\n## Resources\n- https://github.com/kjw0612/awesome-random-forest\n- https://sebastianraschka.com/faq/docs/bagging-boosting-rf.html\n- Bagging and random forests are “bagging” algorithms that aim to reduce the complexity of models that overfit the training data. In contrast, boosting is an approach to increase the complexity of models that suffer from high bias, that is, models that underfit the training data\n- https://scikit-learn.org/stable/modules/ensemble.html#random-forests\n- http://www.listendata.com/2014/11/random-forest-with-r.html\n- https://medium.com/rants-on-machine-learning/the-unreasonable-effectiveness-of-random-forests-f33c3ce28883\n- In particular, trees that are grown very deep tend to learn highly irregular patterns: they overfit their training set or have low bias, but very high variance. Random forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance. This comes at the expense of a small increase in the bias and some loss of interpretability, but generally greatly boosts the performance of the final model.\n\n\n## References\n- #THESIS/PHD Understanding Random Forests: From Theory to Practice (Louppe 2014): https://arxiv.org/abs/1407.7502",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Regression": {
    "title": "Regression",
    "content": "---\n\nSee: \n[Time Series analysis](Time%20Series%20analysis.md)\n[RNNs](RNNs.md)\n[CNNs#Sequence time series modelling](CNNs.md#Sequence%20time%20series%20modelling)\n\n\n## Resources\n- https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/\n- https://towardsdatascience.com/a-beginners-guide-to-regression-analysis-in-machine-learning-8a828b491bbf\n- http://www.datasciencecentral.com/profiles/blogs/10-types-of-regressions-which-one-to-use\n- http://www.datasciencecentral.com/profiles/blogs/23-types-of-regression\n- Curve fitting vs regression: https://blog.datazar.com/curve-fitting-vs-regression-752ce295b0b1\n- Goodness of fit:\n\t- Coefficient of determination (The R-squared measure of goodness of fit): http://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit\n\t- Reduced chi-squared\n- Linear models: http://scikit-learn.org/stable/modules/linear_model.html\n\n\n### Linear Regression\n- https://en.wikipedia.org/wiki/Linear_regression\n- In statistics, linear regression is an approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression.\n- http://www.datasciencecentral.com/profiles/blogs/linear-regression-geometry\n- https://github.com/jmportilla/Udemy",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Supervised-Learning/Supervised-learning": {
    "title": "Supervised Learning",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Supervised_learning\n- Supervised Learning cheatsheet: https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning\n- http://scikit-learn.org/stable/supervised_learning.html\n- Metrics:\n\t- http://docs.aws.amazon.com/machine-learning/latest/dg/binary-model-insights.html\n\t- ROC curves, AUC\n\t\t- http://www.dataschool.io/roc-curves-and-auc-explained/\n\t\t- http://corysimon.github.io/articles/what-is-an-roc-curve/\n\n\n### Classification\nSee [Classification](Classification.md)\n\n### Regression\nSee [Regression](Regression.md)\n\n### Structured learning\n- https://en.wikipedia.org/wiki/Structured_prediction\n\n### Ensemble learning\nSee [Ensemble learning](Ensemble%20learning.md)\n\n### Class imbalance\nSee [Class imbalance](Class%20imbalance.md)\n\n### Model selection and tuning\nSee [Model selection and tuning](Model%20selection%20and%20tuning.md)\n\n### Probability calibration\n- https://en.wikipedia.org/wiki/Calibration_(statistics)\n- https://scikit-learn.org/stable/modules/calibration.html\n- When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction. \n- Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class.\n- https://scikit-learn.org/stable/auto_examples/calibration/plot_compare_calibration.html\n- Isotonic regression: \n\t- https://scikit-learn.org/stable/modules/isotonic.html\n\t- Isotonic regression is a probability calibration technique which can calibrate classifier scores to approximate probability values by fitting a stepwise non-decreasing function along the scores returned by the classifier.",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Time-Series-analysis": {
    "title": "Time series analysis",
    "content": "See: \n[Forecasting](Forecasting.md)\n[RNNs](RNNs.md)\n[CNNs#Sequence time series modelling](CNNs.md#Sequence%20time%20series%20modelling)\n[Deep learning#Deep learning for tabular data](Deep%20learning#Deep%20learning.md%20for%20tabular%20data)\n\n## Resources\n- https://en.wikipedia.org/wiki/Time_series\n- https://github.com/MaxBenChrist/awesome_time_series_in_python\n- https://github.com/frutik/awesome-timeseries\n- https://github.com/cuge1995/awesome-time-series\n- http://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n- Python to work with time series data: https://github.com/MaxBenChrist/awesome_time_series_in_python\n- timeseriesAI: https://github.com/timeseriesAI\n\n## Code\nSee [Forecasting#Code](Forecasting.md#Code)\n\n- #CODE TSflex: https://github.com/predict-idlab/tsflex\n\t- https://predict-idlab.github.io/tsflex/\n- #CODE Merlion: https://github.com/salesforce/merlion\n\t- #PAPER Merlion: A Machine Learning Library for Time Series (Bhatnagar 2021): https://arxiv.org/abs/2109.09265\n\t- Merlion is a Python library for time series intelligence\n- #CODE Kats: https://github.com/facebookresearch/Kats ^kats\n\t- Kats, a kit to analyze time series data, a lightweight, easy-to-use, generalizable, and extendable framework to perform time series analysis, from understanding the key statistics and characteristics, detecting change points and anomalies, to forecasting future trends\n\t- https://facebookresearch.github.io/Kats/\n\t- https://engineering.fb.com/2021/06/21/open-source/kats/\n\t- https://towardsdatascience.com/kats-a-generalizable-framework-to-analyze-time-series-data-in-python-3c8d21efe057\n- #CODE Sktime: https://github.com/alan-turing-institute/sktime\n\t- https://towardsdatascience.com/sktime-a-unified-python-library-for-time-series-machine-learning-3c103c139a55\n- #CODE Tsfresh - Time Series Feature extraction based on scalable hypothesis tests: https://github.com/blue-yonder/tsfresh\n\t- Automatic extraction of relevant features from time series: http://tsfresh.readthedocs.io\n- #CODE TSFEL: https://github.com/fraunhoferportugal/tsfel\n\t- #PAPER TSFEL: Time Series Feature Extraction Library (Barandas 2020): https://www.sciencedirect.com/science/article/pii/S2352711020300017\n- #CODE Tslearn - A machine learning toolkit dedicated to time-series data: https://github.com/rtavenar/tslearn\n- #CODE Pmdarima: https://github.com/alkaline-ml/pmdarima\n\t- Pyramid bridges one more gap between R and Python by bringing R's auto.arima to Python. Pyramid wraps statsmodels' well-tested ARIMA and SARIMAX estimators.\n - #CODE Tick: https://github.com/X-DataInitiative/tick\n\n\n\n## Subtopics\n\n### Time Series Forecasting\nSee [Forecasting](AI/Forecasting.md)\n\n### Anomaly and Outlier Detection\nSee [Anomaly and Outlier Detection](AI/Anomaly%20and%20Outlier%20Detection.md)\n\n### TS models\n- Autoregressive: https://en.wikipedia.org/wiki/Autoregressive\n- Moving average: https://en.wikipedia.org/wiki/Moving_average_model\n- Autoregressive moving average (ARMA): https://en.wikipedia.org/wiki/Autoregressive_moving_average\n- Autoregressive integrated moving average (ARIMA): https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average\n- Generalized additive model (GAM): https://en.wikipedia.org/wiki/Generalized_additive_model\n\t- http://www.kdnuggets.com/2017/04/time-series-analysis-generalized-additive-models.html\n\n### TS classification\n- UEA \u0026 UCR Time Series Classification Repository: http://www.timeseriesclassification.com/\n\t- Datasets: http://www.timeseriesclassification.com/dataset.php\n- Dynamic time warping: https://en.wikipedia.org/wiki/Dynamic_time_warping\n\t- DTW is one of the algorithms for measuring similarity between two temporal sequences, which may vary in speed\n- https://medium.com/@hassanismailfawaz/deep-learning-for-time-series-classification-a-brief-overview-73b58767ed0f\n\n- #PAPER ROCKET: Exceptionally fast and accurate time series classification using random convolutional kernels (Dempster 2019): https://arxiv.org/abs/1910.13051\n- #PAPER InceptionTime: Finding AlexNet for Time Series Classification (Ismail Fawaz 2019): https://arxiv.org/abs/1909.04939\n- #PAPER Deep learning for time series classification: a review (Ismail Fawaz 2019): https://arxiv.org/abs/1809.04356\n\t- #CODE https://github.com/hfawaz/dl-4-tsc\n\t- https://medium.com/@hassanismailfawaz/deep-learning-for-time-series-classification-a-brief-overview-73b58767ed0f\n- #PAPER TS-CHIEF: A Scalable and Accurate Forest Algorithm for Time Series Classification (Shifaz 2020): https://arxiv.org/abs/1906.10329\n\n\n### Time-frequency analysis\n- Fourier analysis: https://en.wikipedia.org/wiki/Fourier_analysis\n\t- Fast Fourier transform: https://en.wikipedia.org/wiki/Fast_Fourier_transform\n\t\t- A fast Fourier transform (FFT) is an algorithm that computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IDFT).\n- Continuous wavelet transform: https://en.wikipedia.org/wiki/Continuous_wavelet_transform\n  \n### Causality\nSee [Causality](AI/Causality.md)",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Transfer-learning": {
    "title": "Transfer learning",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Transfer_learning\n- Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem\n- https://github.com/artix41/awesome-transfer-learning\n- Domain adaptation: https://en.wikipedia.org/wiki/Domain_adaptation\n\t- Domain adaptation is a field associated with machine learning and transfer learning. This scenario arises when we aim at learning from a source data distribution a well performing model on a different (but related) target data distribution\n\n\n## Code\n- #CODE TLlib: https://github.com/thuml/Transfer-Learning-Library\n\t- open-source and well-documented library for Transfer Learning. It is based on pure PyTorch with high performance and friendly API\n- #code Salad: https://github.com/domainadaptation/salad\n\t- https://domainadaptation.org/\n- #code Robustness: https://github.com/bethgelab/robustness\n\t- https://domainadaptation.org/robusta/\n\n\n## References\n- #PAPER A Brief Review of Domain Adaptation (Farahani 2020): https://arxiv.org/abs/2010.03978",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Unsupervised-learning/Clustering": {
    "title": "Clustering",
    "content": "## Resources\n- Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters).\n- http://scikit-learn.org/stable/modules/clustering.html\n- Hierarhical clustering: Method of cluster analysis which seeks to build a hierarchy of clusters. Strategies for hierarchical clustering generally fall into two types:\n\t- Agglomerative: This is a \"bottom up\" approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.\n\t- Divisive: This is a \"top down\" approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.\n\t- The results of hierarchical clustering are usually presented in a dendrogram. The complexity of agglomerative clustering is O(n^2log(n)), slow for large data. Divisive clustering with an exhaustive search is O(2^n), which is even worse.\n\t- https://blog.alookanalytics.com/2017/04/11/intuition-vs-unsupervised-learning-agglomerative-clustering-in-practice/\n\t- Single linkage: Single-linkage clustering is one of several methods of hierarchical clustering. It is based on grouping clusters in bottom-up fashion (agglomerative clustering), at each step combining two clusters that contain the closest pair of elements not yet belonging to the same cluster as each other. A drawback of this method is that it tends to produce long thin clusters in which nearby elements of the same cluster have small distances, but elements at opposite ends of a cluster may be much farther from each other than to elements of other clusters. The naive version has a time complexity of O(n^3). There are improvements: SLINK and Kruskal's algo, with time complexity O(n^2).\n\t- Mean linkage\n\t\t- Unweighted Pair Group Method with Arithmetic Mean: https://en.wikipedia.org/wiki/UPGMA\n\t    - Weighted Pair Group Method with Arithmetic Mean: https://en.wikipedia.org/wiki/WPGMA\n\t- Ward’s method: Ward's minimum variance criterion minimizes the total within-cluster variance.\n\t  To implement this method, at each step find the pair of clusters that leads to minimum increase in total within-cluster variance after merging. This increase is a weighted squared distance between cluster centers. At the initial step, all clusters are singletons (clusters containing a single point).\n\t- Complete linkage: The method is also known as farthest neighbour clustering. At the beginning of the process, each element is in a cluster of its own. The clusters are then sequentially combined into larger clusters until all elements end up being in the same cluster. At each step, the two clusters separated by the shortest distance are combined. \n\t  The definition of 'shortest distance' is what differentiates between the different agglomerative clustering methods. \n\t  In complete-linkage clustering, the link between two clusters contains all element pairs, and the distance between clusters equals the distance between those two elements (one in each cluster) that are farthest away from each other. Complexity O(n^3), CLINK version with O(n^2).\n- K-means: https://en.wikipedia.org/wiki/K-means_clustering\n\t- k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. The standard k-means algorithm is called Lloyd's algorithm:\n\t\t- Initialization: Forgy method (taking k random observations from the data set), random partitioning or k-means++ methods \n\t\t- 2 steps: assignment and update (the \"assignment\" step is also referred to as expectation step, the \"update step\" as maximization step, making this algorithm a variant of the generalized expectation-maximization algorithm):\n\t\t\t- Assignment: Assign each observation to the cluster whose mean yields the least within-cluster sum of squares (WCSS). Also called “Expectation step” because it involves updating our expectation of which cluster each point belongs to\n\t\t\t- Update step: Calculate the new means to be the centroids of the observations in the new clusters. This also minimizes the within-cluster sum of squares (WCSS) objective. Also called “Maximization step” because it involves maximizing some fitness function that defines the location of the cluster centers — in this case, that maximization is accomplished by taking a simple mean of the data in each cluster\n\t  - http://stanford.edu/~cpiech/cs221/handouts/kmeans.html  \n\t  - Five Minutes With Ingo - K Means Clustering: https://www.youtube.com/watch?v=wGzumILN5ww\n- DBSCAN \n\t- Density-based spatial clustering of applications with noise: https://en.wikipedia.org/wiki/DBSCAN\n- HDBSCAN: http://hdbscan.readthedocs.io/en/latest/soft_clustering_explanation.html\n- Embeddings\n\t- http://projector.tensorflow.org\n\t- https://www.tensorflow.org/versions/master/how_tos/embedding_viz/index.html\n\n\n## References\n- #PAPER k-means++: the advantages of careful seeding (Arthur 2007): https://dl.acm.org/doi/10.5555/1283383.1283494\n- #PAPER A Comparative Study of Efficient Initialization Methods for the K-Means Clustering Algorithm (Celebi 2012): https://arxiv.org/abs/1209.1960\n- #PAPER SCAN: Learning to Classify Images without Labels (Van Gansbeke 2020): https://arxiv.org/abs/2005.12320\n\t- #CODE https://github.com/wvangansbeke/Unsupervised-Classification\n\t- Paper explained: https://www.youtube.com/watch?v=hQEnzdLkPj4\n\t- grouping images into semantically meaningful clusters when ground-truth annotations. This is tackling the task of unsupervised image classification in [Computer vision](AI/Computer%20Vision/Computer%20vision.md)\n\t- advocate a two-step approach where feature learning and clustering are decoupled. First, a self-supervised task from representation learning is employed to obtain semantically meaningful features.Second, we use the obtained features as a prior in a learnable clustering  approach.  In  doing  so,  we  remove  the  ability  for  cluster  learning to depend on low-level features, which is present in current end-to-end learning approaches\n- #PAPER Deep Robust Clustering by Contrastive Learning (Zhong 2020): https://arxiv.org/abs/2008.03030",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Unsupervised-learning/Dimensionality-reduction-and-low-rank-modeling": {
    "title": "Dimensionality reduction and low-rank modeling",
    "content": "## Resources\n- The Beginner's Guide to Dimensionality Reduction: https://idyll.pub/post/visxai-dimensionality-reduction-1dbad0a67a092b007c526a45/\n- Distances, Neighborhoods, or Dimensions? Projection Literacy for the Analysis of Multivariate Data: https://visxprojections.dbvis.de/client/index.html\n- Decomposing signals in components (matrix factorization problems): https://scikit-learn.org/stable/modules/decomposition.html\n- Projection techniques transform high-dimensional data to a lower-dimensional space while preserving its main structure. Often, the data is transformed to two-dimensional space and visualized as a scatter plot as a means to analyze and understand the data\n- Two categories: linear and non-linear projection techniques. \n\n### Linear methods\n- Linear projection techniques produce a linear transformation of data dimensions in lower-dimensional space. Proximity between data points indicates similarity. The more similar data points are, the closer they are located to each other and vice versa. This is why linear projection techniques are also known as global techniques.\n\n#### Principal component analysis (PCA)\n- Principal component analysis(PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. The number of principal components is less than or equal to the number of original variables. This transformation is defined in such a way that the first principal component has the largest possible variance(that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors are an uncorrelated orthogonal basis set.\n- http://setosa.io/ev/principal-component-analysis/\n- https://www.neuraldesigner.com/blog/principal-components-analysis\n\n#### Non-negative matrix factorization (NMF)\n- Non-negative matrix factorization (NNMF, or NMF) is a method for factorizing a matrix into two lower rank matrices with strictly non-negative elements.\n- https://en.wikipedia.org/wiki/Non-negative_matrix_factorization\n- https://yliapis.github.io/Non-Negative-Matrix-Factorization/\n- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\n- https://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py\n\n#### Generalized Low Rank Models\nExtension of the idea of PCA to handle arbitrary data sets consisting of numerical, Boolean, categorical, ordinal, and other data types. This framework encompasses many well known techniques in data analysis, such as nonnegative matrix factorization, matrix completion, sparse and robust PCA,-means,-SVD, and maximum margin matrix factorization. The method handles heterogeneous data sets, and leads to coherent schemes for compressing, denoising, and imputing missing entries across all data types simultaneously. It also admits a number of interesting interpretations of the low rank factors, which allow clustering of examples or of features.\n\t- https://github.com/cehorn/GLRM\n\t- #TALK Generalized Low Rank Models - Madeleine Udell: https://www.youtube.com/watch?v=zwvzGuS82MA\n\t- #TALK Introduction to generalized low-rank models and missing values (OREILLY): \n\t  - https://conferences.oreilly.com/strata/strata-eu-2016/public/schedule/detail/49771\n\t  - http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glrm.html\n\n#### Dynamic mode decomposition\n- https://en.wikipedia.org/wiki/Dynamic_mode_decomposition\n- linear dimensionality reduction technique for high-dimensional time-series originating from fluid dynamics. DMD combines the best of two worlds: PCA and Fourier transform. Mathematically, it is related to a fundamental operator in dynamical system theory known as the Koopman operator\n- A case against PCA for time-series analysis: https://towardsdatascience.com/a-case-against-pca-for-time-series-analysis-ac66b47629e0\n\t- Recent studies have shown that DMD behaves as a source separation algorithm (e.g. ICA), although this framework can be more flexible\n\t- For a similar computational cost, it moreover provides a far more interpretable model than PCA\n\n### Non-linear methods\n- Non-linear projection techniques, also known as local projection techniques, aim at preserving the local neighborhoods across the features in the data. Hereby, proximity highlights differences and coherences between observations and is not to put on the same level as similarity\n\n#### Multidimensional scaling (MDS)\n- Multidimensional scaling (MDS) is a means of visualizing the level of similarity of individual cases of a dataset. It refers to a set of related ordination techniques used in information visualization, in particular to display the information contained in a distance matrix. It is a form of non-linear dimensionality reduction.\n\n#### Self organizing maps (SOM)\n- https://en.wikipedia.org/wiki/Self-organizing_map\n- unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while preserving the topological structure of the data\n- https://stackabuse.com/self-organizing-maps-theory-and-implementation-in-python-with-numpy/\n\n#### T-distributed Stochastic Neighbor Embedding (t-SNE)\n- http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n- t-SNE is a tool to visualize high-dimensional data. It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with different initializations we can get different results.\n- t-SNE is a technique for nonlinear dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. The technique can be implemented via Barnes-Hut approximations, allowing it to be applied on large real-world datasets. It is particularly well-suited for embedding high-dimensional data into a space of two or three dimensions, which can then be visualized in a scatter plot. Specifically, it models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points.\n- https://mark-borg.github.io/blog/2016/tsne/\n- https://blog.alookanalytics.com/2017/02/28/analytical-market-segmentation-with-t-sne-and-clustering-pipeline/\n- How to Use t-SNE Effectively (Interactive): http://distill.pub/2016/misread-tsne/\n\n#### Uniform Manifold Approximation and Projection (UMAP)\n- #PAPER UMAP - Uniform Manifold Approximation and Projection for Dimension Reduction (McInnes 2020): https://arxiv.org/abs/1802.03426",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Unsupervised-learning/Unsupervised-learning": {
    "title": "Unsupervised learning",
    "content": "## Resources\n- https://en.wikipedia.org/wiki/Unsupervised_learning\n- Unsupervised Learning cheatsheet: https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-unsupervised-learning\n- Unsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from \"unlabeled\" data (a classification or categorization is not included in the observations).\n\n## Sub-topics\n### Kernel density estimation\n- https://en.wikipedia.org/wiki/Kernel_density_estimation\n- kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable\n- https://scikit-learn.org/stable/modules/density.html\n- https://stackabuse.com/kernel-density-estimation-in-python-using-scikit-learn/\n\n### Dimensionality reduction and low rank modeling\nSee [Dimensionality reduction and low rank modeling](AI/Unsupervised%20learning/Dimensionality%20reduction%20and%20low%20rank%20modeling.md)\n\n### Clustering \nSee [Clustering](AI/Unsupervised%20learning/Clustering.md)\n\n### Blind source separation\n- Blind signal separation (BSS), also known as blind source separation, is the separation of a set of source signals from a set of mixed signals, without the aid of information (or with very little information) about the source signals or the mixing process.\n\n#### Independent component analysis (ICA)\n- https://en.wikipedia.org/wiki/Independent_component_analysis\n- In signal processing, independent component analysis (ICA) is a computational method for separating a multivariate signal into additive subcomponents. This is done by assuming that the subcomponents are non-Gaussian signals and that they are statistically independent from each other.\n- https://scikit-learn.org/stable/modules/decomposition.html#ica\n- https://scikit-learn.org/stable/auto_examples/decomposition/plot_ica_blind_source_separation.html\n\n### Anomaly and Outlier Detection\nSee [Anomaly and Outlier Detection](AI/Anomaly%20and%20Outlier%20Detection.md)",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/Weakly-supervised-learning": {
    "title": "Weakly supervised learning",
    "content": "See:\n[Transfer learning](AI/Transfer%20learning.md)\n[Active learning](AI/Active%20learning.md)\n[Semi-supervised learning](AI/Semi-supervised%20learning.md)\n\n## Resources\n- Weak supervision is a branch of machine learning where noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts of training data in a supervised learning setting. This approach alleviates the burden of obtaining hand-labeled data sets, which can be costly or impractical. Instead, inexpensive weak labels are employed with the understanding that they are imperfect, but can nonetheless be used to create a strong predictive model.\n- Other areas of machine learning exist that are likewise motivated by the demand for increased quantity and quality of labeled training data but employ different high-level techniques to approach this demand. These other approaches include [active learning](AI/Active%20learning.md), [semi-supervised learning](AI/Semi-supervised%20learning.md), and [transfer learning](AI/Transfer%20learning.md).\n- Related to [One, few-shot learning](AI/One,%20few-shot%20learning.md). The most relevant problem to few-shot learning is weakly supervised learning with incomplete supervision where only a small amount of samples have supervised. By definition, weakly supervised learning with incomplete supervision includes only classification and regression, while few-shot learning also includes reinforcement learning problems. Moreover, weakly supervised learning with incomplete supervision mainly uses unlabeled data as additional information in E, while few-shot learning leverages various kinds of prior knowledge such as pretrained models, supervised data from other domains or modalities and does not restrict to using unlabeled data. Therefore, few-shot learning becomes weakly supervised learning problem only when prior knowledge is unlabeled data and the task is classification or regression.information.\n- Weakly Supervised Learning: Introduction and Best Practices: https://datasciencemilan.medium.com/weakly-supervised-learning-introduction-and-best-practices-c65f490d4a0a\n\n\n## References\n- #PAPER A brief introduction to weakly supervised learning (2018): https://academic.oup.com/nsr/article/5/1/44/4093912 \n- #PAPER A Graph-Based Method for Active Outlier Detection With Limited Expert Feedback (2019): https://ieeexplore.ieee.org/document/8871105\n\n### Incomplete supervision\n- In this case, only a (usually small) subset of training data is given with labels while the other data remain unlabeled (e.g., in image categorization the ground-truth labels are given by human annotators, and only a small subset of images can be annotated due to the human cost)\n- #PAPER Learning from Incomplete and Inaccurate Supervision (Zhang 2021): https://ieeexplore.ieee.org/document/9361098\n\n### Inexact supervision\n- In this case, only coarse-grained labels are given. Consider the image categorization task again. It is desirable to have every object in the images annotated; however, usually we only have image-level labels rather than object-level labels. \n- #PAPER Labeled Data Generation with Inexact Supervision (Dai 2021): https://arxiv.org/abs/2106.04716\n\n### Inaccurate supervision\n- The given labels are not always ground-truth (e.g., the image annotator is careless, or some images are difficult to categorize)\n - #PAPER Auxiliary Image Regularization for Deep CNNs with Noisy Labels (2016): https://arxiv.org/abs/1511.07069v2\n - #PAPER Anomaly detection with inexact labels (2019): https://arxiv.org/abs/1909.04807",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  },
  "/AI/XAI": {
    "title": "Explainable AI (XAI)",
    "content": "## Resources\n- https://github.com/anguyen8/XAI-papers\n- https://en.wikipedia.org/wiki/Explainable_artificial_intelligence\n- Ideas on interpreting [[machine learning]]: https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning\n- Explainable AI demos: https://lrpserver.hhi.fraunhofer.de/\n- [Why you need to care about Explainable Machine Learning](https://medium.com/james-blogs/why-you-need-to-care-about-explainable-machine-learning-d01196a6af76)\n- [Interpreting machine learning models](https://towardsdatascience.com/interpretability-in-machine-learning-70c30694a05f)\n- I.am.ai. Explaining artificial intelligence: https://www.i-am.ai/\n- [Baking recipes made by AI](https://cloud.google.com/blog/topics/developers-practitioners/baking-recipes-made-ai)\n- A Review of Different Interpretation Methods:\n\t- https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-1-saliency-map-cam-grad-cam-3a34476bc24d\n\t- https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-2-input-gradient-layerwise-e077609b6377\n\t- https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-3-shap-integrated-gradients-918fc9fedd9b\n\n\n## Events, talks\n- Workshop on Visualization for [[AI]] Explainability: http://visxai.io/\n- ACM Conference on Fairness, Accountability, and Transparency: https://facctconference.org/\n- Explainable AI xAI 2020: https://human-centered.ai/explainable-ai-2020/\n- #TALK Synthesizing Explainable and Deceptive Behavior for Human-[[AI]] Interaction (AAAI 2020 Tutorial): https://yochan-lab.github.io/tutorial/AAAI-2020/\n\t- https://www.youtube.com/watch?v=r6KhJ3ORYnc\n- #TALK Explainable [[AI]] in Industry (Tutorial): https://sites.google.com/view/explainable-ai-tutorial\n\t- https://www.youtube.com/watch?list=PLewjn-vrZ7d3x0M4Uu_57oaJPRXkiS221\u0026v=rcUw7PXHWF4\n- #TALK Explainable AI: Foundations, Industrial Applications, Practical Challenges, and Lessons Learned (AAAI 2020): https://xaitutorial2020.github.io/\n\t- https://xaitutorial2020.github.io/raw/master/slides/aaai_2020_xai_tutorial.pdf\n\n\n## Books\n- #BOOK  Interpretable Machine Learning (Molnar 2021): https://christophm.github.io/interpretable-ml-book/\n\n\n## Code\nSee [#Neural Networks explainability#Code](#Neural%20Networks%20explainability#Code)\n- https://towardsdatascience.com/explainable-ai-xai-a-guide-to-7-packages-in-python-to-explain-your-models-932967f0634b\n\n- #CODE CARLA: https://github.com/carla-recourse/CARLA\n\t- CARLA is a python library to benchmark counterfactual explanation and recourse models\n\t- #PAPER CARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms (Pawelczyk 2021): https://arxiv.org/abs/2108.00783\n\t- https://www.marktechpost.com/2021/08/22/university-of-tubingen-researchers-open-source-carla-a-python-library-for-benchmarking-counterfactual-explanation-methods-across-data-sets-and-machine-learning-models/\n- #CODE Shapash: https://github.com/MAIF/shapash\n\t- https://shapash.readthedocs.io/en/latest/\n- #CODE ExplainerDashboard: https://github.com/oegedijk/explainerdashboard\n\t- https://explainerdashboard.readthedocs.io/en/latest/index.html#\n\t- library for quickly building interactive dashboards for analyzing and explaining the predictions and workings of (scikit-learn compatible) machine learning models, including xgboost, catboost and lightgbm\n\t- #TALK https://www.youtube.com/watch?v=1nMlfrDvwc8\n- #CODE AIX360: https://github.com/Trusted-AI/AIX360 ^aix360\n\t- Interpretability and explainability of data and machine learning models\n\t- http://aix360.mybluemix.net/\n- #CODE LIME: Local Interpretable Model-agnostic Explanations: https://github.com/marcotcr/lime ^limegithub\n- #CODE Skater: https://github.com/datascienceinc/Skater\n\t- Skater is a python package for model agnostic interpretation of predictive models. With Skater, you can unpack the internal mechanics of arbitrary models; as long as you can obtain inputs, and use a function to obtain outputs, you can use Skater to learn about the models internal decision policies.\n\t- https://datascienceinc.github.io/Skater/overview.html\n\t- Understanding How and Why Your Model Works:  https://www.datascience.com/learn-data-science/fundamentals/model-interpretation-algorithms\n\t- https://www.datascience.com/resources/tools/skater\n- #CODE FairML - Auditing Black-Box Predictive Models: https://github.com/adebayoj/fairml\n\t- FairML is a python toolbox auditing the machine learning models for bias. \n\t- http://blog.fastforwardlabs.com/2017/03/09/fairml-auditing-black-box-predictive-models.html\n- #CODE ELI5: https://github.com/TeamHG-Memex/eli5\n\t- ELI5 is a Python library which allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides a way to explain black-box models.\n\t- http://eli5.readthedocs.io/en/latest/\n- #CODE BlackBox Auditing: https://github.com/algofairness/BlackBoxAuditing\n- #CODE SHAP: https://github.com/slundberg/shap ^shapgithub\n\t- Unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations.\n- #CODE InterpretML - Microsoft open-source package that incorporates state-of-the-art machine learning interpretability techniques under one roof: https://github.com/interpretml/interpret\n- #CODE uncertainty-toolbox: https://github.com/uncertainty-toolbox/uncertainty-toolboxç\n- #CODE imodels: https://github.com/csinva/imodels\n\t- Python package for concise, transparent, and accurate predictive modeling. All sklearn-compatible and easy to use.\n\n\n## References\n- #PAPER The Mythos of Model Interpretability (Lipton 2017): https://arxiv.org/abs/1606.03490\n- #PAPER A Survey of Methods for Explaining Black Box Models (Guidotti, 2018): https://dl.acm.org/doi/10.1145/3236009\n- #PAPER Making the Black Box More Transparent: Understanding the Physical Implications of Machine Learning (McGovern et al. 2019): https://journals.ametsoc.org/bams/article/100/11/2175/343787/Making-the-Black-Box-More-Transparent\n- #PAPER Towards Explainable Artificial Intelligence (Samek \u0026 Muller 2019): https://arxiv.org/abs/1909.12072\n- #PAPER Explaining Explanations: An Overview of Interpretability of Machine Learning (Gilpin et al. 2019): https://arxiv.org/abs/1806.00069\n- #PAPER One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques (Arya 2019): https://arxiv.org/abs/1909.03012\n\t- #CODE [[#^aix360]]\n- #PAPER Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead (Rudin 2019): https://www.nature.com/articles/s42256-019-0048-x\n\t- https://arxiv.org/abs/1811.10154\n- #PAPER Explainable Machine Learning for Scientific Insights and Discoveries (Roscher 2020): https://arxiv.org/abs/1905.08883\n- #PAPER Review Study of Interpretation Methods for Future Interpretable Machine Learning (Jian-Xun 2020): https://ieeexplore.ieee.org/document/9234594\n\n### Model-agnostic methods\n- https://christophm.github.io/interpretable-ml-book/agnostic.html\n\t- The great advantage of model-agnostic interpretation methods over model-specific ones is their flexibility\n\t- An alternative to model-agnostic interpretation methods is to use only interpretable models, which often has the big disadvantage that predictive performance is lost compared to other machine learning models and you limit yourself to one type of model\n- #PAPER Model-Agnostic Interpretability of Machine Learning (Tulio Ribeiro 2016): https://arxiv.org/abs/1606.05386\n- #PAPER SHAP - A Unified Approach to Interpreting Model Predictions (Lundberg 2017): https://arxiv.org/abs/1705.07874\n\t- SHAP (SHapley Additive exPlanations)\n\t- #CODE [[#^shapgithub]]\n\t- Can be used for computer vision tasks\n\n- #PAPER Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation (Goldstein 2014): https://arxiv.org/abs/1309.6392\n\n#### Partial Dependence Plot\n- The partial dependence plot (short PDP or PD plot) shows the marginal effect one or two features have on the predicted outcome of a machine learning model\n- https://christophm.github.io/interpretable-ml-book/pdp.html\n- https://scikit-learn.org/stable/modules/partial_dependence.html\n\n#### Individual Conditional Expectation\n- Individual Conditional Expectation (ICE) plots display one line per instance that shows how the instance's prediction changes when a feature changes\n- https://christophm.github.io/interpretable-ml-book/ice.html\n- https://scikit-learn.org/stable/modules/partial_dependence.html\n\n#### Permutation Feature Importance\n- Permutation feature importance measures the increase in the prediction error of the model after we permuted the feature's values, which breaks the relationship between the feature and the true outcome\n- https://christophm.github.io/interpretable-ml-book/feature-importance.html\n- https://scikit-learn.org/stable/modules/permutation_importance.html\n\t- The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled\n\t- Tree-based models provide an alternative measure of feature importances based on the mean decrease in impurity (MDI). Impurity is quantified by the splitting criterion of the decision trees (Gini, Entropy or Mean Squared Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data\n\n#### Surrogate models\n- A surrogate model is a simple model that is used to explain a complex model. Surrogate models are usually created by training a linear regression or decision tree on the original inputs and predictions of a complex model. Coefficients, variable importance, trends, and interactions displayed in the surrogate model are then assumed to be indicative of the internal mechanisms of the complex model. There are few, possibly no, theoretical guarantees that the simple surrogate model is highly representative of the more complex model.\n- The globally interpretable attributes of a simple model are used to explain global attributes of a more complex model. However, there is nothing to preclude fitting surrogate models to more local regions of a complex model's conditional distribution, such as clusters of input records and their corresponding predictions and their corresponding input rows. Because small sections of the conditional distribution are more likely to be linear, monotonic, or otherwise well-behaved, local surrogate models can be more accurate than global surrogate models.\n- #PAPER LIME - \"Why Should I Trust You?\": Explaining the Predictions of Any Classifier (2016). https://arxiv.org/abs/1602.04938 ^lime\n\t- #CODE [[#^limegithub]]\n\t- Formalized approach for local surrogate models. It is meant to shed light on how decisions are made for specific observations. LIME requires that a set of explainable records be found, simulated, or created.\n\t- https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime\n\t- https://github.com/albahnsen/Talk_Demystifying_Machine_Learning\n\t- Interpreting ML models prediction power: http://www.datasciencecentral.com/profiles/blogs/deep-learning-epic-fail-right-answer-wrong-reason\n\t- https://medium.com/@ageitgey/natural-language-processing-is-fun-part-3-explaining-model-predictions-486d8616813c\n\t- Machine Learning Explained - Easysol:  http://blog.easysol.net/machine_learning_explained/\n\t- https://www.slideshare.net/albahnsen/demystifying-machine-learning-using-lime\n\t- https://github.com/albahnsen/Talk_Demystifying_Machine_Learning\n\n\n### Maximum activation analysis\n- See [Neural Networks explainability](#Neural%20Networks%20explainability)\n- In maximum activation analysis, examples are found or simulated that maximally activate certain neurons, layers, or filters in a neural network or certain trees in decision tree ensembles. For the purposes of maximum activation analysis, low residuals for a certain tree are analogous to high-magnitude neuron output in a neural network.\n- Maximum activation analysis elucidates internal mechanisms of complex models by determining the parts of the response function that specific observations or groups of similar observations excite to the highest degree, either by high-magnitude output from neurons or by low residual output from trees.\n\n\n### Sensitivity analysis\n- See [Neural Networks explainability](#Neural%20Networks%20explainability)\n- Sensitivity analysis investigates whether model behavior and outputs remain stable when data is intentionally perturbed or other changes are simulated in data. \n- Beyond traditional assessment practices, sensitivity analysis of machine learning model predictions is perhaps the most important validation technique for machine learning models. \n- Machine learning models can make drastically differing predictions from minor changes in input variable values. In practice, many linear model validation techniques focus on the numerical instability of regression parameters due to correlation between input variables or between input variables and the dependent variable\n- Sensitivity analysis can also test model behavior and outputs when interesting situations or known corner cases are simulated. Output distributions, error measurements, plots, and interpretation techniques can be used to explore the way models behave in important scenarios, how they change over time, or if models remain stable when data is subtly and intentionally corrupted\n\n\n### Variable importance measures\n- Variable importance measures are typically seen in tree-based models but are sometimes also reported for other models.\n- A simple heuristic rule for variable importance in a decision tree is related to the depth and frequency at which a variable is split on in a tree, where variables used higher in the tree and more frequently in the tree are more important. \n- For a single decision tree, a variable's importance is quantitatively determined by the cumulative change in the splitting criterion for every node in which that variable was chosen as the best splitting candidate. \n- For a gradient boosted tree ensemble, variable importance is calculated as it is for a single tree but aggregated for the ensemble. \n- For random forests:\n\t- Variable importance is also calculated as it is for a single tree and aggregated, but an additional measure of variable importance is provided by the change in out-of-bag accuracy caused by shuffling the independent variable of interest, where larger decreases in accuracy are taken as larger indications of importance\n\t- The default method to compute variable importance is the mean decrease in impurity (or gini importance) mechanism: At each split in each tree, the improvement in the split-criterion is the importance measure attributed to the splitting variable, and is accumulated over all the trees in the forest separately for each variable. Note that this measure is quite like the R^2 in regression on the training set\n\t- This example highlights the limitations of impurity-based feature importance in contrast to permutation-based feature importance: https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html\n\t- #PAPER Understanding variable importances in forests of randomized trees (Louppe 2013): https://papers.nips.cc/paper/4928-understanding-variable-importances-in-forests-of-randomized-trees.pdf\n\t\t- #POSTER https://orbi.uliege.be/bitstream/2268/155642/3/poster.pdf\n\t- #PAPER Trees, forests, and impurity-based variable importance (Scornet 2020): https://arxiv.org/abs/2001.04295\n- For neural networks, variable importance measures are typically associated with the aggregated, absolute magnitude of model parameters for a given variable of interest. \n- Global variable importance techniques are typically model specific, and practitioners should be aware that unsophisticated measures of variable importance can be biased toward larger scale variables or variables with a high number of categories.\n\n\n### Neural Networks explainability\n\n#### Resources \n- Using ML to Explore Neural Network Architecture: https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html\n- The Building Blocks of Interpretability: https://distill.pub/2018/building-blocks/\n- Feature Visualization: https://distill.pub/2017/feature-visualization/\n- [Applying deep learning to real-world problems (labeled data, imbalance, black box models)](https://medium.com/merantix/applying-deep-learning-to-real-world-problems-ba2d86ac5837)\n- Unblackboxing webinar (deepsense.io): https://github.com/deepsense-io/unblackboxing_webinar\n- The Dark Secret at the Heart of AI: https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/amp/\n- [How AI detectives are cracking open the black box of deep learning](http://www.sciencemag.org/news/2017/07/how-ai-detectives-are-cracking-open-black-box-deep-learning)\n- [Visualization of activations and filters](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html) \n\t- https://github.com/jacobgil/keras-filter-visualization\n- https://towardsdatascience.com/understanding-your-convolution-network-with-visualizations-a4883441533b\n- https://imatge.upc.edu/web/publications/visual-saliency-prediction-using-deep-learning-techniques\n- [Attributing a deep network’s prediction to its input features](http://www.unofficialgoogledatascience.com/2017/03/attributing-deep-networks-prediction-to.html)\n\t- Integrated gradients method\n\t- It involves a few calls to a gradient operator yielding insightful results for a variety of deep networks\n- Pixel Attribution (Saliency Maps): https://christophm.github.io/interpretable-ml-book/pixel-attribution.html\n\n#### Code\n- #CODE TruLens (tf.keras and pytorch): Explainability for Neural Networks: https://github.com/truera/trulens\n\t- https://www.trulens.org/\n- #CODE Captum (pytorch): https://github.com/pytorch/captum\n\t- Interpretability of models across modalities including vision, text, and more\n\t- https://captum.ai/\n\t- https://captum.ai/api/\n- #CODE Saliency: https://github.com/PAIR-code/saliency\n\t- XRAI, SmoothGrad, Vanilla Gradients, Guided Backpropogation, Integrated Gradients, Occlusion, Grad-CAM, Blur IG\n- #CODE iNNvestigate: https://github.com/albermax/innvestigate ^innvestigate\n\t- Vanilla gradient, SmoothGrad, DeConvNet, Guided BackProp, PatternNet, DeepTaylor, PatternAttribution, LRP, IntegratedGradients, DeepLIFT\n- #CODE TF-explain: https://github.com/sicara/tf-explain\n\t- implements interpretability methods as Tensorflow 2.x callbacks to ease neural network's understanding\n- #CODE TensorSpace (Tensorflow.js): https://github.com/tensorspace-team/tensorspace\n\t- Neural network 3D visualization framework\n\t- https://tensorspace.org\n- #CODE Lucid (Tensorflow 1) - A collection of infrastructure and tools for research in neural network interpretability. https://github.com/tensorflow/lucid\n- #CODE tf-keras-vis: https://github.com/keisen/tf-keras-vis\n\t- Neural network visualization toolkit for tf.keras\n\t- Activation Maximization\n\t- Class Activation Maps (GradCAM, GradCAM++, ScoreCAM, Faster-ScoreCAM)\n\t- Saliency Maps (Vanilla Saliency, SmoothGrad)\n- #CODE Keras-vis: https://github.com/raghakot/keras-vis\n\t- https://raghakot.github.io/keras-vis/\n\t- Activation maximization, Saliency maps, Class activation maps\n- #CODE DeepExplain (TensorFlow 1): https://github.com/marcoancona/DeepExplain\n\t- Saliency maps, Gradient * Input, Integrated Gradients, DeepLIFT, ε-LRP\n- #CODE LRP toolbox: https://github.com/sebastian-lapuschkin/lrp_toolbox\n  \n#### References\n- #PAPER [Visualization of neural networks using saliency maps (Morch 1995)](https://www.researchgate.net/publication/3623243_Visualization_of_neural_networks_using_saliency_maps)\n- #PAPER [Deep inside CNNs: Visualising Image Classification Models and Saliency Maps (Simonyan 2014)](https://arxiv.org/abs/1312.6034)\n\t- Presented two visualisation techniques for deep classification ConvNets\n\t\t- The first generates an artificial image, which is representative of a class of interest\n\t\t- The second computes an image-specific class saliency map, highlighting the areas of the given image, discriminative wrt the given class\n- #PAPER [Understanding Neural Networks Through Deep Visualization (Yosinski 2015)](https://arxiv.org/abs/1506.06579)\n\t- http://yosinski.com/deepvis\n- #PAPER [SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability (Raghu 2017)](https://arxiv.org/abs/1706.05806)\n\t- Interpreting Deep Neural Networks with SVCCA: https://ai.googleblog.com/2017/11/interpreting-deep-neural-networks-with.html\n- #PAPER [Axiomatic Attribution for Deep Networks (Sundararajan 2017)](https://arxiv.org/abs/1703.01365)\n- #PAPER [SmoothGrad: removing noise by adding noise (Smilkov 2017)](https://arxiv.org/abs/1706.03825)\n\t- https://pair-code.github.io/saliency/\n- #PAPER [iNNvestigate Neural Networks! (Alber 2018)](http://arxiv.org/abs/1808.04260)\n\t- #CODE [[#^innvestigate]]\n- #PAPER [XRAI: Better Attributions Through Regions (Kapishnikov 2019)](https://arxiv.org/abs/1906.02825)\n- #PAPER [DeepLIFT - Learning Important Features Through Propagating Activation Differences (Shrikumar 2019)](https://arxiv.org/abs/1704.02685)\n - #PAPER [Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges (Borji 2019)](https://arxiv.org/abs/1810.03716)\n- #PAPER [DAX: Deep Argumentative eXplanation for Neural Networks (Albini 2020)](https://arxiv.org/abs/2012.05766)\n- #PAPER [Interpreting Deep Neural Networks Through Variable Importance (Ish-Horowicz 2020)](https://arxiv.org/abs/1901.09839)\n\t- Their strategy is specifically designed to leverage partial covariance structures and incorporate variable interactions into our proposed feature ranking.  \n\t- Extended the recently proposed “RelATive cEntrality” (RATE) measure (Crawford et al., 2019) to the Bayesian deep learning setting\n\t- Given a trained network, RATE applies an information theoretic criterion to the posterior distribution of effect sizes to assess feature significance\n- #PAPER [Determining the Relevance of Features for Deep Neural Networks (Reimers 2020)](https://link.springer.com/chapter/10.1007%2F978-3-030-58574-7_20)\n\t- Their approach builds upon concepts from causal inference\n\t- Interpret machine learning in a structural causal model and use Reichenbach’s common cause principle to infer whether a feature is relevant\n- #PAPER [Explainable Deep Learning Models in Medical Image Analysis (Singh 2020)](https://arxiv.org/abs/2005.13799)\n- #PAPER [Efficient Saliency Maps for Explainable AI (Mundhenk 2020)](https://arxiv.org/abs/1911.11293)\n- #PAPER [Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications (Samek 2021)](https://ieeexplore.ieee.org/document/9369420)\n- #PAPER [Logic Explained Networks (Ciravegna 2021)](https://arxiv.org/abs/2108.05149)\n\t- https://syncedreview.com/2021/08/18/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-85/\n- #PAPER Toward Explainable AI for Regression Models (Letzgus 2021): https://arxiv.org/abs/2112.11407\n\n \n##### Layer-wise Relevance Propagation (LRP)\n- LRP is an inverse method which calculates the contribution of a single pixel to the prediction made by a DNN in an image classification task\n- http://heatmapping.org/\n- Interactive demo: https://lrpserver.hhi.fraunhofer.de/image-classification\n- https://medium.com/@ODSC/layer-wise-relevance-propagation-means-more-interpretable-deep-learning-219ff5158914\n- https://towardsdatascience.com/indepth-layer-wise-relevance-propagation-340f95deb1ea\n- Saliency map is a broader term from the field of computer vision (https://en.wikipedia.org/wiki/Saliency\\_map). The first reference of saliency maps applied to the predictions of DNNs is Morch et al 1995. Simonyan et al (2014) first proposed a method to produce saliency maps using back-propagation through a CNN, but note that you could compute \"saliency\" from an image in many ways that do not deal with back-propagating the prediction scores of DNNs. \n- There are several approaches for calculating attributions by back-propagating the prediction score through each layer of the network, back to the input features /pixels (DeConvNet, SmoothGrad, GradCam, LRP, XRAI). LRP is just one of them. In the first LRP paper, they talk about heatmaps or relevance maps, probably to avoid confusion with older saliency map techniques\n\n- #PAPER On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation (Bach 2015): https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140\n\t- #CODE Tutorial: Implementing Layer-Wise Relevance Propagation: https://git.tu-berlin.de/gmontavon/lrp-tutorial\n- #PAPER Understanding Individual Decisions of CNNs via Contrastive Backpropagation (Gu 2019): https://arxiv.org/abs/1812.02100\n- #PAPER Beyond saliency: understanding convolutional neural networks from saliency prediction on layer-wise relevance propagation (Li 2019): https://arxiv.org/abs/1712.08268\n\t- proposed a novel two-step understanding method, namely Salient Relevance (SR) map, which aims to shed light on how deep CNNs recognize images and learn features from attention areas\n\t- starts out with a layer-wise relevance propagation (LRP) step which estimates a pixel-wise relevance map over the input image. Following, we construct a context-aware saliency map, SR map, from the LRP-generated map which predicts areas close to the foci of attention instead of isolated pixels that LRP reveals\n- #PAPER Towards Best Practice in Explaining Neural Network Decisions with LRP (Kohlbrenner 2020): https://arxiv.org/abs/1910.09840",
    "lastmodified": "2022-03-10T09:30:02.07358469Z",
    "tags": null
  }
}