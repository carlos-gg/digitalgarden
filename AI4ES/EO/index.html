<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Resources   Towards a European AI for Earth Observation Research & Innovation Agenda  Is DS 4 EO BS?  The value of super resolution ‚Äî real world use case  Mapping roads through deep learning and weakly supervised training  Example of SuperRes with Sentinel 2 data  Quantifying the surface area of road networks in cities  Nice visualization    CNN-Sentinel  Analyzing Sentinel-2 satellite data in Python with Keras (repository of our talks at Minds Mastering Machines 2019 and PyCon 2018)    https://interestingengineering."><title>EO</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=/icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://carlos-gg.github.io/digitalgarden/styles.cd61336c89ed6e03702366ce4a492b75.min.css rel=stylesheet><script src=https://carlos-gg.github.io/digitalgarden/js/darkmode.46b07878b7f5d9e26ad7a3c40f8a0605.min.js></script>
<script>const BASE_URL="https://carlos-gg.github.io/digitalgarden/",fetchData=Promise.all([fetch("https://carlos-gg.github.io/digitalgarden/indices/linkIndex.a053f90d6107ccf3063e38c928e6e139.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://carlos-gg.github.io/digitalgarden/indices/contentIndex.eff8ee58075d8bac1524e093d1f744e7.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n}))</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-S103D50NQ0"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-S103D50NQ0",{anonymize_ip:!1})}</script><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://carlos-gg.github.io/digitalgarden/js/graph.27e8521c25c27c79dea35f434c486167.js></script>
<script>drawGraph("https://carlos-gg.github.io/digitalgarden/AI4ES/EO","https://carlos-gg.github.io/digitalgarden",[{"/moc":"#4388cc"}],-1,!0,!1,!0)</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://carlos-gg.github.io/digitalgarden/js/search.bc849b857f2c1b822264d40635bb67b6.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://carlos-gg.github.io/digitalgarden/>CarlosGG's Knowledge Garden ü™¥</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>EO</h1><p class=meta>Last updated July 15, 2022</p><ul class=tags></ul><aside class=mainTOC><details open><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#resources>Resources</a></li><li><a href=#events>Events</a></li><li><a href=#courses>Courses</a></li><li><a href=#code>Code</a></li><li><a href=#references>References</a><ol><li><a href=#object-detectionrecognition>Object detection/recognition</a></li><li><a href=#semantic-segmentation>Semantic segmentation</a></li><li><a href=#super-resolution>Super-resolution</a></li><li><a href=#data-fusion>Data Fusion</a></li><li><a href=#data-and-benchmark-datasets>Data and benchmark datasets</a></li></ol></li></ol></nav></details></aside><h2 id=resources>Resources</h2><ul><li><a href=http://blogs.esa.int/philab/files/2018/07/Towards-a-European-AI-for-Earth-Observation-Research-Innovation-Agenda-.pdf rel=noopener>Towards a European AI for Earth Observation Research & Innovation Agenda</a></li><li><a href=https://labo.obs-mip.fr/multitemp/is-ds-4-eo-bs/ rel=noopener>Is DS 4 EO BS?</a></li><li><a href=https://medium.com/sentinel-hub/the-value-of-super-resolution-real-world-use-case-2ba811f4cd7f rel=noopener>The value of super resolution ‚Äî real world use case</a></li><li><a href=https://ai.facebook.com/blog/mapping-roads-through-deep-learning-and-weakly-supervised-training/ rel=noopener>Mapping roads through deep learning and weakly supervised training</a></li><li><a href=https://mdl4eo.irstea.fr/2019/03/29/enhancement-of-sentinel-2-images-at-1-5m/%e2%80%af rel=noopener>Example of SuperRes with Sentinel 2 data</a></li><li><a href=https://roadsfromabove.netlify.com/ rel=noopener>Quantifying the surface area of road networks in cities</a><ul><li>Nice visualization</li></ul></li><li><a href=https://github.com/jensleitloff/CNN-Sentinel rel=noopener>CNN-Sentinel</a><ul><li>Analyzing Sentinel-2 satellite data in Python with Keras (repository of our talks at Minds Mastering Machines 2019 and PyCon 2018)</li></ul></li><li><a href=https://interestingengineering.com/mapping-every-solar-panel-in-the-world-with-machine-learning rel=noopener>https://interestingengineering.com/mapping-every-solar-panel-in-the-world-with-machine-learning</a></li><li><a href=https://www.philschmid.de/image-classification-huggingface-transformers-keras rel=noopener>Image Classification with Hugging Face Transformers and Keras (EuroSAT dataset)</a></li></ul><h2 id=events>Events</h2><ul><li><a href=https://phiweek.esa.int/ rel=noopener>ESA EO Phi-week</a></li><li><a href=https://www.eumetsat.int/living-planet-symposium rel=noopener>ESA Living Planet symposium</a></li></ul><h2 id=courses>Courses</h2><ul><li>#COURSE
<a href=https://www.futurelearn.com/courses/artificial-intelligence-for-earth-monitoring rel=noopener>Artificial Intelligence (AI) for Earth Monitoring</a></li><li>#COURSE
<a href=https://github.com/jmartinezheras/2018-MachineLearning-Lectures-ESA rel=noopener>ESA ML lectures 2018</a></li></ul><h2 id=code>Code</h2><ul><li>#CODE
<a href=https://github.com/microsoft/torchgeo rel=noopener>TorchGeo (Microsoft)</a><ul><li><a href=https://torchgeo.readthedocs.io/ rel=noopener>https://torchgeo.readthedocs.io/</a></li></ul></li><li>#CODE
<a href=https://github.com/azavea/raster-vision rel=noopener>Raster vision</a><ul><li><a href=https://docs.rastervision.io/en/0.13/ rel=noopener>https://docs.rastervision.io/en/0.13/</a></li></ul></li><li>#CODE
<a href=https://developers.google.com/earth-engine/ rel=noopener>Google Earth Engine</a><ul><li><a href=https://developers.google.com/earth-engine/datasets/catalog rel=noopener>https://developers.google.com/earth-engine/datasets/catalog</a></li><li><a href=https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR rel=noopener>https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR</a></li><li><a href=https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_DAILY rel=noopener>https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_DAILY</a></li></ul></li><li>#CODE
<a href=https://github.com/sentinel-hub/eo-learn rel=noopener>eo-learn: eo-learn makes extraction of valuable information from satellite imagery easy</a></li><li>#CODE
<a href=https://github.com/open-eo rel=noopener>OpenEO - A Common, Open Source Interface between Earth Observation Data Infrastructures and Front-End Applications</a></li><li>#CODE
<a href=https://github.com/pytroll/satpy rel=noopener>Satpy - package is a python library for reading and manipulating meteorological remote sensing data and writing it to various image and data file formats</a></li><li>#CODE
<a href=https://github.com/mapbox/rasterio rel=noopener>rasterio - access to geospatial raster data</a></li><li>#CODE
<a href=https://github.com/CS-SI/eodag rel=noopener>EODAG - Earth Observation Data Access Gateway</a><ul><li><a href=https://eodag.readthedocs.io/en/latest/ rel=noopener>https://eodag.readthedocs.io/en/latest/</a></li><li><a href="https://www.youtube.com/watch?v=R18yTXKhF-I&list=PLvT7fd9OiI9XORxAfLw_f9CsDkvM9lfKs&index=23" rel=noopener>https://www.youtube.com/watch?v=R18yTXKhF-I&list=PLvT7fd9OiI9XORxAfLw_f9CsDkvM9lfKs&index=23</a></li></ul></li><li>#CODE
<a href=https://github.com/raphaelquast/EOmaps rel=noopener>EOmaps</a><ul><li>A library to create interactive maps of geographical datasets</li><li><a href=https://raphaelquast.github.io/EOmaps/ rel=noopener>https://raphaelquast.github.io/EOmaps/</a></li></ul></li><li>#CODE
<a href=https://github.com/DataverseLabs/pyinterpolate rel=noopener>Pyinterpolate</a><ul><li>interpolate spatial data with the Kriging technique</li><li><a href=https://pyinterpolate.readthedocs.io/en/latest/ rel=noopener>https://pyinterpolate.readthedocs.io/en/latest/</a></li></ul></li><li>#CODE
<a href=https://github.com/sertit/eoreader rel=noopener>EOreader</a><ul><li>Remote-sensing opensource python library reading optical and SAR sensors, loading and stacking bands, clouds, DEM and spectral indices in a sensor-agnostic way</li><li><a href=https://eoreader.readthedocs.io/en/latest/ rel=noopener>https://eoreader.readthedocs.io/en/latest/</a></li><li>#TALK
<a href=https://submit.geopython.net/geopython-2022/talk/FQPN3Q/ rel=noopener>https://submit.geopython.net/geopython-2022/talk/FQPN3Q/</a><ul><li><a href=https://submit.geopython.net/media/eoreader_geopython_2022_compressed_lQL1HCR.pdf rel=noopener>https://submit.geopython.net/media/eoreader_geopython_2022_compressed_lQL1HCR.pdf</a></li></ul></li></ul></li></ul><h2 id=references>References</h2><p>Review papers:</p><ul><li><p>#PAPER
<a href=https://www.mdpi.com/1424-8220/19/18/3929 rel=noopener>Survey of Deep Learning Approaches for Remote Sensing Observation Enhancement (Tsagkatakis 2019)</a></p></li><li><p>#PAPER ESA-ECMWF Report on recent progress and research directions in machine learning for Earth System observation and prediction ()</p></li><li><p>#PAPER
<a href=https://www.researchgate.net/publication/322659251_Machine_Learning_Applications_for_Earth_Observation rel=noopener>Machine Learning Applications for Earth Observation (Lary 2018)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1803.02642 rel=noopener>Learning Spectral-Spatial-Temporal Features via a Recurrent Convolutional Neural Network for Change Detection in Multispectral Imagery (Mou 2018)</a></p></li><li><p>#PAPER
<a href=https://www.mdpi.com/2072-4292/10/9/1473 rel=noopener>Multi-Stream CNNs for SAR Automatic Target Recognition (Zhao 2018)</a></p></li><li><p>#PAPER
<a href=http://arxiv.org/abs/1802.02080 rel=noopener>Multi-Temporal Land Cover Classification with Sequential Recurrent Encoders (Rubwurm 2018)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1807.07778 rel=noopener>Dialectical GANs for SAR Image Translation: From Sentinel-1 to TerraSAR-X‚ÄØ (Ao 2018)</a></p></li><li><p>#PAPER
<a href=https://www.mdpi.com/2072-4292/10/8/1263 rel=noopener>Machine Learning Using Hyperspectral Data Inaccurately Predicts Plant Traits Under Spatial Dependency (Rocha 2018)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1809.09978 rel=noopener>Satellite Imagery Multiscale Rapid Detection with Windowed Networks (Van Etten 2018)</a></p><ul><li>#CODE
<a href=https://github.com/avanetten/simrdwn rel=noopener>https://github.com/avanetten/simrdwn</a></li><li>The SIMRDWN pipeline includes a modified version of YOLO (known as YOLT), along with the models of the tensorflow object detection API: SSD, Faster R-CNN, and R-FCN</li></ul></li><li><p>#PAPER
<a href=https://www.intechopen.com/books/advanced-analytics-and-artificial-intelligence-applications/artificial-intelligence-data-science-methodology-for-earth-observation rel=noopener>AI Data Science Methodology for Earth Observation (Dumitru 2019)</a></p></li><li><p>#PAPER
<a href=https://www.mdpi.com/2072-4292/11/23/2881 rel=noopener>Next Generation Mapping: Combining DL, Cloud Computing, and Big Remote Sensing Data (Parente 2019)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1811.10166 rel=noopener>Temporal CNNs for the Classification of Satellite Image Time Series (Pelletier 2019)</a></p></li><li><p>#PAPER
<a href=https://www.sciencedirect.com/science/article/abs/pii/S0924271619302278?via%3Dihub rel=noopener>Combining Sentinel-1 and Sentinel-2 Satellite Image Time Series for land cover mapping via a multi-source deep learning architecture (Ienco 2019)</a></p></li><li><p>#PAPER
<a href=https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018SW002061 rel=noopener>The Challenge of Machine Learning in Space Weather: Nowcasting and Forecasting (Camporeale 2019)</a></p><ul><li>New trends in ML: Physics‚Äêinformed NNs, Automatic machine learning, Adversarial training.</li><li>Future challenges in ML for space weather: The information problem, The gray‚Äêbox problem, The surrogate problem (What components in the Space Weather chain can be replaced by an approximated black‚Äêbox surrogate model?), The uncertainty problem (Assessing the uncertainty associated to Weather predictions), The too often too quiet problem (data sets are typically imbalanced. Use synthetic data? Use simulated data), The knowledge discovery problem (How do we distill some knowledge from a machine learning model and improve our understanding of a given system? How do we open the black‚Äêbox and reverse‚Äêengineer a machine learning algorithm?)</li></ul></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1912.12132 rel=noopener>Machine Learning for Precipitation Nowcasting from Radar Images (Agrawal 2019)</a></p><ul><li><a href=https://ai.googleblog.com/2020/01/using-machine-learning-to-nowcast.html rel=noopener>https://ai.googleblog.com/2020/01/using-machine-learning-to-nowcast.html</a></li></ul></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1905.03577 rel=noopener>Feature Extraction and Classification Based on Spatial-Spectral ConvLSTM Neural Network for Hyperspectral Images (Hu 2019)</a></p><ul><li>ConvLSTM 3-D</li></ul></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2006.10027v1 rel=noopener>DL meets SAR (Xiang Zhu 2020)</a></p></li><li><p>#PAPER
<a href=https://www.mdpi.com/2072-4292/12/2/279/htm rel=noopener>Sentinel-2 Sharpening via Parallel Residual Network (Wu 2020)</a></p></li><li><p>#PAPER
<a href=http://arxiv.org/abs/2001.07307 rel=noopener>Spectral Variability in Hyperspectral Data Unmixing: A Comprehensive Review (Borsoi 2020)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2002.04539 rel=noopener>Nonlinear PCA for Spatio-Temporal Analysis of Earth Observation Data (Bueso 2020)</a></p><ul><li>#CODE
<a href=https://github.com/DiegoBueso/ROCK-PCA rel=noopener>https://github.com/DiegoBueso/ROCK-PCA</a></li><li>Dimensionality reduction methods can work with spatio-temporal datasets and decompose the information efficiently. Principal Component Analysis (PCA), also known as Empirical Orthogonal Functions (EOF) in geophysics, has been traditionally used to analyze climatic data</li><li>When nonlinear feature relations are present, PCA/EOF fails</li><li>Propose a nonlinear PCA method to deal with spatio-temporal Earth System data</li><li>The proposed method, called Rotated Complex Kernel PCA (ROCK-PCA for short), works in reproducing kernel Hilbert spaces to account for nonlinear processes, operates in the complex kernel domain to account for both space and time features, and adds an extra rotation for improved flexibility</li><li>Results of the decomposition of three essential climate variables are shown: satellite-based global Gross Primary Productivity (GPP) and Soil Moisture (SM), and reanalysis Sea Surface Temperature (SST) data</li><li>The ROCK-PCA method allows identifying their annual and seasonal oscillations, as well as their non-seasonal trends and spatial variability patterns.</li></ul></li><li><p>#PAPER
<a href=https://www.mdpi.com/2072-4292/12/6/1034/htm rel=noopener>Accounting for Training Data Error in Machine Learning Applied to Earth Observations (Elmes 2020)</a></p></li><li><p>#PAPER
<a href=https://www.mdpi.com/2073-4441/12/3/912/htm rel=noopener>Uncertainty Quantification in Machine Learning Modeling for Multi-Step Time Series Forecasting:Example of Recurrent Neural Networks in Discharge Simulations (Song 2020)</a></p></li><li><p>#PAPER
<a href=https://elib.dlr.de/139306/1/igarss2020_tex.pdf rel=noopener>Model and data uncertainty for satellite time series forecasting with deep recurrent models (Rubwurm 2020)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2010.09031 rel=noopener>Living in the Physics and Machine Learning Interplay for Earth Observation (Camps-Valls 2020)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2011.07017 rel=noopener>NightVision: Generating Nighttime Satellite Imagery from Infra-Red Observations (Harder 2020)</a></p></li><li><p>#PAPER
<a href=http://cgi.di.uoa.gr/~koubarak/publications/2021/BIDS21_paper54.pdf rel=noopener>DEEPCUBE: Explainable AI pipelines for big Copernicus data (Papoutsis 2021)</a> ^deepcube</p></li><li><p>#PAPER
<a href=https://www.nature.com/articles/s41598-021-86650-z rel=noopener>Towards global flood mapping onboard low cost satellites with machine learning (Mateo-Garcia 2021)</a></p></li><li><p>#PAPER
<a href=https://www.nature.com/articles/s41467-021-24638-z rel=noopener>A generalizable and accessible approach to machine learning with global satellite imagery (Rolf 2021)</a></p><ul><li>#CODE
<a href=https://github.com/Global-Policy-Lab/mosaiks-paper rel=noopener>https://github.com/Global-Policy-Lab/mosaiks-paper</a></li><li><a href=https://cega.berkeley.edu/research/mosaiks-a-generalizable-and-accessible-approach-to-machine-learning-with-global-satellite-imagery/ rel=noopener>https://cega.berkeley.edu/research/mosaiks-a-generalizable-and-accessible-approach-to-machine-learning-with-global-satellite-imagery/</a></li><li>#TALK
<a href=https://cega.berkeley.edu/resource/video-afternoon-keynotes-catherine-wolfram-sol-hsiang-infra4dev-2020/ rel=noopener>https://cega.berkeley.edu/resource/video-afternoon-keynotes-catherine-wolfram-sol-hsiang-infra4dev-2020/</a></li><li>ML system to tap the problem-solving potential of satellite imaging, using low-cost, easy-to-use technology that could bring access and analytical power to researchers and governments worldwide</li></ul></li></ul><h3 id=object-detectionrecognition>Object detection/recognition</h3><ul><li>#PAPER
<a href=https://arxiv.org/abs/1909.00133 rel=noopener>Object Detection in Optical Remote Sensing Images: A Survey and A New Benchmark (Li 2019)</a> ^dior</li><li>#PAPER
<a href=https://www.mdpi.com/2072-4292/12/1/143/htm rel=noopener>Object Detection in Remote Sensing Images Based on Improved Bounding Box Regression and Multi-Level Features Fusion (Qian 2020)</a></li><li>#PAPER
<a href=https://www.climatechange.ai/papers/neurips2020/46/paper.pdf rel=noopener>An Enriched Automated PV Registry: Combining Image Recognition and 3D Building Data (Rausch 2020)</a><ul><li>#CODE
<a href=https://github.com/kdmayer/PV4GER rel=noopener>https://github.com/kdmayer/PV4GER</a></li><li>computer vision-based pipeline leveraging aerial imagery with a spatial resolution of 10 cm/pixel and 3D building data to automatically create address-level PV registries for all counties within Germany&rsquo;s most populous state North Rhine-Westphalia</li></ul></li><li>#PAPER
<a href=https://arxiv.org/abs/2103.05569 rel=noopener>FAIR1M: A Benchmark Dataset for Fine-grained Object Recognition in High-Resolution Remote Sensing Imagery (Sun 2021)</a> ^fair1m</li></ul><h3 id=semantic-segmentation>Semantic segmentation</h3><ul><li>#PAPER
<a href=https://arxiv.org/abs/1812.01756 rel=noopener>Multi3Net: Segmenting Flooded Buildings via Fusion of Multiresolution, Multisensor, and Multitemporal Satellite Imagery (Rudner 2018)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/1912.05067v2 rel=noopener>Wide-Area Land Cover Mapping with Sentinel-1 Imagery using DL Semantic Segmentation Models (Scepanovic 2020)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/2003.04027v1 rel=noopener>Dense Dilated Convolutions Merging Network for Land Cover Classification (Liu 2020)</a></li><li>#PAPER
<a href=https://arxiv.org/abs/2107.12283 rel=noopener>Continental-Scale Building Detection from High Resolution Satellite Imagery (Sirko 2021)</a><ul><li><a href=https://ai.googleblog.com/2021/07/mapping-africas-buildings-with.html rel=noopener>https://ai.googleblog.com/2021/07/mapping-africas-buildings-with.html</a></li></ul></li><li>#PAPER
<a href=https://www.nature.com/articles/s41598-021-94422-y rel=noopener>Semantic segmentation of PolSAR image data using advanced deep learning model (Garg 2021)</a></li><li>#PAPER
<a href=https://www.mdpi.com/2072-4292/13/22/4547/htm rel=noopener>A Dual Network for Super-Resolution and Semantic Segmentation of Sentinel-2 Imagery (Abadal 2021)</a><ul><li><a href=https://imatge.upc.edu/web/publications rel=noopener>https://imatge.upc.edu/web/publications</a></li></ul></li><li>#PAPER
<a href=https://www.mdpi.com/2072-4292/13/12/2292/htm rel=noopener>Evaluation of Semantic Segmentation Methods for Land Use with Spectral Imaging Using Sentinel-2 and PNOA Imagery (Pedrayes 2021)</a></li><li>#PAPER
<a href=https://www.sciencedirect.com/science/article/pii/S0924271619300383 rel=noopener>Semantic segmentation of slums in satellite images using transfer learning on fully convolutional neural networks (Wurm 2019)</a></li></ul><h3 id=super-resolution>Super-resolution</h3><p>See <a class="internal-link broken">Super-resolution</a> and <a href=/digitalgarden/AI4ES/Statistical-downscaling rel=noopener class=internal-link data-src=/digitalgarden/AI4ES/Statistical-downscaling>AI4ES/Statistical downscaling</a></p><p>Review papers:</p><ul><li><p>#PAPER
<a href=https://arxiv.org/abs/1808.03344 rel=noopener>Deep Learning for Single Image Super-Resolution:A Brief Review (Yang 2019)</a></p></li><li><p>#PAPER
<a href=http://openaccess.thecvf.com/content_iccv_2017/html/Yang_PanNet_A_Deep_ICCV_2017_paper.html rel=noopener>PanNet: A deep network architecture for pan-sharpening (Yang 2017)</a></p><ul><li>#CODE
<a href=https://github.com/oyam/PanNet-Landsat rel=noopener>https://github.com/oyam/PanNet-Landsat</a></li></ul></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1709.06054 rel=noopener>Target-adaptive CNN-based pansharpening (Scarpa 2018)</a></p></li><li><p>#PAPER
<a href=http://arxiv.org/abs/1803.04271 rel=noopener>Super-resolution of Sentinel-2 images: Learning a globally applicable deep neural network (Lanaras 2018)</a></p></li><li><p>#PAPER
<a href=https://www.mdpi.com/2072-4292/10/11/1700/htm rel=noopener>Deep Distillation Recursive Network for Remote Sensing Imagery Super-Resolution (Jiang 2018)</a></p></li><li><p>#PAPER
<a href=http://arxiv.org/abs/1907.01821 rel=noopener>Super-Resolution of PROBA-V Images Using CNNs (Martens 2019)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1903.00440 rel=noopener>Deep Learning for Multiple-Image Super-Resolution (Kawulok 2019)</a></p><ul><li>EvoNet employs a deep ResNet to enhance the capabilities of evolutionary imaging model (EvoIM) for multiple-image SRR</li><li><a href="https://www.youtube.com/watch?v=_RFQP1rRusQ&list=PLvT7fd9OiI9XORxAfLw_f9CsDkvM9lfKs&index=18&t=0s" rel=noopener>https://www.youtube.com/watch?v=_RFQP1rRusQ&list=PLvT7fd9OiI9XORxAfLw_f9CsDkvM9lfKs&index=18&t=0s</a></li></ul></li><li><p>#PAPER
<a href=https://www.mdpi.com/2072-4292/11/1/52/htm rel=noopener>Super-Resolution Restoration of MISR Images Using the UCL MAGiGAN System (Tao 2019)</a></p></li><li><p>#PAPER
<a href=https://www.mdpi.com/2072-4292/11/13/1557/htm rel=noopener>A Multi-Scale Wavelet 3D-CNN for Hyperspectral Image Super-Resolution (Yang 2019)</a></p></li><li><p>#PAPER
<a href=https://www.sciencedirect.com/science/article/abs/pii/S0925231219314602 rel=noopener>Ultra-dense GANs for satellite imagery super-resolution (2020)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2002.00580 rel=noopener>Super-resolution of multispectral satellite images using convolutional neural networks (Muller 2020)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/1907.06490 rel=noopener>DeepSUM: Deep neural network for Super-resolution of Unregistered Multitemporal images (Bordone Molini 2020)</a></p><ul><li>Winner of the PROBA-V super-resolution challenge issued by the European Space Agency</li><li>#CODE
<a href=https://github.com/diegovalsesia/deepsum rel=noopener>https://github.com/diegovalsesia/deepsum</a></li></ul></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2001.06342 rel=noopener>DeepSUM++: Non-local Deep Neural Network for Super-Resolution of Unregistered Multitemporal Images (Bordone Molini 2020)</a></p></li><li><p>#PAPER
<a href=https://arxiv.org/abs/2004.04788 rel=noopener>D-SRGAN: DEM Super-Resolution with GANs (Demiray 2020)</a></p></li><li><p>#PAPER
<a href=https://www.mdpi.com/2072-4292/12/15/2424/htm rel=noopener>Super-Resolution of Sentinel-2 Imagery Using Generative Adversarial Networks (Salgueiro Romero 2020)</a></p><ul><li><a href=https://upcommons.upc.edu/bitstream/handle/2117/329711/Final_thesis_OEC.pdf rel=noopener>https://upcommons.upc.edu/bitstream/handle/2117/329711/Final_thesis_OEC.pdf</a></li></ul></li></ul><h3 id=data-fusion>Data Fusion</h3><ul><li>#PAPER
<a href=http://arxiv.org/abs/1807.01569 rel=noopener>The SEN1-2 Dataset for DL in SAR-Optical Data Fusion (Schmitt 2018)</a></li><li>#PAPER
<a href=https://www.sciencedirect.com/science/article/pii/S1566253519301393 rel=noopener>Urban big data fusion based on deep learning: An overview (Liu 2020)</a></li></ul><h3 id=data-and-benchmark-datasets>Data and benchmark datasets</h3><p>See <a href="/digitalgarden/AI4ES/AI4ES-data#EO and Satellite data" rel=noopener class=internal-link data-src=/digitalgarden/AI4ES/AI4ES-data>AI4ES/AI4ES data</a></p></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/digitalgarden/AI4ES/AI4ES-data>AI4ES data</a></li><li><a href=/digitalgarden/AI4ES/AI4ES>AI4ES</a></li><li><a href=/digitalgarden/AI4ES/Geospatial-science>Geospatial science, geoinformatics</a></li></ul></div></div><div id=contact_buttons><footer><p>Made by Carlos Alberto Gomez Gonzalez using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, ¬© 2022</p><ul><li><a href=https://carlos-gg.github.io/digitalgarden/>Home</a></li><a href=https://carlos-gg.github.io>Carlos'Homepage</a></ul></footer></div><script src=https://carlos-gg.github.io/digitalgarden/js/popover.e57188d2e4c06b0654e020b3a734bb62.min.js></script>
<script>initPopover("https://carlos-gg.github.io/digitalgarden")</script></div></body></html>